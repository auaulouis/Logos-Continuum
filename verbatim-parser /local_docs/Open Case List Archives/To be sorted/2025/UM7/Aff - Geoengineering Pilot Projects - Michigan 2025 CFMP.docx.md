# Notes

It is not the explore the Arctic for Big Foot, but good work by Sophie,
Matthew, Zarar, Andrew, and Miao. We will turn out an addendum to the
aff and neg, but you should also use the work in the geoengineering
files turned out elsewhere.

# Aff

## 1AC\-\--Geoengineering Pilots

### 1AC\-\--Climate

#### Rising emissions means even the most ambitious climate efforts fail \-\-- only examining geoengineering possibilities now balances potential upsides with catastrophic risks.

**MacAyeal et al** **24**,\-\--Professor Emeritus in the Department of
Geophysical Sciences at University of Chicago. (Douglas, Kenneth
Mankoff, Brent Minchew, John Moore , and Michael Wolovick; "Glacial
Climate Intervention: A Research Vision" p. 21-22, The Institute for
Climate and Sustainable Growth, 5/5/24,
https://climateengineering.uchicago.edu/wp-content/uploads/sites/6/2025/06/Glacial-Climate-Intervention_A-Research-Vision.pdf)

4.0 Conclusion: To Where Should Glaciological Science Evolve?

[[In 1990]{.mark},]{.underline} when the Intergovernmental Panel on
Climate Change first assessment report (FAR) was released, [global [CO2
emissions were 22.8 billion metric tons per year]{.mark} and atmospheric
CO2 concentration was 354.5 ppm. [Today, the figures are 37.6
billion]{.mark} metric tons per year and 421.9 ppm, respectively. These
metrics indicate that [the world has done little to slow]{.mark} the
[emission of CO2]{.mark} in the 34 years since the first official report
of the Intergovernmental Panel on Climate Change. [**Climate-system
inertia** guarantees]{.mark} that the consequences of [these emissions
will be with us for generations]{.mark}, as will those occurring [even
with the most ambitious]{.mark} feasible emission [mitigation
efforts]{.mark}]{.underline}.

That first assessment report by the Intergovernmental Panel on Climate
Change raised the specter of accelerating glacier melt propelling
accelerated sea-level rise, with catastrophic global consequences. In
the ensuing decades, research into the two basic questions that opened
this white paper (see the Executive Summary) has had the unexpected
practical benefit of uncovering a catastrophic threat to global
well-being: dynamic collapse of portions of the Antarctic Ice Sheet,
accelerating sea-level rise and the attendant damage to human and
natural systems. [Deep [uncertainties]{.mark} remain [about the timing
and rate of]{.mark} potential [ice-sheet collapse, produc]{.mark}ing
correspondingly deep [uncertainties in our knowledge of the human
impacts]{.mark} of that collapse. Yet that basic [research has]{.mark}
also [identified potential solutions, whose]{.mark} global [return on
investment might be enormous, but which may]{.mark} have effects that
could [induce further catastrophes. We see an urgent need to examine
these solutions while the window of opportunity]{.mark} for possible
deployment [is]{.mark} still [open]{.mark}]{.underline}.

Of course, basic research addressing the first two questions (see the
Executive Summary) remains urgently needed if the people of the world
are to prepare for their shared future. Yet, new research, focused on
the three new questions that opened this white paper (in the Executive
Summary), is also needed if we are to evaluate options for reducing that
threat. [Some of that [investment will involve basic research]{.mark}
focused on the topics discussed here, observing and [modeling]{.mark}
glacier, ocean, and biological [systems]{.mark}. Some of that will be
basic natural research [creating the foundations for]{.mark} potential
[interventions]{.mark} (e.g., ice-stream movement, ecological effects of
salinity changes). Some will be basic research involving [novel
collaborations]{.mark} with social and engineering scientists. Some of
the investment, though, will be largely practical: adapting [and testing
**equipment, project management** ]{.mark}**and [negotiations]{.mark}**,
consultation [and communication]{.mark}.]{.underline}

[[It will take time to lay the]{.mark} scientific, engineering, and
social [groundwork for ice-sheet preservation]{.mark} interventions. [It
will take more time to]{.mark} begin to [reap their]{.mark} sustained
[benefits]{.mark}, should they exist]{.underline}. During all that time,
ice sheets will continue to melt, discharging mass across grounding
lines and inducing sea-level rise. [[Without research, we cannot know if
there are viable interventions. Without]{.mark} the concurrent practical
[planning, engineering, and consultation, there will be an
unconscionable delay]{.mark} in action, should there be a
solution]{.underline}. Such big science and engineering would entail a
major expansion of glaciological research and its integration with other
scientific, engineering, social, and governance bodies. [We are
proposing such an ambitious program because [we see examining options
for reducing sea-level rise]{.mark} from ice-sheet melting [as a
**global imperative**]{.mark}]{.underline}[.]{.mark}

#### Geoengineering pilot projects are able to solve multiple causes including solar radiation, and melting sea ice. Only governed attempts solve, and empirics disprove the supposed risks of geoengineering.

**Baiman et al. 24**\-\--Professor at Benedictine University, previous
researcher for Oxford environmental studies, and has a PhD from The New
School. (Ron, Sev Clarke, Clive Elsworth, Leslie Field, Michael
MacCracken, John Macdonald, David Mitchell, Franz Dietrich Oeste,
Suzanne Reed, Stephen Salter, Herb Simmens, Ye Tao, and Robert Tulip;
"Addressing the urgent need for direct climate cooling: Rationale and
options", Oxford Academic: Climate Change, 8/12/24,
https://academic.oup.com/oocc/article/4/1/kgae014/7731760) sh

[An increasing number of indicators suggest that no plausible cutback in
emissions will be sufficient to keep warming below levels that could
trigger very disruptive tipping points \[]{.underline}9, 10\]. For
example, the Greenland and Himalayan melt rates are strong indicators of
accelerated warming that would in turn lead to more frequent and severe
climate calamities[. More rapid loss of glacial ice in all three poles
(]{.underline}i.e. including the Himalayas) [is accelerating the rate of
sea level rise. Polar warming is also triggering]{.underline} a change
in the mid-latitude atmospheric circulation that is leading to [an
increasing incidence of extreme weather, fundamental disruption of
natural systems, and a high risk that major critical tipping points will
be overstepped to a state beyond repair.]{.underline}

[However, such an irreversible outcome is not yet inevitable. Limiting
global warming with one or more direct global-scale climate cooling
influences while also moderating the worst impacts using one or
more]{.underline} of the regional cooling influences (commonly referred
to as ["geoengineering") might well reduce the likelihood and severity
of destructive climate calamities over the next few
decades.]{.underline} This would give emissions reduction and removal
time to achieve net-zero and then net negative levels, lowering CO~2~
and other greenhouse gas concentrations in the atmosphere to the
habitable levels of the 20th Century. [Deploying cooling influences to
limit global warming, especially peak global warming, would reduce
stresses on ecosystems, thus helping to reinvigorate the natural
environment over the longer term]{.underline} \[11\].

Despite recognition that potential cooling approaches exist, research
and considerations of deployment of direct climate cooling, whether
localized or global, co-deployed or not, have been held back by several
opposing arguments \[12\] (Others, while not directly opposing DCC
deployment, have suggested numerous checkpoints that do not seem to take
into account the risk-risk tradeoff of excessively delaying deployment
\[13\]. See section "Challenges and opportunities" for further
discussion.). [A primary argument has been that pursuing such approaches
constitutes a "moral hazard" because implementation might well slow GHG
emissions mitigation efforts. However, the claim of "moral hazard" was
for example applied to climate adaptation as a substitute for mitigation
before climate impacts became more severe]{.underline} \[14\], and
[there appears to be little solid evidence for this when applied to
"direct climate cooling"]{.underline} (DCC) \[15\]. Now that costs for
renewable energy have fallen below the costs of fossil-fuel energy this
argument appears to have turned on its head as markets have begun to
favor renewables, but global GHG emissions are still increasing. The
real "moral hazard" is the failure to pursue cooling approaches that can
reduce ecological and human disasters and costs. [Another concern
expressed is that cooling technologies could have severe unanticipated
consequences, although increasingly detailed climate modeling has not
supported this speculation]{.underline} \[16\]. Finally, some climate
cooling opponents argue that though cooling influences may be beneficial
for a while, were they to be stopped for some reason, the climate would
warm up relatively quickly resulting in "termination shock" and worse
impacts than if the cooling influences had not been deployed at all.

[Against the termination shock hypothesis, projected costs and
challenges of maintaining cooling influences, when compared to GHG
removal, are much less than other approaches to limiting
warming.]{.underline} Responsible global actions would require
continuance of direct cooling given the severe consequences of not doing
[so. In the face of these concerns, **equitable and responsible global
governance of cooling approaches will be crucial.**]{.underline} The
Montreal Protocol success in repairing the ozone layer suggests this is
possible over an extended term \[17, 18\]. However, the level of impact
has now been allowed to increase so much that adaptation is becoming
critical. Climate restoration measures to mitigate the increasing
threats to global sustainability and governance must be stronger than
the UNFCCC has endorsed \[19\] (By these statements regarding the
governance problem of achieving rapid and at-scale emissions reductions,
we do not mean to suggest that, particularly global-scale, DCC
implementation and governance is not a challenge. Rather, using SAI as
an example, it poses a different kind of governance challenge, having
less to do with overcoming a costly resource intensive free-rider public
good problem, and more to do with transparency and public trust for a
very inexpensive, almost "free-driver", global leverage problem \[20\].
See further discussion in section "Challenges and opportunities".).

[The needed governance for comprehensively limiting global warming **is
not yet in place.**]{.underline} This is suggested by the failure to
consider the climatic effects of the 2020 International Maritime
Organization (IMO) regulations aimed at reducing sulfur emissions from
the "bunker fuel" used to power cargo ships to protect public health.
Observations of accelerated warming estimate that the regulations have
unintentionally triggered rapid global warming of 0.1--10 W/m^2^ not
unlike the suggested "termination shock" \[2, 21--25\]. Considering that
recent (i.e. January 2020--June 2023) CERES data on the total Earth
Energy Imbalance, or total excess energy from the sun absorbed by the
earth, averages 1.37 W/m^2^ compared an earlier (January 2015 to
December 2019) average of 1.12 W/m^2^, all of these estimates suggest
that a significant global heating impact has resulted from the
regulations, as there are no other indications of such a large positive
forcing \[2, 22, 26\]. This sudden warming should lead to IMO and
governments coming together to respond to the problem by assessing
relevant direct cooling influences as proposed in \[23\]. A further
concern regarding the potential deployment of cooling influences has
been whether there are means to verify their performance before
proceeding beyond very limited deployment. For most of the proposed
cooling approaches described in this paper, pilot [testing
would]{.underline} have only local and transitory effects and [could be
conducted transparently under local to national governance without
requiring special approval and oversight by international governance
bodies. Global climate models and other methods that simulate the
climatic responses to both natural and human-induced forcings make it
possible in many cases to evaluate major potential impacts on the
atmosphere]{.underline}, oceans, and biosphere of the various types of
cooling influences with reasonable confidence. Unfortunately,
[sufficient research funds have yet to be provided]{.underline} for many
of the proposed approaches even though the cost would be very small
compared to the likely benefits their deployment would deliver \[27\].

Concerns represented in opposing arguments need to be addressed in any
program advancing direct climate cooling, as discussed further in
section "Challenges and opportunities" of this paper. However, the
reality of accelerated warming, more intense catastrophic events and
ever-increasing damage and loss has not enabled overall reduction in GHG
emissions, much less support for a comprehensive research and
demonstration effort focused on possible cooling approaches. The moral
hazard no longer lies in researching and deploying climate cooling
approaches, but now in the failure to explore all feasible approaches to
reduce near-term global warming. How best to proceed can only be settled
by a "risk-risk approach," comparing, and contrasting the possible risks
of outcomes in which climate cooling approaches are applied against
those that lie ahead if directly cooling the climate is not pursued
\[2\].

[Many of the climate cooling approaches are low-tech and can be
responsibly deployed at local to regional scales with few,]{.underline}
if any, potential risks and often, many co-benefits. Similarly, [various
of the global-scale approaches can be tested and implemented at low
intensity using an "apply, evaluate, adjust" sequencing because their
effects are readily reversible if unexpected, potentially deleterious
consequences arise.]{.underline} Climate change and especially polar
amplification, or disproportionate warming of polar regions relative to
mid-latitudes, have already caused enormous damage. [Further loss of sea
ice and particularly of glacial ice seem likely to accelerate the risk
of catastrophic impacts worldwide.]{.underline}

This paper describes more than a dozen potential direct climate cooling
approaches that merit initial consideration. More approaches, including
variants of those presented here, continue to emerge. The summaries of
the approaches that follow have been prepared primarily by those who are
currently researching or promoting them. They are listed here in
alphabetical order rather than, at this point, seeking to group them by
metrics or qualitative characteristics (see section "Potential
approaches for direct climate cooling," Tables 1 and 2). They are:
\[Figure omitted\] We do not claim that this is an exhaustive list of
all possible cooling approaches. For example, we have not included a
summary of potential space-based DCC approaches that proponents suggest
"be seriously considered in the long term" \[28\] (Abstract) rather than
the near-term (next few decades) time-period during which we believe DCC
is urgently necessary (Other examples are the sixty-one mostly
geophysical "climate intervention" approaches listed in \[29\], with
some overlap with our paper but with a specific Arctic region focus
rather than urgent global DCC.).

With GHG emission reduction and removal proceeding at insufficient pace
or scale to effectively keep warming below 1.5°C, 2.0°C or higher, [we
believe it is essential that direct climate cooling be added to the
frontal set of policy options]{.underline} being considered by
international negotiators and national governments. While GHG emissions
reduction and removal may have the potential to achieve net-zero
emissions in the second half of the 21st century and, over time, to
reduce GHG concentrations, [direct cooling options provide the only way
to impel global warming back toward 1°C and below before even more key
tipping points are passed]{.underline} (The rationale for a global
warming threshold of 1°C is discussed at the end of section "The risks
of not slowing the pace of global climate change".).

[A credible and effective plan to restore the relatively beneficial
climatic conditions of the 20th century would require that negotiators
develop a three-component strategy:]{.underline} (i) [researching, field
testing, and deploying one or more large-scale cooling
influence(]{.underline}s) perhaps [initially in polar
regions]{.underline} and applying local and regional cooling measures
that also support adaptation, (ii) accelerating emissions reductions
with an early prioritization of short-lived climate drivers (Net human
emissions must be cut to zero, global warming induced increases in
natural emissions must be offset with negative human emissions and over
a trillion tons of legacy CO2eq GHG of all types that has accumulated in
the atmosphere and oceans removed, to restore a stable climate not
counting already triggered irreversible feedbacks that may continue for
centuries \[11\] (footnote 9) \[2\]. However, as the rate of emissions
of short-lived GHG such as methane is directly correlated with warming
these should be prioritized to urgently achieve DCC.), and (iii)
deploying large scale carbon removal to draw down legacy greenhouse gas.

[Humanity has never faced an existential threat so critical to the
survival of civilization and our fellow living species on this
planet]{.underline}. Over at least the next several decades, and
possibly much longer, direct cooling influences will be needed to keep
climate change and its especially severe adverse impacts from spiraling
out of control. [Only the application of such emergency cooling
"tourniquets," applied as soon as reasonably feasible in a
evaluating]{.underline}/learning/adjusting [strategy, has the potential
to slow or reverse ongoing climate disruption]{.underline} and avoid
crossing critical tipping points of no return over coming decades.

#### The first scenario is Sea Ice\-\--

#### The melting of Arctic ice is accelerating warming and bringing us closer to tipping points. 

**Tsakali 25**\-\--Sustainability advisor for the Royal Netherlands
Meteorological Institute (Nicoleta, Marlen Kolbe, Richard Bintanja, and
Nomikos Syllas; "The time of emergence of Arctic warming, wetting and
sea ice melting", Scientific Reports, 04/12/35,
https://www.nature.com/articles/s41598-025-96607-1#Sec1) sh

[In the rapidly warming and wetting Arctic, the time of emergence (ToE)
of a new climate state occurs when trends of climate indicators are
large enough to surpass the strong natural climate fluctuations in the
Arctic]{.underline}. Thus far, uncertainties in climate model
projections, variability and methods have yielded diverging estimates of
Arctic ToE. Here we use a robust method and future projections of
multiple state-of-the-art climate models to show that, generally, sea
ice thickness (2036--2051) and surface air temperature (2033--2050)
emerge first, followed by sea ice cover (2039--2074), and
precipitation/rainfall (after 2077). Autumn generally exhibits the
earliest ToE-values due to rapid sea ice retreat. The earliest ToE for
temperature and sea ice thickness occurs in the Central Arctic, whereas
sea ice cover and rainfall first emerge in the Barents Sea region. [Most
regions of the Arctic are close to a new climate state (for temperature
and sea ice), with wide-ranging and possibly irreversible consequences
for vulnerable Arctic ecosystems and human activities.]{.underline}

In view of recent global increases in the occurrence of climate
change-related natural disasters1,2,3, there is enhanced interest in
determining whether extreme climate conditions are a regular feature of
the current climate, or if they pose evidence of a new climate state
having emerged. [One of the most vulnerable regions to climate change is
the Arctic, which is warming two to four times faster than the global
average over the last decades4]{.underline},5,6, while also getting
considerably wetter7,8,9,10. Understanding when the effects of
anthropogenic climate change in the Arctic have/will become
distinguishable from natural climate fluctuations is crucial for
policymakers to develop effective mitigation and adaptation strategies,
and to identify and quantify (potentially irreversible) impacts on
vulnerable Arctic ecosystems. [A useful metric to establish when the
forced climate change trend emerges from the 'background noise', or
natural climate variability, is the time of emergence
(ToE).]{.underline}

Thus far, the few studies that addressed Arctic ToE have provided
inconclusive and diverging results, mainly because the methods to
evaluate ToE and the climate variables/metrics that have been assessed
differ greatly. Previous estimates of ToE for Arctic Amplification12,
surface air temperature16, shortwave radiation11, sea ice extent
(SIE)16, the freshwater budget15, or solar absorption14 focused on only
one or a few variables and concluded that the forced trend has either
already emerged or will likely emerge within the current decade13,16.
[For rainfall, only the ToEs for the first, last, and duration of Arctic
rain days were evaluated and found to occur later this century16.
Studies that evaluated Arctic ToE were sometimes based on spatial and/or
temporal averaging]{.underline} (which reduces variability and hence
results in an earlier ToE, especially in sea ice, see Supplementary
Information Figs. 1 and 2), [as such, these have mostly attributed
emergence to processes associated with Arctic sea ice
decline1]{.underline}2,16,17. For instance, a recent study suggested
that the Arctic climate has already emerged decades ago in terms of both
the seasonal minimum and maximum of SIE16, but these estimates are based
on Arctic average SIE, which due to spatial averaging of variability
yield an unrepresentative early ToE. [To date, crucial Arctic variables
such as sea ice thickness have not been analysed in terms of their first
emergence. Precipitation/rainfall exhibit strongly increasing trends,
and also considerable variability, but so far ToE has been evaluated
only for specific precipitation indices and metrics based on only two
climate models16]{.underline}. As a result, ToE-estimates are often hard
to intercompare because of differing climate variable indices and
metrics, as well as differing methodology such as, most crucially,
spatial and temporal averaging. Evidently, there is an urgent need for a
complete, reliable and internally consistent estimate of the first
emergence of the Arctic climate -- including the associated
uncertainties -- based on a broad range of state-of-the-art climate
models and five climate variables representative of the Arctic climate,
including their geographical and seasonal variations.

Results. Arctic mean time of emergence

Here we use a detailed methodology (see Methods) to robustly determine
Arctic ToE from state-of-the-art climate model simulations using 15
models in standardised scenario simulations (CMIP6, historical and
SSP5-8.5)18 to show that, [averaged over the Arctic (70°N-90°N), the
seasonal emergence of surface air temperature (TAS, 2033--2050) and sea
ice thickness (SIT, 2036--2051) will precede sea ice cover (SIC, around
2039--2074), followed by rainfall and precipitation]{.underline}
(2077--2096, 2090-after the end of the century, respectively) (Fig. 1).
In contrast to seasonal means, annual means average out seasonal
variability; hence we find that annual mean ToE-estimates precede
seasonal values by 14 ± 5 years (Fig. 1). Strong future trends result in
an earlier ToE, but a large variability -- and/or an increase in
variability -- will delay ToE (Supplementary Information Fig. 6). The
later emergence of rainfall/precipitation in spite of strong future
trends can be attributed to comparatively large past and present
variability as well as to further future increases in variability19.
[Until now, estimates of ToE for sea ice changes were based on Arctic
mean/total sea ice concentration,]{.underline} thus averaging out
spatial variability, which likely resulted in too early ToE-values (up
to 56 years compared to our best estimates, see Supplementary
Information Figs. 1 and 2). [Crucially, we find that evaluating the sea
ice cover emergence per grid point considerably delays ToE to just after
that of temperature]{.underline} (Fig. 1). [These results suggest that,
in contrast to earlier studies, the mean Arctic climate, despite
exhibiting trends that are among the largest in the world4,5,6 through
local amplifying feedbacks, has overall not yet moved significantly
outside the current state]{.underline} (although some regions and
variables have already emerged). However, ToE values exhibit
considerable intermodel differences (Supplementary Information Fig. 3),
indicative of diverging model-specific simulated Arctic trends and
variability -- interannual and/or decadal -- as well as the associated
governing processes/feedbacks20,21. This clearly indicates that analyses
of ToE should be based on as many models as possible to accurately
quantify the associated uncertainties.

TAS, SIC, and SIT are expected to transition to a new state across the
Arctic by the end of this century, with changes occurring in all seasons
(Fig. 1a-c). The earliest transitions are projected for autumn TAS,
starting as soon as 2033 (Fig. 1a). SIT generally transitions around the
same time as TAS, except for autumn, where TAS leads SIT by 13 years
(Figs. 1a-b and 2a-b). Notably, some variables and regions have already
emerged, such as SIT in the Central Arctic (Fig. 3e-h), while others,
like winter TAS over Greenland (Fig. 3a) and spring SIC in most regions
(Fig. 3j), are not expected to emerge until after 2100.

[The presence of sea ice influences the emergence of TAS particularly
during warmer seasons, such as summer and autumn, when temperatures
reach the melting point of ice. Once this point is reached, further
warming is limited until the ice fully melts, resulting in TAS and SIC
transitions occurring almost simultaneously during these
months]{.underline} (Fig. 2a, c). However[, in colder seasons, such as
winter and spring, TAS remains well below the melting point and can thus
increase freely.]{.underline} As a result, TAS transitions occur up to
24 years earlier than SIC in spring (Fig. 2a, c). This pattern is
particularly pronounced in the Central Arctic, where TAS is expected to
transition before 2050 in spring (Fig. 3b), while SIC transitions will
not occur until after 2070 or, in many areas, not even before the end of
this century (Fig. 3j). In contrast, in regions with thin sea ice, such
as the Barents Sea, the relationship between TAS and SIC is more
synchronized, with [both transitioning relatively early (Fig. 3b, j) due
to the already thin ice which suggests that surface temperatures have
already reached the melting point.]{.underline} When analyzing
individual models, we find that those with an earlier ToE in temperature
also tend to exhibit an earlier ToE in SIC (Supplementary Information
Fig. 9). This approximately linear relationship is most pronounced in
summer (R = 0.96), likely due to relatively high temperatures
efficiently melting comparatively thin sea ice.

[Sea ice cover demonstrates greater resilience than sea ice thickness,
particularly in regions dominated by multiyear thick ice]{.underline}
(Fig. 3e-l), adding complexity to the timing of their transitions. In
winter and spring, SIC transitions occur 17 and 31 years later than SIT,
respectively (Fig. 2b, c), [as reductions in ice thickness do not
immediately lead to a decline in sea ice cover in these regions. In
contrast, regions with currently relatively thin ice, e.g. the Barents
Sea, exhibit SIT transitions that often lag behind SIC by up to 20
years]{.underline} (Fig. 3e-l), marking the final state before an
ice-free state. This is especially true in regions where both variables
are concurrently near the no-ice threshold. However, SIT exhibits
greater ratio of variability and trend than SIC, especially in the
Central Arctic (Figs. 4 and 5), introducing additional complexity to its
spatiotemporal transition characteristics. This explains why, unlike
SIT, SIC undergoes significant changes only when the ice is already
thin, delaying its transition by up to 60 years compared to SIT---most
notably in the Central Arctic during winter and spring (Fig. 3e-l). This
lag is further exacerbated by the accelerated thinning of multiyear ice
due to rising atmosphere and ocean temperatures20, which promote early
SIT emergence.

#### That causes rapid ocean acidification due to a loss of ice protection from CO2

**Qi et al 22**\-\--Head of the Polar and Marine Research Institue, and
professor for Jimei University. (Di, Zhangxian Ouyang, Liqi Chen, Yingxu
Wu, Ruibo Lei, Baoshan Chen, Richard A. Feely, Leif G. Anderson, Wenli
Zhong, Hongmei Lin, Alexander Polukhin, Yixing Zhang, Yongli Zhang,
Haibo Bi, Xinyu Lin, Yiming Luo, Yanpei Zhuang, Jianfeng He, Jianfang
Chen, and Wei-Jun Cai; "Climate change drives rapid decadal
acidification in the Arctic Ocean from 1994 to 2020", Science, 9/11/22,
https://www.science.org/doi/10.1126/science.abo0383) sh

[The Arctic Ocean has experienced rapid warming and sea ice loss in
recent decades,]{.underline} becoming the first open-ocean basin to
experience widespread aragonite undersaturation \[saturation state of
aragonite (Ωarag) \< 1[\]. However, its trend toward long-term ocean
acidification and the underlying mechanisms remain undocumented. Here,
we report rapid acidification there, with rates three to four times
higher than in other ocean basins, and attribute it to changing sea ice
coverage on a decadal time scale. Sea ice melt exposes seawater to the
atmosphere and promotes rapid uptake of atmospheric carbon dioxide,
lowering its alkalinity and buffer capacity]{.underline} and thus
leading to sharp declines in pH and Ωarag. We predict a further decrease
in pH, particularly at higher latitudes where sea ice retreat is active,
whereas Arctic warming may counteract decreases in Ωarag in the future.

[In the global ocean, an increase in anthropogenic carbon dioxide (CO2)
has led to decreases in seawater pH based on the total hydrogen ion
concentration]{.underline} scale (pHT) [and the saturation state of the
calcium carbonate mineral aragonite (Ωarag) in a process known as ocean
acidification]{.underline} (1). Although substantial regional and
decadal variability in ocean acidification, driven by climate-induced
atmospheric and oceanic circulation changes, has been observed in low-
and mid-latitude ocean basins (2--4) and in the Southern Ocean (3),
long-term ocean acidification rates generally have followed the trends
predicted from the increase in the concentration of CO2 in the
atmosphere (2, 3). [For the Arctic Ocean,]{.underline} although
[numerical models have predicted high acidification rates]{.underline}
(5--8), observation-based decadal rates of surface water pHT and Ωarag
change are sparse[. Over the past three decades, climate warming has
induced notable changes in the Arctic atmosphere-ice-ocean
system]{.underline} (fig. S1). [These changes include (i) a rapid sea
ice retreat from a nearly fully ice-covered state]{.underline} before
the 1990s to an ice-free state in the southern part of the Canada Basin
and a partially ice-covered state in the northern part of the basin (9),
(ii) [a change]{.underline} from cyclonic circulation in the 1990s [to
an anomalous anticyclonic circulation pattern]{.underline} (10), and
(iii) a spin-up of the Beaufort Gyre (11) over the past 20 years (fig.
S1). There are also increases in freshwater storage (11), Pacific Summer
Water inflow (12), biological production (13), stratification (14),
air-sea CO2 exchanges and carbon sinks (15, 16), and nutricline depth
(17) and decreases in surface nutrients (18) and subsurface
anthropogenic CO2 storage (19). In addition, pHT and calcium carbonate
saturation conditions have been substantially altered by these changes
(20--26). For example, the Canada Basin was the first open-ocean basin
where surface aragonite undersaturation (i.e., Ωarag \< 1) was detected
(20, 22) together with subsurface (21, 27) and intermediate water (28,
29) acidification. Thus, [the Arctic Ocean is considered to be a
bellwether of global climate change and ocean acidification]{.underline}
(30).

Here, by using pHT and Ωarag estimates derived from data collected on 47
Arctic research cruises from 1994 to 2020 (see materials and methods),
we document [the high rates of long-term ocean acidification trends and
basin-scale spatial expansion in terms of both pHT and Ωarag declines in
the western Arctic Ocean.]{.underline} With this dataset, we further
examine [how sea ice loss and increasing atmospheric CO2 have altered
the sea-surface carbonate chemistry over the past two
decades]{.underline}, and we propose an "ice melt--driven enhanced
anthropogenic CO2 acidification" mechanism to explain such rapid rates
of regional ocean acidification.

The pHT and Ωarag values were calculated based on underway measurements
of the partial pressure of CO2 (Pco2) and salinity-derived total
alkalinity (TA), together with sea surface temperature and salinity,
from 1994 to 2020 (table S1). Data were supplemented with pHT and Ωarag,
which were calculated from discrete measurements of TA and dissolved
inorganic carbon (DIC) (see materials and methods). The salinity-derived
TA and corresponding calculated DIC values match well with those of the
discrete samples, yielding uncertainties of less than ±14 μmol kg−1
(fig. S2), which are further quality controlled as described in the
materials and methods. The combined uncertainties of estimated pHT and
Ωarag were 0.0113 and 0.0109, respectively, which were computed using
the uncertainty propagation routine for CO2SYS (31).

Our results show that the area of sea surface with relatively low pHT
(\<8.05) and Ωarag (\<1) expanded substantially (\~0 to 0.88 × 106 km2)
from 1994 to 2020, not only increasing in areal coverage but also
extending into higher latitudes in the western Arctic Ocean (Fig. 1).
During the 1990s, more than 90% of the western Arctic Ocean basin waters
were covered by sea ice, with a high pHT (8.17 ± 0.05), and were
supersaturated with respect to aragonite (Ωarag = 1.46 ± 0.23) (Fig. 1,
A and E). These initial conditions of the relatively higher pHT and
Ωarag in the sea ice--covered period are due to the absence of gas
exchange to replenish CO2 from the atmosphere and low water temperature
(i.e., for the same TA and DIC values, pHT is higher in cold than warm
waters). As sea ice in the western Arctic Ocean basin began to melt
beyond the annual seasonal cycle of advance and retreat in the early
2000s, relatively lower pHT (8.12 ± 0.04) and Ωarag (1.21 ± 0.14) were
observed in surface waters. This acidification happened first in the
southern Canada Basin and slope and then extended northward to 76°N
(Fig. 1, B and F). By the late 2000s, extreme summertime sea ice retreat
mediated by both climate change and natural variability led to a broad
ice-free area (\~1.7 × 106 km2) with a large-scale lower pHT (8.04 ±
0.02) and aragonite undersaturation (Ωarag = 0.97 ± 0.05) that extended
into the central Canada Basin (Fig. 1, C and G). [Whereas the pHT
decrease could be attributed to a combination of rapid warming and CO2
uptake from the atmosphere, the Ωarag decrease was mainly due to CO2
uptake because warming would result in an opposite trend.]{.underline}
From 2011 to 2020, although the overall sea ice concentration and pHT
and Ωarag values were similar to those of the late 2000s, the areas of
low-pHT (8.02 ± 0.01) and Ωarag-undersaturated (0.95 ± 0.05) waters
continued to expand northwestward (Fig. 1, D and H). [We attribute this
acidification to the continuously increasing atmospheric CO2 uptake over
the expanded ice-free regions.]{.underline} [Overall, from the 1990s to
the 2010s, rapid sea ice loss and acidification co-occurred in the
western Arctic Ocean, but thereafter, relatively slow acidification
occurred, accompanied by interannual fluctuation in sea ice
coverage.]{.underline}

\[Figure omitted\] To quantify the long-term trends in pHT and Ωarag, we
first divided the western Arctic Ocean into five subregions based on
spatial patterns of decadal ice retreat and ocean acidification
expansion: the Chukchi Sea shelf (CS), Southern Canada Basin (SCB),
Northeastern Canada Basin (NECB), Northwestern Canada Basin (NWCB), and
permanent ice-covered region (IC, north of 80°N) (i.e., where minimal
sea ice concentration is \>70%) (Fig. 1A). We then averaged pHT and
Ωarag within each grid cell (0.1° latitude by 0.25° longitude) to obtain
daily and monthly means for each cruise dataset. Finally, we averaged
the gridded results within each subregion to obtain monthly and yearly
(from June to October) means (see materials and methods). Different grid
sizes, averaging schemes, deseasonalization treatments, and sensitivity
tests (randomly removing 15 or 30% of measurements or cruises) were
tested (figs. S3 to S11) for the determination of long-term trends.
These various approaches yielded comparable and consistent rates of sea
surface pHT and Ωarag decrease in all subregions except for the NWCB and
CS, where undersampling in the former and the large natural
spatiotemporal variability in the latter prohibit a good performance of
deseasonalization. Our results revealed rapid acidification in the
western Arctic Ocean basins, with a mean annual rate of −0.0069 ± 0.0011
for pHT and −0.0216 ± 0.0040 for Ωarag from 1994 to 2020 (table S2).
These rates are approximately four and three times faster, respectively,
than the long-term decline rates in other ocean basins \[Fig. 1, K and
L, table S2, and (32)\]. Similarly, the increase rate (0.128 ± 0.019
nmol kg−1 year−1) of hydrogen ion \[H+\] is also about four times faster
than that in other ocean basins (table S2). The mean annual
acidification rate was highest in the NECB (−0.0086 ± 0.0013 for pHT and
−0.020 ± 0.0028 for Ωarag) and slowest in the ice-covered
higher-latitude ocean basin (Fig. 1, I and J). These observational rates
in the western Arctic basins are much faster than those projected by
both regional and global models (e.g., −0.0025 to −0.0030 year−1 for pH)
(5--8). By contrast, we found a relatively slower rate of acidification
on the CS than in the basins, with a mean annual rate of change of
−0.0031 ± 0.0024 for pHT and −0.0009 ± 0.0138 for Ωarag (fig. S12). The
long-term acidification rates on the CS are likely mitigated by a strong
and increasing biological CO2 removal driven by nutrient inputs from the
Pacific Ocean, which uses and counteracts CO2 influx from the atmosphere
(13, 16, 33). When we focus on the regions of massive sea ice loss in
the Canada Basin (including SCB, NWCB, and NECB), a notable finding
appears---the decreases in pHT and Ωarag are strongly correlated with
the decrease in sea ice extent over the past 26 years (Fig. 2). Notably,
the earlier 18-year period (1994 to 2012) has the steepest decline
trends in pHT (−0.0098 ± 0.0019 year−1) and Ωarag (−0.0342 ± 0.0077
year−1), which corresponds well with the steepest decrease in sea ice
(Fig. 2). However, the decreasing trends of both pHT and Ωarag were
slower during 2010 to 2020, which is consistent with the alleviated
reduction of sea ice since 2008, though a strong interannual variability
is apparent (Fig. 2A). Nevertheless, even during this period, the rate
of pHT decrease is still comparable to rates of other ocean basins (Fig.
2A and table S2), which are mainly driven by the increasing atmospheric
CO2. Unlike pHT, no statistically significant trend for Ωarag was found
during 2010 to 2020, reflecting the counteracting effect of warming.
Clearly, massive sea ice retreat, modulated by the large-scale climate
change pattern, has played a critical role in the fast acidification in
the Arctic Ocean over the past two to three decades.

\[Figure omitted\]

To explain the link between rapid long-term pHT and Ωarag decline rates
and the massive sea ice loss in the Arctic Ocean, a thorough
understanding of the evolution of carbonate chemistry in response to the
sea ice condition is required. In the 1990s, when most of the Arctic
Ocean surface was covered by sea ice, the transfer of CO2 from the
atmosphere into the surface waters was impeded by sea ice (fig. S1A),
resulting in a large deficit of DIC from the atmospheric equilibrium
value (ΔDIC = −25 μmol kg−1; figs. S13C and S14). As a consequence, the
cold surface seawater beneath the sea ice has a high potential to absorb
atmospheric CO2 once it is exposed to the atmosphere.

Since the 2000s, [the Arctic Ocean has experienced accelerated warming
and substantial sea ice retreat]{.underline} (e.g., ice extent was at
its lowest in the summer of 2012) (Fig. 2A and fig. S1B). We used a
simple one-dimensional (1D) dynamic model to simulate the response of
Pco2, pH, and Ωarag to the decrease of sea ice (Fig. 3; see
supplementary materials for a description of the model). We found that,
under partially or newly ice-free conditions, the low-Pco2 waters that
were originally under the ice were exposed to higher atmospheric Pco2
and rapidly took up CO2 through air-sea gas exchange (Fig. 3D). In other
words, the initial CO2 deficit resulted in a CO2 increase "boost" over
that time period. The shallow surface mixed layer and strong
stratification (34, 35) also prevented the dilution of the absorbed CO2,
leading to rapid responses of the carbonate system parameters (Fig. 3, B
and C, and fig. S1B).

\[Figure omitted\]

The rapid decreases in pHT and Ωarag along with [sea ice retreat are
seen not only over a seasonal time scale but also over a decadal time
scale]{.underline} (Fig. 3). We further quantified and decomposed the
decadal drivers of acidification (table S7) and translated the results
to a graphic illustration (Fig. 4, A to C). We found that the net
increase in DIC due to [CO2 uptake plays the predominant role in
regulating acidification, with minor contributions from warming and
dilution. However, we further diagnosed that, indirectly, approximately
half of the changes]{.underline} in Pco2, pHT, and Ωarag that resulted
from CO2 uptake are attributable to the additional CO2 [deficit
triggered by sea ice melt]{.underline} (i.e., dilution of TA and DIC
leads to lower initial Pco2; see Fig. 4, A to C, fig. S15, and table
S7). Thus, [the indirect effect of dilution on the seawater carbonate
system through the promotion of CO2 uptake is an important factor
driving acidification and weakening buffer capacity in the western
Arctic Ocean]{.underline} (Fig. 4, A to C).

\[Figure omitted\]

[The progression in sea ice loss represents a major change in seawater
carbonate chemistry, from a state of well-buffered seawater with
relatively high alkalinity]{.underline} and low Pco2 underneath the sea
ice (fig. S1A[) to a meltwater-diluted state characterized by lower
alkalinity]{.underline}, higher Pco2[, and lower buffer
capacity]{.underline} under the partially or fully ice-free surface
(Fig. 4, D to F, and fig. S1C). [As a result, atmospheric CO2 invasion
would lead to a greater overall decrease in]{.underline} pHT, Ωarag, and
[buffer capacity in seawater diluted by meltwater than the original
water]{.underline} (Fig. 4, A to C, and fig. S15), illustrated also as a
jump from one pHT-Pco2 evolving locus along the high iso-alkalinity line
in the 1990s to the low iso-alkalinity line in the 2010s (Fig. 4, D to
F). We name this distinctive mechanism "ice melt--driven enhanced
anthropogenic CO2 acidification[." The mechanism explains the amplified
rapid acidification observed in the Arctic Ocean over the past two to
three decades, in contrast to the slower acidification in other global
oceans along only one alkalinity line]{.underline} (Fig. 4, D to F).
This mechanism could conceivably also operate in the sea ice zone within
the Southern Ocean, where [seasonal sea ice melt also plays an important
role in sea surface CO2 dynamics and in air-sea CO2 gas
exchange]{.underline} (36).

We must also point out that further warming could result in contrasting
impacts on pHT and Ωarag trends (fig. S16; see supplementary text for
details). This phenomenon has emerged in late summer in ice-free
southern regions since the 2010s, where both warming and CO2 uptake from
the atmosphere decreased pHT (fig. S16A), whereas warming (when it
exceeds +1°C) increased and CO2 uptake decreased Ωarag (fig. S16B). When
temperature further increases, the net Ωarag trend could even be
positive, similar to what has been observed in some other parts of the
world's oceans (37, 38); this is also illustrated as the cancellation
effect of the red-plus circle by the blue-minus circle in Fig. 1L).

Although Arctic sea ice coverage has fluctuated over the past decade, it
is also shifting from multiyear ice to first-year ice (fig. S17). [This
thinning trend of sea ice implies that summer sea ice will continue to
decline in extent and lower the seawater alkalinity and buffer capacity
until the Arctic Ocean is turned into an ice-free region]{.underline}.
Finally, although the overall freshwater increase, including that from
rivers, has decreased the anthropogenic CO2 inventory in the subsurface
water (19), there is, at present, no significant decadal trend in
river-water content in the surface layer (Fig. 2B). Therefore, both
larger winter-to-summer meltwater-induced seawater alkalinity dilution
and greater subsequent CO2 uptake from the atmosphere are expected to be
the dominant processes in surface waters. [As a consequence, the "ice
melt--driven enhanced anthropogenic CO2 acidification" mechanism may
continue to operate over the next few decades, becoming even more
pronounced until the time that sea ice completely disappears during
summer]{.underline} (at which time, Arctic Ocean surface seawater may
reach its lowest alkalinity) (Fig. 4). [Therefore, this greatly
amplified summertime ocean acidification modulated by large-scale
climate change may lead to long-lasting impacts on the biogeochemistry,
ecosystem, and organisms in the Arctic Ocean basins.]{.underline}

#### Ocean acidification causes mass ecosystem collapses and loss of biodiversity\-\--history proves

**Carrington 19**\-\--PhD in geology from the University of Edinburgh
where he dd post-doctoral research at and now is a journalist. (Damian,
"Ocean acidification can cause mass extinctions, fossils reveal", The
Guardian, 10/21/19,
https://www.theguardian.com/environment/2019/oct/21/ocean-acidification-can-cause-mass-extinctions-fossils-reveal)
sh

[Ocean acidification can cause the mass extinction of marine life,
fossil evidence from 66m years ago has revealed.]{.underline}

[A key impact of today's climate crisis is that seas are again getting
more acidic, as they absorb carbon emissions from the burning of coal,
oil and gas. Scientists said the latest research is a warning that
humanity is risking potential "ecological collapse" in the oceans, which
produce half the oxygen we breathe.]{.underline}

The researchers analysed small seashells in sediment laid down shortly
after a giant meteorite hit the Earth, wiping out the dinosaurs and
three-quarters of marine species. Chemical analysis of the shells showed
a sharp drop in the pH of the ocean in the century to the millennium
after the strike.

This spike demonstrated it was the meteorite impact that made the ocean
more acidic, effectively dissolving the chalky shells of many species.
Large-scale volcanic activity was also considered a possible culprit,
but this occurred over a much longer period.

The oceans acidified because the meteorite impact vaporised rocks
containing sulphates and carbonates, causing sulphuric acid and carbonic
acid to rain down. [The mass die-off of plants on land after the strike
also increased CO2 in the atmosphere.]{.underline}

"[We show ocean acidification can precipitate ecological collapse,"
said]{.underline} Michael Henehan at the GFZ German research centre for
geosciences in Potsdam, who led the study. "[Before we had the idea, but
we did not have the empirical proof]{.underline}."

[The researchers found that the pH dropped by 0.25 pH units in the
100-1,000 y]{.underline}ears after the strike. It is possible that there
was an even bigger drop in pH in the decade or two after the strike and
the scientists are examining other sediments in even finer detail.

Henehan said: "[If 0.25 was enough to precipitate a mass extinction, we
should be worried." Researchers estimate that the pH of the ocean will
drop by 0.4 pH units by the end of this century]{.underline} if carbon
emissions are not stopped, or by 0.15 units if global temperature rise
is limited to 2C.

Henehan said: "We may think of \[acidification\] as something to worry
about for our grandchildren. But if it truly does get to the same
acidification as at the \[meteorite strike\] boundary, then you are
talking about effects that will last for the lifetime of our species. It
was hundreds of thousands of years before carbon cycling returned to
normal."

The research, published in the journal Proceedings of the National
Academy of Sciences, analysed sediments that Henehan encountered by
chance, during a conference field trip in the Netherlands. The
sediments, which straddle the moment of the impact, lie in caves that
were used by people hiding from the Nazis during the second world war.
"It was so lucky," said Henehan.

The rocks contained foraminifera, small-shelled marine organisms. "In
the boundary clay, we managed to capture them just limping on past the
asteroid impact. But you can see their shell walls were much thinner and
poorly calcified after the impact," he said.

[It was the knock-on effects of acidification and other stresses, such
as the "nuclear winter" that followed the impact, that finally drove
these foraminifera to extinction, he said: "You have the complete
breakdown of the whole food chain."]{.underline} He said oceans also
faced additional stresses today, from global heating to widespread
pollution, overfishing and invasive alien species.

Phil Williamson, at the University of East Anglia, who was not involved
in the research, said: "[It is relatively easy to identify mass
extinction events in the fossil record, but much harder to know exactly
what caused them. Evidence for the role of ocean acidification has
generally been weak, until now."]{.underline}

He said caution was needed in making the comparison between the
acidification spike 66m years ago and today: "When the asteroid struck,
atmospheric CO2 was naturally already much higher than today, and the pH
much lower. Furthermore, large asteroid impacts cause prolonged
darkness."

Williamson added: "Nevertheless, this study [provides further warning
that the global changes in ocean chemistry that we are currently driving
have the potential to cause highly undesirable and effectively
irreversible damage to ocean biology."]{.underline}

Henehan said the generally lower ocean pH 66m years ago might have made
shelled organisms more resilient to acidification. "Who knows if our
current \[marine\] system is as well set up to cope with sudden
acidification?"

#### Biodiversity collapse is [existential]{.underline}\-\--it's a [threat]{.underline} multiplier.

Phil **Torres '19** \[Phil Torres, Affiliate Scholar at the Institute
for Ethics and Emerging Technologies, Founder of the X-Risks Institute,
Writer Appearing in Skeptic, Free Inquiry, Bulletin of the Atomic
Scientists, Salon, Truthout, Erkenntnis, Metaphilosophy, "Biodiversity
Loss: An Existential Risk Comparable To Climate Change," Bulletin of the
Atomic Scientists, April 11, 2016,
https://thebulletin.org/2016/04/biodiversity-loss-an-existential-risk-comparable-to-climate-change\]

Catastrophic consequences for civilization. [The [consequences
of]{.mark}]{.underline} this [rapid [**pruning** of]{.mark} the
[evolution]{.mark}ary **tree of life** extend beyond the
obvious]{.underline}. There could be surprising effects of biodiversity
loss that scientists are unable to fully anticipate in advance. For
example, prior research has shown that [localized [ecosystems]{.mark}
can [undergo]{.mark} **abrupt** and **irreversible** shifts when they
reach a **[tipping point]{.mark}**]{.underline}. According to a 2012
paper published in Nature, there are reasons for thinking that [we may
be **approach**ing a **tipping point**]{.underline} of this sort [in the
**global** ecosystem, beyond which the [consequences]{.mark} could be
**[catastrophic]{.mark} for civilization**]{.underline}. As the authors
write, [a **[planetary-scale transition]{.mark}** could [precipitate
"**substantial losses** of]{.mark} ecosystem [services **required**
to]{.mark} **[sustain]{.mark}** the **human
[population]{.mark}**."]{.underline} An ecosystem service is any
ecological process that benefits humanity, such as food production and
crop pollination. If the global ecosystem were to cross a tipping point
and substantial ecosystem services were lost, [the [results]{.mark}
could be "**widespread [social unrest]{.mark}**[, **economic
instability**]{.mark}, and **loss of human life**."]{.underline}
According to Missouri Botanical Garden ecologist Adam Smith, one of the
paper's co-authors, this could occur in a matter of decades---far more
quickly than most of the expected consequences of climate change, yet
equally destructive. [**Biod**iversity loss is [a **"threat
multiplier"**]{.mark} that, by pushing societies to the brink of
collapse, will **[exacerbate]{.mark} existing [conflicts]{.mark}** and
[introduce]{.mark} entirely new [struggles]{.mark} between state and
non-state actors. Indeed, it could even [fuel]{.mark} the rise of
**[terrorism]{.mark}**]{.underline}. (After all, climate change has been
linked to the emergence of ISIS in Syria, and multiple high-ranking US
officials, such as former US Defense Secretary Chuck Hagel and CIA
director John Brennan, have affirmed that climate change and terrorism
are connected.) The reality is that we are entering the sixth mass
extinction in the 3.8-billion-year history of life on Earth, and the
impact of this event could be felt by civilization "in as little as
three human lifetimes," as the aforementioned 2012 Nature paper notes.
Furthermore, the widespread decline of biological populations could
plausibly initiate a dramatic transformation of the global ecosystem on
an even faster timescale: perhaps a single human lifetime. The
unavoidable conclusion is that [[biod]{.mark}iversity [loss]{.mark}
constitutes [an existential threat]{.mark}]{.underline} in its own
right. As such, [it ought to be considered alongside climate change and
nuclear weapons as one of the most significant contemporary risks to
human prosperity and survival.]{.underline}

#### The second scenario is Solar Warming\-\--

#### As surface albedo decreases in the Arctic solar radiation will affect temperatures more and warming will accelerate

**Stamatis et al. 24**\-\--Leader for the Laboratory of Meteorology &
Climatology, Department of Physics, and professor at the University of
Ioannina. (Micael, Nikolaos Hatzianastassiou, Marios-Bruno
Korras-Carraca, Christos Matsoukas, Martin Wild, and Ilias Vardavas;
"How strong are the links between global warming and surface solar
radiation changes?", Springer Nature, 10/09/24,
https://link.springer.com/article/10.1007/s10584-024-03810-6#Sec5) sh

In order to examine and quantify the theoretically established
dependence of surface temperature on SSR, the two parameters were
correlated all over the globe, on a monthly basis, and the 35-year study
period (1984-2018). [In general, SSR is positively correlated with
surface temperature]{.underline} (yellowish and reddish colors), as
expected, over most areas of the globe. Figure 1a shows that Tmean is
more strongly correlated with SSR over land areas such as Europe, much
of Asia, especially its southern parts, and South America, as well as
over western North America and eastern southern Africa, wherervalues
reach 0.70. On the other hand, however, a negative correlation appears
mainly over the polar regions and the Sahara with the maximum negative
value being -0.62. [While, theoretically, a positive correlation (i.e.,
more solar radiation leading to higher temperatures) is generally
expected, local and regional factors, such as changing surface albedo or
changes in temperature advection through changes in atmospheric
circulation, can influence the distribution of heat within a region and
introduce complexities]{.underline}. For instance, [regions with high
and increasing surface reflectivity (albedo), such as areas covered by
snow, ice, or deserts, may experience lower temperatures due to the
decrease of the surface absorbed solar radiation.]{.underline} [The
dependence of surface temperature on SSR is expected to be
stronger]{.underline} for Tmax, [since the temperature daily maximum
values, occurring around noon, are largely determined by the surface
incoming solar radiation]{.underline}, especially in cloudless skies
(Wild 2009). Indeed, this is confirmed in Fig. 1b, which shows larger
correlation coefficients between SSR and Tmax than between SSR and
Tmean. Now, the regions that already had high correlation coefficients
with Tmean show even higher coefficients with Tmax, with values reaching
0.78, again being larger over land than over ocean. [Yet still a slight
negative correlation remains over the polar regions and the
Sahara.]{.underline} The r values between SSR and Tmin generally remain
the lowest in Fig. 1, which has to do with the fact that the daily
minimum temperature, practically occurring during the night, is
determined by the emitted thermal radiation by the Earth's surface and
the associated longwave radiative cooling and not by solar radiation
(Campbell and VonderHaar 1997; Makowski et al. 2008; Wild et al. 2007).
The strongest correlation is found between SSR and DTR, but this is
valid over land, whereas over the oceans the corresponding r values are
either smaller in magnitude when positive or larger in magnitude when
negative, i.e. they are worse than r values for the SSR and Tmax and the
SSR and Tmin pairs. This can be expected, since the sea surface
temperature and the temperature near over the sea change much less over
the course of a day than over land. Hence, the correlation coefficients
between SSR and DTR range between -0.84 and 0.88, reaching larger values
for positive correlation over land and negative correlation over ocean.
This confirms that DTR is a good proxy of the interannual change of SSR
over land, as it is expected, since the subtraction of Tmin from Tmax,
minimizes the thermal effects inthe DTR records (Wild et al. 2007; Wild
2009). The stronger negative correlation between SSR and DTR over oceans
should be attributed either to the larger thermal inertia of oceans
compared to land as well as to the different meteorological conditions
that prevail over them. The larger thermal inertia of oceans means that
they respond more slowly to changes in solar radiation, as the heat
absorbed during the day is released more gradually over time. Besides,
evaporation from the ocean surface absorbs a significant amount of solar
energy, leading to cooling. This latent heat flux can act as a buffer,
dampening the direct impact of solar radiation on surface temperature
over oceans (Hastenrath 1991). There is a noticeable strong
anticorrelation between SSR and surface temperatures (Tmean, Tmax, Tmin
and DTR) over the tropical oceans, which is even more evident for DTR
(Fig. 1d). This can be explained by the intricate interplay of factors
unique to tropical climates. The combination of high convective cloud
activity, which limits the solar radiation impact, and the thermal
dynamics associated with elevated temperatures and enhanced latent heat
release can contribute to an anticorrelation between SSR and
temperatures. Furthermore, the influence of phenomena like El Niño and
the trade winds introduce additional complexities, altering atmospheric
circulation patterns and intensifying the estimated negative correlation
between solar radiation and DTR in tropical regions (Hastenrath 1991).

[In the next step, we investigated if there is a correlation between the
long-term changes of SSR, namely the GDB, and the Earth's surface
temperatures,]{.underline} but on a global average scaleand annual basis
and the results are shown in Fig. 2. Different temporal changing
patterns are observed between the time series of both SSR and
temperatures over land and ocean as it is shown in detail in Table S1.
More specifically, over land (Fig. 2a), in parallel to the brightening
(0.58 \[-5.74, 5.71\] Wm^-2^decade^-1^) occurring from 1984 to 1999
there is a corresponding accelerated rate of land warming, with the
changes of T~mean~, T~max~ and T~min~ being equal to 0.37 \[0.12,
0.63\], 0.37 \[0.11, 0.68\] and 0.35 \[0.11, 0.63\] ^o^Cdecade^-1^,
respectively. On the contrary, when the brightening over land ceased
during 2000-2009 and GDB shifted to a slight dimming (-0.02 \[-3.56,
2.35\] Wm^-2^decade^-1^), the land warming slowed down, actually at
least halved to 0.19 \[-0.45, 0.65\], 0.26 \[-0.38, 0.74\] and 0.11
\[-0.32, 0.65\] ^o^Cdecade^-1^ for T~mean~, T~max~ and T~min~,
respectively, corresponding to the so-called recent hiatus (Douville et
al. 2015; Gou et al. 2022; Xie and Kosaka 2017; Yan et al. 2016; Yang et
al. 2023). This behavior is remarkable as similar findings were observed
in the 1950-1980 dimming (Wang and Dickinson 2013; Wild et al. 2007)
which preceded the brightening starting in the early 1980s. Following
the 2000's slight dimming and recent hiatus, in the absence of dimming
during the 2010s, the SSR increased producing a brightening of 7.47
\[4.93, 11.18\] Wm^-2^decade^-1^ (note that this high value is
associatedwith the negative 2012 anomaly of -1.65 Wm^-2^ and the large
2017 and 2018 anomalies both 3.44 Wm^-2^ and 5.72 Wm^-2^, respectively),
while the land warming continued its accelerating pace, with the
T~mean~ increasing by 0.45 \[-0.29, 1.22\] ^o^Cdecade^-1^[. Thus, our
findings reinforce the hypothesis that a solar dimming is accompanied by
a decelerated warming of global land areas, while the brightening is
associated with an accelerated global warming.]{.underline} It should be
noted that in contrast to the clear increase in temperatures (T~mean~,
T~max~, T~min~) over the entire 35-year study period, the DTR does not
show a noticeable change, but only a small increase equal to 0.06
\[0.05, 0.08\] ^o^Cdecade^-1^, which is qualitatively consistent with
the overall increase of SSR (1.79 \[0.58, 3.21\] Wm^-2^decade^-1^) over
the entire study period of 1984-2018. Furthermore, the interdecadal
changes of DTR, which are clearly smaller than those of the other
surface temperature variables, do not seem to be in line with the phases
of GDB. On the other hand, the interdecadal changes show a bit different
behavior over oceans. The temperature appears to have undergone a much
smaller increase compared to over land, 0.54 \[0.43, 0.66\] versus 1.19
\[0.97, 1.39\] ^o^C, respectively for the entire time period 1984-2018,
while it appears to be increasing continuously (0.15 \[0.12,
0.19\] ^o^Cdecade^-1^ for T~mean~, T~max~, T~min~ and 0.005 \[0.0002,
0.01\] ^o^Cdecade^-1^ for DTR) despite the decreasing SSR during the
study period. Note that although during the 2000s the dimming is
stronger over the oceans than land areas (-0.35 \[-7.19, 3.04\] versus
-0.02 \[-3.56, 2.35\] Wm^-2^decade^-1^), the decelerated rate of the
warming, in comparison to the rate of the 1990s[, is more apparent over
the land than the ocean (maybe also related to the higher heat capacity
and associated inertia of the oceans), indicating a stronger link of GDB
with the global warming rate over land areas that over
oceans.]{.underline}

The same analysis was performed for the Northern and Southern
Hemispheres, both over land and oceans (Fig. 3). [The warming is larger
for the NH than SH,]{.underline} being equal to 0.31 \[0.26, 0.35\] and
0.11 \[0.08, 0.15\] ^o^Cdecade^-1^, respectively. In addition, this
warming is stronger over land than oceans in both hemispheres with the
largest rate of warming occurring over land in the NH (0.40 \[0.32,
0.48\] ^o^Cdecade^-1^). [With respect to the GDB, the NH experienced a
brightening equal to 0.60]{.underline} \[0.05, 1.20\]
Wm^-2^decade^-1^ during the study period, which arose mainly from land,
while the SH underwent a dimming that mainly occurs over the oceans.
Moreover, Fig. 3 reveals that during the 2000s the warming rate slowed
down with respect to the period 1984-99 on the NH, which is not evident
on the SH, although the 2000s dimming seems to be stronger on the SH.
This is rather expected since during the 2000s dimming over land, the
decelerated rate of the warming is more apparent than over the ocean as
Fig. 2 shows, and the NH contains much more land areas than the SH.
Also, the stronger dimming in the 2000s over NH land leads to a clearer
slowdown of the warming rate than over SH land, which experiences a weak
dimming, while oceans show an almost steadily increasing warming despite
the GDB phases.

#### Irreversible warming causes devastating climate scenarios and extinction

**Kemp et al 22**\-\-- Lead researcher at The Centre for the Study of
Existential Risk, and professor at the University of Cambridge,
Cambridge. (Luke, Chi Xu, Joanna Depledge, Kristie
L. Ebi, Goodwin Gibbins, Timothy A. Kohler,
Johan Rockström, Marten Scheffer, Hans
Joachim Schellnhuber, Will Steffen, and Timothy M. Lenton; "Climate
Endgame: Exploring catastrophic climate change scenarios", Proceedings
of the National Academy of Sciences of the United States of America,
8/1/22, https://www.pnas.org/doi/full/10.1073/pnas.2108146119) sh

[Prudent risk management requires consideration of bad-to-worst-case
scenarios.]{.underline} Yet, for climate change, such potential futures
are poorly understood. Could anthropogenic [climate change result in
worldwide societal collapse or even eventual human extinction? At
present, this is a dangerously underexplored topic. Yet there are ample
reasons to suspect that climate change could result in a global
catastrophe]{.underline}. Analyzing the mechanisms for these extreme
consequences could help galvanize action, improve resilience, and inform
policy, including emergency responses. We outline current knowledge
about the likelihood of extreme climate change, discuss why
understanding bad-to-worst cases is vital, articulate reasons for
concern about catastrophic outcomes, define key terms, and put forward a
research agenda. The proposed agenda covers four main questions: 1) What
is the potential for climate change to drive mass extinction events? 2)
What are the mechanisms that could result in human mass mortality and
morbidity? 3) What are human societies\' vulnerabilities to
climate-triggered risk cascades, such as from conflict, political
instability, and systemic financial risk? 4) How can these multiple
strands of evidence---together with other global dangers---be usefully
synthesized into an "integrated catastrophe assessment["? It is time for
the scientific community to grapple with the challenge of better
understanding catastrophic climate change.]{.underline} How bad could
climate change get? As early as 1988, the landmark Toronto Conference
declaration described the ultimate consequences of climate change as
potentially "second only to a global nuclear war." Despite such
proclamations decades ago, climate catastrophe is relatively
under-studied and poorly understood.

The potential for catastrophic impacts depends on the magnitude and rate
of climate change, the damage inflicted on Earth and human systems, and
the vulnerability and response of those affected systems. [The extremes
of these areas, such as high temperature rise and cascading impacts, are
underexamined]{.underline}. As noted by the Intergovernmental Panel on
Climate Change (IPCC), there have been few quantitative estimates of
global aggregate impacts from warming of 3 °C or above (1). Text mining
of IPCC reports similarly found that coverage of temperature rises of
3 °C or higher is underrepresented relative to their likelihood (2).
Text-mining analysis also suggests that over time the coverage of IPCC
reports has shifted towards temperature rise of 2 °C and below. Research
has focused on the impacts of 1.5 °C and 2 °C, and studies of how
climate impacts could cascade or trigger larger crises are sparse.

A thorough risk assessment would need to consider how risks spread,
interact, amplify, and are aggravated by human responses (3), but even
[simpler "compound hazard" analyses of interacting climate hazards and
drivers are underused. Yet this is how risk unfolds in the real
world.]{.underline} For example, a cyclone destroys electrical
infrastructure, leaving a population vulnerable to an ensuing deadly
heat wave (4). Recently, [we have seen compound hazards emerge between
climate change and the COVID-19 pandemic]{.underline} (5). As the IPCC
notes, [climate risks are becoming more complex and difficult to manage,
and are cascading across regions and sectors (6).]{.underline}

Why the focus on lower-end warming and simple risk analyses? One reason
is the benchmark of the international targets: the Paris Agreement goal
of limiting warming to well below 2 °C, with an aspiration of 1.5 °C.
Another reason is the culture of climate science to "err on the side of
least drama" (7), to not to be alarmists, which can be compounded by the
consensus processes of the IPCC (8). Complex risk assessments, while
more realistic, are also more difficult to do.

This caution is understandable, yet it is mismatched to the risks and
potential damages posed by climate change. We know that temperature rise
has "fat tails": low-probability, high-impact extreme outcomes (9).
C[limate damages are likely to be nonlinear and result in an even larger
tail (10). Too much is at stake to refrain from examining high-impact
low-likelihood scenarios.]{.underline} The COVID-19 pandemic has
underlined the need to consider and prepare for infrequent, high-impact
global risks, and the systemic dangers they can spark. Prudent risk
management demands that we thoroughly assess worst-case scenarios. Our
proposed "Climate Endgame" research agenda aims to direct exploration of
the worst risks associated with anthropogenic climate change. To
introduce it, we summarize existing evidence on the likelihood of
extreme climate change, outline why exploring bad-to-worst cases is
vital, suggest reasons for catastrophic concern, define key terms, and
then explain the four key aspects of the research agenda. Worst-Case
Climate Change

Despite 30 y of efforts and some progress under the United Nations
Framework Convention on Climate Change (UNFCCC) anthropogenic greenhouse
gas (GHG) emissions continue to increase. [Even without considering
worst-case climate responses, the current trajectory puts the world on
track for a temperature rise between 2.1 °C and 3.9 °C by
2100]{.underline} (11). If all 2030 nationally determined contributions
are fully implemented, warming of 2.4 °C (1.9 °C to 3.0 °C) is expected
by 2100. Meeting all long-term pledges and targets could reduce this to
2.1 °C (1.7 °C to 2.6 °C) (12). [Even these optimistic assumptions lead
to dangerous Earth system trajectories. Temperatures of more than 2 °C
above preindustrial values have not been sustained on Earth's surface
since before the Pleistocene Epoch]{.underline} (or more than 2.6
million years ago) (13).

Even if anthropogenic GHG emissions start to decline soon, this does not
rule out high future GHG concentrations or extreme climate change,
particularly beyond 2100. [There are feedbacks in the carbon cycle and
potential tipping points that could generate high GHG
concentrations]{.underline} (14) that are often missing from models.
[Examples include Arctic permafrost thawing that releases methane and
CO2 (15), carbon loss due to intense droughts and fires in the Amazon
(]{.underline}16), and the apparent slowing of dampening feedbacks such
as natural carbon sink capacity (17, 18). These are likely to not be
proportional to warming, as is sometimes assumed. [Instead, abrupt
and/or irreversible changes may be triggered at a temperature threshold.
Such changes are evident in Earth's geological record, and their impacts
cascaded across the coupled climate--ecological--social system (19).
Particularly worrying is a "tipping cascade" in which multiple tipping
elements interact in such a way that tipping one threshold increases the
likelihood of tipping another]{.underline} (20). Temperature rise is
crucially dependent on the overall dynamics of the Earth system, not
just the anthropogenic emissions trajectory.

The potential for tipping points and higher concentrations despite lower
anthropogenic emissions is evident in existing models. Variability among
the latest Coupled Model Intercomparison Project Phase 6 (CMIP6) climate
models results in overlap in different scenarios. For example, the top
(75th) quartile outcome of the "middle-of-the-road" scenario (Shared
Socioeconomic Pathway 3-7.0, or SSP3-7.0) is substantially hotter than
the bottom (25th) quartile of the highest emissions (SSP5-8.5) scenario.
Regional temperature differences between models can exceed 5 °C to 6 °C,
particularly in polar areas where various tipping points can occur (SI
Appendix). [There are even more uncertain feedbacks, which, in a very
worst case, might amplify to an irreversible transition into a "Hothouse
Earth" state]{.underline} (21) (although there may be negative feedbacks
that help buffer the Earth system). [In particular, poorly understood
cloud feedbacks might trigger sudden and irreversible global
warming]{.underline} (22). Such effects remain underexplored and largely
speculative "unknown unknowns" that are still being discovered. For
instance, recent simulations suggest that stratocumulus cloud decks
might abruptly be lost at CO2 concentrations that could be approached by
the end of the century, causing an additional ∼8 °C global warming (23).
Large uncertainties about dangerous surprises are reasons to prioritize
rather than neglect them.

#### Independently, as climate crises occur that leads to global and civil wars

**Bhatt 22**\-\--Manager for the Center for Diplomatic Engagement in
Washington D.C. with a BA in International Relations and Environmental
Studies from The George Washington University. (Vishva, "Is climate
change causing more wars?", The YEARS Project, 2/1/22,
https://theyearsproject.com/latest/is-climate-change-causing-more-wars)
sh

[As climate change has caused global temperatures to rise, there also
seems to be an ever-growing number of conflicts around the
worl]{.underline}d. So, what is the evidence linking climate change to
war?

Alarmingly[, several studies suggest that climate change makes conflicts
such as civil war or genocide more likely]{.underline}. It is important
to note that climate change alone has not been proven to increase the
likelihood of discord; however, [climate change compounded with
challenging economic, political, or social conditions can heighten the
risk of conflict. Climate change is a threat multiplier,]{.underline}
which means it amplifies problems already facing the world. [Stressors
such as poverty, political instability, and crime are magnified by
increased droughts, floods, or heat waves.]{.underline}

[As anthropogenic climate change continues to alter the environment,
scientists have been tracking an increase in the frequency and intensity
of extreme weather events]{.underline}. Extreme weather events adversely
affect communities around the world as they experience unusually warm
winters or sweltering summer temperatures much higher than usual.
Fluctuating temperatures may not derail urban areas that have adequate
coping capacities, but they are detrimental to communities that depend
on agriculture or other natural resources for their livelihoods.

[Increases in various climate-related disturbances such as floods,
droughts, or fires further stress already-vulnerable communities and
threaten their livelihoods. Evidence links rise in temperature to a rise
in civil war. Researchers at Princeton University and UC Berkeley found
that a rise in average annual temperature by even 1° Celsius (1.8°
Fahrenheit) leads to a 4.5% increase in civil war that
year]{.underline}. There has been a global increase in the incidence of
civil war following World War II, with civil wars even having a greater
number of casualties than international wars. [Civil wars are dangerous,
and climate change is making them more common.]{.underline}

S[yria has been engulfed in a civil war since 2011. Experts agree that a
detrimental drought played a major role in triggering the war. Climate
modeling at UC Santa Barbara shows that greenhouse gas emissions made
the drought two times more likely than it would have been with natural
fluctuation.]{.underline} Drought and famine still plague the country.
While acknowledging that factors such as economic hardship, corrupt
leadership, and inequality factor into Syria's uprising, the severe
drought played a significant role. It was worsened by climate change,
and as farmers were forced to flee to cities to find food for their
starving families, tensions continued to amass. A climate change fueled
drought coupled with Syria's weak economy, poor governance, and social
inequality made the perfect breeding ground for civil war.

A decade-long drought in the late-1900s caused Lake Chad, then the
sixth-largest freshwater lake in the world, to shrink. The drought was
attributed to rising greenhouse gas emissions mixed with natural
environmental factors. On the edge of the Sahara, Lake Chad is a life
source for those populating Niger, Nigeria, Cameroon, and Chad. As the
lake began to shrink in the 1970s, the surrounding population was forced
to move towards it and began competing for access. As the people became
concentrated in a significantly smaller area, there was a measurable
rise in confrontations between local farmers and herders. As climate
change altered the landscape, the competition for access to Lake Chad
and its precious resources rose, and so did the conflict.

[Experts point to Sudan's civil war as the first example of a modern
climate change-induced conflict. The United Nations linked
desertification and dwindling rainfall caused by rising temperatures to
food and water insecurity;]{.underline} the [insecurity then resulted in
a rebellion that the Sudanese government]{.underline} reacted to with a
campaign of violence. Famine plagued Sudan, as rains dwindled and
fertile land became arid. The lack of food paired with deep-rooted
social and political tensions exacerbated the risk of conflict until the
country broke into civil war. [Climate change heightened the competition
for invaluable resources, further intensifying the preexistent tensions
between ethnic groups]{.underline}. Average temperatures are expected to
rise if the amount of carbon in the atmosphere is not significantly
reduced within the next few years. The high temperatures will lead to
more drought, which has the potential to be an impetus for more
conflict.

[Climate change is threatening not only people's livelihoods but also
their lives. Its adverse effects on global temperatures and rainfall
result in increased competition for necessary resources, such as food
and water.]{.underline} As competition for life-sustaining resources
continues to rise, so does the potential for violent, deadly conflict.
In Syria, climate change's adverse environmental effects on top of
existing instability sparked civil war, resulting in hundreds of
thousands of deaths. The shrinking of Lake Chad forced communities to
compete for precious resources, and conflict arose between previously
friendly neighbors. [The continuous rise of global temperatures has
induced food and water insecurity in Sudan, and violence has broken out
as people fight for control of life-sustaining resources. While climate
change itself does not cause war, with a mix of economic, social, or
political tensions the ground is ripe for conflict to grow]{.underline}.

### 1AC\-\--Plan

#### The United States federal government should significantly increase its development of geoengineering pilot projects in the Arctic.

### 1AC\-\--Governance Advantage

#### Geoengineering is rapidly developing now, but presents governance challenges absent regulation and research \-\-- specifically domestic governance solves best by elevating governance and triggering stakeholder engagement that spill over to global governance. 

Kerryn **Brent et al** 11-22-20**24**, Dr Kerryn Brent is a research
scientist based at Waite Campus, South Australia. Kerryn\'s research
focuses on the governance of emerging climate intervention technologies.
Manon Simon is PhD candidate from Brittany, France. She graduated with a
Bachelor's in Public and International Law from the University of
Poitiers, before pursuing a LL.M. in Environmental and Natural Resources
Law at the University of Oregon, USA. She started her PhD in 2017 at the
University of Wuhan, China, working on international regulations of
weather modification activities. Jan McDonald is the New Star Professor
of Environmental and Climate Law at University of Tasmania. *Climate
Policy*, p.948-949 "From informal to formal governance of solar
radiation management"
https://www.tandfonline.com/doi/pdf/10.1080/14693062.2024.2430688 //MDC

1\. Introduction

[Solar radiation management ([SRM]{.mark}) technologies that reflect
sunlight away from Earth [are being proposed to address climate change,
by limiting temperature rise]{.mark} while emissions reductions
occur]{.underline} (Crutzen, 2006; NASEM, 2021). The most prominent
technology, stratospheric aerosol injection (SAI), would involve placing
particles in the stratosphere to reflect a percentage of incoming
sunlight (NASEM, 2021). Some technologies are also being developed to
bolster the resilience of vulnerable ecosystems. Most notably, marine
cloud brightening (MCB) is being investigated for regional-scale
applications (Latham et al., 2014), including to prevent coral bleaching
on the Great Barrier Reef (RRAP, n.d.; McDonald et al., 2019) and
protect Arctic sea ice (Kurvits et al., 2023; Argüello & Johansson,
2022). Other SRM proposals involve increasing surface albedo in key
locations (e.g. glaciers, polar regions) (Lockley et al., 2020; Duffey
et al., 2023). [[However]{.mark}, the feasibility of SRM proposals
remains poorly understood (Pörtner et al., 2022) and [**further research
is essential** to resolve uncertainties]{.mark} and assess
appropriateness (NASEM, 2021).]{.underline}

[[SRM presents **significant governance challenges**]{.mark}, and it is
well-recognized that robust governance is needed to address risks and
enable responsible R&D]{.underline} (e.g. Nicholson et al., 2018; Brent
et al., 2015). [The [potential risks]{.mark} associated with
global-scale SRM technologies have generated strong opposition. In
addition to environmental impacts, opponents [raise questions
about]{.mark} technological [lock-in, moral hazard, and social
acceptability]{.mark}]{.underline} (e.g. McKinnon, 2019; Stephens &
Surprise, 2020). These challenges manifest even at the research and
development (R&D) stage, presenting significant hurdles for progressing
research (Parker, 2014; McLaren & Corry, 2021). Efforts to conduct even
modest outdoor trials have been opposed by environmental and indigenous
groups (Risse, 2023). Some researchers are calling for states to
negotiate a 'non-use agreement' for global-scale SRM to prohibit outdoor
experimentation, deployment, and the public funding of research for
global scale SRM (Biermann et al., 2022). Regional SRM proposals are
generally considered more feasible and less controversial than global
SRM (Bernstein et al., 2013; Low et al., 2022). Indeed, proponents of an
international non-use agreement recognize that localized SRM could fall
outside any such prohibitive framework, provided that adequate
safeguards are in place (Biermann et al., 2022, p. 2; Gupta et al.,
2024, p. 16).

[[There is a pressing need to develop rules that]{.mark} can
[provide]{.mark} robust and [effective governance for
SRM]{.mark}]{.underline}. In Australia, MCB field tests have been
conducted on the Great Barrier Reef since 2020 to test the delivery
system (Brent et al., 2020). [[In the US]{.mark}, the first MCB outdoor
[experiment]{.mark} commenced in May 2024 in California, led by
scientists from the University of Washington. However, it [was
suspended]{.mark} soon after [due to concerns]{.mark} from the local
officials [over **lack of engagement and transparency**]{.mark} about
the experiment]{.underline} (Flavelle, 2024). Proposed SAI outdoor
experiments have also been cancelled due to public opposition, the most
recent example being the US-led SCoPEx programme (further discussed
below, see Jinnah et al., 2024). [[SRM R&D is already taking place, so
**it is not a question of should we develop governance**]{.mark}
**norms, [but how]{.mark}**]{.underline}.

[[Despite]{.mark} more than [15 years of governance research]{.mark}
(Reynolds, 2019b), [there are no]{.mark} binding [international]{.mark}
legal [instruments]{.mark} specifically [governing SRM]{.mark} at any
scale. [Nor have national]{.mark} [governments enacted SRM- specific
legislation]{.mark} or policies, including rules directed at
research]{.underline}. 1 Scholars provide multiple reasons for this
inertia, including uncertainty over which international forums are most
appropriate to govern SRM, and how the ambiguity/indeterminacy of these
technologies could stymie political action (Rabitz et al., 2022). [[The
international community has been extremely reluctant]{.mark} to develop
norms that might be seen to legitimize R&D of these controversial
technologies (Biermann & Gupta, 2024). Yet the development of
anticipatory and precautionary [governance]{.mark} for SRM [should
not]{.mark} [be postponed until]{.mark} the [technologies are ready for
deployment]{.mark}. Instead, [governance must be developed alongside
research]{.mark} (Stilgoe et al., 2013; Geden & Dröge, 2019) and respond
as we learn more from R&D]{.underline} (Buck & Nicholson, 2023, p.
1653). Given the evident reluctance to develop international law, and
because research and development of SRM will be site specific, SRM
governance must look beyond international law and institutions (Hester,
2013). [[**Domestic governance holds promise** as a starting
point]{.mark} for formal SRM governance. As well as governing the risks
of local-level R&D, [domestic measures]{.mark} may [afford]{.mark}
[opportunities to trial different approaches and provide]{.mark} levels
of [confidence in]{.mark} the [subsequent]{.mark} development of
[international rules]{.mark}.]{.underline}

Academics, scientific bodies, and non-governmental organizations (NGOs)
have attempted to build governance norms for climate intervention
generally, and SRM specifically, 'from the bottom up'. Numerous sets of
principles and frameworks for good governance have been published, using
a variety of terms to label these sets of principles (Brooks et al.,
2023), including 'code of conduct', 'guidelines', 'policy
considerations'. For simplicity, we refer to them collectively as
'governance proposals'. Since 2009, ten prominent proposals for SRM
research governance have been published (Table 1), and there is a
significant push to develop additional informal frameworks. In its One
Atmosphere report, the United Nations Environment Programme recommended
developing further 'codes of conduct' for SRM (UNEP, 2023, p. 25).
Similar recommendations have been made by the Council on Foreign
Relations (Geden & Dröge, 2019) and Brookings Institution (Versen et
al., 2021). The American Geophysical Union is currently developing its
own set of ethical principles for SRM research, experimentation and
deployment (AGU, 2022). [However, additional [voluntary frameworks will
not ensure adequate governance]{.mark} of SRM R&D. [Voluntary
frameworks]{.mark} tend to espouse general principles that [need to be
interpreted]{.mark} and operationalized [in a specific]{.mark}
jurisdictional [context. They]{.mark} also [lack oversight and]{.mark}
[accountability]{.mark} mechanisms which are [essential to promote
compliance and]{.mark} to [ensure that governance remains
relevant]{.mark} and responsive to changing conditions]{.underline}.

The priority is to see general principles expounded in instruments that
impose binding obligations, such as domestic legislation and
institutional research ethics processes, especially in countries where
SRM R&D is already afoot. We investigate whether the principles set out
in the various governance proposals published to date are a useful and
expedient starting point for progressing SRM governance. We do not
suggest that existing governance proposals are complete, or that
policymakers should accept their principles on face- value. Indeed, most
were developed by participants in the Global North. They will therefore
require adjustment and augmentation to suit the specific governance
needs of SRM R&D in individual jurisdictions. [Indeed, the process of
[translating]{.mark} these [principles into formal rules may trigger
**multistakeholder processes at the domestic level**, including]{.mark}
broader [community engagement, deliberation and
consensus-building]{.mark} regarding SRM governance. [This would]{.mark}
also [elevate]{.mark} questions of [SRM governance beyond]{.mark} a
scant [few international institutions]{.mark}, expert circles and the
pages of academic journals]{.underline}. However, given the increasing
number of informal governance proposals, each with different target
audiences, scope and terminology, it may be challenging for domestic law
and policymakers, and research institutions, to put these principles
into practice for SRM R&D.

To assist these bodies in developing domestic governance of SRM R&D,
this article considers ten prominent informal governance proposals for
SRM and distils a common set of principles. We highlight the level of
commonality regarding key principles as well as gaps and ambiguities
that domestic policymakers will need to address, in consultation with
communities and stakeholders. The next section introduces the relevant
governance proposals and examines the context for their development. It
highlights that these proposals are the product of extensive
multi-disciplinary expert deliberation, and provide a foundation for
developing robust domestic instruments for the good governance of SRM
R&D. In Section 3, we distil common principles from the proposals.
Section 4 considers the implications of the high level of commonality
between these various proposals. [We conclude in Section 5 with a call
for governments of countries involved in SRM research to recognize the
necessary elements of a domestic SRM regime and progress the
implementation of those requirements, either through research ethics
frameworks or law reform]{.underline}.

#### Effective governance and engagement is key to holistically regulating Arctic geoengineering.

Federica **Catonini et al** 4-20-20**25**, Federica Cantonini is a PhD
candidate at the Centre for Climate Change Law and Governance (CLIMA) at
the University of Copenhagen. Her PhD research focuses on the regulation
of ocean carbon sinks (conservation and enhancement) in international
climate change, ocean and biodiversity law and governance. Johanna
Sophie Buerkert is a postdoc at the Environmental Policy Group. She
obtained her PhD in international law from the University of Copenhagen
in 2024. Kristian Søby Kristensen is the head of the Department of
Strategy and War Studies at the Royal Danish Defence College. "Arctic
Geoengineering Between Governance and Science: A Structured Literature
Review of the Arctic Geoengineering Discourse" p. 7 //MDC

5 \| Conclusion: A Call for Interdisciplinarity

As the effects of climate change are materializing rapidly in the
Arctic, the geoengineering discourse is gaining traction. However, the
present state of the literature raises a number of questions. [While
necessary to have strong scientific and technical foundational studies
on Arctic geoengineering, we believe that the [divide between the
natural sciences and technology]{.mark} studies on the one hand, and
societal considerations on the other hand, [has the potential to lead to
**technocratic decision-making** that fails to consider the]{.mark}
possible [effects of these technologies on the Arctic
environment]{.mark}, on the Arctic [peoples, and]{.mark} the potential
[security]{.mark} concerns both inside and beyond the
Arctic]{.underline}. Interdisciplinary and inclusive decision- making
processes that take all stake- and right- holders into account are a
precondition for effective and just governance of geoengineering.
[Moreover, we observe an urgent need to bridge the divide between
governance, scientific research, and Indigenous knowledge. [In order to
avoid]{.mark} [governance traps and a governance vacuum, it is essential
that governance develops]{.mark} closely [alongside
technology]{.mark}---this also has merit from a security aspect, [as it
may contribute to]{.mark} [preventing security concerns that unilateral
development]{.mark} of technologies [may bring]{.mark}]{.underline}.
Research that focuses on the technological aspects of geoengineering
should therefore include governance and policy considerations, instead
of leaving the "governance problem" to later or to other disciplines.

Overall, [[this review highlights the]{.mark} benefits and [need for
cooperation and inter- and transdisciplinary approaches to Arctic
geoengineering]{.mark} research, including both western science and
other types of knowledge. [These would help]{.mark} the development of
[governance proposals that consider the wider consequences of Arctic
geoengineering]{.mark} for the environment, people, and security [in a
holistic manner]{.mark}]{.underline}.

#### Lack of geoengineering governance triggers unilateral use by both [state]{.underline} and [non-state]{.underline} actors.

Craig **Martin and** Scott **Moore** 1-7-20**25**, Craig Martin is
Professor of Law and Co-Director of the International and Comparative
Law Center, Washburn University School of Law; Scott Moore is Practice
Professor of Political Science and Director of China Programs and
Strategic Initiatives, University of Pennsylvania. *Harvard
International Law Journal, Vol. 66*, p. 123-124 "Geoengineering Wars and
Atmospheric Governance" //MDC

III\. The Risk of Armed Conflict

In Part I we examined the strong incentives for engaging in SAI, as well
as the considerable risk of both direct and indirect harms that SAI
poses to the environment and to the climate system. [We also explained
the [increasing possibility]{.mark} [that]{.mark} some **[states,
or]{.mark} even [non-state actors]{.mark}**[, may]{.mark} nonetheless
attempt to [engage in unilateral SAI efforts]{.mark}. In Part II we
explored the [existing]{.mark} international law and other forms of
international [governance structures that may]{.mark} operate to limit
or [deter]{.mark} such [action]{.mark}, and noted that these constraints
[are]{.mark} rather [weak and uncertain]{.mark}. This combination of
[strong incentives]{.mark} [for action]{.mark}, the risk of harm from
such action, [and the absence of]{.mark} effective legal [constraints,
should be cause for]{.mark} considerable
[apprehension]{.mark}]{.underline}. And it is indeed the basis for many
concerns that have been raised elsewhere regarding possible unilateral
SAI efforts. On the other hand, as we discussed briefly above, some
argue that due to the future warming already baked into the climate
system, the risk of harm posed by not doing everything we can to
moderate rising temperatures, including the use of SAI in the short
term, is actually greater than the risk of harm that SAI poses.182 Those
who take this view argue that employing some form of SAI as a temporary
stop-gap measure to moderate global temperature until we can bring
emissions down is the lesser evil.183

There is, however, [a second-order or knock-on risk posed by [unilateral
SAI efforts]{.mark} that is under-appreciated and under-theorized in
this debate: The risk that a unilateral effort to engage in SAI will
[provoke an armed response leading to armed
conflict]{.mark}]{.underline}. This risk is often gestured to in passing
as a "geopolitical risk," including by such institutions as the IPCC,184
UNEP,185 and the U.S. national intelligence community,186 but this risk
has not been unpacked and explained, and thus it is not sufficiently
accounted for in the debate on SAI. This risk is certainly not
sufficiently considered by policymakers trying to balance the risks of
action and inaction on the geoengineering front. [In our view, [this
risk]{.mark}, when fully appreciated, likely tips the balance of
precaution and prudence firmly in favor of constraint on SAI, and [adds
to the urgency of establishing]{.mark} a strong [global governance
structure for atmospheric SRM]{.mark} in general [and SAI]{.mark} in
particular]{.underline}.

#### Unilateral geoengineering by states triggers conflicts that collapse international law.

Craig **Martin and** Scott **Moore** 1-7-20**25**, Craig Martin is
Professor of Law and Co-Director of the International and Comparative
Law Center, Washburn University School of Law; Scott Moore is Practice
Professor of Political Science and Director of China Programs and
Strategic Initiatives, University of Pennsylvania. *Harvard
International Law Journal, Vol. 66*, p. 137-138 "Geoengineering Wars and
Atmospheric Governance" //MDC

In sum, [[governments]{.mark} already quite clearly and explicitly
[view]{.mark} the consequences of [climate change as a threat to]{.mark}
both [national security]{.mark} and to international peace and security.
Thus, some [governments would similarly view]{.mark} the risk of harm
posed by [unilateral SAI]{.mark} efforts [as a **threat to their
security**. Without]{.mark} sufficiently institutionalized and
enforceable [international law]{.mark} and policy constraints to prevent
such unilateral SAI activity, there is a considerable risk that [states
would consider]{.mark} resorting to [armed force]{.mark} to do
so]{.underline}. Then, the question becomes whether there are sufficient
legal constraints to prevent such a unilateral use of force, and thus
limit the risk of armed conflict in response to unilateral SAI. This
requires assessing whether the jus ad bellum regime would provide such a
constraint.

The foregoing analysis suggests that [the [current]{.mark} jus ad bellum
[regime would impose only a weak check on such]{.mark} a use of
[force]{.mark}. Indeed, [depending on]{.mark} which [states]{.mark} were
proposing to undertake the SAI activity and the configuration of
political dynamics at the time, the [jus ad bellum]{.mark} regime [could
enable]{.mark} the [use of force]{.mark} through a U.N. Security Council
authorization, [and thereby]{.mark} [increase the **risk of armed
conflict**]{.mark}]{.underline}. But even in the more likely event that
the U.N. Security Council remained uninvolved, recent history suggests
that states would be inclined to engage in a unilateral use of force to
address the threat, and advance creative ways to justify that use of
force as being compliant with an adjusted and relaxed jus ad bellum
regime. [In short, the more seriously states view the threat posed by
unilateral SAI efforts, the more pressure there will be to relax the
constraints on the use of force to permit military action to address the
threat. The [further weakening of]{.mark} the [jus ad bellum]{.mark}
regime itself, [and]{.mark} the [undermining of]{.mark} the
[international]{.mark} rule of [law]{.mark} more generally, [would
be]{.mark} yet another [collateral harm caused by]{.mark} the
[unilateral SAI]{.mark} effort]{.underline}. The forgoing analysis
explains how attempts to engage in unilateral SAI programs at scale
would create a significant risk of armed conflict. In our view,
[[this]{.mark} additional risk significantly [strengthens the argument
for]{.mark} prudence, and for a much [stronger global governance of
geoengineering activity]{.mark}]{.underline}. We turn next to discuss
what form such governance should take.

#### International law is key to maintaining global peace and deescalating conflict through diplomacy.

Adama **Gross** 2-18-20**24**, Gross has a Master of Science degree in
Political Science and is a PhD candidate for a degree in Political
Science with an emphasis in International Law and Diplomacy from Babcock
University in Nigeria. "International Law and Diplomacy: a Sine Qua Non
of Global Peace?" p. 24-25 //MDC

Conclusion

The [study on international law and diplomacy underscores their
indispensable role as the sine qua non for upholding **international
peace**]{.underline}. Through a comprehensive examination of their
interplay, it becomes evident that these two pillars form the bedrock of
a stable and cooperative global community. [[International law serves as
a normative framework, providing]{.mark} states with a set of
[rules]{.mark} and principles [that]{.mark} [govern]{.mark} their
[interactions. It establishes]{.mark} a common ground for [dispute
resolution]{.mark}, delineates [boundaries, and]{.mark} promotes the
[peaceful coexistence]{.mark} of nations. The adherence to
[international law fosters trust and predictability, reducing]{.mark}
the likelihood of [conflicts]{.mark} and contributing to the maintenance
of a just and equitable world order.]{.underline}

Diplomacy, as the art of negotiation and communication between states,
complements international law by providing the channels through which
disputes can be addressed and agreements reached. Effective diplomacy
fosters dialogue, encourages compromise, and builds relationships that
contribute to the prevention of conflicts. Skillful diplomats navigate
complex geopolitical landscapes, working to find common ground and
advance shared interests.

The symbiotic relationship between international law and diplomacy
becomes particularly evident in times of crisis, where diplomatic
efforts guided by legal frameworks offer viable solutions to mitigate
tensions and prevent the escalation of conflicts. [Treaties and
agreements negotiated through diplomatic channels not only provide a
roadmap for resolving disputes but also serve as a testament to the
commitment of nations to uphold the principles of international
law]{.underline}.

In a world characterized by interconnectedness and interdependence, the
study affirms that the [[continued adherence to international
law]{.mark} and the practice of effective diplomacy [are imperative
for]{.mark} the preservation of [global peace. As nations grapple
with]{.mark} diverse [challenges]{.mark}, ranging [from transnational
threats to economic inequalities]{.mark}, the [collaborative
spirit]{.mark} embedded [in these]{.mark} [principles becomes]{.mark}
increasingly [vital]{.mark}]{.underline}. In essence, the study
underscores that international law and diplomacy are inseparable
elements in the pursuit of a peaceful world order. [[Their]{.mark}
combined [strength fosters an]{.mark} [environment where nations]{.mark}
can coexist, [cooperate, and **address shared
challenges**]{.mark}]{.underline}. As we navigate an ever-evolving
international landscape, it is imperative that the global community
reaffirms its commitment to these fundamental principles, recognizing
them as indispensable instruments for upholding international peace.

#### Independently, rogue terrorist groups cause extinction from [climate weapons]{.underline}.

Bartłomiej **Terebiński** 9-30-20**24**, Lt. Col. Bartłomiej Terebiński,
PhD Eng is the head of the Department of Cybersecurity, Military Faculty
of the War Studies University in Warsaw. *Scientific Journal of the
Military University of Land Forces* p. 56-57 \"Climate weapons -- a new
weapon of mass destruction?\" //MDC

Conclusion

The history of international relations indicates that in the conditions
of modern civilization, armed conflicts and wars are still constant
companions of humanity, fulfilling the function of redistributing
resources and spheres of influence, and sometimes contributing to a
radical change in the geopolitical situation between the warring
parties. A society developing asymmetrically and unevenly, in order to
overcome external and internal conflicts, resorts to one of two ways of
solving them within the political process -- cooperation or
confrontation.

Since there is a stable cause-and-effect relationship between war and
politics, each civilization corresponds to a certain level of
development of weapons and military equipment. The tendency of the 21st
century to constantly accumulate and improve weapons, which began in the
20th century, has led to the creation of advanced technologies, forms
and methods of armed combat.

In place of the "old" wars (Antczak, 2018), [[it is a time of]{.mark}
new, so called "**[sixth generation" wars]{.mark}** (Alderman, 2015, May
12), [based on advanced-technology]{.mark} weapons that reduce the
degree of direct involvement of soldiers by using physical, chemical and
biological factors, and the natural environment, based on geophysical,
information and network-centric weapons.]{.underline}

The concepts of cyber-war, war based on computer technology, emerged.
Consequently, armed violence is no longer the dominant feature of war.
The socio-political dimension of war is replaced by military-technical
and informational-psychological capabilities. [Therefore, it seems
justified to define the concept of [the "climate weapon]{.mark}", which
[can be assigned to a new generation of weapons]{.mark}, for example
non-traditional ones, [as a type]{.mark} [of geo physical weapon]{.mark}
(Fig. 9). Moreover, "[climate weapons" can be considered]{.mark} one of
[the **most dangerous types of w**]{.mark}**eapons of [m]{.mark}ass
[d]{.mark}estruction**, on a par with traditional forms (nuclear,
chemical and biological) [because their use can have]{.mark} global and
largely [unpredictable consequences]{.mark}, where a possible aggressor
may later also be their victim.]{.underline}

\[Figure 9 omitted\]

In the current situation, [the possibility of [terrorist groups
acquiring "**climate weapons**]{.mark}" or other types of weapons of
mass destruction [is becoming increasingly worrying, given]{.mark} the
[increased]{.mark} frequency and scale of the [terrorist threat]{.mark}
around the world. [The potential use]{.mark} of such weapons to achieve
political goals during armed conflicts [could lead to mass accidents and
put]{.mark} [humanity on the **brink of survival**, not to
mention]{.mark} the occurrence of a global [environmental
"**apocalypse**]{.mark}]{.underline}". It cannot be ruled out that
recent unusual forms of climate change may be linked to the hidden use
of "climate weapons", and the complete lack or unavailability of both
analyses and information does not help to identify problems in this
field or to find ways to effectively solve them.

#### US leadership in geoengineering is key to global governance.

**Sikorsky and Ellison 24**\-\-- Erin Sikorsky: Director of the Center
for Climate and Security (CCS), and the International Military Council
on Climate and Security (IMCCS) with a masters of International Affairs
at Columbia University, Tom Ellison: Deputy Director of the Center for
Climate and Security (CCS) with a M.A. in Security Studies from
Georgetown University ("Geoengineering and Climate Change in an Age of
Disinformation and Strategic Competition", Council on Strategic Risks,
04/23/24,
https://councilonstrategicrisks.org/2024/04/23/geoengineering-and-climate-change-in-an-age-of-disinformation-and-strategic-competition/)

[[Geoengineering]{.mark}, sometimes called climate intervention, [is
gaining more attention]{.mark} as a potential tool to manage the impacts
of climate change]{.underline}. A steady drumbeat of reports from
governments and scientific institutions argue for developing research
programs to allow for better informed decisions on the risks and
benefits of geoengineering. [At the same time, [the national security
community is raising concerns]{.mark} emphasizing the risk [of]{.mark}
large-scale, successful [unilateral deployment by a middle or rogue
power]{.mark}.]{.underline}

However, the more acute, [near-term [security risks]{.mark} associated
with geoengineering [have little to do with the ultimate effect of such
interventions, but instead with]{.mark} the **[perceptions]{.mark}** of
such interventions, [particularly]{.mark} in a world [shaped by
geopolitical competition, growing divides between the]{.mark} Global
[North and]{.mark} Global [South, and dis/misinformation]{.mark}. These
risks include rising tensions between or among states attributing
disasters to each other's real or perceived geoengineering
attempts,]{.underline} a dynamic that could arise even in the research
or testing phase of geoengineering projects. Additionally, expanding
geoengineering efforts may exacerbate the growth of harmful conspiracy
theories and influence campaigns that further undermine trust in
government and science. Such issues have gotten comparably little
attention in the national security discourse and are largely absent in
discussions about geoengineering among the scientific and environmental
community.

To manage such risks, a push for a full ban or prohibition on
geoengineering will become more and more unrealistic, and perhaps
harmful, particularly as the climate crisis intensifies. Instead, [[the
United States]{.mark}, with its allies and partners, [should lead the
development of guardrails and norms that manage]{.mark} not only the
[scientific challenges but also]{.mark} the [geopolitical risks]{.mark}
associated with geoengineering]{.underline}. [A responsible framework
would ensure that research is conducted transparently, led by civilian
institutions and agencies, and integrates political, sociological and
historical viewpoints.]{.underline} In building the framework, the
United States should learn from weather modification controversies in
the 1960s and 1970s, nuclear nonproliferation negotiations, and the
development of bioethics -- all of which offer lessons regarding norm
building for complex, nascent technologies. The United States must also
develop robust science communication and science diplomacy to engage the
public, the private sector and other governments on geoengineering in
the coming years to combat mis- and disinformation. Such efforts should
draw lessons from analogous science communication and misinformation
challenges--such as vaccine skepticism and election interference.

Importantly, geoengineering discussions should not siphon resources or
political capital from continuing the transition away from fossil fuels
as quickly as possible, while also robustly investing in
adaptation--policies that will lessen the need for more radical
solutions. Realistically, however, [[interest in geoengineering will
only grow]{.mark} in the next few decades [and the United States cannot
afford to be caught flat-footed]{.mark} on the associated security
risks.]{.underline}

Current State of Play

[As climate-driven disasters pile up around the world, there is growing
interest among governments and scientific bodies in exploring climate
intervention or geoengineering techniques]{.underline}. The long-held
taboo in the scientific community that prevented even basic research
into climate intervention approaches such as Solar Radiation Management
(SRM) appears to be weakening. China launched a large, government-funded
program in 2017, while in the United States universities like Harvard
(though its major effort shuttered in 2024), the University of Chicago
and the University of Washington have been leaders in the field.1 [2 A
2021 [report]{.mark} from the US National Academy of Sciences argued it
was time to create a transdisciplinary geoengineering research program
in the United States, [focused on developing "policy-relevant
knowledge," not]{.mark} advancing [deployment]{.mark}]{.underline}.3 Two
years later, in June 2023, a Congressionally-mandated report from the
White House Office of Science and Technology Policy echoed the Academy's
recommendations and laid out a US research program on solar radiation
modification, noting such a program would, "...enable better-informed
decisions about the potential risks and benefits of SRM as a component
of climate policy."4

Of note, [[the US government reports]{.mark} mentioned above [emphasize
the importance of]{.mark} developing [international governance
mechanisms alongside the scientific research]{.mark}]{.underline}, yet
little detail is provided on how such mechanisms might be developed, and
what the obstacles might be. While the White House report details a
short list of US principles for governing research, [it does not address
how [the United States will encourage]{.mark} [other countries to adhere
to]{.mark} such [principles]{.mark} or what to do if countries decide
not to adhere or develop principles of their own.]{.underline} This gap
is likely due to the fact that these reports are largely led by the
scientific community, while questions related to international
governance and risk perceptions are best answered by social scientists,
diplomats and security policymakers and practitioners. Also, these
questions are frankly thornier and harder to address than laying out a
sensible scientific research agenda. One can assess the types of planes
needed to consistently inject aerosols into the atmosphere (as would be
needed for stratospheric aerosol injections, a likely form of
geoengineering) [with much more certainty than one can understand the
range of reactions governments and societies may have to the deployment
of such planes.]{.underline}

[On the international stage, the topic is gaining attention as well,
with the EU and the UN Environment Programme endorsing international
efforts to assess the risks and uncertainties of climate
intervention]{.underline}.5 While in February 2024 a Swiss proposal to
establish an expert panel to examine SRM technologies was withdrawn at
the UN Environmental Assembly in Nairobi due to lack of support, [it is
likely that the topic will continue to gain time on the agenda in the
environmental and climate communities in coming years.]{.underline}

## Climate Advantage

### 2AC\-\--AT: Trump

#### Trump will love geoengineering.

Hugh **Hunt** and Shaun **Fitzgerald** 2-17-20**25**, Hugh Hunt is
Professor of Engineering Dynamics and Vibration in Cambridge
University\'s Engineering Department. He is Deputy Director of the
Centre for Climate Repair in Cambridge. Shaun Fitzgerald is the Direct
of the Centre for Climate Repair in Cambridge. "Geoengineering is
politically off-limits -- could a Trump presidency change that?"
https://theconversation.com/geoengineering-is-politically-off-limits-could-a-trump-presidency-change-that-248589
//MDC

[Donald [Trump's second]{.mark} presidential [term is likely to mean big
changes for those]{.mark} of us [interested in
geoengineering]{.mark}]{.underline}. The term refers to deliberate
large-scale manipulation of the climate, perhaps by blocking out some
sunlight or directly removing greenhouse gases from the atmosphere.
Sometimes called climate engineering, we prefer the term "climate
repair".

Trump is not the most natural supporter of climate change interventions.
He is set to expand oil and gas production hot on the heels of the most
terrible wildfires in California. At some point the US could see
hurricanes on scales even more extreme than Katrina or Helene.

[Extreme [weather will become **harder to ignore**. Trump]{.mark} could
of course downplay any link to climate change but there's a chance this
[might]{.mark} trigger him to decide emergency action is required and
[demand to know more about climate engineering]{.mark}
options.]{.underline}

After all, [[Trump is close to]{.mark} certain [tech figures who like
big technological solutions]{.mark} to global problems. [He likes to act
fast]{.mark} and is prepared to deal with democratic reactions later. In
those circumstances [he might feel that we should do whatever it takes
to deploy new climate-saving strategies]{.mark} at speed]{.underline}.

The most effective methods for cooling the planet involve making the
Earth more reflective so that it absorbs less heat from the sun. One
option, known as stratospheric aerosol injection, involves spraying
sulphur dioxide into the upper atmosphere to mimic the cooling effect of
volcanic eruptions.

Clouds could also be altered to become more reflective, an option known
as marine cloud brightening. We can even make ice in the Arctic more
reflective by thickening it during the winter months so that it lasts
longer in the summer, reflecting the sun's heat back into space.

These technologies sound rather fanciful. Some might find them scary.
[But with the devastation of hurricanes and wildfires, Trump could
potentially instruct the US military to give aerosol injection a
go]{.underline}. At present, the technology would rely on high-altitude
jets to take millions of tonnes of sulphur dioxide up to the
stratosphere above the Arctic, and the US has a lot of these planes.

Alternatively, Trump might take the opposite path and say "this is just
part of the natural cycle of weather". Climate-change deniers or those
who believe reducing emissions alone will work to hit the 1.5°C or even
2°C targets may be given a platform to convince us all that there is no
need for geoengineering.

Geoengineering as an investment

Maybe there is a middle ground. [[Trump could decide to support
geoengineering]{.mark} research [to help the **insurance
industry**]{.mark}. If insurance companies will benefit by having fewer
storms and fires, then [this would be good for the US economy]{.mark}.
So perhaps some expenditure on research right now may be a strategic
investment.]{.underline}

Behind the scenes are deep discussions on geoengineering governance.
There are some who argue that geoengineering is so risky for the climate
(what if the world cools too much? are we prepared for any unintended
consequences?) that it shouldn't be researched -- or at least the
research should not be funded by governments.

Others argue that global governance and democratic issues (who is in
charge? who gets a say?) need to be addressed before any research can
begin. Then there's the "slippery slope" argument, that once we start
then we'll never stop.

Until now these kinds of arguments have slowed the pace of research, but
Trump could say that the current position is wrong, as it holds back our
knowledge of something which might help the US economy. [If Trump
decides to unlock geoengineering as an opportunity, then [he may not
just provide funding but instruct the national labs to get on with
research at pace]{.mark}, thereby [accelerating our knowledge]{.mark} of
the different options. With good data we can make informed
decisions]{.underline}.

How much would this cost? [It turns out that [geoengineering research is
**not very expensive** and Trump may figure that the potential upside is
huge]{.mark}]{.underline}. If he gets excited about it, then
geoengineering might suddenly capture the imagination of the US public.

There is increased interest around the world so the situation in the US
is being watched closely. [[With]{.mark} additional [funding]{.mark} and
instructions from the new president, [geoengineering would soon
become]{.mark} established in the [mainstream]{.mark}.]{.underline}

Our team at the Centre for Climate Repair in Cambridge are not the only
ones thinking about all of this. This is a hot topic and one which is
likely to see significant changes in the coming year.

**[2AC -- Warming Tipping Points]{.underline}**

**The melting of ice in the Arctic is accelerating warming and bringing
us closer to tipping points.**

**Tsakali 25**\-\--Sustainability advisor for the Royal Netherlands
Meteorological Institute (Nicoleta, Marlen Kolbe, Richard Bintanja, and
Nomikos Syllas; "The time of emergence of Arctic warming, wetting and
sea ice melting", Scientific Reports, 04/12/35,
https://www.nature.com/articles/s41598-025-96607-1#Sec1)

[In the rapidly warming and wetting Arctic, the time of emergence (ToE)
of a new climate state occurs when trends of climate indicators are
large enough to surpass the strong natural climate fluctuations in the
Arctic]{.underline}. Thus far, uncertainties in climate model
projections, variability and methods have yielded diverging estimates of
Arctic ToE. Here we use a robust method and future projections of
multiple state-of-the-art climate models to show that, generally, sea
ice thickness (2036--2051) and surface air temperature (2033--2050)
emerge first, followed by sea ice cover (2039--2074), and
precipitation/rainfall (after 2077). Autumn generally exhibits the
earliest ToE-values due to rapid sea ice retreat. The earliest ToE for
temperature and sea ice thickness occurs in the Central Arctic, whereas
sea ice cover and rainfall first emerge in the Barents Sea region. [Most
regions of the Arctic are close to a new climate state (for temperature
and sea ice), with wide-ranging and possibly irreversible consequences
for vulnerable Arctic ecosystems and human activities.]{.underline}

In view of recent global increases in the occurrence of climate
change-related natural disasters1,2,3, there is enhanced interest in
determining whether extreme climate conditions are a regular feature of
the current climate, or if they pose evidence of a new climate state
having emerged. [One of the most vulnerable regions to climate change is
the Arctic, which is warming two to four times faster than the global
average over the last decades4]{.underline},5,6, while also getting
considerably wetter7,8,9,10. Understanding when the effects of
anthropogenic climate change in the Arctic have/will become
distinguishable from natural climate fluctuations is crucial for
policymakers to develop effective mitigation and adaptation strategies,
and to identify and quantify (potentially irreversible) impacts on
vulnerable Arctic ecosystems. [A useful metric to establish when the
forced climate change trend emerges from the 'background noise', or
natural climate variability, is the time of emergence
(ToE).]{.underline}

Thus far, the few studies that addressed Arctic ToE have provided
inconclusive and diverging results, mainly because the methods to
evaluate ToE and the climate variables/metrics that have been assessed
differ greatly. Previous estimates of ToE for Arctic Amplification12,
surface air temperature16, shortwave radiation11, sea ice extent
(SIE)16, the freshwater budget15, or solar absorption14 focused on only
one or a few variables and concluded that the forced trend has either
already emerged or will likely emerge within the current decade13,16.
[For rainfall, only the ToEs for the first, last, and duration of Arctic
rain days were evaluated and found to occur later this century16.
Studies that evaluated Arctic ToE were sometimes based on spatial and/or
temporal averaging]{.underline} (which reduces variability and hence
results in an earlier ToE, especially in sea ice, see Supplementary
Information Figs. 1 and 2), [as such, these have mostly attributed
emergence to processes associated with Arctic sea ice
decline1]{.underline}2,16,17. For instance, a recent study suggested
that the Arctic climate has already emerged decades ago in terms of both
the seasonal minimum and maximum of SIE16, but these estimates are based
on Arctic average SIE, which due to spatial averaging of variability
yield an unrepresentative early ToE. [To date, crucial Arctic variables
such as sea ice thickness have not been analysed in terms of their first
emergence. Precipitation/rainfall exhibit strongly increasing trends,
and also considerable variability, but so far ToE has been evaluated
only for specific precipitation indices and metrics based on only two
climate models16]{.underline}. As a result, ToE-estimates are often hard
to intercompare because of differing climate variable indices and
metrics, as well as differing methodology such as, most crucially,
spatial and temporal averaging. Evidently, there is an urgent need for a
complete, reliable and internally consistent estimate of the first
emergence of the Arctic climate -- including the associated
uncertainties -- based on a broad range of state-of-the-art climate
models and five climate variables representative of the Arctic climate,
including their geographical and seasonal variations.

Results. Arctic mean time of emergence

Here we use a detailed methodology (see Methods) to robustly determine
Arctic ToE from state-of-the-art climate model simulations using 15
models in standardised scenario simulations (CMIP6, historical and
SSP5-8.5)18 to show that, [averaged over the Arctic (70°N-90°N), the
seasonal emergence of surface air temperature (TAS, 2033--2050) and sea
ice thickness (SIT, 2036--2051) will precede sea ice cover (SIC, around
2039--2074), followed by rainfall and precipitation]{.underline}
(2077--2096, 2090-after the end of the century, respectively) (Fig. 1).
In contrast to seasonal means, annual means average out seasonal
variability; hence we find that annual mean ToE-estimates precede
seasonal values by 14 ± 5 years (Fig. 1). Strong future trends result in
an earlier ToE, but a large variability -- and/or an increase in
variability -- will delay ToE (Supplementary Information Fig. 6). The
later emergence of rainfall/precipitation in spite of strong future
trends can be attributed to comparatively large past and present
variability as well as to further future increases in variability19.
[Until now, estimates of ToE for sea ice changes were based on Arctic
mean/total sea ice concentration,]{.underline} thus averaging out
spatial variability, which likely resulted in too early ToE-values (up
to 56 years compared to our best estimates, see Supplementary
Information Figs. 1 and 2). [Crucially, we find that evaluating the sea
ice cover emergence per grid point considerably delays ToE to just after
that of temperature]{.underline} (Fig. 1). [These results suggest that,
in contrast to earlier studies, the mean Arctic climate, despite
exhibiting trends that are among the largest in the world4,5,6 through
local amplifying feedbacks, has overall not yet moved significantly
outside the current state]{.underline} (although some regions and
variables have already emerged). However, ToE values exhibit
considerable intermodel differences (Supplementary Information Fig. 3),
indicative of diverging model-specific simulated Arctic trends and
variability -- interannual and/or decadal -- as well as the associated
governing processes/feedbacks20,21. This clearly indicates that analyses
of ToE should be based on as many models as possible to accurately
quantify the associated uncertainties.

TAS, SIC, and SIT are expected to transition to a new state across the
Arctic by the end of this century, with changes occurring in all seasons
(Fig. 1a-c). The earliest transitions are projected for autumn TAS,
starting as soon as 2033 (Fig. 1a). SIT generally transitions around the
same time as TAS, except for autumn, where TAS leads SIT by 13 years
(Figs. 1a-b and 2a-b). Notably, some variables and regions have already
emerged, such as SIT in the Central Arctic (Fig. 3e-h), while others,
like winter TAS over Greenland (Fig. 3a) and spring SIC in most regions
(Fig. 3j), are not expected to emerge until after 2100.

[The presence of sea ice influences the emergence of TAS particularly
during warmer seasons, such as summer and autumn, when temperatures
reach the melting point of ice. Once this point is reached, further
warming is limited until the ice fully melts, resulting in TAS and SIC
transitions occurring almost simultaneously during these
months]{.underline} (Fig. 2a, c). However[, in colder seasons, such as
winter and spring, TAS remains well below the melting point and can thus
increase freely.]{.underline} As a result, TAS transitions occur up to
24 years earlier than SIC in spring (Fig. 2a, c). This pattern is
particularly pronounced in the Central Arctic, where TAS is expected to
transition before 2050 in spring (Fig. 3b), while SIC transitions will
not occur until after 2070 or, in many areas, not even before the end of
this century (Fig. 3j). In contrast, in regions with thin sea ice, such
as the Barents Sea, the relationship between TAS and SIC is more
synchronized, with [both transitioning relatively early (Fig. 3b, j) due
to the already thin ice which suggests that surface temperatures have
already reached the melting point.]{.underline} When analyzing
individual models, we find that those with an earlier ToE in temperature
also tend to exhibit an earlier ToE in SIC (Supplementary Information
Fig. 9). This approximately linear relationship is most pronounced in
summer (R = 0.96), likely due to relatively high temperatures
efficiently melting comparatively thin sea ice.

[Sea ice cover demonstrates greater resilience than sea ice thickness,
particularly in regions dominated by multiyear thick ice]{.underline}
(Fig. 3e-l), adding complexity to the timing of their transitions. In
winter and spring, SIC transitions occur 17 and 31 years later than SIT,
respectively (Fig. 2b, c), [as reductions in ice thickness do not
immediately lead to a decline in sea ice cover in these regions. In
contrast, regions with currently relatively thin ice, e.g. the Barents
Sea, exhibit SIT transitions that often lag behind SIC by up to 20
years]{.underline} (Fig. 3e-l), marking the final state before an
ice-free state. This is especially true in regions where both variables
are concurrently near the no-ice threshold. However, SIT exhibits
greater ratio of variability and trend than SIC, especially in the
Central Arctic (Figs. 4 and 5), introducing additional complexity to its
spatiotemporal transition characteristics. This explains why, unlike
SIT, SIC undergoes significant changes only when the ice is already
thin, delaying its transition by up to 60 years compared to SIT---most
notably in the Central Arctic during winter and spring (Fig. 3e-l). This
lag is further exacerbated by the accelerated thinning of multiyear ice
due to rising atmosphere and ocean temperatures20, which promote early
SIT emergence.

### 2AC -- Yes Feedback Loops

**The sea ice albedo feedback and longwave radiation caused by melting
and warmer ice are accelerating the rate of shrinking ice in the
Arctic**

**Cao et al. 17**\-\--PhD from the China University of Mining and
Technology, professor at Beijing Forestry University who does research
in Remote Sensing, Geoinformatics (GIS) and Climatology (Yunfeng,
Shunlin Liang, Xiaona Chen, Tao He, Dongdong Wang, and Xiao Cheng;
"Enhanced wintertime greenhouse effect reinforcing Arctic amplification
and initial sea-ice melting", Scientific Reports, 8/16/17,
https://www.nature.com/articles/s41598-017-08545-2)

[The speeds of both Arctic surface warming and sea-ice shrinking have
accelerated over recent decades.]{.underline} However, the causes of
this unprecedented phenomenon remain unclear and are subjects of
considerable debate. In this study, we report strong observational
evidence, for the first time from long-term (1984--2014) spatially
complete satellite records, that increased cloudiness and atmospheric
water vapor in winter and spring have caused an extraordinary downward
longwave radiative flux to the ice surface, which may then amplify the
Arctic wintertime ice-surface warming. In addition, [we also provide
observed evidence that it is quite likely the enhancement of the
wintertime greenhouse effect caused by water vapor and cloudiness has
advanced the time of onset of ice melting in mid-May through inhibiting
sea-ice refreezing in the winter and accelerating the pre-melting
process in the spring, and in turn triggered the positive sea-ice albedo
feedback process and accelerated the sea ice melting in the
summer.]{.underline}

Despite an apparent hiatus in global warming1,2,3, [the Arctic climate
continues to experience unprecedented changes. Summer sea ice is
retreating at an accelerated rate4, 5, and surface temperatures in this
region are rising at a rate double that of the global
average]{.underline}, a phenomenon known as Arctic amplification6, 7.
Several major competing hypotheses have been proposed to explain the
causes of Arctic amplification and summer sea-ice retreat. For instance,
an enhanced Atlantic Meridional Overturning Circulation (AMOC)
transporting extraordinary amounts of heat northward to the Arctic Ocean
has been hypothesized to substantially amplify Arctic warming and
accelerate summer sea-ice melting in this region8,9,10,11. However,
evidence has instead shown significant slowing of the AMOC over the last
few decades12, 13. [Sea-ice albedo feedback caused by the continuously
shrinking summer sea ice potentially increasing the absorption of
shortwave radiation is also believed to play a critical role in recent
Arctic amplification14]{.underline},15,16,17. But certain model
simulations have indicated that sea-ice albedo feedback was likely not
the dominant factor18, 19 - robust warming amplification still occurs in
the Arctic in the absence of albedo feedback20, 21. [Recently, downward
longwave radiation (LWD) at the surface has been suggested as an
important driver of Arctic winter warming and summer sea-ice
dynamics1]{.underline}9, 22,23,24,25,26. [Because LWD is affected by
several highly correlated climatic factors, including atmospheric
temperature, and the amounts of water vapor and cloudiness27, which of
these factors has been the fundamental force driving Arctic
amplification is still under debate. Based on model simulations, several
studies have claimed that atmospheric temperature feedback (also called
lapse-rate feedback at the top of the atmosphere), which is associated
with wintertime temperature inversions in the Arctic boundary layer, is
the dominant factor responsible for amplifying Arctic surface
warming]{.underline}18, 28. The other two greenhouse effect factors,
water vapor and cloudiness, have very limited (even negative) effects on
Arctic amplification17, 18. However, other analyses, based on
observations24, 29 and atmospheric reanalysis23, 25, have pointed in the
opposite direction and demonstrated that the cloud- and water
vapor-induced greenhouse effect is crucial to Arctic winter warming and
the development of summer sea ice. In fact, LWD is much more sensitive
to water vapor anomalies at high latitudes30,31,32,33, which suggests
that the water vapor effect in the Arctic may be considerably stronger
than that at lower latitudes. However the findings that support this
hypothesis are either from small regions23 or very short spans of time
(early winter24, 25 or late spring23, 34), and therefore are
insufficient and problematic for fully interpreting the mechanism that
drives variation in LWD at the surface and its effects on Arctic
amplification and sea-ice variations. Strong and comprehensive
additional evidence is therefore required to clarify the relationship
between LWD at the surface and Arctic amplification.

Furthermore[, because the state of sea ice at the onset of the melting
season is crucial for evaluating surface energy uptake35, 36 which
largely determines the minimum sea-ice coverage reached in the fall37,
and is asynchronous with Arctic amplification, which occurs mainly in
the wintertime6]{.underline}, 15, it is important to chronologically
investigate the causal relationships between Arctic wintertime
amplification and initial sea-ice melting to elucidate the physical
mechanisms of recent Arctic warming.

For this study, we use for the first time, long-term (1984--2014)
spatially complete satellite data to provide strong observational
evidence that [the enhanced greenhouse effect from increased atmospheric
water vapor and cloudiness in both winter and spring may reinforce the
amplification of Arctic wintertime warming, which in turn has triggered
the accelerated sea-ice melting in the summer.]{.underline}

Results and Analysis

[To investigate the relationships among atmospheric longwave radiative
forcing, wintertime surface warming and the late spring initial sea-ice
melting in the Arctic, we calculated long-term anomalies]{.underline} in
spatial (maximum sea-ice coverage north of 60°N) and wintertime
(including both winter and spring) temporally averaged surface downward
longwave radiative flux (LWD), water vapor (WV), cloud area fraction
(CFC), skin temperature (SKT), and sea ice concentration (SIC) for the
melting onset period37 between May 16 and June 5 (days of year 136 to
156). In addition, we identified the correlations between these
variables from records of the last 30 years (1985--2014) (Fig. 1a and b,
SIC shown here represent inverted records). The wintertime SKT of the
Arctic Ocean is strongly correlated (r = 0.95, and 0.89 after
de-trending, p \< 0.001) with the surface LWD, and both exhibit a
pronounced upward trend over the 30-year study period. Given LWD is the
main source energy at the Arctic surface in boreal wintertime and a
continually weakening AMOC12, 13 would unlikely transport extraordinary
heat northward to the Arctic, the strong coupling of surface LWD and SKT
imply that both inter-annual and long-term changes in SKT in the Arctic
have been closely associated with surface LWD over this period. Surface
LWD is related to three main parameters: temperature, clouds and water
vapor18, 28. Therefore, the high correlation coefficients between
wintertime LWD and WV over 1985--2014 (r = 0.91, and 0.82 after
de-trending, p \< 0.001), and between wintertime LWD and CFC over
2001--2014 (r = 0.93, and 0.82 after de-trending, p \< 0.001; a high
correlation was also detected for 1985--2000, Fig. S10[) imply the
likelihood that it is the enhanced greenhouse effect from water vapor
and cloudiness that caused the increase of surface LWD, and in turn
reinforced the Arctic wintertime warming over the past several decades.
I]{.underline}t is indicated that poleward moisture fluxes into the
Arctic associated with large-scale circulations significantly
contributed to the variation of precipitable water vapor in the
Arctic38, 39. We also examined the relationship between the injected
moisture across 70°N and the total precipitable water vapor in the
Arctic (Fig. S11), the strong correlation between the two variables
demonstrate that the variation of the Arctic water vapor is primarily
controlled by the transported convergence of moisture from the lower
latitude. The poleward transported moisture would bring not only water
vapor, but also latent energy into the Arctic23, 38.

\[Figure omitted\]

[To investigate the influence of wintertime surface LWD on the state of
sea ice at the onset of melting, we directly calculated the correlation
between wintertime LWD and the melting onset SIC]{.underline} in late
spring. As shown in Fig. 1a and b, [the total wintertime surface LWD is
strongly negatively correlated with the subsequent onset
SIC]{.underline} (r = −0.90, and −0.76 after de-trending) in late
spring. Arctic sea ice usually begins to refreeze in early October and
attains its maximum coverage in early March40, 41 before entering an ice
pre-melting state until the onset of melting in mid-May40. The gradual
increase in correlation coefficients between the integrated surface LWD
and onset SIC (Fig. 1c,d, two correlation maps are also generated and
shown in Fig. S12) [demonstrates that the accumulated wintertime surface
LWD potentially influences both the ice refreezing and pre-melting
processes through reducing ice thickness25, and the perturbing of ice
thickness would in turn affects the SIC during the period of melting
onset]{.underline} (especially over these coastal regions with thin
ice)42. [After sea-ice melting begins, shortwave albedo feedback becomes
more important on driving variations in ice coverage over the subsequent
months35]{.underline}, 36. The conclusions of this study, based on
long-term observational evidence, are partially consistent with previous
studies that have reported isolated cases of atmospheric conditions
influencing ice melting in either the late spring23, 29, 34 or winter24,
25. However, our results indicate that the downward longwave radiation
from early winter to late spring is continually affecting both the
inter-annual and long-term changes of the

**Longwave radiation and ice melting are heavily correlated to ice
thickness and temperature**

**Uhlíková et al 25**\-\-- Author for the Institute for Atmospheric and
Earth System Research, Faculty of Science, University of Helsink.
(Tereza, Timo Vihma, Alexey Yu Karpechko, and Petteri Uotila; "Effects
of Arctic sea-ice concentration on surface radiative fluxes in four
atmospheric reanalyses", European Geosciences Union, 03/06/25,
https://tc.copernicus.org/articles/19/1031/2025/)

\* [*T*~ice\ ~]{.underline}= Surface temperature of Arctic Sea ice

\*SIC = Sea Ice concentration

\*ULW = Upward longwave radiation

[Utilizing linear bilateral ODR analysis, we assessed the effects of SIC
on ULW. These two variables were negatively correlated in all seasons
and both study periods]{.underline} (Fig. 1; see Figs. S1, S3, and S4 in
the Supplement), meaning that [less SIC leads to more ULW or more SIC
leads to less ULW. The sign of the correlation was in agreement with the
theoretical expectations as the open-ocean surface in the Arctic is
usually warmer than the sea-ice surface]{.underline} (and much warmer in
the cold season from November--April) [and accordingly emits more
longwave radiation]{.underline}. As depicted in the above-mentioned
figures, the sensitivity of ULW to SIC (slope of the regression line)
did not vary considerably among reanalyses, with the highest values over
150 W m^−2^ ULW per −0.1 change in SIC in November--April in the Central
Arctic (north of 81.5° N). The dark grey areas in Figs. 1, S1, S3, and
S4 indicate a failure of the linear bilateral ODR model to converge. For
JRA-55 (panels b, f, and j in these figures), this was caused by the
binary representation of SIC in the reanalysis, which assigns a value of
1 to SIC \> 0.55 and a value of 0 to SIC ≤ 0.55. Then, because the SIC
in these dark grey areas was never less than 0.55 during the 21-year
periods, every grid cell was assigned a value of 1. Hence, no dependence
with ULW or any other variable could be found. In other reanalyses, the
ODR model failure also occurred either because of very low variability
in SIC or due to high uncertainty in the slope of regression between the
two variables (as shown in Figs. S1 and S2). In the warm season
(May--October), the effect of SIC on ULW was generally weaker, with up
to 80 W m^−2^ ULW per −0.1 change in SIC (Figs. S3 and S4).

\[Figures omitted\]

The sensitivity of ULW to SIC mostly decreased in all seasons between
1980--2000 and 2001--2021 (shades of red in panels i--l in Figs. 1, S1,
S3, and S4) but strengthened in the Central Arctic (shades of blue
panels i--l in Figs. 1, S1, S3, and S4). To explain these changes, in
Fig. 2, we show the daily values of SIC and ULW in grid cells from ERA5,
MERRA-2, and NCEP/CFSR data, where the sensitivity changed considerably
between 1980--2000 and 2001--2021 in November--December--January. While
in Point 1 (see Fig. 1), from the border of the Chukchi and East
Siberian seas, the slope of the regression line became less steep in
2001--2021 compared to 1980--2000, in Point 2, from the Central Arctic,
the slope became steeper in the second (more recent) study period.

As shown in Uhlíková et al. (2024; Fig. 5), [the surface temperature of
the Arctic sea ice (bare or snow-covered; *T*~ice~) generally increased
between the two study periods; hence, the difference
between *T*~ice~ and the sea surface temperature decreased, causing
lower sensitivity of ULW to SIC in the majority of the Arctic in all
seasons]{.underline} in the second study period. Also in this study, we
show in Point 1 of Fig. 2 that ULW (and therefore the surface
temperature) is generally higher in 2001--2021 (lower panels) than
1980--2000 (upper panels) in days with SIC = 1. Another cause of
decreasing sensitivity of ULW to SIC is the fact that in areas where the
SIC declined or disappeared completely between the two study periods,
there is naturally a smaller effect or no effect of SIC on ULW in the
second study period. [ULW is also generally not so sensitive to SIC in
regions where SIC is low because, in such regions, *T*~ice~ is typically
higher and closer to the sea surface temperature.]{.underline} This is
illustrated in the lower panels of Point 1 of Fig. 2, where all the
values of ULW in the grid cells with SIC lower than approximately 0.5
fluctuate close to 300 W m^−2^.

The increased sensitivity of ULW to SIC in smaller areas in the Central
Arctic may be due to increased SIC in reanalyses in these areas in
2001--2021 compared to 1980--2000. As shown in Point 2 of Fig. 2, there
is indeed higher SIC, as well as steeper slopes of the regression lines
in the second study period (lower panels), than in the first one (upper
panels). We discuss the possible mechanisms of the increased SIC in
Sect. 4.1.

To further explore the effect of the surface type in the marine Arctic
on ULW, we investigated whether the main driver of ULW is the SIC
or *T*~ice~. To answer this question, we compared *R*^2^ (coefficient of
determination) using SIC and *T*~ice~ as explanatory variables for ULW.
To calculate *T*~ice~ from the grid-averaged surface temperature
(*T*~s~), we utilized the following equation:

where we assumed the temperature of the ocean (*T*~ocean~) at −1.8 °C
(271.35 K). This assumption cannot be applied in the warm season
(May--October) in the majority of adjacent seas outside the Central
Arctic because the surface temperature of the ocean is likely often
higher than −1.8 °C. Hence, we focused on the cold season
(November--April) in these analyses. We are also aware that in the
Greenland and Barents seas, even cold-season ocean temperature may be
warmer than −1.8 °C due to the North Atlantic Current carrying warm
Atlantic water to this area. We utilized data from only ERA5, MERRA-2,
and NCEP/CFSR because JRA-55 comes with binary representation of SIC;
hence, Eq. (2) is not applicable for this data set. As shown in Figs. 3
and S5, in November--April, [*T*~ice~ explained over 90 % of the
variance of ULW in areas, where SIC is very high, whereas SIC explained
only around 30 % of the variance in ULW in these areas.]{.underline}
However, in the marginal ice zone, the coefficient of determination was
higher for SIC (around 60 %) compared to *T*~ice~ (\< 30 %). These
results were quantitatively very similar in both study periods, and we
found very good agreement between the three reanalyses. \[Figure
omitted\]

[In addition to SIC, sea-ice thickness and snow depth on top of sea ice
affect the surface temperature and, hence, the upward longwave
radiation.]{.underline} Due to the limited amount and accuracy of data
on sea-ice thickness and snow depth in the Arctic Ocean, we estimate
their effect on ULW via analytic calculations, analogous to those
in Uhlíková et al. (2024). We focus on the cold season when the
insulating effects of ice and snow are largest. As a first
approximation, we assume that the temperature profile through ice and
snow is piecewise linear, resulting in the following expression for the
conductive heat flux *C* (Makshtas, 1991):

where *k*~i~ stands for the heat conductivity of ice, *T*~s~ for the ice
surface temperature, *T*~b~ for the ice bottom temperature, *h*~i~ for
the ice thickness, *k*~s~ for the heat conductivity of snow, and *h*~s~
for snow thickness. We used −1.8 °C for *T*~b~, 2.1 W m^−1^ K^−1^ for
*k*~i~, and 0.3 W m^−1^ K^−1^ for *k*~s~. The turbulent fluxes of latent
and sensible heat (LHF and SHF) were calculated by applying the
following standard bulk formulae:

where *ρ* stands for the air density, *LE* for the latent heat of
sublimation, *c*~p~ for the specific heat of the air, and *C*~HE~ for
the turbulent exchange coefficient. (*Q*~a~−*Q*~s~) and (*T*~a~−*T*~s~)
are the differences in the specific humidity and temperature between the
lowest atmospheric level and the surface, and *V* stands for the wind
speed at the lowest atmospheric level of the model applied in each
reanalysis. The upward longwave radiation (ULW) was calculated as
follows:

where *σ* stands for the Stefan--Boltzmann constant ( W m^−2^ K^−4^). As
in Uhlíková et al. (2024), the downward longwave radiation (DLW) and the
input for Eqs. (3) to (6) were taken from observations from the SHEBA
campaign in the Central Arctic in February 1998 (Persson et al., 2002)
when the mean values were as follows: 155 W m^−2^ for DLW, 5.0 m s^−1^
for *V*, −32 °C for *T*~a~, and 0.9 for the relative humidity, yielding
0.17 g kg^−1^ for *Q*~a~. Then Eqs. (3) to (6) were solved by applying
the following values of *h*~i~: 0.2, 0.5, 1.0, 1.5, 2.0, 2.5, and 3.0 m,
with *h*~s~ systematically set as 0.1 × *h*~i~. As *T*~s~ is unknown,
and all the fluxes except DLW depend on it, a set of calculations with
various *T*~s~ values was carried out for each combination of *h*~i~ and
*h*~s~ until the *T*~s~ yielded a zero net heat flux (DLW − ULW + SHF +
LHF + *C*) at the snow surface to represent equilibrium conditions.

[The sensitivity of *T*~s~, *C*, and ULW to snow and ice thickness is
presented in Fig. 4. In the case of thin ice, the snow surface
temperature is highly sensitive to ice thickness, but the sensitivity
decreases when the ice gets thicker]{.underline} (Fig. 4a). This is
reflected in ULW. For 0.2 m ice thickness (0.02 m snow depth), ULW is
227 W m^−2^, whereas for 3 m ice thickness (0.3 m snow depth) ULW is
183 W m^−2^, representing a difference of −44 W m^−2^. The difference in
ULW between ice thicknesses of 2 and 3 m is minor (−2 W m^−2^), as the
conductive heat flux through ice and snow is small already for 2 m thick
ice (covered by 0.2 m snowpack). A comparison of Figs. 4 and S1 shows
that in winter in the Bering Sea, the Sea of Okhotsk, and the Barents
Sea, [ULW is approximately equally sensitive to a decrease in ice
thickness from 3 to 0.2 m and to a decrease in SIC by 0.1. However,
closer to the central Arctic Ocean and in the Canadian Arctic
archipelago, the sensitivity is higher for a decrease in
SIC]{.underline} by 0.1. These high statistical sensitivities to SIC may
be partly due to co-occurrence of low SIC and high ice surface
temperatures.

**[2AC -- Ice Pumps Good]{.underline}**

**Using wind power to pump water directly onto the surface of the arctic
thickens ice and prevents melting**

**Desch et al. 16**\-\--Professor of astrophysics in the School of Earth
and Space Exploration at ASU (Steven, Nathan Smith, Christopher Groppi,
Perry Vargas, Rebecca Jackson, Anusha Kalyaan, Peter Nguyen, Luke
Probst, Mark E. Rubin, Heather Singleton, Alexander Spacek, Amanda
Truitt, Pye Pye Zaw, Hilairy E. Hartnett; "Arctic ice management",
American Geophysical Union, 12/16/16,
https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2016ef000410)

To constrain the ability of mechanical devices to thicken Arctic sea
ice, it is first necessary to have a model of how seawater freezes. Here
we derive such a model, similar in spirit to the pioneering work of
Maykut and Untersteiner \[1971\]. [Seawater in the Arctic Ocean
typically starts to freeze in September, when insolation ceases and the
surface temperature stays below −1.8°C]{.underline} (271 K), the
freezing point of water with ocean-level salinity near 35 parts per
thousand (ppt). (Salinity varies from 32 to 37 ppt, and each 5 ppt of
extra salinity depresses the freezing point by 0.28°C.) The first ice
crystals to form on the surface agglomerate into a slush known as
frazil. [As freezing continues, the ice thickens and becomes
fresher.]{.underline} If pockets of liquid brine are trapped in the ice,
they will slowly migrate downward, depressing the melting point of the
ice the brine is in contact with, eventually reaching the ocean at the
base of the ice. This leaves long thin trails in the ice that cause the
mechanical properties of the ice to change. Snow may also cover the
sheet of ice.

Because the surface temperatures in the Arctic winter drop to −35°C to
−40°C on average, the ice is very cold, and seawater in contact with the
ice can continue to freeze, but only if the latent heat of fusion can be
carried away from the bottom of the ice to the cold surface. From the
surface the heat can be carried away by wind or radiated to free space.
If the heat flux through the ice, F, is known, then the rate at which
the ice thickness, x, changes is easily found, since where ρi = 917 kg
m−3 is the ice density, and li = 3.32 × 105 J kg−1 is the latent heat of
fusion. The heat flux is carried through the ice by conduction, and so
is related to the temperature gradient across the ice: where k(x) is the
thermal conductivity and is a function of the ice thickness, x.
Following Trodahl et al. \[2001\], we assume k(x) = ki = 2 W m−1 K−1 if
x \> x0 = 0.5 m, but for x \< x0, k(x) = ki \[1 + x/x0 \]/2, accounting
for the fact that ice near the surface is more porous and less
conductive. We also assume a thin layer of snow with relatively low
thermal conductivity ks and thickness d, on top of the ice. Above the
snow, the temperature is the ambient surface temperature, which is ΔT
degrees colder than the base of the ice, which is at −1.8°C. Integrating
between the surface and the base of the ice, we solve for the flux F, as
a function of x. We then relate dx/dt to x, and then integrate to find x
as a function of (ΔT) t. This product is related to the commonly used
quantity known as freezing degree days, or FDDs. Each day spent below
freezing, the FDDs are augmented by the number of degrees celsius the
surface is below freezing: where Tfrz = −1.8°C, and t is measured in
days. In our derivation, there is one unknown quantity, the product of
the snow\'s thermal conductivity and its thickness, which we
parameterize by c = (ki d)/(ks x0). We set this to c = 0.68, equivalent
to a snow thermal conductivity ks = 0.045 W m−1 K−1 \[Pomeroy and Brun,
2001\] and (time-averaged) thickness d = 8 mm. We choose this value to
match our derived x(t) to an empirical formula found by Maykut \[1986\]:

In Appendix A we solve the above formulas. The results are displayed in
Figure 4. For the optimal value of c = 0.68, deriving the following
formula (for x \> x0): Winter Arctic ice thickness as a function of FDD
(see text for definition). The black curve is the empirical fit from
Maykut \[1986\]. The other curves are results from our first-principles
model using three different assumptions about snow cover (parameterized
by c; see text). The orange curve (c = 0.68) is our best fit to the
empirical data and corresponds to a thin (time average ∼8 mm) layer of
snow on the ice. For 100 \< FDD \< 5000 (a typical value at the end of
the Arctic winter), our formula predicts the thickness of ice in the
Arctic to within 10%. Both formulas predict that at the end of Arctic
winter, if FDD = 5000, about 1.92 m of ice should grow.

2.2 Thickening Arctic Ice With Pumping

[Water pumped directly to the surface can freeze more rapidly, because
the latent heat of fusion can immediately be lost to the atmosphere or
space]{.underline}. [Pumping 1 m of water to the surface will result in
the ice being thicker by a substantial fraction of 1 m,]{.underline}
although two effects prevent the ice from thickening by exactly the
amount that is pumped. First, the latent heat released at the surface
potentially could raise the surface temperature, effectively reducing
the number of FDDs experienced by the ice sheet. Second, as the ice
sheet thickens from above, it makes it more difficult for the heat
released by ice freezing at the ice--ocean interface to reach the
surface.

We first consider the effect of the release of heat at the surface,
which could raise the surface temperature. In the calculation above, we
assumed that the surface temperature equaled the temperature of the air.
We could instead have calculated the surface temperature directly: the
ice surface will attain a temperature balancing heating by release of
latent heat of fusion (at the base of the ice layer, due to normal
freezing, as well as the top of the ice layer, due to freezing of pumped
water) against the cooling due to radiation and contact with the air:
where T is the surface temperature, ϵ is the fraction of the outgoing
long radiation that is transmitted through the Arctic clouds (we assume
ϵ = 0.18), h = 30 W m−2 K−1 is a typical heat transfer coefficient (see
below), Tfrz = −1.8°C, and k is the average thermal conductivity through
the ice (see Appendix A). The rate at which ice would be added to the
surface by pumping is (dx/dt)pump. For the case (dx/dt)pump = 0, we
would derive a surface temperature that is 0.7°C warmer than the air
temperature. Under typical conditions, roughly half the heat released
from freezing water is lost by radiation, and half by contact with cold
air. If we repeat the calculation assuming enough water is pumped to
produce 3 m of ice over the Arctic winter, we would find under typical
conditions that the surface temperature exceeds the air temperature by
2.1°C. Direct losses by radiation are little changed, but the loss of
heat to the air is tripled. Ultimately, though the change in surface
temperature is slight.

[An additional consideration is the blanketing effect of the extra ice,
which impedes the loss of heat released as seawater freezes on the
underside of the ice.]{.underline} The formula relating heat flux F to
the temperature difference ΔT and the ice thickness x remains the same
as before (Appendix A), but the equation for the ice thickness is
altered to account for the water pumped to the surface:

where again (dx/dt)pump is the rate at which ice is added to the top of
the ice sheet by pumping. The solution must be found numerically. We do
so by balancing the heating and cooling terms at the surface to solve
for the surface temperature, Tsurf. Once Tsurf is found, the flux F
through the ice and the rate of increase of the ice thickness, dx/dt,
are readily found and integrated.

[If pumping moves enough water to the surface to add a
thickness]{.underline} Δx = (dx/dt)pump (6 mos) [to the ice over the
Arctic winter, we find as a general result that energetics of the system
limit the increase in the ice thickness above]{.underline} the
no-pumping case to about 0.7 Δx. For example, without pumping, the ice
grows to thickness of 1.92 m after 5000 FDDs. If pumping moves enough
water to add thickness Δx = 1 m, we find the ice thickness at the end of
the winter is 2.61 m, an increase of 0.69 m. For Δx = 2 m, the thickness
at the end of winter is 3.36 m, an increase of 1.44 m; and for Δx = 3 m,
the final ice thickness is 4.16 m, an increase of 2.24 m. [The relation
that the ice thickness increases by ≈0.7 m]{.underline} Δx holds roughly
(±10%) across the range of relevant FDDs seen by the Arctic. [Pumping
has the effect of increasing the surface temperature (due to latent heat
released as water freezes on the surface), resulting in an increase in
heat losses to the air. On the other hand, as the ice is thicker, the
flux of heat from water freezing at the bottom of the ice is lower. The
two effects combine to add about 0.7 Δx to the ice
thickness.]{.underline}

In summary[, pumping water to the surface is a viable means of adding to
the thickness of the ice over the Arctic winter]{.underline}. For a
typical Arctic location that would experience 5000 FDDs, the ice would
normally freeze to a thickness of about 2 m over the winter. Pumping at
a rate (dx/dt)pump over the Arctic winter, raising enough water to add
to the ice thickness by Δx, will increase the thickness of the ice above
the natural increase; however, the latent heat released at the surface
will limit the increase to about 0.7 Δx. Nevertheless, this is a
significant amount. In our discussion of wind-powered pumps we adopt Δx
≈ 1.4 m as a baseline (requiring pumping of 1.3 m of water), which
implies that [wind-powered pumping can increase the thickness of the ice
by about 1.0 m beyond what it would normally attain]{.underline}.

2.3 Melting of Ice in the Arctic SummerWith the right equipment, it is
possible to produce extra ice in the Arctic winter, but the presence of
this ice will help the ice-albedo feedback only if it persists through
the summer months, so that the ice can reflect sunlight. We anticipate
that production of ice will be more cost-effective in certain regions
than in others: extra ice produced too far south will melt too quickly
in the summer to make a difference, while in other regions ice may
naturally survive the Arctic summer anyway. We must therefore calculate
the rate at which the ice sheet melts as a function of its location
during the Arctic summer, to quantify the effect of adding ice during
the winter months and to determine where such an action will have the
greatest effect. Here we present a first-principles model for the
decrease in ice thickness due to summer ice melting, benchmarking it
against ice thickness and meteorological data. To calculate the summer
melting of ice, we construct a model including heating of the ice by
insolation and contact with warm air. After every time interval Δt, the
thickness of the ice decreases by an amount Δx, where S is the
insolation, a the albedo, f the cloud cover, and h is a heat transfer
coefficient. As before, ρi = 917 kg m−3 is the ice density, and li =3.32
× 105 J kg−1 is the latent heat of fusion. We take where ϕ is the local
latitude (75° at the average location of the buoy), the Sun\'s
declination is δ = 23.44° sin (2π (t − t0)/365.25 d)), where t0 refers
to the vernal equinox, and HA = 2π (t − 12 h)/(24 h) is the hour angle
(equal to zero at noon). If this formula returns a negative insolation,
S = 0 is assumed. Both albedo and cloud cover can vary with location and
time of year. Generally, the albedo is characteristic of ice or snow, a
= 0.75, at the beginning of the summer, switching to a much lower albedo
in the range 0.2--0.6 at the end of the summer, as melt pools like that
depicted in Figure 5 develop \[Agarwal et al., 2011\]. The transition
apparently occurs at this location after 15 TDDs (roughly 29 June), and
we let the late-summer albedo be a free parameter in our model. As for
the cloud fraction, the Cloud-Aerosol Lidar with Orthogonal Polarization
sensor in the Afternoon Constellation of Earth-observing satellites
indicates that the a typical cloud fraction for regions of the Arctic
with over 90% ice coverage is f = 0.832 \[Chan and Comiso, 2013\].

Where V is the average wind speed, in m/s, valid for 2 m s−1 \< V \< 20
m s−1 \[Osczevski, 1995\]. If T \< 273 K, this term is assumed to
vanish. While wind speed data are lacking at the specific position of
the buoy, the typical wind speed in the Arctic summer is 5 m s−1
\[Kalnay et al., 1996\]. For V = 5 m s−1, h = 27.1, and h varies from
this value by only 10% over the range 3--8 m s−1. Temperature data from
the buoy are available at 2-hour intervals. Because we wish to focus on
regions where ice persistence is marginal, we benchmark against data
from ice mass balance (IMB) buoy (ID code: 30106) deployed in April 2007
by the Sea-Ice Experiment -- Dynamic Nature of the Arctic (SEDNA)
campaign in the Beaufort Sea \[Perovich et al., 2015\], an Arctic
location that experienced a dramatic loss of sea ice coverage at the end
of summer 2007 despite being covered with ice in most previous summers.
Because the IMB buoys are designed to function in thick, perennial ice
sheets, data was only collected through 25 August 2007, data collection
ceasing shortly after the part of the ice sheet that the IMB buoy was
mounted to melted to less than 1.5-m thick. This particular buoy is also
useful because of its limited coverage area. The buoy drifted only in an
area spanning a longitudinal range of 73.1°N--77.4°N and a latitudinal
range of 146.6°W--159°W, with coverage area of only 1.68 × 105 km2,
smaller than the coverage area of other buoys.

In Figure 6 we show the results of our model calculation using the
temperatures at the location of buoy 30106, benchmarked against the ice
thickness it recorded. We display ice thickness as a function of TDDs.
The first day above freezing (TDD = 0) was 4 June, and 32 TDDs had
elapsed by 25 August, after which the buoy stopped recording data. In
the last summer, ice melted by insolation even though the temperatures
were essentially at or below the freezing point. Around 29 June, at 15
TDDs, melt pools became prominent enough to lower the albedo, although
it is difficult to constrain the melt pool fraction. We start our
calculations presuming initial thickness of 2.7 m, and assume three
different late-summer albedos: a = 0.6 (blue curve), a = 0.4 (purple
curve) and a = 0.2 (red curve). The observed ice thickness (green
crosses) are well matched by a model in which a = 0.30. For this value
of the albedo, the late-summer melting rate matches the observed rate of
4.6 cm per TDD. [These calculations highlight the importance of
insolation as the driver of melting: the melting rate due to heat
transfer alone]{.underline} would be (h/ρi li) = 0.77 cm per TDD, and
after 35 TDDs[, the ice would only decrease in thickness by 0.27 m.
Thus, our results are most sensitive to assumptions about albedo, and
relatively insensitive to assumptions about temperature and wind
speed]{.underline}.

Summer ice thickness as a function TDDs (see text for definition). The
black circles represent ice thickness and temperature data returned from
Buoy 30106 in the Beaufort Sea. TDD = 0 corresponds to 4 June, and TDD =
32 corresponds to 25 August, after which the buoy ceased to return data.
The colored curves represent our model predictions, assuming different
values of the late-summer albedo. An albedo of 0.3 closely matches the
data. [The fact that ice thickness decreases in late summer without an
increase in TDDs signifies that melting is predominantly attributable to
insolation.]{.underline}

[The fact that insolation dominates, and melting is insensitive to the
details of the air temperature, suggests that we can treat the two
effects separately.]{.underline} We assume that the albedo changes
abruptly on 30 June, from 0.75 to 0.30. We find that insolation alone is
responsible for 1.11 m of melting over the entire summer at 90°
latitude. The amount melted increases with more southerly latitudes,
climbing to 1.22 m at 75°N, and 1.38 m at 65°N. The melting of sea ice
is mostly due to insolation, which is more-or-less independent of the
air temperatures, as well as heating by the air. We predict that at
75°N, by the end of the summer, the combined effects of insolation and
32 TDDs would lead to 1.47 m of melting: 1.22 m from the insolation, and
0.25 m from the heating by air. In this sense, insolation at 75°N is
equivalent to 158 TDDs (or 144--179 TDDs at other latitudes). The sea
ice at 75°N in the Beaufort Sea does not melt completely, only because
that region experiences net negative thawing degree days, with TDD =
−200 (Figure 3).

2.4 Effect of Thicker Ice in the Arctic Summer

With a model in hand to calculate the thickness of ice over the course
of an Arctic winter and summer, we can estimate how well adding 1 m of
ice to the Arctic can counteract existing trends. It is noteworthy that
half of the Arctic sea ice currently has a mean annual thickness of only
1.5 m (Figure 3). Adding 1 m of ice in the course of one winter is a
significant change. Also evident from Figure 3 is the fact that the mean
annual thickness of ice decreased by 0.58 m per decade over the years
2000--2012 \[Lindsay and Schweiger, 2015\]. [Adding 1 m of ice to the
average thickness of the Arctic is equivalent to instantaneously setting
back the clock about 17 years. Implementation over the entire Arctic in
the early 2030s, in 1 year adding 1 m of ice, would reset the clock to
the present day, instead of the largely ice-free summer state one
expects by the 2030s.]{.underline}

But in fact, the effects are likely to be cumulative. [Artificial
pumping could add an additional 1 m of ice every winter. In this sense,
implementing artificial pumping in 10% of the Arctic Ocean could have
the effect of offsetting 1 m per decade decline in mean annual sea-ice
thickness, more than enough to counteract current trends.]{.underline}

Another way to judge the efficacy of increasing ice thickness is to
assess how much longer ice extent would survive in the summer.
Currently, we expect ice of thickness 2.7 m to survive the summer at the
location of the Beaufort Sea buoy, melting only 1.5 m; but if the ice
started the summer thinner than 1.5 m, it would melt before the end of
the summer. Using our melting model described above, we calculate that
sea ice would survive the summer if it started at 1.5 m or thicker,
would melt on 15 September if it started at 1.4 m, 18 August if it
started at 1.2 m, and 4 August if it started at 1.0 m. From these
calculations [we estimate that each 0.2 m of ice thickness would delay
the melting of the sea ice by approximately 3 weeks, depending on the
exact initial thickness.]{.underline} Very similar results obtain at
different latitudes. As seen in Figure 1, survival of the ice through
the Arctic summer is marginal in over half of the Arctic Ocean; in those
regions, artificial pumping over the Arctic winter to increase ice
thickness by 1 m translates into several months of extra ice extent,
potentially enough to last the summer.

We note that if the ice were to survive the entire summer, instead of
there being no ice over the entire summer, the albedo difference (0.3
versus 0.06) would be sufficient to reflect back 2.3 × 108 J m−2 of
sunlight over the course of the summer. Assuming the loss of albedo
takes place over the entire 107 km2 of the Arctic Ocean, this would
represent a direct global, yearly averaged radiative forcing of 0.14 W
m−2, which by itself is a significant portion of the global
anthropogenic radiative forcing, approximately 1 W m−2.

Alternatively, we can consider the effect of increased air temperatures.
[We assume that insolation would not be quite sufficient to melt the
ice, but that the extra heating from the warmer air would cause the ice
to melt. In that case, addition of 1 m of ice therefore counteracts a
melting rate of 0.77 cm per TDD,]{.underline} [extending the duration of
the ice]{.underline} by about 130 TDDs. Given that locations in the
Arctic Ocean typically experience 0 to −200 TDDs (Figure 7), an extra
130 TDDs to melt the sea ice is significant. Since ice melts over the 4
months of June--September, 130 TDDs is equivalent to an increase of
about 1.0°C. It is noteworthy that temperatures in the Arctic in summer
2007, which had exceptionally low sea ice extent, were about 0.5°C
warmer than the 1971--2000 average \[Kumar et al., 2010[\]. Artificially
enhancing the thickness of Arctic sea ice can significantly offset the
melting of ice by warmer air temperatures.]{.underline}

TDDs experienced by different parts of the Arctic in summer 2009,
computed using daily mean temperatures from the National Centers for
Environmental Prediction dataset. The silver contour hugging the
coastlines shows where the net TDDs is zero. Most of the Arctic Ocean is
seen to experience between 0 and −200 TDDs per summer. Figure courtesy
Yanling Yu and James Maslanik.
http://psc.apl.washington.edu/nonwp_projects/landfast_ice/freezing.php

Moving forward, analysis is needed to identify where the multiyear ice
is decreasing in thickness or where the net TDDs are increasing. Our
[analysis so far shows that artificial thickening of the ice can
counteract a roughly 1°C temperature increase across the
Arctic]{.underline}. Or, for ice that is marginally able to survive the
summer, artificial thickening of ice keeps the ice frozen throughout the
summer when it might otherwise melt. [Addition of 1 m of ice each winter
throughout 10% of the Arctic Ocean would offset the current decrease in
ice thickness observed since 2000. The potential effects are
significant, and it is worth examining how they might be
implemented.]{.underline}

**Wind pumps are feasible and cover and are able to make 1.5 meters of
ice over an area.**

**Desch et al. 16**\-\--Professor of astrophysics in the School of Earth
and Space Exploration at ASU (Steven, Nathan Smith, Christopher Groppi,
Perry Vargas, Rebecca Jackson, Anusha Kalyaan, Peter Nguyen, Luke
Probst, Mark E. Rubin, Heather Singleton, Alexander Spacek, Amanda
Truitt, Pye Pye Zaw, Hilairy E. Hartnett; "Arctic ice management",
American Geophysical Union, 12/16/16,
https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2016ef000410)

In this section we examine the feasibility of creating machines or
devices that could use wind power to pump roughly 1.3 m of water over
the course of the Arctic winter, sufficient to thicken the ice around
the device by 1 m. Our goal is to demonstrate feasibility and to provide
insights into the scale of the devices. A more detailed design, to be
undertaken in conjunction with Arctic engineers is deferred to future
investigations.

3.1 Energy Requirements

As described in Section 2, [increasing the ice thickness by 1.0 m
requires pumping about 1.3 m of water, equivalent to about 1.4 m of ice.
This water must be pumped using local energy sources, which in the
Arctic winter means using wind. Fortunately, wind is plentiful in the
Arctic.]{.underline}

Figure 8 shows the average wind speed in the Arctic over the decade
1986--1996 \[Kalnay et al., 1996\]. [The average wind speed over the
whole Arctic is Vw = 6.4 m s−1. If this wind is intercepted by a turbine
with effective area like a windmill with 6 m-diameter blades, the
intercepted power will be π(3 m)2 (1/2) ρa Vw3 = 5.2 kW, sufficient to
pump water a height of 7 m at a rate of 7.5 kg s−1, or 27 metric tons
per hour,]{.underline} assuming ρa = 1.4 kg m−3 (appropriate for the
Arctic winter) and an efficiency of 10%. (It must be noted that wind
power density scales as wind speed cubed, so using the mean speed 6.4 m
s−1 to derive a power density 180 W m−2 potentially underestimates the
average power density. We find that the actual time-averaged power
densities range from 170 W m−2 near Greenland to 700 W m−2 in the
Barents and Beaufort Seas. [Over the course of an Arctic winter, this is
sufficient to pump enough water to make 1.5 m of ice over an area
approximately 0.1 km2.]{.underline} Steel wind pumps like those used in
agricultural settings for a century typically achieve efficiencies
approximately 13%. An example is a commercial windmill 12-m tall, with 6
m-diameter blades, rated to pump 9.6 kg s−1 or 35 m3 h−1 in winds 4.5--7
m s−1 like those in the Arctic
(http://www.ironmanwindmill.com/images/brochure/brochure.pdf, 10 Jul.
2016). [Using different wind turbines, efficiencies closer to 30% would
seem achievable, which would pump enough water to cover 0.3
km2.]{.underline} Sufficient wind energy exists to pump the required
amounts of water, but would require on the order of 10 windpumps per
square kilometer to capture it.

3.2 Description of the Wind-Powered Pump and Its Implementation [We
propose that a windpump mounted on a large buoy, could perform the
function of capturing wind energy to pump seawater to the
surface.]{.underline} While a complete set of design specifications for
a wind-powered pumping device and entire AIM system are beyond the scope
of this paper, the basic requirements of such a system can be
identified. The basic components of such a device would include: a large
buoy; a wind turbine and pump, [drawing up seawater from below the ice;
a tank for storing the water; and a delivery system that takes the water
periodically flushed from the tank and distributes it over a large
area]{.underline}. The goal is to raise enough water over the Arctic
winter to cover an area approximately 0.1 km2 with approximately 1 m of
ice. A system of such devices would have to be manufactured and
delivered to the Arctic Ocean, probably repositioned each season, and
would need to be maintained. The engineering challenges of translating
even such a common technology to the harsh environment of the Arctic are
daunting. Gusts and lulls may increase wind speeds outside the operating
range of the turbine, reducing efficiencies. Ambient temperatures are
much colder than in other environments; it is a challenge to prevent the
water inside the device (tank, delivery system) from freezing. Ice
riming (on the outside of the device) is a common and serious problem in
the Arctic that a wind turbine design must contend with. The design must
also stabilize the buoy so that high winds do not tip over the wind
turbine and buoy[. Any final design for a buoy-mounted windpump would
have to be developed in conjunction with engineers experienced in
working in polar environments. That said, we note that many of the
needed technologies already have been developed for other
purposes.]{.underline} For example, [several different wind turbine
designs have been used successfully at South Pole station and in the
Arctic]{.underline} (
https://www.asme.org/engineering-topics/articles/arctic-engineering/wind-turbines-whirling-arctic-regions
5 Oct. 2016), and many of the issues associated with storing and
distributing liquid water during the Arctic winter are similar to the
problems associated with supplying drinking water in high-arctic
communities in the winter, such as the need for heated/insulated storage
tanks and distribution systems
(http://sciencenordic.com/arctic-town-has-running-water-just-four-months-year,
5 Oct. 2016).

## Governance Advantage

### 2AC\-\--Testing Key

#### Testing works \-\-- neg examples lacked proper management.

Benjamin K. **Sovacool et al** 5-6-20**25**, Benjamin K. Sovacool,
Director of the Boston University Institute for Global Sustainability
(IGS), is a Professor in the Department of Earth & Environment. He works
as a researcher and consultant on issues pertaining to global energy
policy and politics, energy security, energy justice, climate change
mitigation, and climate change adaptation. Chad M. Baum is an Assistant
Professor at the Aarhus University Department of Business Development
and Technology. He also works for the iCLIMATE Aarhus University
Interdisciplinary Centre for Climate Change. Dr. Livia Fritz is an
interdisciplinary social scientist drawing on approaches from political
theory and Science and Technology Studies to analyze relations between
science, policy and society in the field of sustainability and climate.
Livia studied development studies with a focus on political science at
the University of Vienna and the Institut d'études politiques de Paris
(Sciences Po) and received her PhD from EPFL. Sean Low explores the
politics of science in environmental and technology governance, with a
focus on how novel socio-technical strategies for addressing climate
change are constructed through different practices of expert and
participatory assessment. "Exploring global climate intervention
experiments: sociotechnical promises, innovation dynamics, and perceived
co‑impacts across 20 projects and pilots"
https://doi.org/10.1007/s11625-025-01696-6 //MDC

Conclusion

[[Climate intervention **research, experiments, and pilots** involve a
diversity of actor]{.mark} coalitions, propose solutions to a plethora
of emergent scientific and environmental problems, and are increasingly
coalescing around manifold requirements about how those technologies
will perform into the future]{.underline}. Salient characteristics of
their innovation dynamics and styles, as [revealed by [our
**20**]{.mark} [**case studies** and]{.mark} respondent
[interviews]{.mark} along with ethnographic observations,
[exemplify]{.mark} immense [heterogeneity]{.mark} across attributes as
diverse as efficacy, cost, scale, location, permanence, and
temporality.]{.underline}

In response to a challenge as complex, multi-scalar, and multifarious as
climate change, this reveals how the search for potential solutions
broadly mirrors the complexity of the problem itself. More skeptically,
it might also be that the amount of resources flowing to addressing this
problem, and its diverse impacts, is attracting attention broadly across
the sectors of economy and society. In any case, perceptions of the
different experiments reveal notable tensions between risks and
benefits, with almost one hundred different perceived co-impacts
evident, involving an array of distinct financial and economic,
socioenvironmental, technical, and institutional and political
dimensions. Co-impacts of a socioenvironmental and financial/ economic
nature are notably more commonly identified, especially in contrast to
institutional and political aspects. [Given the broad [consensus
of]{.mark} the [governance challenges of climate intervention
approaches]{.mark} (e.g., NASEM 2019, 2021; Honegger et al. 2022;
Reynolds 2019; Gupta et al. 2020; McLaren and Corry 2021), this
[underscores]{.mark} a possible [neglect of]{.mark} such aspects among
those [**planning** and undertaking the experiments]{.mark} in
question]{.underline}.

The utility of [[climate interventions]{.mark} involving CDR and solar
radiation modification [depends not]{.mark} necessarily [on the
technology, but]{.mark} on [how they are managed]{.mark}, on the actor
[coalitions that]{.mark} [support or oppose them]{.mark}, on the
[innovation dynamics and]{.mark} styles evident, or the [perceived
co-impacts]{.mark} at play]{.underline}. There is some agreement that
[innovations and [experiments have]{.mark} the [potential]{.mark} to
work well, when undertaken [with proper safeguards]{.mark} in place,
properly regulated and enforced, done [in a fully **transparent**
manner, with]{.mark} requisite **[accountability]{.mark}**, and with
robust **[measuring]{.mark} and [monitoring]{.mark}** of environmental
impacts [and]{.mark} **meaningful [engagement]{.mark}** with local
communities]{.underline} (e.g., Boettcher et al. 2023; Gardiner and
Fragnière 2020; Hubert 2021; Nawaz and Lezaun 2024; Nawaz et al. 2024;
Reynolds 2019).

However, [[when]{.mark} environmental [impacts are poorly
managed]{.mark}, when [promises are overhyped]{.mark}, when [community
well-being or social attitudes are downplayed]{.mark} or disregarded,
[uncertainty can]{.mark} [give rise to public opposition and]{.mark}, in
extreme cases, a call for moratoria or sustained
[protest]{.mark}]{.underline}. In this way, any purported benefits of
climate interventions can be as much a mirage as a miracle; they can
quickly evaporate under the wrong sociotechnical, innovation, or
political conditions.

### 2AC\-\--Governance Key

#### Governance is key \-\-- otherwise unregulated experiments proliferate.

Sikini **Jinnah et al** 8-8-20**24**, Dr. Sikina Jinnah is a Professor
of Environmental Studies, an affiliated graduate faculty of Politics at
the University of California at Santa Cruz. Dr. Shuchi Talati is a
climate technology governance expert and founder & executive director of
The Alliance for Just Deliberation on Solar Geoengineering. Louise
Bedsworth is Executive Director at the Center for Law, Energy, and the
Environment where she also serves as a Senior Advisor to the
California-China Climate Institute. Michael Gerrard is the former chair
of the American Bar Association's 10,000-member Section of Environment,
Energy, and Resources and a Professor of Professional Practice at
Columbia Law School. Michael Kleeman is a visiting scholar at the School
and senior fellow at the UC Institute on Global Conflict and
Cooperation. Robert Lempert is director of the Frederick S. Pardee
Center for Longer Range Global Policy and the Future Human Condition, a
principal researcher at RAND, and a professor of policy analysis at the
RAND School of Public Policy. Katharine Mach is professor and chair of
the Department of Environmental Science and Policy at the University of
Miami Rosenstiel School of Marine, Atmospheric, & Earth Science. Dr.
Nurse has been a member of the IPCC's research and author team for four
global assessment reports. Dr. Hosea Olayiwola Patrick is a Postdoctoral
fellow in the School of Built Environment and Development Studies,
University of KwaZulu-Natal, South Africa. Masahiro (Masa) Sugiyama is a
Professor at the Institute for Future Initiatives(IFI), the University
of Tokyo(UTokyo). He is an expert on long-term climate policy. "Do small
outdoor geoengineering experiments require governance?" DOI:
10.1126/science.adn2853 //MDC

Political Context

Atmospheric research similar to that proposed through SCoPEx has been
conducted for years under the auspices of basic science (3). However,
understanding the deep uncertainties surrounding SG and the broader
implications of SG research, the Harvard research team communicated
SCoPEx as an SG experiment from the very beginning, even though the
project could have been (disingenuously) framed as one solely interested
in basic science. The SCoPEx research team was transparent about their
plans, regularly engaging with media and other interested parties. These
were socially responsible decisions, which brought with them both
acclaim and scrutiny and informed Harvard's 2019 decision to create an
independent AC. These decisions were prescient, given the recent
increase in activity around SG research.

[[Although taboo]{.mark} for many years, [there has been a noticeable
increase]{.mark} recently [in]{.mark} discussion and activity around
[SG]{.mark} research due to growing concern that greenhouse gas
emissions mitigation and climate change adaptation efforts alone will be
insufficient to limit harm from climate impacts]{.underline}. This
includes activities with the United Nations (UN) Environment Programme
(4), the US Congress and White House Office of Science and Technology
Policy (5, 6), and the US National Academies of Science, Engineering,
and Medicine (7). We have also seen an uptick in discussions of SG and
its governance within international forums, including consideration of
increased assessment activities with the Intergovernmental Panel on
Climate Change (8), and two relatively innocuous, yet nonetheless
controversial, draft resolutions considered (and subsequently withdrawn)
at the UN Environment Assembly (UNEA) in 2019 and 2024. Additional
activity reports in 2023 related to solar radiation modification include
the European Commission, the UN Human Rights Council Commission Advisory
Committee, and the UN Educational, Scientific, and Cultural
Organization.

The [[first]{.mark} outdoor **[marine cloud brightening
experiment]{.mark}** in the United States [was launched in]{.mark}
Alameda, California, in [April 2024]{.mark}]{.underline}. The
experiment, led by researchers from the University of Washington, took
place on the deck of the USS Hornet, a ship docked in Alameda. The city
asserted authority over the experiment location and halted the
experiment a few weeks after its launch owing in large part to
transparency concerns and a lack of research team engagement with the
city (9). [[There has also been an uptick in irresponsible SG
activities]{.mark}, including Make Sunsets' particle release using
balloons in both the United States and Mexico, which were not tied to
any legitimate scientific pursuit or controlled experiment but were
rather a performative endeavor to commercialize SG by creating and
selling unverified "cooling credits]{.underline}." These irresponsible
activities led to an intended ban on SG experimentation by the Mexican
government (9--11) and [[point to a need for research governance that
can]{.mark} both [inhibit irresponsible]{.mark} and/or unnecessary [work
and enable responsible]{.mark}, inclusive, well-designed
[research]{.mark}.]{.underline}

Governance Framework

Harvard's Solar Geoengineering Research Program provided funding for
SCoPEx, and in 2019, Harvard established the AC to provide research
governance for the project. A search committee nominated the initial
committee chair (co-author L.B.) to Harvard's vice provost of research.
The chair then worked with Harvard to nominate and invite initial AC
members, under the assumption SCoPEx would be a domestic experiment. The
AC worked with Harvard and the research team until Harvard's public
announcement of SCoPEx's cancellation in 2024. Over this period, AC
membership shifted, and the AC adopted a co-chair structure (co-authors
L.B., S.J., and S.T.). At the same time, the research team developed and
built the gondola to be used for the experiment and explored possible
launch sites. This included consideration of a site in Sweden for a
potential engineering test flight (i.e., no particle release) that was
cancelled in 2021. After that test flight cancellation, the research
team turned its attention back to possible sites in the United States.

Per its terms of reference, the AC developed a governance framework to
guide evaluation of SCoPEx along several dimensions: engineering and
safety, technical and scientific merit, financial conflict of interest
and transparency, legal compliance, and societal engagement (2). Drawing
on lessons from the scholarly literature and building on previous work
done on public engagement of outdoor experimentation (e.g., 12, 13) and
responsible research and innovation (14), the AC's framework is, as far
as we are aware, the most comprehensive research governance framework to
be empirically applied in the SG field.

Tensions

The process of developing and implementing this framework was complex,
and the AC grappled with various tensions, which are shared here to
assist others in pursuing research governance in the future. The
principal tension was related to societal engagement. The cancellation
of SCoPEx's first proposed engineering test flight in 2021 in Sweden was
due in part to strong resistance from the Saami Council, whom the
research team had not engaged with. Leading up to this 2021
cancellation, the AC disagreed, internally, on whether engagement was
necessary for a test flight that did not include a particle release. In
late 2020, the majority of the AC recommended that once a safety review
was completed with no concerns, the test flight could proceed without
engagement. Following the letter from the Saami Council, the AC
recommended cancelling the planned test flight in Sweden. Although the
Saami's concerns were broader than the lack of engagement, engagement
would have provided an opportunity to discuss and possibly find a path
forward that all interested parties could agree to. Nonetheless, this
disagreement on the AC around engagement brought these tensions into
sharp relief and colored the AC's discussions on this matter for several
years. These tensions surrounded questions about who should do
engagement (e.g., AC, research team, or an outside entity), who should
be engaged (i.e., local and/or global publics), how to ensure the
integrity of engagement processes (e.g., avoiding disruption by bots),
and the type and extent of engagement needed (e.g., informing versus
co-creating). On the latter, for example, some AC members pushed for
following best practices as outlined in the engagement literature, which
demand early engagement that allows time for relationship building with
communities, integrating their questions into the research design, and
co-creation of research questions with communities \[see (15)\]. Others
argued that because SCoPEx would have no environmental impact, such
extensive engagement efforts were not necessary. Other expert groups
have struggled with similar tensions \[see (4)\], which are
fundamentally about whether engagement efforts should be determined by
actual physical impacts of the discrete project or by the broader
meaning of SG research as related to, for example, moral hazard (e.g.,
the debated hypothesis that turning time and resources to SG comes at
the expense of using those resources for mitigation and/or adaptation).
These tensions around engagement extended beyond the AC. Recently, one
leader of the SCoPEx research team cited struggles with the AC about how
to engage with the public as a reason why the experiment was ultimately
canceled (2).

\[image omitted\]

Directly related to engagement were tensions surrounding broader
communication, with disagreement on whether and how to publicly share
information about the AC's deliberations and about completed and ongoing
processes. Some felt that communications should be frequent and robust,
using social media and other modalities to push information out to
ensure transparency. Others were not convinced that this was a need or
were concerned about risks of disruption to both the research itself and
the governance process.

The AC's evaluation of SCoPEx's scientific merit was another area of
tension. The SCoPEx research plan did not fit neatly into any
established processes for scientific review. SCoPEx was internally
funded by Harvard and had not gone through a standard external peer
review process for either funding or publication. Because of the broader
implications of the experiment, it was difficult to consider scientific
merit on its own. Rather, the core question of the scientific review
was, ultimately, whether scientific merit warranted advancing the
project in the context of broader social risks and concerns surrounding
SG. This was a tremendous challenge for the AC, and an area where
greater guidance and clarity is needed for emerging technology
governance more broadly. Drawing from a range of different models, the
AC developed its own review process, involving an interdisciplinary
panel of experts to identify and help recruit reviewers and interpret
and summarize the reviewers' assessments of the research plan (1). The
panel's summary of the reviews \[see (1)\] reflects disagreement between
the reviewers on the scientific merit of the project and, importantly, a
reluctance to separate scientific merit from broader social risks and
concerns, including moral hazard. There were parallel disagreements
within the AC on these points, which was ultimately decided by a vote,
with the majority voting that the bar for scientific merit was met to
recommend that the project move forward to an engagement process.

Finally, the AC grappled with tensions on the timeline and pace of their
work. Some on the AC expressed concern that the urgency of the need for
research necessitated limiting activities not seen as core to the
committee's directive. Others argued that the broader social
implications of the experiment, and that the AC's work could be a model
for future governance efforts, demanded taking the time to, for example,
do more extensive engagement work. This tension cut across the issues of
scope, communications, and engagement discussed above. Tensions around
timing were also practical. Throughout the process, the AC often
experienced long delays in receiving requested information from the
research team (e.g., a research plan for the scientific merit review).

Lessons

[Most of the [tensions]{.mark} described above [are an empirical
manifestation of]{.mark} many parallel [unresolved theoretical
debates]{.mark} in the literature on SG. We argue that most of [these
tensions can]{.mark} [be ameliorated]{.mark} by standardizing and/or
**[centralizing research governance]{.mark}**]{.underline}. A core
lesson from the SCoPEx AC experience is that ad hoc, reactive research
governance, especially at the experiment level, is extremely challenging
and should only be used in the absence of a more standardized or
centralized approach. Tensions, disagreements, responsiveness of the
research team, and, at times, lack of clear leadership (both on the AC
and at Harvard) slowed our work. [The AC also worked on a voluntary
basis, which helped maintain independence from Harvard but also created
challenges related to recruiting diverse members and responding to
events in a timely manner. The [ad hoc, reactive process]{.mark} also
[didn't work]{.mark} well for the research team. [It was unpredictable,
time consuming, and not aligned with]{.mark} timelines for research
[development]{.mark}]{.underline}. The latter is key in that
high-quality engagement requires early collaboration with communities
before research plans are set (15). Scientists cannot effectively
implement this best practice if engagement is undertaken by ad hoc
committees that are established in a reactive manner once research plans
are already developed and funded. Engagement after research plans have
been finalized also disempowers communities who then have less scope for
input, and late-stage engagements may be seen by communities as merely
pro forma.

[Most of the [challenges]{.mark} we faced [could be resolved if research
governance were proactive]{.mark} as well as, at a minimum,
[standardized and]{.mark}, in some cases,
[centralized]{.mark}]{.underline}. Standardized processes or tools for
research governance can provide greater predictability and transparency
for researchers and participants in the governance process. In addition,
standardization can ensure that researchers adhere to theoretical best
practices and provide accountability. Moreover, continuity,
transparency, and predictability might help to overcome some of the
resistance in the research community to engagement efforts, which can be
time, labor, and financially intensive. Because most US SG research
receives private funding, standards should include financial
transparency and a scientific review process commensurate with that
applied to publicly funded research. [[Transparency]{.mark} of research
results and plans [would allow]{.mark} the public to know that [broader
norms]{.mark} around responsible research and innovation are
functioning.]{.underline}

A [[**centralized governance body** would be helpful to determine
standards]{.mark} for different scales or types of
research]{.underline}. Although centralization would yield consistent
and predictable norms that researchers can follow, it will likely be
difficult to establish an accepted centralized governance system rapidly
enough to keep up with the increased pace of SG research activity.
[[Centralization]{.mark} or standardization of research governance
[could be]{.mark} [achieved]{.mark} in various ways. Ideally, it would
be led [by a public entity]{.mark} with enforcement authority that is
informed by a multistakeholder advisory board]{.underline}.
Implementation could be done by universities, nonprofit institutions,
and/or funders through clear standards and/or guidelines for researchers
to follow. An international component would also add legitimacy, a
diversity of views, and more access to local information.

The SCoPEx experience suggests actions that nongovernmental entities,
such as universities or other research organizations, might follow to
provide interim research governance. Most importantly, SCoPEx
demonstrates that even when armed with a robust framework and set of
best practices, these need to be understood, proactively implemented,
and approached with humility and flexibility. Importantly, any such
research governance should be put in place long before any research
plans are finalized. The scope and lines of authority should be clearly
established. For instance, SCoPEx suffered from a lack of clarity on who
was responsible for organizing and funding any engagement
activities---the research team, the AC, or Harvard. This stemmed in part
from a lack of clarity on the purpose and scope of engagement, both
between the AC and the research team and within the AC itself. Such
questions should be resolved at the start of the research governance
process.

The SCoPEx experience also suggests that [[the time is ripe for
governments to begin discussing]{.mark} coordination of **[research
governance]{.mark}**]{.underline}, potentially through the UNEA, which
has already begun to discuss the issue. UNEA-6 in February 2024 saw
clear interest in developing governance guidance and an understanding of
SG from a widely diverse set of countries. UNEA-7, planned for 2025, may
be a critical opportunity to build collaborative SG research governance.
We hope that the learnings from the SCo-PEx AC will inform these and
other future research governance efforts.

### 2AC\-\--AT: Geoengineering Regulated Now

#### Current regulation fails \-\-- it's non-binding.

Edward **Parson and** David **Keith** October 20**24**, Edward A. (Ted)
Parson is Dan and Rae Emmett Professor of Environmental Law and Faculty
Co-Director of the Emmett Institute on Climate Change and the
Environment at the University of California, Los Angeles. Parson studies
international environmental law and policy, the role of science and
technology in policy-making, and the political economy of regulation. He
was formerly a Professor of Public Policy at the University of Michigan.
David Keith is Professor of Geophysical Sciences and founding faculty
director of the Climate Systems Engineering initiative at the University
of Chicago. Best known for his work on the science, technology, and
public policy of solar geoengineering, David led the development of
Harvard's Solar Geoengineering Research Program before moving to Chicago
in 2023."Solar Geoengineering: History, Methods, Governance, Prospects"

3.  THE CURRENT GOVERNANCE LANDSCAPE RELEVANT TO SRM

[While SRM\'s potential future governance needs are expansive, the
[present governance]{.mark} **landscape [is thin]{.mark}**]{.underline}.
Many international regimes have relevant mandates, including those on
climate change, the ozone layer, long-range air pollution, the law of
the sea, and the Antarctic. [Other [regimes]{.mark}, notably in security
and technology cooperation, [may offer]{.mark} relevant
[insights]{.mark} for SRM governance. [But none]{.mark} of these bodies
[has a mandate]{.mark} that would include control of SRM, [or]{.mark}
the [capacity]{.mark} to control it effectively. Several principles of
[customary international law are]{.mark} also [relevant but provide **no
concrete**]{.mark} **[guidance]{.mark}** for potential SRM
use]{.underline} (55, 56). In particular, none takes account of the dual
effects of SRM, which would reduce climate risks but also introduce new
risks (37, 38).

The [[international actions]{.mark} to date most relevant to SRM
[are]{.mark} decisions [under two environmental
treaties]{.mark}]{.underline}. In a 2010 decision (57), the [[Convention
on Biological Diversity]{.mark} "Invite(d) Parties...to consider the
guidance below...(w) [Ensure]{.mark},...in the absence of science based,
global, transparent and effective control and regulatory
mechanisms...that [no climate-related geo-engineering]{.mark} activities
that may affect biodiversity take place, until there is an adequate
scientific basis on which to justify such activities and appropriate
consideration of the associated risks...."]{.underline} Although
sometimes claimed to represent a moratorium (real or "de facto"), this
text\'s advisory language and multiple qualifications mean it neither
creates any legal obligations nor makes a clear declaration of
intentions. [[It is]{.mark} best understood as [a **nonbinding statement
of concern**]{.mark}.]{.underline}

[Parties to the [London Convention and Protocol]{.mark}, which regulate
ocean dumping, have also taken actions of potential relevance to SRM,
based on prior concern with ocean fertilization (OF), a potential CDR
method]{.underline}. Following OF resolutions in 2008 and 2010 (52, 58,
59), parties adopted a 2013 amendment barring "placement of matter into
the sea...for marine geoengineering activities." [Although a 2022
[statement]{.mark} [suggested]{.mark} the aim [that "marine
geoengineering" include]{.mark} marine cloud brightening ([MCB)
and]{.mark} one other [SRM]{.mark} method (60), the amendment explicitly
names only OF and is not yet in force, so its [implications]{.mark} for
SRM [remain hypothetical]{.mark}]{.underline}.

[The 1976 Convention on Environmental Modification ([ENMOD]{.mark}) is a
treaty often proposed as relevant to SRM]{.underline}. Adopted after US
use of defoliants and cloud seeding in the Vietnam War, ENMOD prohibits
military or other hostile use of environmental modification "having
widespread, long-lasting, or severe effects" (61, Article I). [While
ENMOD\'s definition of [environmental modification]{.mark} would clearly
[include SRM, its prohibition]{.mark} [only covers "...military]{.mark}
and other hostile use...as the means of destruction, damage or injury to
any other State Party" (61, Article I). The treaty explicitly exempts
modification for peaceful aims, indeed [charges parties to cooperate in
"...preservation]{.mark}, improvement, and peaceful utilization of the
environment..." (61, Article III)---text [that could]{.mark} be read to
**affirmatively [support]{.mark} international [research]{.mark}**
[programs on SRM]{.mark}]{.underline}.

Several international bodies are starting to address SRM. From 2017 to
2023, the Carnegie Climate Governance Initiative (C2G) briefed national
and international officials on CDR and SRM (62). The 2023 report of the
Climate Overshoot Commission, an independent high-level body on the risk
of exceeding the Paris targets, recommended SRM research and governance
consultations, paired with a moratorium on large-scale interventions
(2). Discussion papers on SRM were issued by the United Nations
Educational, Scientific, and Cultural Organization (UNESCO) and
commissioned by the Human Rights Advisory Council in 2023 (49, 52). At
the United Nations Environment Programme (UNEP), a February 2023 expert
panel called for international SRM assessment and research governance,
while resolutions supporting an ongoing SRM assessment role were
proposed at the 2019 and 2024 UN Environment Assemblies but not adopted
(48, 63). The World Climate Research Programme adopted climate
intervention as a new research initiative in October 2023 (50). [These
[steps signal]{.mark} organizations' [interest in joining]{.mark}
expected [SRM debates]{.mark} and decisions, [but none]{.mark} yet
[engages SRM\'s governance]{.mark} challenges [with specific]{.mark}
diagnoses or [proposals]{.mark}]{.underline}.

#### No treaties cover geoengineering

Daniel Barstow **Magraw and** Patsorn **Udomritthiruj** 1-25-20**19**,
Daniel Barstow Magraw is President Emeritus and Distinguished Scholar at
the Center for International Environmental Law. Patsorn Udomritthiruj
holds a Master of Arts from Johns Hopkins School of Advanced
International Studies (SAIS) and a Bachelor of Arts from Williams
College, demonstrating applied knowledge of social sciences and
expertise in international affairs. "Water and multilateral
environmental agreements: an incomplete jigsaw puzzle" p. 181 //MDC

C. Geoengineering

Geoengineering is the deliberate large-scale intervention in the Earth's
natural systems to counteract climate change. The two approaches
primarily being considered are carbon capture and sequestration (CCS),
i.e., capturing carbon and storing it, and solar radiation management
(SRM), i.e., managing the earth's atmospheric reflexivity to decrease
the amount of energy entering the atmosphere. The methods being
discussed for these have different implications for water depending on
the process and the outcomes. [These [implications are speculative
because little experimentation has been conducted]{.mark} and the
biosphere is so complex, but it is clear that some methods could have
significant impacts on water and more generally, on the
environment]{.underline}. For example, CCS that injects carbon into the
earth could affect groundwater through mobilizing organic and inorganic
compounds and affect seismic activity; and SRM that deposits sulphuric
acid into the atmosphere could affect precipitation patterns on earth
and damage the stratospheric ozone layer.

[[Though some]{.mark} environmental [impacts]{.mark} of geoengineering
[would be covered]{.mark} by existing international law (such as
Principle 21 and the human right to water), [and some
non-binding]{.mark} [guidelines exist]{.mark} (such as the CCS
guidelines published by the World Resource Institute83), [no treaty or
customary law]{.mark} exists that **[coherently and comprehensively
governs geoengineering]{.mark}**.]{.underline}

### 2AC\-\--AT: CIL Turn

#### Geoengineering testing is consistent with international law.

Jesse L. **Reynolds** 6-30-20**20**, Jesse L. Reynolds is an
Emmett/Frankel Fellow in Environmental Law and Policy at the University
of California, Los Angeles School of Law, as well as an associate
researcher at Universiteit Utrecht and a research affiliate at Harvard
University, Massachusetts. He has degrees from Tilburg University; the
University of California, Berkeley; and Hampshire College, and has been
a US Environmental Protection Agency Science to Achieve Results Graduate
Fellow and a Fulbright Scholar. "Solar Geoengineering Could Be
Consistent with International Law"
https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3639214 //MDC

Conclusion

The [**[large-scale outdoor testing]{.mark}** and deployment [of]{.mark}
solar [geoengineering]{.mark} could be [consistent with international
law]{.mark}. This is because the [legal order's]{.mark} default is
[permissive and grounded in]{.mark} [sovereignty, and]{.mark} because
there are [no]{.mark} existing legal [rules]{.mark} that
[preclude]{.mark} solar geoengineering]{.underline}. As noted, this does
not mean it necessarily would be so. This section has found a handful of
modest constraints. [[Under]{.mark} the customary international law of
[transboundary harm, the]{.mark} acting [state would]{.mark} need to
[act with]{.mark} due [diligence and satisfy]{.mark} mostly [procedural
duties]{.mark} such as prior impact assessment, notification, and
consultation. Solar geoengineering may not be for hostile
purposes]{.underline}. In the marine environment, it would need to be
done in ways that ultimately prevent, reduce and control pollution. And
on the high seas and in outer space, the solar geoengineering state must
act with due regard for other states' rights and interests. [A
[reasonably **well designed field test**]{.mark} or use of solar
geoengineering [to reduce climate]{.mark} change [risks]{.mark} should
be able to [satisfy these]{.mark} constraints]{.underline}. Furthermore,
[in some ways [international law tilts]{.mark} favourably
[toward]{.mark} solar [geoengineering. ENMOD requires]{.mark} its
[parties to cooperate in]{.mark} peaceful [environmental
modification]{.mark}, such as solar geoengineering. And more
importantly, [the UN climate regime]{.mark} may be [read as
**encouraging**]{.mark} **solar [geoengineering]{.mark}**]{.underline}
for several reasons, among which is that it could be a precautionary
response to climate change.

#### Customary international law is unworkable -- nobody cares

**Joyner 19** -- Professor of Law at University of Alabama Law School,
J.D. from Duke University School of Law, an M.A. in political science
from the University of Georgia, and a PhD in law from the University of
Warwick School of Law \[Daniel, "Why I Stopped Believing in Customary
International Law," Asian Journal of International Law, 9 (2019), pp.
31--45 doi:10.1017/S2044251318000188\]

On balance, in my reading and consideration, I have become persuaded
that [[the problems]{.mark} which have been identified in the processes
of identification and determination [of CIL]{.mark}, and their
implication for the international legal system, [are of such
a]{.mark}]{.underline}[ **[serious and
institutionalized]{.underline}**]{.mark} [nature [that I]{.mark} now
[presumptively distrust any statement about what is or is not]{.mark} a
rule of [CIL]{.mark}.]{.underline} Basically, as I've learned more about
how CIL is used in practice, I've **[[stopped believing in CIL as
a]{.mark} supportable [source for]{.mark} the creation of [international
legal obligation]{.mark}.]{.underline}** I have become convinced that if
CIL is going to retain its place as a source of international legal
obligation, the process of identifying and authoritatively determining
CIL must evolve to more objectively evidence the positive assent of
states to the making of customary rules.

cil and its several identifiers

The orthodox view of howCIL works is deceptively simple. One looks at
the record of state actions and statements and if something like a
supermajority of states have engaged in the same or similar practice
with regard to some normative principle of international interaction,
and have engaged in this practice for a long time with little
inconsistency, and if they appear to do this because they think it is
legally obligatory for them todoso(oratleast that doing so is in harmony
with existing law), then those two elements of state practice and opinio
juris (i.e. one objective element and one subjective element) evidence
that states have accepted this principle as a rule of customary
international law.5 If this is determined to be the case, the rule of
customary law becomes a legal obligation for all states, even for those
who did not participate in the rule's creation, subject only to the
caveat that states who persistently object to the creation of the rule
throughout its development are exempt fromthisobligation. Again, the
idea is that states can agree on rules governing their behaviour through
their customary conduct and sense of legal obligation attaching to it,
without having to put this obligation into writing. Proponents of the
utility of CIL argue that such a source of legal obligation has always
been, and continues to be, a necessary component of the international
legal system for a number of reasons. These include its role as a source
for overarching systemic or secondary rules for the international legal
system, its role in addressing issue areas not covered by an existing
treaty including technologically new or dynamic issue areas, its role in
filling in gaps in existing treaty coverage, and its role in creating
parallel obligations to those included in the provisions of
broadlysubscribed-to treaties in order to make those treaty provisions
binding upon all states, including treaty outliers.6

The problematic aspects of this concept of a legal source, however,
become apparent pretty quickly upon closer examination. [With CIL,
the devil really is in the details]{.underline}. How many states does it
take to manifest their state practice in support of a new rule of CIL?
How long must this practice have continued? What kind of state practice
counts? How much inconsistent state practice can be tolerated? Does the
practice of some states matter more than others?

The questions concerning the subjective element of opinio juris are even
more problematic. What doesit mean forastate to act underasense of legal
obligation? Do they actually have to think that what they're doing is
required by existing law? And what does it mean for astate to "think"
this? If so, isn't there a real chicken and egg problem there---i.e.
what did the first state who acted in this way think? Were they just
deluding themselves? And how are we supposed to know what states are
thinking about why they are acting in a certain way? They seldom discuss
their subjective understanding of their legal obligations. So what kinds
of evidence will count in manifesting that opinio juris? How much of
that evidence is required, and of how many states, before we can say
that the subjective element is satisfied?

When I teach the principle of customary international law to my classes,
and the brighter students start to ask these questions, I tell them
that, as a practical matter, international lawyers look to several
different law-identifying agencies to sort through what is CIL and what
is not. The first and most important of these is international courts,
including the ICJ.

International Courts

So how do international courts sort out, or identify, the existence of a
rule of CIL? This question has actually been one of the most fascinating
subjects of the recent wave of scholarship on CIL. [A number of authors
have conducted]{.underline} [**[empirical studies]{.underline}** [of
cases decided by international courts]{.underline}]{.mark}[, including
the ICJ, international criminal tribunals, and others.]{.underline} What
they have found is that these august international judicial bodies
typically [[do not display systematic, rigorous analysis of
evidence]{.mark} falling [under the framework]{.mark} of the orthodox
two-element test.]{.underline} Stefan Talmon, for example, has
criticized the ICJ itself for engaging in a deductive and assertive, as
opposed to a properly inductive, methodology when considering evidence
of CIL, and for thereby engaging in judicial legislation---although he
also observes the perceived need for the Court to take this approach. As
he explains:

In a majority of cases the Court has not examined, whatever it may say
on the matter, the practice and opinio juris of States, but has simply
asserted the rules which it applies. This methodological approach has
been criticized even by its own members. But assertion is not always
merely a convenient methodological shortcut. There are situations where
the inductive and deductive methods will not allow the Court to fulfil
its normal judicial function of determining the applicable rules of
customary international law because induction is virtually impossible,
or because there are no relevant general rules or principles from which
to deduce the applicable law. Judicial assertion is the price States
have to pay for the Court not to declare an epistemological non liquet.7

In another such study, involving a broader range of international
judicial bodies, Stephen Choi and Mitu Gulati found that:

Courts in this area, it turns out, do not neatly separate out the
evidence that they look at in terms of saying X piece of evidence helped
persuade them on prong one and Y piece of evidence helped persuade them
on prong two. Instead they tend to bundle all the evidence into a single
discussion and then assert whether the two-prong test is satisfied (and
sometimes they do not even mention the two-prong test).8

Choi and Gulati are less sympathetic than Talmon to considerations
regarding the judicial function and the need for CIL to serve a
jurisprudential gap-filling role:

[The **[data suggest]{.mark}** that [international courts do not come
anywhere close to]{.mark} engaging in the type of analysis the
officially stated two-part rule for the evolution of [CIL]{.mark} sets
up. Instead,]{.underline} **[as best]{.underline}** [we can
tell, [courts analyzing CIL]{.mark}]{.underline}---whether they find it
or not---[[are]{.mark} generally engaged in a forward-looking
or [aspirational]{.mark} exercise.9]{.underline}

These studies have helped to shed light on how international courts in
fact go about looking for CIL, what kinds of evidence they think are
relevant to that determination, and what standards they actually apply
to that evidence. [And, as the studies show, international courts cannot
be said to be exemplary in their application of the orthodox two-element
approach to CIL identification, which remains the orthodoxy in all of
the textbooks on international law, and which has been reaffirmed
through the recent work of the ILC.]{.underline}

[[This fact]{.mark} alone [is]{.mark}]{.underline}[ **[extremely
problematic]{.underline}**]{.mark}**[.]{.underline}** Inasmuch as my
standard answer to my students is that their methodological questions on
identifying and determining [CIL in practice]{.underline} can be
answered by reference to how international courts go about this
exercise---which really ought to be a sound answer to those
questions---[the fact that [international courts demonstrably do not
apply the principles]{.mark} that I am teaching them as orthodox,
seriously decreases my own confidence in that answer.]{.underline}

### 1AR\-\--AT: CIL Turn\-\--Geoengineering Consistent with I-Law

#### The U.S. would invoke the necessity clause \-\-- that avoids conflicts with customary international law.

Jesse L. **Reynolds** 6-30-20**20**, Jesse L. Reynolds is an
Emmett/Frankel Fellow in Environmental Law and Policy at the University
of California, Los Angeles School of Law, as well as an associate
researcher at Universiteit Utrecht and a research affiliate at Harvard
University, Massachusetts. He has degrees from Tilburg University; the
University of California, Berkeley; and Hampshire College, and has been
a US Environmental Protection Agency Science to Achieve Results Graduate
Fellow and a Fulbright Scholar. "Solar Geoengineering Could Be
Consistent with International Law"
https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3639214 //MDC

Necessity

[[If]{.mark} a state that conducts [geoengineering were]{.mark} to be
[accused]{.mark} by another [of]{.mark} acting in [breach of]{.mark} its
[international]{.mark} legal [obligations, the accused state may
invoke]{.mark} circumstances in which the customary international law of
state responsibility preclude an act from being wrongful. The most
pertinent of these is **[necessity]{.mark}**, in which the act that
would otherwise be contrary to international law "is the only way for
the State [to safeguard an essential interest]{.mark} against a grave
and imminent peril]{.underline}", according to the ILC's Draft
Articles.78 [[Climate change]{.mark} will [threaten]{.mark} some states'
[essential interests]{.mark}, including the very existing of low-lying
island states. A state could assert that solar [geoengineering is the
only way]{.mark} for it [to safeguard such an **essential
interest**]{.mark}, despite any possible ways in which the activities
would be contrary to international law]{.underline}.

#### CIL does not preclude geoengineering, or its [thumped]{.underline}.

Jesse L. **Reynolds** 6-30-20**20**, Jesse L. Reynolds is an
Emmett/Frankel Fellow in Environmental Law and Policy at the University
of California, Los Angeles School of Law, as well as an associate
researcher at Universiteit Utrecht and a research affiliate at Harvard
University, Massachusetts. He has degrees from Tilburg University; the
University of California, Berkeley; and Hampshire College, and has been
a US Environmental Protection Agency Science to Achieve Results Graduate
Fellow and a Fulbright Scholar. "Solar Geoengineering Could Be
Consistent with International Law"
https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3639214 //MDC

Customary international law

Solar geoengineering would entail the use of territory and natural
resources. [A [state's sovereignty]{.mark} over its territory
[is]{.mark} arguably the [foundation of international law]{.mark}.21
States also have permanent sovereignty over their natural
resources]{.underline}. This has been expressed in multiple UN General
Assembly resolutions22 and confirmed as a rule of customary
international law by the International Court of Justice (ICJ).23

Sovereignty is not absolute: states are constrained by international
law's obligations. Importantly, solar geoengineering would affect other
states' environments. The foundational Stockholm and Rio Declarations
couple states' "sovereign right to exploit their own resources pursuant
to their own environmental and developmental policies" with their
obligations regarding harm that would be transboundary (that is, to
other states or to areas beyond national jurisdiction).24 The ICJ has
recognized at least some of these obligations as customary international
law,25 although the individual rules' precise contours and legal status
are for the most part somewhat unclear. [Regardless, pursuant to these,
the source [state need not prevent]{.mark} [all transboundary]{.mark}
environmental [harm but instead]{.mark} must [comply with]{.mark}
various, mostly [procedural duties]{.mark} -- such as prior [risk
assessment, notification]{.mark} of and (if requested) consultation with
potentially affected states, [and]{.mark} taking appropriate substantive
[measures to]{.mark} prevent or [minimize risks]{.mark}.26
**[None]{.mark} of these duties [preclude]{.mark} solar
[geoengineering]{.mark}**.]{.underline} Ultimately, [a [state
may]{.mark} undertake or [approve]{.mark} an [action that causes
transboundary risks]{.mark} or certain negative impacts on other states.
In fact, [such **actions occur regularly**]{.mark}]{.underline}.27

## Disadvantages

### PTX\-\--Link Turn

#### Geoengineering is [bipartisan]{.underline}.

Corbin **Hiar** 3-2-20**23**, Hiar is a journalist for E&E News. A
former fellow of the National Press Foundation's Paul Miller program and
the University of Rhode Island's Metcalf Institute, he previously
reported on the environment at the Center for Public Integrity and what
is now known as S&P Global Market Intelligence. "Blocking sun rays finds
support in the Senate" Nexis Uni, accessed via University of Michigan
//MDC

[[Senators on **both sides of the aisle** are open to funding research
on]{.mark} solar [geoengineering]{.mark},]{.underline} a little
understood and potentially dangerous method of blocking the sun\'s rays
to quickly reduce global warming. [Their receptiveness comes after years
of Senate apprehension over such funding. While the House has passed
bills to study the method - also known as solar radiation management -
those efforts have struggled to gain traction on the other side of the
Capitol. But more [leaders in Washington, Beijing and other capitals are
reviewing geoengineering]{.mark} technology while their economies
continue to burn fossil fuels - the main cause of climate
change]{.underline}.

There is also a growing scientific debate about the viability of solar
radiation management as an emergency measure to protect ice sheets,
ecosystems and low-lying nations from the worst impacts of global
warming. \"[Climate change is to a point where **[we should look at
everything]{.mark}**,\" Sen. John [Hickenlooper]{.mark} (D-Colo.) [told
E&E News]{.mark}]{.underline}. A former petroleum geologist,
Hickenlooper won his seat in part by campaigning against that called for
a federal jobs guarantee to help rapidly scale up climate mitigation and
adaption efforts. \"[[I think it\'s sensible]{.mark},\" Sen. **Lisa
[Murkowski]{.mark}** (R-Alaska) [said]{.mark} of geoengineering research
and small-scale testing. Her state is on the front lines of climate
change, with the Arctic portions of Alaska warming more than twice as
fast as the rest of the globe, according to NOAA. \"I have had
constituents come to me with proposals. I have been to Arctic
conferences where we\'ve been presented these,\" she said. \"I haven\'t
done anything legislatively to address any of it. But it is
interesting]{.underline}.\" Many academics have long considered solar
radiation management too dangerous to research . That\'s because the
process - which can involve reflecting sunlight by shooting aerosols
into the stratosphere or increasing marine cloud cover - could create
new geopolitical tensions and distract from the urgent need to slash
emissions of carbon dioxide and other heat-trapping gases. Those
concerns were echoed by some senators. \"Are you talking about the stuff
that people are worried is going to start a war?\" Florida Sen. Marco
Rubio, the top Republican on the Select Committee on Intelligence, said
when asked about supporting geoengineering research. He spoke with E&E
News on Tuesday, shortly after The Washington Post reported that top
national security officials gamed out how to avoid conflicts triggered
by weather or precipitation changes blamed on geoengineering. \"I\'m not
downplaying it or being negative about it,\" Rubio added. \"I just
don\'t know enough about it to give you an informed opinion about
whether we should be spending more money on it.\" Sen. Sheldon
Whitehouse (D-R.I.), a leading advocate of aggressive climate action,
said \"most of the geoengineering schemes that I\'ve heard about create
massive, massive unintended consequence risks.\" [Yet even he remains
open to funding solar geoengineering research. \"I suppose [**knowledge
never hurts**,\" Whitehouse said]{.mark}. \"But at the end of the day, I
suspect what the research will prove is that these are extremely
dangerous risks compared to the obvious one right in front of us of stop
burning the goddamn fossil fuels]{.underline}.\" On Monday, prominent
scientists from around the globe urged policymakers to invest in a major
expansion of geoengineering studies and field experiments, which they
argue are necessary to understand whether the potential benefits of
solar radiation management outweigh its risks. From sci fi to spending
bills Geoengineering has long been a source of inspiration for science
fiction, such as the movie and TV show Snowpiercer . But until recently,
it hadn\'t attracted much attention on the Hill or K Street,
congressional records show. The most recent hearing . In 2019, House
appropriators directed NOAA to begin \"observations, monitoring, and
forecasting of stratospheric conditions and Earth\'s radiation budget.\"
As part of that new program, they specifically called on the agency to
\"improve the understanding of the impact of atmospheric aerosols on
radiative forcing as well as on the formation of clouds, precipitation,
and extreme weather.\" Kelly Wanser, the executive director of
SilverLining, said numerous lawmakers back continued spending on that
NOAA program . \"We\'ve had over 50 offices, almost evenly balanced
between Democrats and Republicans, supporting\" that funding, Wanser
said. \"There are equivalent \[appropriations\] requests for the
Department of Energy too, related to cloud aerosol research.\" Last
year, appropriators also ordered the White House Office of Science and
Technology Policy to prepare a five-year research plan on \"rapid
climate interventions.\" Outside of the appropriations process, however,
legislative proposals related to geoengineering have floundered. A 2019
bill from then-Rep. Jerry McNerney (D-Calif.) would have directed NOAA
to prioritize research into the \"effects of proposed interventions in
the stratosphere and in cloud-aerosol processes.\" The legislation was
approved by a House Science, Space and Technology subcommittee but was
never sent to the floor. McNerney tried again when Congress debated the
National Science Foundation reauthorization in 2021. [[An
amendment]{.mark} from him and Rep. Peter Meijer (R-Mich.) [would have
allowed NSF to research geoengineering. \"We cannot just hide our heads
in the sand]{.mark} and hope for the best,\" he said during the House
Science committee\'s June 2021 markup of the NSF bill. \"Some research
in solar radiation management strategies is already taking place in
China, and it\'s imperative that the appropriate authorities are leading
this initiative to ensure safe practices are being promoted and proper
governance is being applied]{.underline}.\" The committee approved of
McNerney and Meijer\'s provision and the NSF reauthorization bill passed
the House later that month. But the bipartisan amendment was ultimately
stripped out of the bill when it was folded into the CHIPS and Science
Act, a 2022 semiconductor subsidy law that also set the research
priorities for NSF and other science agencies. McNerney and Meijer are
now both out of office. [But some [lawmakers expect]{.mark} that [the
fringe issue they once championed could]{.mark} soon [gain **widespread
support**]{.mark} in Congress. \"[It\'s emerging today and before long
it will be mainstream]{.mark},\" said Sen. Kevin Cramer
(R-N.D.).]{.underline}

## Counterplans

### Federal Government Key

#### The [federal]{.underline} [government]{.underline} is key \-\-- private sector and state counterplans fails.

Aayan **Khasgiwala** 4-25-20**25**, Plan II Honors and Economics Student
at The University of Texas at Austin. "Engineering the Future: The Case
for Geoengineering as the Key to Solving Climate Change" p. 43-46 //MDC

7.2 Who is Responsible for Implementing Geoengineering?

Having examined the science, consequences, benefits, and ethical
considerations of geoengineering, the final part of this thesis will
explore the question of implementation: [Who should be responsible for
carrying out these strategies? As noted in Section 6, initiatives such
as the development of sponge cities are typically led by government
entities, but the question of which level--federal, state, or
local---remains a matter of debate]{.underline}. While this thesis
cannot offer a definitive answer, it aims to highlight the potential
actors capable of facilitating the adoption of geoengineering efforts.
[[Central to]{.mark} this [discussion is the recognition]{.mark} [that
geoengineering requires **large-scale implementation**]{.mark}; no
technological solution will yield meaningful benefits unless it is
adopted broadly and systematically]{.underline}.

First, we can consider the smallest potential actor: the individual.
Unlike many geoengineering methods that require significant financial
and technological resources, ERW is accessible to both local farmers and
larger agricultural companies. However, as discussed in Section 6.3,
[the benefits of ERW become significant only when implemented across
millions of acres. To achieve nationwide or global adoption, [government
subsidies will]{.mark} likely [be]{.mark} [necessary]{.mark} to support
farmers in making this transition]{.underline}. While these subsidies
may not need to be permanent, they could play a crucial role in helping
initiate the shift in the agricultural sector from traditional
pesticides and fertilizers to the use of silicate rocks. [[ERW
demonstrates that]{.mark}, currently, even the most easily implemented
[geoengineering]{.mark} technique [requires]{.mark} some **[government
intervention]{.mark}**.]{.underline}

Larger geoengineering methods, such as SAI, pose even greater
implementation challenges because of potential violations of the
Environmental Modification Convention (ENMOD). ENMOD states that,
"states may not engage in the hostile use of environmental modification
techniques having widespread, long-lasting or severe effects as the
means of destruction, damage or injury to another State party" (The
United Nations, 1976). Given the potential risks of geoengineering,
however minimal, critics may argue that its implementation could violate
the ENMOD Convention. A rebuttal to this argument lies in the widespread
use of cloud seeding in the U.S. and globally. Despite concerns that its
application, whether to induce rainfall or prevent hail over
agricultural areas, may have adverse impacts on the surrounding
environment, it continues to be practiced. The underlying justification
is that cloud seeding is perceived to produce more benefits than harm,
both in providing rain during drought and averting hail that could wipe
out entire harvests. Following the utilitarian reasoning outlined in
Section 7.1, geoengineering should be evaluated through a similar lens.

The [[federal government is the most feasible]{.mark} entity for
implementing geoengineering, [given]{.mark} its [**broad authority** and
substantial **financial resources**]{.mark}]{.underline}. However, one
crucial aspect of climate change-related policy that has yet to be
addressed is the role of insurance companies. Insurance companies play a
critical role in providing financial protection to those affected by
climate-related disasters by distributing the financial burden of such
events. Reinsurance companies, in turn, offer stability by absorbing a
portion of the risks and losses, particularly during large-scale or
catastrophic events, enabling insurers to remain solvent and continue
providing coverage. This layered structure is essential to the global
insurance industry's capacity to manage the escalating risks posed by
climate change.

Analyzing the climate change policies of major reinsurers helps inform
the broader discussion about responsibility for implementing
geoengineering and other climate interventions. Swiss Re, one of the
world's largest reinsurance companies, has developed extensive climate
policies and is committed to achieving net-zero greenhouse gas emissions
by 2050. The company emphasizes that climate mitigation should be a
joint effort between the public and private sectors, emphasizing that
the scale and complexity of the climate crisis cannot be addressed by a
single actor alone. [They believe that [governments should lead with
strong policies and investments]{.mark}, while the private sector,
including insurers and reinsurers, supports these efforts by providing
expertise, risk management solutions, and financial
investments]{.underline} (Swiss Re, n.d). Swiss Re, for example,
primarily advances climate action through partnerships with other firms
and governments, supporting research, advocacy, and policy development.
They collaborate with the World Economic Forum and the United Nations to
fund research and support global climate initiatives (Swiss Re, n.d).
The firm, along with other reinsurers, sees its role as an enabler and
accelerator in the transition to a low-carbon economy.

Even after analyzing reinsurance companies' climate change policies, the
question of agency--who is ultimately responsible for implementing
geoengineering-- remains unresolved. While most entities, both public
and private, agree that addressing climate change requires a collective
effort, the challenges of high financial demands and the complexities of
navigating international agreements like ENMOD often lead to a
reluctance in definitive answers about who should take the lead in this
global challenge.

Even with the challenges of agency, there are methods of geoengineering
that can be implemented at smaller scales that will still have positive
effects. Their projected potential, along with early signs of
effectiveness, will provide governments with the invaluable time
necessary to develop and deploy additional solutions that address the
root causes of climate change. Research in the geoengineering methods
mentioned in this thesis, along with other novel approaches, must be
diligently continued. Only through embracing a multifaceted approach can
humanity hope to not only mitigate the dire impacts of climate change
but also secure a sustainable and resilient future for generations to
come.

**[Possible US Key warrants]{.underline}**

**US action in the Arctic reinforces regional leadership, and recommits
NATO cooperation which is key to counter Russia and China**

**Murkins 24**\-\--United States Marine and Foreign Area Officer who is
currently based out of the U.S. Embassy, Oslo. She holds a Master of
Arts in Security Studies (Europe and Eurasia) from Naval Postgraduate
School (Sydney, "The Future Battlefield is Melting: An Argument for Why
the U.S. Must Adopt a More Proactive Arctic Strategy", The Arctic
Institute, 12/03/24,
https://www.thearcticinstitute.org/future-battlefield-melting-argument-us-must-adopt-more-proactive-arctic-strategy/)

[The Arctic is insufficiently prioritized amidst the United States'
competing global interests]{.underline}. [The future battlefield is
melting and demands US attention, as a partnership between Russia and
the People's Republic of China fuels strategic competition in the
Arctic. Thus, the United States must adopt a proactive Arctic
strategy,]{.underline} working with its NATO Allies to ensure that the
Arctic remains stable and free from conflict. The US's 2022 National
Defense Strategy (NDS) outlines that the United States "seeks a stable
Arctic region characterized by adherence to internationally agreed upon
rules and norms."1) To achieve a secure Arctic, the 2024 Arctic
Strategy, produced by the U.S. Department of Defense, follows a
"monitor-and-respond" approach. However, this reactive strategy is
inadequate.2)

Russia's 2022 invasion of Ukraine provides evidence that Moscow will not
adhere to the current global order and will continue to challenge
Western international norms wherever possible, including in the Arctic.
NATO's growing appeal among European states suggests that NATO may also
be called upon to guarantee the future of Arctic stability. Instead of
dividing Europe, isolating Ukraine, and expanding its influence,
Moscow's invasion of Ukraine has resulted in a closer alliance between
the United States and its Arctic NATO allies. Moreover, NATO, with the
accession of Finland and Sweden, has expanded,, and now seven out of the
eight Arctic nations are NATO members. The alliance offers an
opportunity for the United States to strengthen its position in the
Arctic region while not having to go it alone.

T[he current US Arctic Strategy insufficiently counters Russian and
Chinese strategic Arctic ambitions,]{.underline} though the makings of a
more effective Arctic Strategy already exist in the pages of the 2024
Arctic Strategy. [Washington must build on this foundation, shifting its
mindset towards the Arctic. A proactive Arctic Strategy is needed, in
which the United States and its NATO partners are not afraid to define
the rules and laws governing the north.]{.underline} Critics of this
approach will claim that taking a more assertive position in the Arctic
will further antagonize Russia and divert important resources from the
Indo-Pacific region and China. This is simply not the case. [Russia and
China have already taken steps to claim and militarize the Arctic. By
acting now, the US and its NATO allies will be better positioned to
counter the threat posed by Russia and China in the Arctic and
beyond.]{.underline}

Why the Next War Will Be Won or Lost in the Arctic. [Climate change has
accelerated strategic competition in the region among both Arctic and
non-Arctic nations, such as China. Melting sea ice from rising global
temperatures has created new military and economic opportunities in the
region]{.underline}. Since 1979, the Arctic has warmed four times faster
than the rest of the world, according to an August 2022 scientific study
published in Nature.3) As ice rapidly melts in the Arctic, increased
access to critical rare earth elements, such as platinum, copper,
lithium, cobalt, and nickel emerge. Moreover, melting ice is opening
more easily traversed Arctic waters, which has led to a surge of both
military and commercial ship activity in the region. These two
developments have increased the potential for conflict in the Arcti

[Any nation that can effectively mine, process, and refine the materials
will have a strategic advantage.]{.underline} These minerals are
required for developing technologies ranging from renewable energy
systems to electronics used for national defense. According to the World
Bank, the demand to produce minerals, many of which are found in the
Arctic, could increase by nearly 500 percent by 2050 to meet the growing
demand for clean energy technologies.4) [China already dominates the
global supply chain for critical materials. The United States depends on
these materials for its economic competitiveness and national
defense.5)]{.underline}

[As ice melts, new routes are emerging that are more navigable. This has
resulted in more ship activity in the region.]{.underline} For instance,
the Arctic Council Working Group on the Protection of the Arctic Marine
Environment reports that there has been a 37 percent increase in ship
numbers and distance sailed in the Arctic over the past ten years.6)
While much of this activity is commercial[, Russia and China have also
taken advantage of the new sea routes to project their naval
power.]{.underline} They have carried out numerous regional deployments
and patrols, demonstrating their ability to execute military operations
in the austere Arctic climate.7[) The expanded presence of Russian and
Chinese ships in the region poses a growing threat to NATO member
states.]{.underline} In October 2023, Finnish investigators suspected
the Chinese vessel NewNew Polar Bear of dragging its anchor over the
seabed and severing three Baltic telecom cables and one pipeline. While
the international community has not assigned blame wholly to China,
China later admitted to accidentally destroying an important gas
pipeline connecting Finland and Estonia in the Baltic Sea in 2024. These
examples suggest that incidents of this nature could become more likely
as military activity increases in the region.8)

Competition in the Arctic Is Heating Up: Russian and Chinese Ambitions

[The growing partnership between Russia and China provides early warning
signs that the region could become a site of future
conflict]{.underline}. In 2021 Russia and China renewed their
20-year-old Sino-Russian Treaty of Good Neighborliness and Friendly
Cooperation, a move described as "an act of friendship against
America."9) Moreover[, both Russia and China have deep historic and
economic ties to the Arctic. NATO's expansion to include Finland and
Sweden have increased tensions in the region, while both Russia and
China have expressed their disapproval of NATO's increasing presence in
the Arctic.]{.underline}10) However, despite feeling antagonized by
NATO's actions, Moscow and Beijing may not have the economic and
military capacities to reshape the current international rules-based
order in the Arctic in the near term.

Despite being the only non-NATO member in the Arctic, Russia controls
over 53 percent of the Arctic coastline, making it a decisive player in
the future of the region.11) Yet, Russia's Arctic ambitions are not new.
Russia's connection with the Arctic can be traced back to the sixteenth
century, beginning with its conquest of Siberia, which was part of a
larger initiative to search for resources and trade routes.12) As the
nation matured, its Arctic ambitions did as well. During the Cold War,
the Soviets established both a nuclear and naval presence on the Kola
Peninsula to project power against the U.S. With the collapse of the
Soviet Union, Russia, as the de jure inheritor of the Soviet nuclear
arsenal, did not abandon its desire to be an Arctic power. As the
Russian economy recovered in the early 2000s under Vladimir Putin,
Russia began posturing for Arctic supremacy, reopening multiple
Soviet-era military bases, modernizing its navy, and developing new
hypersonic missiles designed to evade U.S. sensors and defenses.13)
Moreover, in August 2022, Moscow announced that it would refocus its
military power on the Arctic and Nordic region.14) According to Colin
Wall, a research associate at Center for Strategic and International
Studies in Washington, "The military balance in the Arctic is heavily
weighted towards Russia." Furthermore, the International Institute for
Strategic Studies and Reuters cite that Russia's bases inside the Arctic
Circle outnumber NATO's by roughly a third.15) Russia's remilitarization
of the Arctic and its revitalized strategic partnership with China,
provides both countries with the means to challenge the current Western
rules-based international order. Although China's Arctic history does
not mirror Russia's centuries-old presence in the north, Beijing's
desire for Arctic supremacy has rapidly evolved over the past century.
China's involvement in the Arctic began in 1925 with the signing of the
Svalbard Treaty, providing a legal basis for China to conduct
non-military activity, such as scientific exploration, resource
extraction, and fishing in the Arctic.16) However, China's rationale to
operate in the region extends beyond scientific exploration.

In 2018 China released its first Arctic White Paper, which asserts that
it is a "Near-Arctic State."17) China employs a dual narrative to
explain its aims in the Arctic. Externally, Beijing appeals to foreign
audiences by advocating for the safeguarding of international interests
and promoting sustainable Arctic development. However, this is
juxtaposed against the narrative it promotes for domestic audiences,
which emphasizes competition for resources and China's desire to become
a "polar great power."18) The Svalbard Treaty has currently enabled
China to shroud its military activity and influence in the Arctic as
scientific exploration and global cooperation[. But it is becoming clear
from its growing partnership with Russia and increasingly aggressive
military action in the Arctic that China's intentions to reshape the
international system extend well beyond the Indo-Pacific. The U.S. and
NATO would be wise to recognize China's aims in the Arctic.]{.underline}

The historic ties of Russia and China and their Arctic ambitions reveal
that the Arctic is likely to be an arena for future strategic
competition. Russia's 2022 invasion of Ukraine has temporarily bolstered
the West's position in the Arctic, as previously neutral Finland and
Sweden joined NATO. Finland's accession into NATO not only increased the
NATO-Russia land border by over 650 percent and moved the defense
alliance a mere 250 miles from St. Petersburg, but it also contributed
to creating a divided Arctic, where nearly half belongs to NATO while
the remaining half is Russian territory.

Threatened by the growing alliance, in June 2022, Putin warned that if
U.S.-NATO military contingents or military infrastructure appears in
either Sweden or Finland, Russia will respond "symmetrically" by
deploying nuclear weapons to the Baltic Sea region to restore military
balance and strengthen its defenses.19) In February 2023, Putin made
good on this threat and deployed Russian ships armed with tactical
nuclear weapons to the Baltic Sea. According to Norway, this was the
first time in 30 years that this has happened.20) Then in June 2024,
Moscow began to train soldiers and sailors to deploy tactical nuclear
weapons in Leningrad, a military district bordering NATO members Norway,
Finland, Poland, Estonia, Latvia, and Lithuania.21) As evidenced by
these actions, while Putin is not afraid to rattle the nuclear saber, it
is not likely that Russia has the military or economic capacity to
engage in a direct conventional conflict with NATO. NATO leaders
recognize that there is a finite window of time to prepare for conflict
against Russia. In 2024 the head of the Norwegian armed forces warned
that NATO countries only have two to three years to prepare for a
Russian attack. Norwegian General Eirik Kristoffersen claims that Moscow
is building up its military stockpile faster than previously predicted,
while Western nations have depleted their own weapons by supplying them
to Ukraine.22) Several other European leaders have echoed these
concerns, citing that they have between three and eight years to prepare
for a Russian attack against NATO.23) Despite Russia's aggressive
rhetoric, Moscow understands that because of its war against Ukraine it
likely will not have the capability to attack NATO in the near future.
For instance, Russia removed nearly all its ground forces from the
Finnish border to Ukraine in June 2024.24) Russia's timeframe to launch
a successful attack is dependent not only on its economy but also on its
partnership with the PRC.

Why the U.S. Needs its Arctic NATO Allies

[The United States has already begun to take a more active approach in
the Arctic; however, the region must become an even greater
priority]{.underline}. Following Finnish and Swedish accession to NATO,
the alliance's center of gravity, its primary source of strength and
stability, shifted North and closer to the Russian border. This is not
the first instance of NATO borders moving closer to Russia. In 2007,
Putin provided a final "friendly" warning that NATO expansion
"represents a serious provocation that reduces the level of mutual
trust."25) The National Defense Strategy (NDS) reaffirms its commitment
to NATO, underscoring the importance of collective defense aimed at
deterring Russian aggression. Despite this stated commitment, the NDS
does not directly address how it will respond in the event that Russia
attacks a NATO member state, forcing the alliance to respond. [While the
current NDS and Arctic Strategy offer assurances of protection to the
U.S. homeland, a proactive Arctic posture will mitigate future conflict
in the region.]{.underline}

[The United States already views itself as a leader in the European
Arctic.]{.underline} Since the end of the Cold War, the United States
has sought to uphold international law, close gaps in governance, and
protect sovereign rights in the European Arctic.26) The United States
was integral in developing multiple intergovernmental institutions,
including the Arctic Council in 1991.27) With growing competition in the
European Arctic, [the United States should continue to use its great
power status to insert itself as a lead actor in the region through the
establishment of a proactive Arctic Strategy coupled with enhanced
economic and military cooperation with its Nordic NATO
Allies.]{.underline} Today, while Russia is engrossed in its war against
Ukraine, the United States and its allies have the opportunity to remain
one step ahead.

Since Russia's invasion of Ukraine in 2022, the United States has begun
to increase its presence in the European High North. Underscoring the
importance of collective defense, the United States has entered into
several new bilateral Defense Cooperation Agreements (DCA) with Nordic
nations. In 2022, the United States signed a DCA with Norway, which
acknowledges that the presence of U.S. forces in Norway contributes to
strengthening the security and stability of the region and permit
American forces unimpeded access to four Norwegian military bases.28)
Since the establishment of the defense agreement, Norway and the United
States added an amendment, allowing U.S. forces and NATO allies to
access eight additional facilities in Norway for military purposes,
emphasizing the growing security threat in the European Arctic.29)
Following Norway's lead, Denmark signed its DCA with the United States
in 2023 followed by Finland and Sweden in 2024.30) DCAs such as these
offer increased and mutually beneficial opportunities for the United
States and its Nordic NATO Allies to prepare for any future hostilities.

As part of the US's proactive Arctic Strategy, Washington should
prioritize economic investments in companies owned by NATO members.
Through these investments, energy security within NATO can be improved,
and the nations can decrease their dependence on rare earth materials
from China. The United States has already taken initial steps to secure
critical mineral and clean energy supply chains, but more can be done.
In September 2024, the United States signed a Critical Minerals
Agreement with Norway, demonstrating both countries' commitment to
working together to ensure energy security.31) Another such opportunity
for the U.S. to further support its Nordic Allies exists in Sweden. In
2024 the Swedish mining company LKAP discovered Europe's largest deposit
of rare earth elements in the northern city of Kiruna, Sweden. Norway
and Sweden have already begun collaborating to increase energy security
through the Norwegian company, REETec, which has developed technology to
separate rare earth metals that competes with China's production of
these materials.32) According to the CEO of LKAB, Jan Moström, this
cooperation provides the foundation to develop a "strong and sustainable
Nordic value chain for rare earth metals."33) A [proactive U.S. Arctic
Strategy that takes into consideration increased NATO energy security
through Nordic investment further bolsters the United States' ability to
decrease dependence on China and should be pursued]{.underline}.

[Increased cooperation between the United States and its Nordic NATO
Allies provides an opportunity for the U.S. to couple a new proactive
Arctic Strategy with tangible training goals for forces at the tactical
and operational levels]{.underline}. For example, U.S. forces and their
Norwegian counterparts have benefited from a mutually supportive
military alliance for decades. During the Cold War, Norway was a
critical U.S. ally for power projection, defense, and deterrence in the
north. Its geostrategic location was optimal for protecting NATO's
northern flank from Soviet aggression so much so that the United States
stockpiled weapons, vehicles, and ammunition in strategic locations
across Norway.34) [These stockpiles were crucial for increasing U.S.
power projection and enhancing NATO's operational responsiveness in the
European arena.]{.underline} Additionally, Norway's proximity to the
Soviet Union and the adjacent Norwegian and Barents Seas allowed NATO to
challenge the Soviets' ability to deploy nuclear-powered submarines if
the Cold War turned hot.

The U.S.--Norwegian Alliance has only grown since the end of the Cold
War. In 2017, the United States Marine Corps began sending a battalion
of Marines to Northern Norway as part of a rotational deployment. The
United States Marine Corps continues to deploy thousands of forces to
train alongside its Norwegian Allies annually. Moreover, in 2018, Norway
hosted Exercise Trident Juncture, a NATO-led military exercise based on
a fictitious Article 5 collective defense scenario. It was the largest
exercise of its kind in Norway since the 1980s, and 31 nations
participated.35) [Large-scale multinational exercises of this kind
increase force proficiency operating in Arctic environments and enhance
NATO member states' ability to work with each other in
wartime.]{.underline}

The United States has been increasing its ability to work with its
Swedish and Finnish counterparts in the case of war. The United States
should establish bilateral training exercises with Sweden and Finland in
order to give these new NATO nations a greater understanding of how to
operate in a NATO construct. Conversely, cooperation with allies and
partners improves U.S. forces' understanding of how to operate
effectively in an Arctic environment, making it a more reliable and
efficient partner for Arctic allies. This operational experience ensures
that allied forces are familiar with strategic terrain that may be
leveraged during a conflict with Russia. Conclusion: How a Proactive
Arctic Strategy Supports America's Focus on the Indo-Pacific

The United States publication of the 2024 Arctic Strategy provides a
transparent approach aimed at reducing the possibility of escalation in
the Arctic. [Moreover, the current strategy recognizes Russia's and
China's Arctic ambitions and that the growing collaboration between
Russia and the PRC have "the potential to alter the Arctic's stability
and threat picture]{.underline}."36) The strategy presents a tangible
and realistic way forward for the U.S. to enhance the Joint Force's
Arctic capabilities, engage with Allies and partners, and demonstrate an
ability to work together across defense forces. Although the strategy
indicates increased U.S. involvement in the Arctic, it remains reactive.
The 2024 Arctic Strategy already outlines a tangible way for the United
States to commit energy and resources to the region. Although a
deliberate shift in messaging will not change the U.S. footprint in the
Arctic, it will change the U.S. mindset towards the region. [By making
the Arctic a priority, the U.S. demonstrates its commitment to
supporting its Allies in the event that Russia or China
attacks.]{.underline}

[Furthermore, by shifting to a proactive Arctic Strategy, the United
States is not abandoning its focus on the Indo-Pacific, because the PRC
envisions itself as a polar power and intends to reshape the
international system in its favor. F]{.underline}uture conflict with the
PRC will not be geographically constrained to the Indo-Pacific. By
shifting to a proactive Arctic Strategy now, the United States can deter
China from expanding its control over the Arctic and its critical
resources. [The future battlefield is melting and only by taking actions
today can the United States and its NATO allies win tomorrow's war in
the Arctic.]{.underline}

**American lead in geoengineering ensures national security, leads to
cooperation, and prevents Russia China interventions**

**Sikorsky and Ellison 24**\-\-- Erin Sikorsky: Director of the Center
for Climate and Security (CCS), and the International Military Council
on Climate and Security (IMCCS) with a masters of International Affairs
at Columbia University, Tom Ellison: Deputy Director of the Center for
Climate and Security (CCS) with a M.A. in Security Studies from
Georgetown University ("Geoengineering and Climate Change in an Age of
Disinformation and Strategic Competition", Council on Strategic Risks,
04/23/24,
https://councilonstrategicrisks.org/2024/04/23/geoengineering-and-climate-change-in-an-age-of-disinformation-and-strategic-competition/)

[Geoengineering, sometimes called climate intervention, is gaining more
attention as a potential tool to manage the impacts of climate
change]{.underline}. A steady drumbeat of reports from governments and
scientific institutions argue for developing research programs to allow
for better informed decisions on the risks and benefits of
geoengineering. [At the same time, the national security community is
raising concerns emphasizing the risk of large-scale, successful
unilateral deployment by a middle or rogue power.]{.underline}

However, the more acute, [near-term security risks associated with
geoengineering have little to do with the ultimate effect of such
interventions, but instead with the perceptions of such interventions,
particularly in a world shaped by geopolitical competition, growing
divides between the Global North and Global South, and
dis/misinformation. These risks include rising tensions between or among
states attributing disasters to each other's real or perceived
geoengineering attempts,]{.underline} a dynamic that could arise even in
the research or testing phase of geoengineering projects. Additionally,
expanding geoengineering efforts may exacerbate the growth of harmful
conspiracy theories and influence campaigns that further undermine trust
in government and science. Such issues have gotten comparably little
attention in the national security discourse and are largely absent in
discussions about geoengineering among the scientific and environmental
community.

To manage such risks, a push for a full ban or prohibition on
geoengineering will become more and more unrealistic, and perhaps
harmful, particularly as the climate crisis intensifies. Instead, [the
United States, with its allies and partners, should lead the development
of guardrails and norms that manage not only the scientific challenges
but also the geopolitical risks associated with
geoengineering]{.underline}. [A responsible framework would ensure that
research is conducted transparently, led by civilian institutions and
agencies, and integrates political, sociological and historical
viewpoints.]{.underline} In building the framework, the United States
should learn from weather modification controversies in the 1960s and
1970s, nuclear nonproliferation negotiations, and the development of
bioethics -- all of which offer lessons regarding norm building for
complex, nascent technologies. The United States must also develop
robust science communication and science diplomacy to engage the public,
the private sector and other governments on geoengineering in the coming
years to combat mis- and disinformation. Such efforts should draw
lessons from analogous science communication and misinformation
challenges--such as vaccine skepticism and election interference.

Importantly, geoengineering discussions should not siphon resources or
political capital from continuing the transition away from fossil fuels
as quickly as possible, while also robustly investing in
adaptation--policies that will lessen the need for more radical
solutions. Realistically, however, [interest in geoengineering will only
grow in the next few decades and the United States cannot afford to be
caught flat-footed on the associated security risks.]{.underline}

Current State of Play

[As climate-driven disasters pile up around the world, there is growing
interest among governments and scientific bodies in exploring climate
intervention or geoengineering techniques]{.underline}. The long-held
taboo in the scientific community that prevented even basic research
into climate intervention approaches such as Solar Radiation Management
(SRM) appears to be weakening. China launched a large, government-funded
program in 2017, while in the United States universities like Harvard
(though its major effort shuttered in 2024), the University of Chicago
and the University of Washington have been leaders in the field.1 [2 A
2021 report from the US National Academy of Sciences argued it was time
to create a transdisciplinary geoengineering research program in the
United States, focused on developing "policy-relevant knowledge," not
advancing deployment]{.underline}.3 Two years later, in June 2023, a
Congressionally-mandated report from the White House Office of Science
and Technology Policy echoed the Academy's recommendations and laid out
a US research program on solar radiation modification, noting such a
program would, "...enable better-informed decisions about the potential
risks and benefits of SRM as a component of climate policy."4

Of note, [the US government reports mentioned above emphasize the
importance of developing international governance mechanisms alongside
the scientific research]{.underline}, yet little detail is provided on
how such mechanisms might be developed, and what the obstacles might be.
While the White House report details a short list of US principles for
governing research, [it does not address how the United States will
encourage other countries to adhere to such principles or what to do if
countries decide not to adhere or develop principles of their
own.]{.underline} This gap is likely due to the fact that these reports
are largely led by the scientific community, while questions related to
international governance and risk perceptions are best answered by
social scientists, diplomats and security policymakers and
practitioners. Also, these questions are frankly thornier and harder to
address than laying out a sensible scientific research agenda. One can
assess the types of planes needed to consistently inject aerosols into
the atmosphere (as would be needed for stratospheric aerosol injections,
a likely form of geoengineering) [with much more certainty than one can
understand the range of reactions governments and societies may have to
the deployment of such planes.]{.underline}

[On the international stage, the topic is gaining attention as well,
with the EU and the UN Environment Programme endorsing international
efforts to assess the risks and uncertainties of climate
intervention]{.underline}.5 While in February 2024 a Swiss proposal to
establish an expert panel to examine SRM technologies was withdrawn at
the UN Environmental Assembly in Nairobi due to lack of support, [it is
likely that the topic will continue to gain time on the agenda in the
environmental and climate communities in coming years.]{.underline}

## Topicality

### 2AC\-\--T -- Significant

#### Counter-interpretation \-\-- "significantly" includes pilot projects.

Adam **Bryant** 6-8-20**22**, CEO of AxleHire and Forbes Councils
Member. "The Significance Of Pilots In A Rapidly Changing Business
World"
https://www.forbes.com/councils/forbestechcouncil/2022/06/08/the-significance-of-pilots-in-a-rapidly-changing-business-world/
//MDC

Challenging The Status Quo

**[[Pilots]{.underline}]{.mark}** are an educational tool that allow
companies to [[run]{.mark} small [experiments and]{.mark} use the
findings to [determine large-scale viability, cost and]{.mark} potential
[payoff]{.mark}. By analyzing the current and future challenges within
an industry, a good [pilot allows]{.mark} a company [to experiment with
potential solutions. They]{.mark} can [have a **significant
role**]{.mark}]{.underline} in challenging an industry's current status
quo and provide potential positive results that can allow a company to
stand out among its competition.

### 1AR\-\--T -- Significant 

#### Pilot projects are significant.

Han **Zhang et al** January 20**24**, all authors work for the Nanjing
University of Finance and Economics School of Accounting."Can the
deregulation of market access reduce the cost of corporate debt
financing: A quasinatural experiment based on the "negative list for
market access" pilot project" https://doi.org/10.1016/j.irfa.2023.103017
//MDC

Based on the above, whether the "negative list for market access" system
can reduce the cost of corporate debt financing needs further empirical
testing. We discuss the impact of the negative list system on the debt
financing cost from the perspective of supply-side reform of the real
economy. The results show the following. (1) As an important part of
supply-side reform, the deregulation of market access can significantly
reduce the cost of corporate debt financing. This conclusion is still
valid after a series of robustness tests. (2) The mechanism test shows
that the mechanism for reducing the cost of corporate debt financing is
to reduce transaction costs. (3) Further analysis shows that [the
implementation of]{.underline} the [[pilot project has a]{.mark}
**[significant effect]{.mark}**]{.underline} on reducing the debt
financing cost of firms in regions with low marketization degree of
credit fund allocation or of non-SOE firms. (4) Consequence analysis
shows that the deregulation of market access leads to a significant
increase in the proportion of the total debt financing scale to total
assets, the proportion of short-term loans to total assets, the
proportion of long-term loans to total assets and the amount of current
liabilities, indicating an increase in the proportion of corporate debt
financing.

#### "Significant" increases can be temporary.

Sonia **Sotomayor** 6-6-20**22**. "Siegel v. Fitzgerald, 596 U.S. \_\_\_
(2022)", majority opinion (unanimous), Supreme Court of the United
States, <https://supreme.justia.com/cases/federal/us/596/21-441/> \[AY\]

[In 2017]{.underline}, concerned with a shortfall in the UST Fund,
[[Congress enacted a **temporary**, but **significant**, increase
in]{.mark} the [fee rates]{.mark} applicable to large Chapter 11
cases]{.underline}. See Pub. L. 115-72, Div. B, 131 Stat. 1229 (2017
Act). The increase was set to take effect only if the UST Fund balance
dropped below \$200 million as of September 30 of the most recent fiscal
year. If that condition was met, the increase applied on a quarterly
basis to any debtors with a disbursement of \$1 million or more during
that quarter, regardless of whether their case was newly filed or
already pending when the increase took effect. For those debtors, the
maximum fee was increased from \$30,000 a quarter to \$250,000 a
quarter. §1004(a), id., at 1232. The statute provided that the fee raise
would become effective in the first quarter of 2018 and would last only
through 2022.

## AT: CPs

### AT: Governance PICs

#### Geoengineering fails absent governance. The plan is key to solve -- pilot projects are what researchers have consensus about now.

Sean **Mowbray** 8-1-20**24**. Sean Mowbray is a freelance writer from
Scotland. He often covers lesser-known species that fly under the
conservation radar. His reporting also appears in New Scientist, Hakai,
Earth Island Journal, Discover magazine, and others. \"Geoengineering
gains momentum, but governance is lacking, critics say,\" Mongabay
Environmental News,
https://news.mongabay.com/2024/08/geoengineering-gains-momentum-but-governance-is-lacking-critics-say/.

As climate change rapidly advances, with 2023 and 2024 vying for the
hottest year on record, [solar radiation modification (**SRM**)
geoengineering strategies are gaining momentum as short-term climate
fixes.]{.underline} These especially [include **proposals** for the
release of **cooling aerosols** into the Earth's lower
stratosphere.]{.underline}

But [preliminary geoengineering efforts]{.underline} (represented by
lots of computer modeling and a smattering of small-scale field tests)
[are proceeding against a backdrop of **public mistrust and
resistance**,]{.underline} while also [provoking urgent calls by experts
for national and international policies and regulatory structures to
govern this burgeoning field.]{.underline}

[Many analysts are **truly concerned** as to whether majorly tinkering
with Earth's atmosphere --- physically altering the planet's
climate]{.underline} --- [**can be governed in a just
way**,]{.underline} or accomplished at all by the world's 195 nations,
which barely ever agree on anything.

Who precisely, experts ask, will judge the worthiness of proposed
geoengineering technologies and projects? Who will launch them, oversee
and monitor them --- and stop them if things go wrong?

Even the [research community remains divided over
geoengineering]{.underline}. Some scientists are vigorously advocating
for objective and "responsible" research into the feasibility of various
technologies, including stratospheric aerosol injection (SAI[). But
hundreds of academics recently signed a call for a Solar Geoengineering
Non-Use Agreement, specifically targeting SAI.]{.underline}

Researchers and policymakers do broadly agree that governance is needed
to safely and transparently guide small-scale field research projects
and eventually regulate planetary deployment, if the world's countries
choose to go that route.

\[image omitted\]

Firefighters look on as wildfire flames engulf Pine Gulch, Colorado, in
2020. SAI and other geoengineering technologies are gaining momentum as
possible climate change "emergency brakes." There is some certainty that
SAI global deployment is possible and could reduce global temperatures,
says Shuchi Talati with the Alliance for Just Deliberation on Solar
Geoengineering. But "we have very little understanding around what other
impacts would look like." Image by National Interagency Fire Center via
Flickr (Public domain).

Global regulatory framework 'completely insufficient'

Stratospheric aerosol injection is considered the most mature of a large
suite of geoengineering approaches, and it could likely effectively cool
the planet, with deployment plausible within the next decade or so,
according to experts such as Andrea Hinwood, chief scientist with the
United Nations Environment Programme (UNEP).

But planetary-scale SAI implementation raises environmental concerns
over still poorly understood impacts on the ozone layer, climate change
at regional levels, hydrology, biodiversity and ecosystems and human
health.

A recent report published by UNEP includes SRM technologies as a
potentially disruptive "signal of change" and warns that its deployment
carries multiple and inherent risks to the environment and society writ
large. "Recognizing that SRM technologies remain speculative and highly
contentious, scientific scrutiny and more inclusive public discourse on
the implications (including ethical issues) of SRM is critical at this
stage," the report reads.

Analysts are urging that international and national policies be
negotiated now, with global oversight rules quickly put in place to
prevent a single country or group of nations from pulling the trigger on
SAI or other technologies, ushering in a new planetwide climate regime
full of unknowns.

"I think that's what we are worried about, and therefore governance of
... these groups of technologies is critical," Hinwood says. She
co-authored a 2023 UNEP report on solar radiation modification outlining
the risks and potential governance concerns, though she stresses that
UNEP is not promoting such approaches or technologies.

"The regulatory framework is just completely insufficient ... and I
think that's becoming more and more dangerous," agrees Shuchi Talati,
director of the Alliance for Just Deliberation on Solar Geoengineering,
an NGO. She emphasizes that the "biggest problem" right now is the utter
lack of coordinated governance structures for approving small-scale
field experiments.

\[image omitted\]

Modeling suggests solar geoengineering could contribute to the Amazon
Rainforest drying out, which could bring more forest die off and worsen
climate change. That's just one example of potential knock-on effects
that have led some experts to call for an outright ban on field tests
and deployment. For Ben Kravitz, an assistant professor in the
Department of Earth and Atmospheric Sciences at Indiana University,
there are also social impacts to consider. "Those are the things that we
really need to figure out," he says. Image by Neil Palmer/CIAT via
Flickr (CC BY-NC-ND 2.0).

A 'piecemeal ... patchwork' of policies

In 2021, the U.N General Assembly adopted a resolution seeming to
address geoengineering without, however, specifically mentioning it. The
body agreed then, "Activities aimed at intentional large-scale
modification of the atmosphere should only be conducted \[by nation
states\] with prudence and caution, and subject to any applicable rules
of international law, including those relating to environmental impact
assessment."

But so far, the U.N. has taken no concrete action toward a
geoengineering treaty. Lacking that, experts point to several existing
international agreements that could set boundaries on the use of
geoengineering techniques, including SAI. Among these is a 2010 decision
by the Convention on Biological Diversity (CBD) that many say acts as a
de facto moratorium. The CBD states that any climate-related
geoengineering that could harm biodiversity should be off-limits "until
there is an adequate scientific basis on which to justify such
activities."

Mary Church, geoengineering campaign manager at the Center for
International Environmental Law, interprets this to mean that even
small-scale field experiments could violate the CBD ruling. "Governments
must act to uphold and enforce these agreements in national contexts, to
send a clear signal that geoengineering is off limits," she says.

But others question this strict reading of the CBD resolution. "This is
one of the most misunderstood and misrepresented decisions in the field
of SRM," says Andy Parker, chief executive officer of the DEGREES
Initiative, an NGO. "What the CBD decision said was that no SRM that
would have significant adverse and transboundary impacts on biodiversity
should proceed unless certain conditions are met," which creates an
opening for small-scale field research projects.

He also notes that the CBD agreement is not legally binding --- a
conundrum likely to hamper any future attempt to get all the world's
nations to agree on overarching geoengineering policies.

\[image omitted\]

The eruption of Mount Pinatubo in 1991. This event pumped more than 15
million tons of sulfur dioxide into the stratosphere, dropping average
global temperatures by around 0.6 degrees Celsius (1°F) for a year. SAI
would theoretically be designed to mimic this effect. But its unknown
environmental, social, and political risks are a cause for concern.
Image by Kentucky National Guard Public Affairs Office via Flickr (CC BY
2.0).

Other advisory bodies, such as the U.S. National Academy of Sciences,
have proposed setting up transdisciplinary research programs focused on
solar geoengineering, with the United States acting "in collaboration
with other nations." In addition, the U.S. government, UNEP and European
Union have mandated research into governance of geoengineering in
general or solar radiation modification in particular.

The European Union is actively investigating whether responsible science
can be conducted into geoengineering and how those activities should be
governed. But in February at a UNEP meeting, efforts by Switzerland to
set up an international geoengineering research and scientific body
failed, rebuffed by African nations, some of which called for a
geoengineering "nonuse" agreement, out of fear of deployment inequities.
As with past U.N. environmental negotiations, geoengineering is already
seeing a regulatory tug-of-war between the Global North and Global
South.

Searching for other global governance mechanisms, analysts point to the
binding Montreal Protocol. "When it comes to stratospheric aerosol
injection, there is the ozone protection regime, which does not mention
SRM but states that you should avoid introducing things in the
atmosphere that disturb the ozone layer," notes Dana Ruddigkeit,
researcher and policy adviser for Public International Law, with the
German Environment Agency. Precisely how, or if, SRM might impact the
ozone layer is still a matter of scientific debate.

"We have international legal principles like the 'no harm principle,'
the precautionary principle, no transboundary harm to another's
territory, which would prevent any sort of unilateral deployment of
solar geoengineering," says Aarti Gupta, professor of global
environmental governance at Wageningen University who backs a global
nonuse agreement.

But taken all together, experts agree the current state of global
geoengineering governance is "piecemeal" and a "patchwork" of
restrictions and guidance that are vague and weak, leaving a glaring
oversight gap that urgently needs to be addressed.

\[image omitted\]

In 2023, a NOAA project named SABRE flew over the Arctic to conduct
stratosphere research. A larger, congressionally mandated SRM research
program, known as the Earth Radiation Budget, is a test intended to
"inform evaluations of potential future efforts to slow global warming
by modifying the amount of heat captured by the atmosphere." Image by
Chelsea Thompson/NOAA.

Controlling experimentation: 'A little bit Wild West'

Thus far, the vast majority of stratospheric aerosol injection research
has focused on modeling, work no one has opposed. But attempts at
undertaking small-scale outdoor research and experimentation --- vital
to inform any future planetwide stratospheric intervention --- remain
mired in controversy.

In response to a controversial launch by a private U.S.-based company of
a solar geoengineering test balloon over Mexican territory, that Latin
American country announced its intention to ban all future
geoengineering tests. Likewise, the U.S. state of Tennessee is
implementing bans on testing, though the justification for this measure
is mixed up with chemtrails conspiracy theory --- an indication of the
sort of public and official misinformation now guiding some
geoengineering responses.

But these zealous outright prohibitions contrast drastically with
extremely lax national regulations. Politico reports that the only
requirement for a U.S. company or citizen intent on modifying the
weather by injecting aerosols into the atmosphere is to fill out and
file a one-page form with the National Oceanic and Atmospheric
Administration (NOAA) 10 days before project start.

Similarly, in the United Kingdom, researchers launched "an engineering
proof-of-concept" series of high-altitude solar engineering test
balloons in 2022, deploying a basketball-sized 400-gram
(less-than-1-pound) sphere of sulfate aerosols at high altitude. The
"Stratospheric Aerosol Transport and Nucleation," balloon systems
(boasting the provocative acronym SATAN), were supposedly built from
stock and hobbyist components, with hardware costing less than \$1,000.
The flights were launched with no prior notice or government approval.
Though the effects were likely innocuous, the tests raised concern over
transparency and the risk of triggering panic with the public.

The current experimentation situation is "a little bit Wild West," says
Max Holmes, president and CEO of the Woodwell Climate Research Center.
He worries that in the absence of wider governance, the world could be
plagued by a wave of geoengineering tech commercialization. "There's the
potential that while \[field tests\] are very small-scale right now, ...
\[if\] it ramps up in scale, that's where it gets scary to me," he says.

One such small-scale project by Harvard University, dubbed the
Stratospheric Controlled Perturbation Experiment (SCoPEx), officially
pulled the plug this year following years of controversy, which came on
the back of a failed attempt to launch a controlled experiment in
Sweden, in part due to a groundswell of local opposition.

"The ScoPEx project did an admirable job of establishing small-scale
self-governance with a strong degree of independence," Faye McNeill,
professor of chemical engineering and Earth and environmental sciences
at Columbia University, and Han Huynh, research scientist at
CU-CIRES/NOAA, wrote in an email. Together they published a recent paper
outlining SAI risks and need for governance. They warn,
"\[S\]elf-governance is not sufficient for a technology that potentially
impacts the environment and societies to the extent that SAI is intended
to."

The lack of global regulation, they say, creates a chicken-and-egg
conundrum: Developing SAI will prove challenging without such
experimentation conducted at the local level, but the absence of
overarching rules and regulations is a roadblock to such tests.

"More public engagement, education and discussion prior to field
experimentation could be helpful, but some of the fundamental distrust
of this technology could come from the lack of independent governance at
the \[national\] government or international level," they wrote.

For small-scale research to move forward, experts say coordinated
governance at the local and national levels are needed, including
required environmental impact assessments, oversight, transparency on
experimentation and funding, codes of conduct and more.

A 2024 report by the failed SCoPEx project's independent advisory
committee underlined the necessity early on of community engagement.
Also, "From a governance perspective, it would be great to actually have
a register of who's doing what, and what those outcomes are," Hinwood
says.

\[image omitted\]

A graphic showing some proposed and theoretical geoengineering
techniques. Stratospheric aerosol injection (3) is considered by some as
the most mature, but major questions remain regarding the consequences
of geoengineering planetary deployment. Image by Chelsea Thompson,
NOAA/CIRES via Wikimedia Commons (Public domain).

Governing the ungovernable?

Geoengineering poses significant unforeseeable regional and global
environmental risks. That being the case, analysts say, strong
governance is required to ensure "responsible" research and
experimentation.

This work, most say, should be in the hands of reputable scientific
researchers and institutions, not profit-motivated companies. Further, a
serious inclusive global discussion is needed to create a legal
framework for geoengineering in general, and SAI in particular.

Currently, Parker says, no country has yet set a "gold standard" for
such an approach.

Others, however, believe that a technology as contentious and
potentially dangerous as SAI is unlikely to ever be governed effectively
or democratically within existing international structures, meaning
geoengineering should be removed from the table entirely.

"We cannot have a situation where a few major powers or a few countries
decide when to deploy, how much to deploy, when to stop and what kind of
global temperature we want," Gupta says. The "enforceable governance of
solar geoengineering deployment at the international level \[that\] is
feasible, is very limited."

In the end, the failure to cut carbon emissions, along with rapidly
escalating climate change impacts, could leave the world's nations with
little choice but to respond with planetwide geoengineering. In
preparation for that moment, governance discussions should start now,
some experts say.

And as flawed as its record may be, the U.N. offers a potential forum
for those discussions. With all 195 nations potentially impacted by a
geoengineering fix, a binding and flexible international treaty similar
to the Montreal Protocol needs to set boundaries on use. But as with the
Paris Agreement, the devil will be in the details.

### AT: FPIC 

**Arctic FPIC fails.**

Corine **Wood-Donnelly and** Johanna **Ohlsson** 5-15-20**23**. Dr.
Corine Wood-Donnelly (PhD, government research): Professor of
International Relations and the High North, Nord University. Johanna
Ohlsson (PhD, ethics): Head of Department of Human Rights and Democracy,
University College Stockholm. "FPIC and Geoengineering in the Future of
Scandinavia", *Arctic Justice: Environment, Society and Governance*,
[[https://doi.org/10.51952/9781529224832.ch010]{.underline}](https://doi.org/10.51952/9781529224832.ch010)
\[AY\]

[Conclusion: Can a more robust FPIC provide a solution?]{.underline}

The protection of these rights is directed towards ensuring the survival
and continued development of the cultural, religious and social identity
of the minorities concerned, thus enriching the fabric of society as a
whole.

Human Rights Committee, 1994

[In short, **it is unlikely**]{.underline}. This chapter has focused
upon raising awareness of these complex issues. Human civilization is
unique in that in most cases our presence in an environment is
immediately apparent, and we can make large-scale alterations to the
environment to suit our needs. Climate change and global warming is a
consequence of an excessive ability to change the natural world.
Overall, it is a scenario that has been created by the behaviour of a
group of nations that since the industrial revolution has continued to
benefit a distinct group of individuals. Now is a time where the
relationship between nature and the human race is being redefined. But
how this relationship evolves is often dictated by our social values and
technological development. It has been shown that technology interacts
with our value and belief systems; it alters behaviours -- both
conscious and subconscious. In this context, regardless of the whether
geoengineering is an inevitability, it is not an exceptional concept
that geoengineering could provide a novel technological solution to a
problem.

There is a great degree of apprehension around geoengineering and how it
could potentially preserve this status quo (practically and legally) --
effectively leading to the perpetuation of the colonial hierarchies
which have essentially laid the foundations for the situation we see
with geoengineering (and its inability to cope with the requirements of
justice). While we could potentially stave off the more serious
consequences of climate change, we are still allowing the highest
emitters of greenhouse gases to continue (Zhen et al, 2021). The green
transition on the whole has been somewhat of a detriment to the
participatory rights of the Sámi. Even [though there is some recognition
(in terms of guaranteeing economic and cultural self- determination) it
is still quite limited]{.underline}. The Scandinavian states have not
fully implemented their international obligations when it comes to the
protection of Indigenous groups. In terms of success stories there is
little that could be provided when it comes to engagement and benefit
sharing. Communicative planning scholars often claim that forms of
participatory planning centred on public deliberation can facilitate
more equitable decision making by overcoming power differentials between
citizens and stakeholders. [The FPIC as a procedure is **ineffective**
and its implementation rests upon the cooperation of the states
involved, which is contingent upon the balance within the
states]{.underline}. Consequently, the emphasis here is on the
construction of a robust system to tackle these challenges.
Intergenerational justice depends upon laws designed to hold states and
corporations accountable for pollution and rights violations and their
enforcement by courts willing to acknowledge public alarm about global
heating. [For the Arctic, when it comes to geoengineering, it must tread
carefully when engaging with these tools]{.underline}.
