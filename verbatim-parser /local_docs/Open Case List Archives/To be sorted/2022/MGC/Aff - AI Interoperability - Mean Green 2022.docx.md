**AFF Packet -- Mean Green Debate**

**Intro Stuff**

**[Topic]{.underline}**

Resolved: The United States federal government should substantially
increase its security cooperation with the North Atlantic Treaty
Organization in one or more of the following areas: artificial
intelligence, biotechnology, cybersecurity.

**[Definitions]{.underline}**

Definitions of AI

1.  Artificial intelligence (AI) is the ability of a computer or a robot
    controlled by a computer to do tasks that are usually done by humans
    because they require human intelligence and discernment. --
    Britannica

2.  In his book Sentient Machine, Amir Husain defines AI as "the
    overarching science that is concerned with intelligent algorithms,
    whether or not they learn from data.

EDTs = Emerging and Disruptive Technologies

STS studies = Science, technology, and society studies

RRI = responsible research and innovation---Focused on responsible
innovation

Corrigibility = capable of being corrected, reformed, or improved.

CDA = The DoD's new Office of the Chief Data and AI Officer

Interoperability = the ability of computer systems or software to
exchange and make use of information. AND/OR the ability of military
equipment or groups to operate in conjunction with each other.

**[Intro cards]{.underline}**

**Intro to NATO's role in AI/Emerging Tech**

**Stanley-Lockman & Trabucco 3/22**

Zoe Stanley-Lockman & Lena Trabucco , "NATO's Role in Responsible AI
Governance in Military Affairs", Zoe Stanley-Lockman Nanyang
Technological University, Lena Trabucco University of Copenhagen, Center
for Military Studies The Oxford Handbook of AI Governance Edited by
Justin Bullock, Yu-Che Chen, Johannes Himmelreich, Valerie M. Hudson,
Anton Korinek, Matthew Young , and Baobao Zhang Subject: Political
Science, Political Institutions Online Publication Date: Mar 2022DOI:
10.1093/oxfordhb/9780197579329.013.69

[This chapter explores a role for]{.underline} the North Atlantic Treaty
Organization ([NATO]{.underline}) **[in the emerging military artificial
intelligence (AI) governance architecture]{.underline}**. As global
powers compete for capabilities that AI can offer, NATO has the
challenging task of recalibrating strategic relationships in the coming
years. NATO has begun to recognize technological change as a necessary
variable and, in turn, adapt its organizational composition and strategy
to increase the Alliance's capacity to meet emerging security
challenges. [As NATO bodies and Allies prepare for the impact of AI on
future military op]{.underline}eration[s, NATO has its own
responsibility to **steward AI in ways that promote harmonization among
Allies and advance the NATO mission**]{.underline}. Toward this effort,
the chapter highlights [two governance mechanisms within
NATO]{.underline}'s competency---**[strategic and policy planning, and
standards and certification]{.underline}**---as practices that exemplify
NATO's power to shape the trajectory of technological development. We
operationalize these governance tools by examining the three pillars
that are particularly challenging for AI governance: ethics and values,
legal norms, and safety and security. Within each pillar, we examine
NATO's facilitation of strategic policy planning and standards and
certification to emerge as a leader in establishing responsible
technological development and, ultimately, a more secure international
security environment. [This chapter finds there is space for NATO to
pursue its agenda to maintain technological superiority not just to
protect and defend its way of life, but to build on AI governance
pillars to steward military innovation on a responsible
trajectory]{.underline}.

**Intro to China view on AI**

**Sullivan** 10/4/20**21**

Ryan Sullivan Army pilot studied at the prestigious Fudan University in
Shanghai, China, as an Olmsted Scholar graduate-level work in the field
of Artificial Intelligence to deliver an in-depth study of the critical
elements of U.S.-China competition in Artificial Intelligence, "The
U.S., China, and Artificial Intelligence Competition Factors",
<https://www.airuniversity.af.edu/Portals/10/CASI/documents/Research/Cyber/2021-10-04%20US%20China%20AI%20Competition%20Factors.pdf?ver=KBcxNomlMXM86FnIuuvNEw%3D%3D>
-- ECM

In his book Sentient Machine, Amir Husain defines AI as "the overarching
science that is concerned with intelligent algorithms, whether or not
they learn from data."5 This paper centers on competition within the
scope of narrow AI and not artificial general intelligence (AGI).6 Rapid
breakthroughs in machine learning (ML) resulted from an open ecosystem
that encourages collaboration across platforms, unconstrained by
national boundaries. The extent to which those collaborations should
continue when the transfer of data, algorithms, and other dual-use
technologies directly impact national security, is a central question
facing AI competition with China. AI (人工智能) allows China to innovate
and surpass the capabilities of other nations rapidly, often referred to
in Chinese research as "overtake by changing lanes" (换道超车).7 Rapid
innovation and focusing on emerging technologies without established
global leadership is a way to build comprehensive national power to
preserve domestic social stability, create economic and military
strength, and protect core interests (核心利 益).7F8 [China's core
interests extend beyond borders and into cyberspace]{.underline}
(网络空间) **[via the pursuit of AI norms that promote cyber
sovereignty]{.underline}**.9 [Protecting sovereignty for
the]{.underline} Chinese Communist Party ([CCP]{.underline}) **[that
appears fragile and insecure]{.underline}**, increasingly [relying on AI
as a means of promoting stability and growth within China to bolster
the]{.underline} CCP's [legitimacy]{.underline}. As prominent Beijing
scholar Wang Jisi notes, **[the CCP's legitimacy to govern is linked to
performance and "the current mainstream view in China]{.underline}**
[emphasizes -- party, government, military, then the
people]{.underline}....and the Party leads everything."10 Diverging
values and competing national interests between democracies and the CCP
amplify AI competition and challenge the U.S. and China to compete below
the conflict threshold. Despite breakdowns in bilateral relations,
zero-sum conflict is not predestined, as Shanghai scholar Wu Xinbo
notes, "promoting pragmatic cooperation and constructive competition,
effective management, control of risks, and [prevention of major
conflicts between China and the U]{.underline}nited [S]{.underline}tates
**[remains the basic direction of China's diplomacy with the
U]{.underline}**nited **[S]{.underline}**tates."11 Several U.S. scholars
and leaders such as Elizabeth Economy and Graham Allison also advocate
cooperative approaches to competition by promoting coopetition,
coevolution, or rivalry partnerships.12 Such strategies are hard to
imagine in a period of increasingly strained bilateral relations and
diverging values, and are likely to fail if the leaders of both nations
maintain a binary approach to engagement. This paper explores
competition through the lens of values, cohesion, influence, and
legitimacy to better understand each nation's positional advantages and
identify possibilities for cooperation in bilateral or multilateral
engagements.

**[AI strengthens the CCP's ability to preserve power through expansions
of its targeted population programs]{.underline}** (重 点人口)·**[and
increased surveillance of its people]{.underline}**.13 The People's
Liberation Army (PLA) is the Army of the Party and plays an essential
role in domestic security. AI's role in surveilling and suppressing
society for the benefit of a ruling entity represents a values conflict
and the most significant single obstacle to cooperation on AI norms,
rules, and procedures between our nations. As China seeks to export
surveillance technology and gain access to international data, a sense
of urgency emerges over China's efforts to legitimize its authoritarian
governance model and to secure its interests through promoting standards
and norms in international institutions. The "China Standard 2035" plan
was not released in 2020 as expected. However, the focus on protecting
core interests, strengthening emerging industries, pursuing leadership
positions in international institutions, and extending global influence
in the emerging world order by giving voice to developing nations,
appear throughout the current 14th five-year plan (2020-2025), seeking
to ensure the international order better represents China's interests,
including the Party's values. This paper offers that [the U.S. leads the
overall AI competition]{.underline} with China, **[but]{.underline}**
that [China retains the edge in both perceived utility and adaption of
AI]{.underline} across society, a result of central planning efforts
which better organizes China to promote AI applications at scale.
China's competitive advantage results from vast amounts of data
generated from mobile payments, the pursuit of digital currency, and the
widespread installation of cameras that feed predictive algorithms
controlled by the CCP.14 In contrast, Americans remain mostly
distrustful of authority, and mobile payments are less widely accepted.
The concern over misinformation and the ethics of algorithms that
reinforce desired content for users and increased partisanship will
bring AI to the forefront of American discussion but will do little to
encourage robust AI adoption. Without significant adoption the U.S.
should increase investments in research into alternative means of
synthetically generating data or techniques allowing deep learning (DL)
to train effectively on smaller amounts of data.15 Achieving such
success requires increased investments in basic research and a cohesive
approach to policy and strategy that encourages domestic collaboration
and R&D spending while strengthening international partnerships to
address gaps or inefficiencies within the U.S. AI ecosystem effectively.

[China views national strength as the foundation for global AI
competition and Chinese scholars put forward the idea that "without
national strength, how can we talk about standards]{.underline}."16
Military-civil fusion (军民融合 战略) represents a cohesive approach to
organizing talent and resources around a strategy to address domestic
deficiencies, build national strength, and close the overall U.S.
advantages in AI. The collaborative nature of AI research and reciprocal
interaction by university scholars of AI and related techno-subjects
present examples of "win-win" competition for both the U.S. and China.
However, the Chinese military's close relationship with many of China's
leading universities and AI-focused companies presents significant
challenges to the notion of AI cooperation between the U.S. and China.
In particular, the PLA's exploration of brain science and pursuit of
"brain control" (制脑权), which they consider the "new high ground"
(新的高地), results from collaborations with industry and
universities.17 Coupled with the concerns over intellectual property
(IP) theft, espionage, visa restrictions, and export controls, the
cohesion chapter explores the inherent risks to U.S. national security
of pursuing collaboration and cooperation with China. The Chinese
military directly benefits from working with national high technology
enterprises such as Baidu, Alibaba, Tencent, and Huawei (BATH) and
prestigious universities across China. Many U.S. companies and
universities also work with those same Chinese universities through
research centers and joint laboratories, generating U.S. national
security concerns. China understands its second adapter advantages are
dwindling.18 The open-source nature of AI research could likely end,
threatening future Chinese AI development nearly as much as their
hardware vulnerabilities and reliance on international firms within the
global supply chain. The Chinese 19th National Congress in 2017 directed
the requirement to strengthen "basic research" (基础研究) and "applied
basic research" (使用基础研究), making universities the focal point of
this effort.19 With a large population and a focused government driving
investments, quantity is not the issue in China, but quality remains a
concern. Quantity superseding quality applies to the number of sciences,
technology, engineering, math (STEM) graduates, patents, research
papers, and supercomputers. China is closing the gap, but the U.S. is
well-positioned to maintain its advantages, provided America recognizes
the importance of attracting top foreign talents and reinvest in STEM
and research and development (R&D).

China's approach to AI utilization presents nations of the world with an
alternative model to the democratic prosperity narrative. AI also allows
Beijing to project its alternative views on power abroad and nurture
China's influence among developing nations, which will prove critical
when the time comes for China to push for acceptance of Chinese
standards and norms. However, influence focuses on China's competing
models in overseas markets and AI's role in providing security, economic
development, and improved livelihoods for nations. Global concerns over
Huawei and regional concerns over Belt and Road Initiative (BRI)
represent just some of the problems facing China's overseas forays. The
use of AI at home and abroad, while attractive to some autocratic
leaders, creates a significant cause for concern in other countries
regarding ethical concerns or applications of AI. Lack of transparency
in BRI projects and handling of COVID does little to demonstrate to
other nations that China will act in good faith or adhere to the
standards and norms of most countries. Detention camps in Xinjiang and
repression of dissidents in Hong Kong continue to impact Xi's global
favorability ratings. However, China's core interests, particularly
sovereignty and territorial integrity, remain red lines that stoke
conflict rather than competition. The U.S. withdrawal from the
Trans-Pacific Partnership (TPP) and refusal to participate in Asia
Infrastructure Investment Bank (AIIB) or other China-led initiatives
leads one to believe that competing for influence is an area of zero-sum
competition; however, the lack of international standards and norms
concerning data and ethical applications of AI extend beyond the ability
of the U.S. or China to unilaterally impose solutions. Competing for
influence gives rise to input from other nations. While the U.S. would
appear to possess an advantage based on standing alliances and shared
liberal democratic values, data privacy concerns among democratic
nations differ widely and offer opportunities for both the U.S. and
China to collaborate with other nations on a global solution.

With domestic stability and its emergence as a global power, **[Beijing
hopes to parlay increased international influence and legitimacy to
pursue global standards that better represent Chinese values and
norms]{.underline}**. [With the publication of the "Beijing AI
Principles" and "Global Initiative on Data Security," the competition
for AI norms is underway]{.underline}.20 [China's antagonism toward the
U.S. as a "technological hegemon"]{.underline} (技术霸权) **[and
Beijing's explicit support for multipolarity]{.underline}**
**[highlights the CCP belief that "multipolarity is more sustainable
than unipolarity]{.underline}**, while less divisive and antagonistic
than bipolarity" and that "multipolarity could be less predictable than
both unipolarity and bipolarity."21 [Thus, China may continue to pursue
AI norms through the existing global framework but will prepare for the
prospects of decoupling if Chinese standards fail to gain
acceptance]{.underline}. The idea of "two systems, three worlds"
(两大体系， 三大世界) goes beyond 5G, and Chinese initiatives on
satellite navigation and digital currency are other examples where
decoupling could occur. 22 The importance of shared values and the role
of soft and hard power will significantly influence the Sino-American
competition over AI norms in the standing liberal, multipolar order.
Competition, not conflict, is most likely to occur at a variety of
levels. China, and the U.S., for that matter, remain dissatisfied with
the current liberal world order. The Chinese perceive a decline in the
U.S. desire to lead and an opportunity to reform existing organizations
from within. All indications are that China views the UN as central to
preserving a liberal order. [As a nation that benefitted greatly from
the current Westphalian order, China seems unlikely to pursue
significant revisions in the structure or composition of the current
world order for now. Seeking to work within the framework of the UN and
World Trade Organization (WTO), China will promote a governance model
that emphasizes sovereignty above all else, and minimize significant
value conflicts by pursuing leadership positions and relying on support
from sympathetic nations to block unfavorable or undesirable resolutions
or actions]{.underline}. In an anticipated multipolar world order,
Beijing will champion initiatives such as AIIB, BRI, or the Shanghai
Cooperation Organization (SCO) as alternative models for collaboration
and non-binding alliances that better represent developing nations.
These organizations demonstrate an inclusive approach to membership,
which Beijing hopes will validate their legitimacy to lead in an
increasingly multipolar world.

**Affirmative**

**1AC v1**

**[Plan]{.underline}**

**Resolved: The United States federal government should substantially
increase its security cooperation with the North Atlantic Treaty
Organization in artificial intelligence by**

- **Establishing a 10-year roadmap for upgrading data
  interoperability.**

- **A set of definitions over how AI should be used.**

- **Create a process for collecting technical and policy knowledge from
  international interactions with AI.**

**Advantages + Solvency**

**[Advantage ( ): Cyber]{.underline}**

**Cyber-attacks are increasing against NATO nations**

**Check Point 3/21**/2022

"Cyber Attacks from Chinese IPs on NATO Countries Surge by 116%",
https://blog.checkpoint.com/2022/03/21/cyber-attacks-from-chinese-ips-on-nato-countries-surge-by-116/

Last week, Check Point Research ([CPR]{.underline}) **[observed an
increase in cyber attacks aimed for NATO countries]{.underline}** that
were [sourced from Chinese IP addresses]{.underline}. CPR examined the
trend before and after Russia's invasion into Ukraine, learning that
[cyber attacks]{.underline} from Chinese IPs **[jumped by
116%]{.underline}** [on NATO countries]{.underline}, and 72% world-wide.
CPR can not attribute the cyber attacks to the Chinese entities or to
any known Chinese threat actor. [The observation indicates a trend that
hackers]{.underline}, likely [within China and abroad]{.underline}, [are
increasingly using]{.underline} Chinese IPs as a resource to launch
[cyber attacks after the advent of the]{.underline} Russia-[Ukraine
conflict]{.underline}.

Check Point Research (CPR) sees an increase in cyber attacks sourced
from Chinese IP addresses throughout the current Russia-Ukraine
conflict.

- Last week, [the weekly average of]{.underline} worldwide
  [attacks]{.underline} originating from China per organization [was 72%
  higher than before the invasion]{.underline} [and]{.underline} 60%
  higher than the first three weeks of the conflict

- Last week, the weekly average of cyber-attacks sourced from China [on
  NATO]{.underline} corporate **[networks was 116% higher]{.underline}**
  than before the invasion, and 86% higher than the first three weeks of
  the conflict

- The increase is significantly higher than the overall global increase
  in cyber attacks seen during the same timeframes

**Ambiguity over how to respond results in [adversary
testing]{.underline} and [miscalculation]{.underline}\-\--that collapses
cyber [deterrence]{.underline} and [cohesion]{.underline}**

**Patrick 18**.

Stewart M., James H. Binger Senior Fellow in Global Governance and
Director of the International Institutions and Global Governance
Program. \"NATO\'s Deterrence Problem: An Analog Strategy for a Digital
Age\". Council on Foreign Relations. 8-8-2018.
https://www.cfr.org/blog/natos-deterrence-problem-analog-strategy-digital-age

At their annual summit last month, [the twenty-nine allies reaffirmed
the integral role cybersecurity plays in NATO]{.underline}, creating a
Cyberspace Operations Center to supplement existing cyber defense
facilities and reaffirming the need for an offensive capability "to
deter, defend against, and to counter the full spectrum of cyber
threats." Missing from the communique, however, were any rules of
engagement for the cyber sphere. [This raises the question: **How would
NATO respond** if a member state were to **invoke Article V** of the
North Atlantic Treaty following a **cyberattack**?]{.underline}

The [NATO]{.underline} alliance [has long maintained a policy of
strategic **ambiguity**]{.underline} when it comes to nuclear policy,
[leaving open the possibility that a conventional attack might be met
with a nuclear response]{.underline}. (By contrast, China and India have
adopted "no--first use" policy for nuclear weapons.) [NATO's nascent
cyber policy exhibits a similar ambiguity]{.underline}, intentionally
[leaving unclear how the alliance would react to a cyberattack. Rather
than responding in kind, NATO might]{.underline} instead conduct
conventional attacks, such as missile strikes, [allow]{.underline}ing
[for **rapid escalation**]{.underline}.

[Early cyberattacks were largely seen as low-stakes]{.underline} events:
an inconvenience for the financial sector and dangerous for personal
data, but not a threat to national security or justification for a
military response. [This is no longer necessarily the case]{.underline}.
A coordinated Russian cyberattack against a nuclear power plant in
Europe and the United States could have devastating consequences, were
it to result in major radiation leaks. An attack on a country's electric
grid, a softer target, could in theory cause hundreds of billions of
dollars in damage and put lives at risk as traffic lights stop working,
hospitals lose power, and unrest erupts.

Given these stakes, NATO has an obvious incentive to strengthen its
capacity to deter and punish cyberattacks, including through
conventional retaliation. A U.S. Department of Defense memorandum
published in early 2017 stated that at least for the next decade,
[offensive cyber capabilities are likely to **outpace cyber
defense**]{.underline}, making deterrence the most viable option. Both
[the United States and NATO]{.underline} also [recognize that a
devastating cyberattack could **quickly escalate to violent conflict**
by triggering a conventional response. Unfortunately]{.underline}, the
alliance's policy of strategic [**ambiguity falls short**. By failing to
define the rules of engagement for retaliation, the alliance leaves
**open the potential for chaos** in determining an appropriate response
to cyberattacks]{.underline}. In doing so, **[it invites adversaries to
test the waters.]{.underline}**

[Cyber deterrence is **inherently more challenging** than nuclear or
conventional deterrence]{.underline} because such [attacks are
**difficult to definitively attribute**]{.underline} to a particular
actor. For example, it is easier to mask the source of a cyberattack on
a power grid than it would have been for the Warsaw Pact to conceal a
massive incursion into West Germany. [This attribution problem could
**complicate NATO's capacity** to conclusively determine the
source]{.underline} of a cyberattack and justify [**and conduct a timely
conventional response**, particularly if member states diverge in their
perceptions. This dilemma could **strain the foundations of collective
defense and undermine any unified front against
cyberattacks**.]{.underline}

[For NATO to commit]{.underline} to military action, **[all of its
members would need certainty]{.underline}**, beyond a reasonable doubt,
about the identity of the perpetrator. [This is particularly true in the
case of **Russia**]{.underline}---a known sponsor of cyberattacks.
[Without conclusive proof, it might be a challenge to convince a distant
country like Portugal or a dangerously close one like Estonia to
join]{.underline} in a counterattack. Complicating matters, [such
post-attack decisions would need to be made **quickly**, given Russia's
precedent of using cyberwarfare as a precursor to kinetic invasion. The
need for speed leaves **little room for**]{.underline} philosophical
[**debates** over what constitutes]{.underline} an act of
[war]{.underline}.

To be sure, NATO's strategic ambiguity is not without its benefits.
Uncertainty about the threshold for a military response could persuade
an adversary not to push the envelope with an audacious attack. But that
same [ambiguity could lead an adversary to
**miscalculate**]{.underline}. Moreover, [the doctrine]{.underline} also
[leaves open the possibility of **discord in the ranks** of NATO member
states regarding how to deal with any such attack.]{.underline}

NATO's policy of [strategic ambiguity served]{.underline} it [well
during]{.underline} the long Cold War [nuclear confrontation. But it may
be **less appropriate to**]{.underline} the era of
**[cyberwarfare]{.underline}**, particularly [given the problem of
attribution and the potential for **inter-allied
disagreement**]{.underline} on the appropriate response to any
particular incident. [NATO policymakers need to **resolve this dilemma**
by formulating a more **explicit cyberwarfare doctrine**]{.underline} to
which all of its member states can adhere. [This should include updating
their]{.underline} mutual [understanding of **what constitutes an act of
aggression** under NATO's **collective defense
provisions**]{.underline}, making explicit to potential adversaries just
what its red lines are, [and establishing clear procedures]{.underline}
and channels for robust allied response to cyberattacks. [Unless NATO
**clarifies current ambiguities**, Russian **aggression in the cyber
realm could go unchecked**]{.underline}.

**NATO recently agreed that a cyber-attack *[CAN]{.underline}* trigger
Article 5 -- but ambiguity exist over when and how. NATO will respond
militarily if it deems a violation has occurred.**

**Laity 3/2**/2022

Mark Laity, senior director at the StratCom Academy and former head of
NATO's military SHAPE Communications Division. "Would a cyberattack on a
NATO country trigger Article 5?",
<https://www.cybersecuritydive.com/news/cyberattack-nato-article-5/619654/>
\-- ECM

When [a NATO official told Reuters that a cyberattack]{.underline}
**[could be considered an armed attack and trigger "Article
5,"]{.underline}** it was a significant moment. How significant is
harder to judge.

"Article 5" is NATO's holy grail, the core of what NATO is about. It is
part of the Washington Treaty, signed in 1949, that set up the North
Atlantic Treaty Organization, which started with 12 members and now has
30.

[Article 5 states]{.underline}, "[The Parties agree that an armed attack
against one]{.underline} or more of them in Europe or North America
[shall be considered an attack against them all]{.underline}."

So, an attack on Latvia is effectively the same as an attack on the
United States -- a powerful deterrent to a potential aggressor, but of
course life is never that simple.

For decades it seemed simpler, as an armed attack would be obvious and
NATO nations would respond with tanks, artillery, and warplanes. Now,
[in our new world]{.underline}, [nations can be undermined
through]{.underline} information warfare and infrastructure crippled by
[cyberattacks]{.underline}, often difficult to trace.

[How NATO should respond]{.underline} to such attacks
[create]{.underline}d [much debate]{.underline}, [first]{.underline}
[on]{.underline} the principles of [whether a cyberattack could be
considered an "armed attack," and secondly]{.underline} if it is, [what
to do]{.underline} about it.

The first question has been answered: it can, but the circumstances in
which it would are less clear, and I would say at present unknown even
within the Alliance. We can assume it will have to clear a very high
bar.

The second question is even harder, and it is worth returning to Article
5 here. Yes, an armed attack on one is considered an attack on all, but
each member is only required to take "...such action as it deems
necessary, including the use of armed force\..."

So, if for instance Latvia was attacked with tanks, individual nations
are not obliged to respond with military force. Article 5 is powerful
but how nations individually respond, with a lot or a little, is still
up to them.

Nevertheless, a conventional military attack on a NATO nation would, I
believe, get a massive response. Deterrence has worked. But [when we
move into the gray zone of "hybrid warfare" that response is harder to
predict]{.underline}.

**[This is one of the aims of Russia]{.underline}**n strategy towards
NATO, [to achieve its goals while operating below]{.underline} the
threshold that will trigger [Article 5]{.underline}. On cyber, [those
waters will be even muddier given how deniable activity is within
cyberspace]{.underline}.

To that end, for instance, it has a technical agreement with the
European Union and a NATO Industry Cyber Partnership. At SHAPE, NATO's
military headquarters, there is also a Cyberspace Operations Centre.

Currently, NATO is far more focused on defensive cyber, to secure its
systems from attack, and the nature of that is a point of debate.

Many say [passive cyber defense]{.underline}, where you simply build up
your virtual walls, [leaves the initiative with your
adversary]{.underline}, [enabling]{.underline} ~~him~~ **[them to probe
without consequence]{.underline}** until he finds your weak point.
[Effective defense means also going after the attacker]{.underline} and
forcing him onto the back foot -- so-called cyber offense. That is also
what would be needed if NATO's responding to an Article 5 breach.

It is also important to recognize NATO as an institution does not
possess significant cyber capabilities. When it comes to activities,
NATO is a command and control organization using hardware and personnel
loaned by members.

Few nations have sophisticated cyber capabilities and for operational
security reasons, they are closely guarded, rarely shared, and carefully
used.

It means **[if a cyberattack did trigger]{.underline}** NATO **[Article
5]{.underline}**, then the actual use of cyber weapons would be
outsourced to nations for use on behalf of the Alliance in a coordinated
manner.

I am assuming, surely likely, that any first response to a cyberattack
would include cyber. However, as [the NATO source told Reuters, a
response does not have to be symmetrical, and **could**]{.underline}
theoretically **[escalate to include a military one]{.underline}**.

**Uncertainty regarding cyber law causes [quick
miscalc]{.underline}\-\--escalates [outside]{.underline} the cyber
domain**

**Goodman 18**

Ryan The Anne and Joel Ehrenkranz Professor of Law at New York
University School of Law. He served as Special Counsel to the General
Counsel of the Department of Defense (2015-16). He is also a Professor
of Politics and Professor of Sociology at NYU. "Cyber Operations and the
U.S. Definition of "Armed Attack"" Just Security. 03-08-2018.
https://www.justsecurity.org/53495/cyber-operations-u-s-definition-armed-attack/

A widely accepted view of the UN Charter is that a State can use force
in self-defense only in response to an "armed attack," which is
importantly defined as the gravest forms of force in scale and effects.
In contrast, the United States has long maintained that a State can use
force in self-defense in response to any amount of force by another
State. The U.S. view might have worked well when it came to bombs and
battleships. There are reasons, however, to think that the [application
of the U.S. view in the cyber realm may risk **unintended, accidental,
and unnecessary militarized conflicts.** That's]{.underline} partly
[because of the **uncertainty of the law in cyberspace**]{.underline}
and partly because of the uncertainty of facts when cyber operations
occur. The U.S. position, one might think, reduces the overall risk of
militarized conflicts between States. One reason to recommend the U.S.
view is that it might enable a government to prevent escalation---for
example by using cyber-ops to impede another State's test missiles---in
response to the latter's low-level uses of force, and thus buy more time
for diplomacy to avoid a larger battle. What's more, if a State's hands
are tied such that it cannot use force to respond to a low-level use of
force by an aggressor, it will put pressure on governments to expand
what is meant by an "armed attack," which has potentially dangerous
precedential effects in the future. Those concerns, however, may not be
as relevant for the United States, which, above and beyond other States,
has a broader range of potential diplomatic, economic, and other
non-forcible, non-military means to defend its interests. More important
is deterrence. [In favor of the U.S. view of the law is that a lower
threshold for triggering the right of self-defense can deter aggressors
from acting in the first place.]{.underline} In terms of defensive
posture, the United States deters others who know that the American
military can use its mighty arsenal in response to any illegal use of
force. [That empirical claim, however, is **weaker** in a world in which
States very **frequently engage in low-level uses of force in
cyber**]{.underline}, or might be thought to have done so by their
adversaries. In that world, [many States will have the legal right to
use force in self-defense against others on an ongoing
basis.]{.underline} Also, consider the U.S. offensive posture. The
greater extent to which the United States, in particular, is engaged in
cyber activities across the world that will be considered a use of force
by other States, the greater license the United States may be handing
those States to use force---whether in the cyber or kinetic realm---in
response. That is, if those States adopt a view similar to the United
States that "the inherent right of self-defense potentially applies
against any illegal use of force." It may have been more satisfying to
the United States to operate in world in which it maintained the legal
prerogative to adopt a forcible response in reaction to any illegal use
of force while other States did not maintain that position. Our legal
world may be changing, however. Witness, for example, Japan's recent
shifts toward the U.S. position. Taken in light of Mutual Defense
Agreements, in which the United States has accepted an obligation to
support other States who have been subject to an "armed attack," and the
kinds of calculations of what makes the world safer and better protects
U.S. national security must surely shift. More specifically, if more
U.S. allies start moving toward the U.S. view of "armed attack," the
United States may be drawn into far-flung cyber conflicts as an
unintended consequence. [Now add to this mix the legal uncertainties
that exist in this specific area of cyber law. The **legal definition**
of what exactly is a use of force in the cyber realm is **far less
settled** than in the kinetic realm.]{.underline} What's more, it is
safe to assume that several States around the world are frequently
engaging in actions that others might consider a use of force. Is the
laying of specific types of malware on the systems of another State in
preparation for possible future activation analogous to laying landmines
in another State's territory? The Tallinn Manual's definition of
cyberattacks (at least in the context of jus in bello) may lead one to
think so, but widespread State practice would appear to contradict that
conclusion. So which is it? Also, could the alteration or destruction of
data count as a use of force or attack? This is an area where views are
developing in one direction, but what happens in the limbo period
between now and then, when some States and legal authorities hold one
view and others hold different ones? That seems like a dangerous period
for calibrating the use of force in cyber. And those are just two
examples of legal uncertainties out of many that one could describe.
These types of legal uncertainties are compounded by factual
uncertainties in the cyber realm. While the United States appears to
have an increasingly impressive ability to determine attribution, many
other States lack that sophistication and are thus more likely to make
costly errors. State D may mistake a cyber operation launched by a rogue
hacker or organized non-State group operating out of country Y as being
perpetrated by State Y itself. And governmental or non-governmental
cyber hackers in a third country may very purposefully make it look like
State Y conducted a cyberattack. Another difficulty in the cyber realm
is determining whether certain effects of a hostile cyber operation were
intended by the attacker. For example, State D may detect an imminent
threat of malware in its systems that appears would at least temporarily
compromise its most sensitive military arsenal---but is that what the
perpetrator intended (and how, as a legal issue, should that question of
intentionality matter)? [In cyberspace, many of these actions and
interactions will **take place at greater speeds**]{.underline} thanks,
in part, to artificial intelligence. [These conditions may **shrink the
window of time** for political and military leaders to make decisions,
and **place pressure on them to pre-authorize** or create automated
responses. It is not hard to imagine tit-**for-tat uses of force quickly
ascending a ladder of escalation.** And there is no legal reason the
rungs of that ladder will remain **confined to the cyber
realm.**]{.underline}

**Cyber miscalculations cause [nuclear war]{.underline}\-\--extinction**

**Moniz & Nunn 18**

Ernest Sam Ernest Moniz, the former US secretary of energy, and Sam
Nunn, a former US senator, are co-chairmen of the Nuclear Threat
Initiative. "Cyber attacks and rising risks of an accidental nuclear
war" 02-03-2018.
https://www.straitstimes.com/opinion/cyber-attacks-and-rising-risks-of-an-accidental-nuclear-war

[The world has crossed over to a new nuclear era in which a fateful
error]{.underline}, rather than intentional aggression, [is the **most
likely catalyst to nuclear catastrophe.**]{.underline} American leaders
have been warned more than once of incoming Russian missiles - in each
case, it was a false alarm resulting from technical or human error.
Former Russian president Boris Yeltsin was mistakenly alerted to a
possible United States missile strike after the launch of a Norwegian
scientific rocket. [After every incident, we deceive ourselves that we
can solve the problem with better technology and training, or we
reassure ourselves]{.underline} that the combination of diligence and
good luck we experienced during the Cold War will continue. But do we
really believe we can prevent a nuclear catastrophe indefinitely in a
world that has nine states with nuclear weapons and significant
suspicion and hostility in many of their mutual relationships? The
[risks of human error involving nuclear weapons are compounded by the
potential for deliberate **cyberthreats to warning and
command-and-control systems.** Hackers could insert a **false warning of
a nuclear attack** into national warning and alert systems]{.underline}
and falsely attribute that attack to an innocent country. [At a time of
heightened global tensions, with **too little communication or
cooperation between nuclear rivals** and only **minutes of decision
time**, how would leaders of states with nuclear weapons
respond?]{.underline} The [Trump]{.underline} administration recently
[**declared plans to broaden the role of nuclear weapons** in national
defences beyond deterring nuclear attacks on the United States and its
allies.]{.underline} Its new National Security Strategy states that the
arsenal is now \"essential\" to preventing not just a nuclear attack but
also \"non-nuclear strategic attacks, and large-scale conventional
aggression\". A leaked draft of its forthcoming Nuclear Posture Review
has similar language. Expanding the range of threats against which
nuclear weapons might be used - which implies, for example,
\"strategic\" cyber attacks - will greatly increase the risks of
miscalculation or blunder. If a cyber attack took out a major part of
our electrical grid, would we be able to quickly and confidently
identify the attacking country? If Russia, China, India, Pakistan and
others adopt similar policies, are we moving down a path where nuclear
use becomes highly probable? Every country with nuclear weapons
perceives its geopolitical circumstances differently, but we all face
substantially increasing nuclear risks. Every country with nuclear
weapons perceives its geopolitical circumstances differently, but
[we]{.underline} all [face **substantially increasing nuclear
risks.**]{.underline} Individually, where necessary, and together where
possible, they must move with urgency on policies that can reduce these
risks for all nations.

**Cyber defense doesn't apply -- Doesn't assume AI -- increases in
fragmented AI responses will *[INEVITABLY]{.underline}* trigger a
*[PHYSICAL ATTACK]{.underline}*. Only regulated AI can solve.**

- Regulated AI is key to cyber defense

**Taddeo & Floridi 18**

NATURE \| VOL 556 \| 19 APRIL 2018, Mariarosaria Taddeo is a research
fellow and deputy director of the Digital Ethics Lab at the Oxford
Internet Institute, University of Oxford, UK; and a Turing fellow of the
Alan Turing Institute, London, UK. Luciano Floridi is professor of
philosophy and ethics of information at the University of Oxford, UK;
director of the Digital Ethics Lab at the Oxford Internet Institute; and
chair of the Data Ethics Group at the Alan Turing Institute. "Regulate
artificial intelligence to avert cyber arms race",
<https://media.nature.com/original/magazine-assets/d41586-018-04602-6/d41586-018-04602-6.pdfv>
\--ECM

[Cyberattacks are]{.underline} **[becoming more frequent, sophisticated
and destructive]{.underline}**. Each day [in 2017]{.underline}, [the
U]{.underline}nited [S]{.underline}tates [suffered]{.underline}, **[on
average]{.underline}**, **[more than 4,000]{.underline}** ransomware
[attacks]{.underline}, which encrypt computer files until the owner pays
to release them1 . In 2015, the daily average was just 1,000. In May
last year, when the WannaCry virus crippled hundreds of IT systems
across the UK National Health Service, more than 19,000 appointments
were cancelled. A month later, the NotPetya ransomware cost
pharmaceutical giant Merck, shipping firm Maersk and logistics company
FedEx around US\$300 million each. Global damages from cyberattacks
totalled \$5 billion in 2017 and may reach \$6 trillion a year by 2021
(see go.nature.com/2gncsyg).

[Countries]{.underline} are partly behind this rise. They [use
cyberattacks both offensively and defensively]{.underline}. For example,
[No]{.underline}rth [Ko]{.underline}rea has been linked to WannaCry,
[and Russia]{.underline} to NotPetya.

[As]{.underline} the [threats escalate, so do defence
tactics]{.underline}. Since 2012, the United States has used 'active'
cyber defence strategies, in which computer experts neutralize or
distract viruses with decoy targets, or break into a hacker's computer
to delete data or destroy the system. In 2016, the United Kingdom
announced a 5-year, £1.9-billion (US\$2.7-billion) plan to combat cyber
threats. [NATO]{.underline} also [began drafting principles for active
cyberdefence]{.underline}, to be agreed by 2019. **[The
U]{.underline}**nited **[S]{.underline}**tates and the United Kingdom
**[are leading this initiative]{.underline}**. Denmark, Germany, the
Netherlands, Norway and Spain are also involved (see
go.nature.com/2hebxnt).

Artificial intelligence ([AI)]{.underline} [is poised to
revolutionize]{.underline} this activity. **[Attacks and
responses]{.underline}** will become faster, more precise and more
disruptive. **[Threats will be dealt with in hours]{.underline}**, not
days or weeks. AI is already being used to verify code and identify bugs
and vulnerabilities. For example, in April 2017, the software firm
DarkTrace in Cambridge, UK, launched Antigena, which uses machine
learning to spot abnormal behaviour on an IT network, shut down
communications to that part of the system and issue an alert. The value
of AI in cybersecurity was \$1 billion in 2016 and is predicted to reach
\$18 billion by 2023 (ref. 2).

By the end of this decade, [many countries plan to deploy AI
for]{.underline} national [cyberdefence]{.underline}; for example, [the
U]{.underline}nited [S]{.underline}tates [has been evaluating the use of
autonomous defence systems]{.underline} and is expected to issue a
report on its strategy next month3 . **[AI makes deterrence possible
because attacks can be punished]{.underline}** 4. [Algorithms can
identify the source and neutralize it without having to identify the
actor behind it]{.underline}. Currently, countries hesitate to push back
because they are unsure who is responsible, given that campaigns may be
waged through third-party computers and often use common software.

**[The risk is a cyber arms race]{.underline}** 5. [As states
use]{.underline} increasingly **[aggressive AI-driven
strategies]{.underline}**, [opponents **will respond** ever more
fiercely]{.underline}. **[Such a vicious cycle might lead ultimately to
a physical attack]{.underline}**.

[Cyberspace is]{.underline} a domain of **[warfare]{.underline}**, and
AI is a new defence capability. **[Regulations are thus necessary for
state use]{.underline}** of AI, as they are [for]{.underline} other
**[military domains]{.underline}** --- [air, sea, land and
space]{.underline} 6. [Criteria are needed to determine proportional
responses, as well as]{.underline} to set clear thresholds or '**[red
lines]{.underline}**' for distinguishing legal and illegal cyberattacks,
and to apply appropriate sanctions for illegal acts7 . In each case,
unilateral approaches will be ineffective. Rather, [an international
doctrine must be defined for state action in cyberspace]{.underline}.
Alarmingly, international **[efforts to regulate cyber conflicts have
stalled]{.underline}**.

**[Advantage ( ): Heg]{.underline}**

**The SQ is unsustainable -- maintain AI advantages requires alliance
buy in. Absent adaption China fills in.**

**Sullivan** 10/4/20**21**

Ryan Sullivan Army pilot studied at the prestigious Fudan University in
Shanghai, China, as an Olmsted Scholar graduate-level work in the field
of Artificial Intelligence to deliver an in-depth study of the critical
elements of U.S.-China competition in Artificial Intelligence, "The
U.S., China, and Artificial Intelligence Competition Factors",
<https://www.airuniversity.af.edu/Portals/10/CASI/documents/Research/Cyber/2021-10-04%20US%20China%20AI%20Competition%20Factors.pdf?ver=KBcxNomlMXM86FnIuuvNEw%3D%3D>
-- ECM

The paper assesses that [the U.S. is well-positioned to maintain
competitive advantage with China in the AI]{.underline} domain.
**[However]{.underline}**, [American advantage hinges on
forming]{.underline} flexible and overlapping **[alliances based on
values]{.underline}** and committing the required domestic resources
**[to address legitimate national concerns]{.underline}** over
science-technology engineering-math (STEM) education, gaps in domestic
manufacturing, obstacles to attracting foreign talent, and ethical
concerns over data AI application. [If the U.S. does not
adapt]{.underline} in these areas, **[China can quickly narrow the AI
gap]{.underline}**. Moreover, while the U.S. and China remain the two
nations best positioned to benefit from increased adoption of AI across
society, this paper concludes that [their competition is
not]{.underline} just [binary]{.underline} for [it exists
within]{.underline} **[concentric circles of overlapping international
partnerships and agreements]{.underline}**. Such an environment is as
malleable as it is uncertain for the international community today as
all governments struggle with challenges over data privacy, [the role of
AI-empowered multinational companies, and critical choke points in
supply chains that impact the AI industry and threaten national security
interests]{.underline}. The importance of [global trade, the
dual-use]{.underline} nature of AI, and the emergence of
[tech]{.underline}nology [clusters and]{.underline} critical [supply
components]{.underline} outside of the U.S., [illustrate the complex
web]{.underline} that both [the U.S. and China must
navigate]{.underline} to extend influence to pursue desired objectives
with AI.

The monograph establishes that **[without allies and
partners]{.underline}**, [American AI growth]{.underline}, high
technology innovation, and productive economic development **[will
stagnate]{.underline}** [as]{.underline} many [nations address the
complexities of data]{.underline} sharing in a world [where
China]{.underline} will [cast an enormous shadow]{.underline}.
**[Coop]{.underline}**erating **[with any nation that shares similar
values with the U.S. is essential]{.underline}** [for expanding the
scope and scale of]{.underline} coordination on [AI]{.underline} in
existing multilateral institutions and new organizations very likely to
form in response to AI's increasingly important impact throughout
society. [If liberal democracies]{.underline} **[do not establish norms
and standards for AI, then China will fill the vacuum]{.underline}**.
While many view techno-democratic alliances as the best solution for
enabling durable AI norms and standards, one must not lose sight of the
fact that national interests will not always align, even among liberal
democratic allies. [After the establishment of]{.underline} a firm base
of **[support for agreeable AI procedures among nations]{.underline}**
with shared values and norms, the next step should be an outreach to
nations with "illiberal values," thus incrementally including them by
design. [Only after these steps toward a robust collective of
like-minded nations might greater collaboration and
coop]{.underline}eration [with China on AI standards]{.underline}, norms
and institutions [make sense]{.underline}.

**China victory in AI risk overturning unipolarity -- AI is the
*[KEY]{.underline}* internal link between unipolarity and multipolarity.
That EXPANDS the risk international competition and instability.**

**Sullivan** 10/4/20**21**

Ryan Sullivan Army pilot studied at the prestigious Fudan University in
Shanghai, China, as an Olmsted Scholar graduate-level work in the field
of Artificial Intelligence to deliver an in-depth study of the critical
elements of U.S.-China competition in Artificial Intelligence, "The
U.S., China, and Artificial Intelligence Competition Factors",
<https://www.airuniversity.af.edu/Portals/10/CASI/documents/Research/Cyber/2021-10-04%20US%20China%20AI%20Competition%20Factors.pdf?ver=KBcxNomlMXM86FnIuuvNEw%3D%3D>
-- ECM

Henry Kissinger once wrote that "the stability of any international
system ultimately relies on what he termed 'generally accepted
legitimacy."371 [Any international framework needs buy-in from the
powers within it]{.underline}", **[and the U.S. must play a central
role]{.underline}** [in shaping the AI world order]{.underline}.372 This
chapter focuses on AI competition between the U.S. and China for
legitimacy to lead efforts "conforming to recognized principles or
accepted rules and standards."373 The international contest over global
leadership occurs [when China's rise challenges U.S.
heg]{.underline}emony in a liberal world order created without
participation from the CCP. [AI and other emerging
tech]{.underline}nologies **[will disrupt traditional measures of
power]{.underline}**. While the U.S. and China will remain the strongest
poles, [the emerging world order will be more
**multipolar**]{.underline} than bipolar in design, [as AI enables
regional powers to seek greater input over norms and
standards]{.underline}.374 [China]{.underline} perceives and **[desires
multipolarity to limit U.S. power]{.underline}** and influence to the
degree that the U.S.'s preferred values and political institutions are
not dictated to others. While some rush to make comparisons to the Cold
War or the space race, a CNAS report suggests [that]{.underline}
"[competition in the AI arena]{.underline} [could be]{.underline} even
more **[intense]{.underline}**. The space race was fundamentally a
bipolar competition -- a subset of the broader Cold War\... Competition
in AI, on the other hand, **[may be much more intense because it will be
much more multipolar and multisector]{.underline}**."375 This chapter
focuses on AI competition in an increasingly multipolar world structure
where values and influence with rising middle powers and developing
nations "lend authority or respectability" to a nation's leadership
position on AI.376 However, for China, there is a domestic element of
legitimacy competition related to Sino-American values competition in
the first chapter of this monograph. [For China]{.underline},
[legitimacy also addresses]{.underline} the CCP's [concern over
maintaining domestic legitimacy as the sole power in a single-party
system]{.underline}. The CCP's domestic problems reflect legitimacy in
terms of "popular acceptance of a government, political regime or system
of governance."377 This definition highlights an area where competition
over legitimacy and values overlap and should be understood by readers
when viewing China's actions in the global setting. There are two
audiences for the CCP, the international community, and its domestic
base, who want to see an emergent China take on a larger leadership
role.

This global leadership focus aligns with one of [the
NSCAI's]{.underline} National Technology Strategy's key pillars, which
[calls for the U.S. to lead a "favorable international AI
order]{.underline}."378 [China views actions over norms]{.underline} and
standards [as those of a tech]{.underline}nological
[hegemon]{.underline}. Fudan's Cai Cuihong believes that the U.S.'
excessive pursuit of technological hegemony will result in a weakened
superpower that cannot effectively compete, disrupted global markets and
supply chains, a loss of "trust and soft power as a source of
legitimacy," and weakened efforts to form technical alliances of
support.379 Written in 2019, Cai's article addresses many of the
emerging challenges that face both the U.S. and China, and she claims
that China will never pursue technological hegemony. Nevertheless,
leadership in developing AI norms, rules, and strategies for the new
world order is more likely to occur in a multiparticipant setting where
the U.S. and China lead factions but must rely on the support of other
nations to achieved desired ends. As the CSG points out, "The successful
adoption of AI in adjacent fields and technologies will drive economies,
shape societies, and determine which states exert influence and exercise
power in the world. Many countries have national AI strategies. However,
[only the U]{.underline}nited [S]{.underline}tates [and China have
the]{.underline} resources, commercial might, talent pool, and
innovation [ecosystem to lead the world in AI]{.underline}."380 AI will
serve as a great enabler, and this paper aligns with the CSG in putting
forth the argument that AI will emerge as a tool for other states to
have a voice and punch above their weight in both regional and global
settings. **[Influencing those nations and relying on a shared values
approach is essential for the U.S. to gain a competitive edge over
China]{.underline}**.

**That makes war inevitable. Collapse of US Heg means the no allies
comes to the US aide.**

**Ataman** 9/29/20**21**

Prof. Muhittin Ataman graduated from the Faculty of Political Science in
the Department of International Relations at Ankara University. "Global
leadership crisis: The U.S. hegemony vs. China",
<https://www.dailysabah.com/opinion/columns/global-leadership-crisis-the-us-hegemony-vs-china>
\-- ECM

Therefore, [it can easily be assumed that the Chinese challenge
for]{.underline} global [heg]{.underline}emony [is in the
making]{.underline}. [The only reason why China]{.underline} **[has not
claimed global heg]{.underline}**emony **[is timing]{.underline}**. In
other words, [according to the Chinese leadership]{.underline}, **[China
is not yet ready for global hegemony]{.underline}**. [When China begins
to involve itself **in the political**]{.underline} and economic
**[affairs of other countries and steer them away from the
U.S.]{.underline}**, **[a global confrontation will become
inevitable]{.underline}**. At that time, the U.S. is not sure how many
countries will continue to remain on its side. [Many]{.underline}
[Eu]{.underline}ropean [countries may remain indifferent to a possible
confrontation]{.underline} between the U.S. and China in the
Indo-Pacific region.

**The US will try to defend it [inevitably]{.underline} -- decline
causes [war]{.underline}**

**Beckley 15**

(Michael Beckley is a research fellow in the International Security
Program at Harvard Kennedy School's Belfer Center for Science and
Internatio nal Affairs., "The Myth of Entangling Alliances Michael
Beckley Reassessing the Security Risks of U.S. Defense Pacts",
<http://live.belfercenter.org/files/IS3904_pp007-048.pdf>)

[The finding that]{.underline} U.S. [entanglement is rare **has
important implications for international relations
scholarship**]{.underline} and U.S. foreign policy. For scholars, **[it
casts doubt on classic theories of imperial overstretch]{.underline}**
in which great powers exhaust their resources by accumulating allies
that free ride on their protection and embroil them in military
quagmires.22 [The U.S. experience instead suggests that **great powers
can dictate the terms of their security commitments and that allies
often help their great power protectors avoid strategic
overextension.**]{.underline} For policy, [the rarity of U.S.
entanglement suggests that the United States' current grand strategy of
deep engagement]{.underline}, which is centered on a network of standing
alliances, does not preclude, and [may]{.underline} even
[facilitate]{.underline}, U.S. **[military restraint]{.underline}**.
Since 1945 the United States has been, by some measures, the most
militarily active state in the world. [The most egregious cases of U.S.
overreach]{.underline}, however, **[have stemmed not from
entangling]{.underline}** alliances, [but from the penchant of American
leaders **to define national interests expansively**,]{.underline} to
overestimate the magnitude of foreign threats, and to underestimate the
costs of military intervention. Scrapping alliances will not correct
these bad habits. In fact, [disengaging from alliances may unleash the
**U**]{.underline}nited **[S]{.underline}**tates **[to intervene
recklessly]{.underline}** abroad [while **leaving it without partners**
to share the burden **when those interventions go awry**.]{.underline}

**That ensures -- global conflicts, warming, water wars, and
pandemics.**

**Beckley 12**

Michael Assistant professor of political science at Tufts. "China's
Century? Why America's Edge Will Endure." International Security 36(3):
41-78.

One danger is that **[declinism]{.underline}** [could prompt **trade
conflicts**]{.underline} [and **immigration restrictions**]{.underline}.
The results of this study suggest that [the]{.underline}
**[U]{.underline}**nited **[S]{.underline}**tates [benefits immensely
from]{.underline} the [free flow of goods, services, and
people]{.underline} around the globe; this is what allows American
corporations to specialize in high-value activities, exploit innovations
created elsewhere, and lure the brightest minds to the United States,
all while reducing the price of goods for U.S. consumers. Characterizing
China's export expansion as a loss for the United States is not just bad
economics; [it blazes a trail for **jingoistic**]{.underline} [and
**protectionist policies**]{.underline}. It would be tragically ironic
[if Americans reacted to **false prophecies** of decline by cutting
themselves off from a]{.underline} potentially [vital source of American
power]{.underline}.

Another danger is that [declinism]{.underline} may [impair foreign
policy decisionmaking]{.underline}. [If top government officials come to
believe that China is overtaking the]{.underline}
**[U]{.underline}**nited **[S]{.underline}**tates, [they are **likely to
react** in]{.underline} one of two [ways]{.underline}, both of [which
are]{.underline} potentially **[disastrous]{.underline}**.

The first is that [policymakers]{.underline} may [imagine
the]{.underline} **[U]{.underline}**nited **[S]{.underline}**tates
[faces a **closing "window of opportunity"**]{.underline} [and should
**take action** "while it still enjoys preponderance and not wait until
the diffusion of power has already made international politics more
competitive and unpredictable."]{.underline}158 [This
belief]{.underline} may spur positive action, but it also [invites
**parochial thinking**]{.underline}, **[reckless
behavior]{.underline}**, [and **preventive war**]{.underline}.159
[As]{.underline} Robert [Gilpin and others have shown, "**\[H\]egemonic
struggles** have **most frequently** been triggered by **fears of
ultimate decline**]{.underline} [and the **perceived erosion of
power**]{.underline}."160 [By **fanning such fears**]{.underline},
[declinists]{.underline} may **[inadvertently promote]{.underline}**
[the type of **violent overreaction**]{.underline} [that they seek to
prevent]{.underline}.

The other potential reaction is retrenchment---the divestment of all
foreign policy obligations save those linked to vital interests, defined
in a narrow and national manner. [Advocates of retrenchment **assume**,
or]{.underline} **[hope]{.underline}**, [that the world will sort itself
out on its own]{.underline}; that whatever replaces American hegemony,
whether it be a return to balance of power politics or a transition to a
postpower paradise, will naturally maintain international order and
prosperity.

[**Order** and **prosperity**]{.underline}, however, [are
**unnatural**]{.underline}. [They can **never be
presumed**]{.underline}. [When achieved, they are the **result** of
determined action by **powerful actors**]{.underline} [and]{.underline},
in particular, by [the most powerful actor]{.underline}, which is, and
[will be]{.underline} for some time, [the]{.underline}
**[U]{.underline}**nited **[S]{.underline}**tates. [**Arms buildups**,
**insecure sea-lanes**, and **closed markets** are only the most
**obvious risks** of U.S. retrenchment]{.underline}. [Less obvious are
**transnational problems**, such as]{.underline} **[global
warming]{.underline}**, **[water scarcity]{.underline}**, [and
**disease**]{.underline}, [which]{.underline} may **[fester without a
leader to rally collective action]{.underline}**.

Hegemony, of course, carries its own risks and costs. In particular,
America's global [military presence **might** tempt policymakers to use
force when they should choose diplomacy or inaction]{.underline}. [If
the]{.underline} **[U]{.underline}**nited **[S]{.underline}**tates
[abuses its power, **however**]{.underline}, [it is **not because it is
too engaged**]{.underline} [with the world, but because its engagement
lacks strategic vision]{.underline}. [The solution is **better
strategy**, **not retrenchment**]{.underline}.

[The **first step**]{.underline} toward sound strategy [is to recognize
that the status quo]{.underline} for the United States [is pretty
good]{.underline}: it does not face a hegemonic rival, and the trends
favor continued U.S. dominance. [The **overarching goal**]{.underline}
[of American foreign policy should be to **preserve this state of
affairs**]{.underline}. **[Declinists]{.underline}** [claim the
**U**]{.underline}nited **[S]{.underline}**tates [should]{.underline}
"adopt a neomercantilist international economic policy" and
"**[disengage]{.underline}** from current alliance commitments in East
Asia and Europe."161 [But the fact that the]{.underline}
**[U]{.underline}**nited **[S]{.underline}**tates [rose relative to
China while propping up the world economy and maintaining a hegemonic
presence abroad casts doubt on the wisdom of such calls for radical
policy change]{.underline}.

**[And]{.underline} the US loses! DIB weakness cements US collapse.**

**Harper 20**

(Jon Harper Has a Masters Degree in National Foreign Studies from
Georgetown---Received Bachelors Degree at Yale in History. He is the
Managing Editor for National Defense Magazine.
https://www.nationaldefensemagazine.org/articles/2020/1/24/industrial-base-could-struggle-to-surge-production-in-wartime
/) A\$

The **[U.S. industrial base would be challenged to ramp up production to
meet wartime requirements in the event of a protracted great power
conflict]{.underline}**, analysts and Pentagon officials say. The
National Defense Industrial Association's new report, "Vital Signs: The
Health and Readiness of the Defense Industrial Base," said 27 percent of
**[critical defense supplier industries would likely experience
shortages in the event of a surge in demand for combat-essential
products.]{.underline}** (See story) That finding is of particular
concern in the new strategic environment. In the decades following the
Cold War, the United States was focused on regional wars such as Iraq
and Afghanistan, noted Mark Cancian, senior adviser at the Center for
Strategic and International Studies. "For the most part, losses \[of
equipment\] have been low and your existing industrial base could handle
it," he said. But in recent years "[the **focus changed** **to great
power conflict with China and Russia**, and in **such a conflict
attrition** might be **very high** and the **industrial base is not
designed to handle that kind of demand**]{.underline}" for more systems.
Susannna Blume, director of defense programs at the Center for a New
American Security, noted that [**China has been** **investing heavily**
in its missile forces. "]{.underline}Those forces are [designed to
cripple the U.S. military]{.underline}," she said. "That's a huge
concern. **[The ability to reconstitute quickly could be critical in
prevailing in that kind of conflict]{.underline}**." Cancian said that,
based on historical analysis of attrition rates in large conventional
wars, the U.S. **[Army could be reduced to just two armored brigades in
the first nine months of a fight against another great power. Similar
rates of attrition would be expected to be sustained by aircraft and
other major systems,]{.underline}** he added. The [Defense Department
would struggle to replace losses or expand its force structure in such a
scenario,]{.underline} analysts say. "**[The industrial base has been
designed to produce equipment in peace time as efficiently as
possible]{.underline}**, so much of the spare capacity has been squeezed
out in order to reduce costs," Cancian said. "It is not a worthwhile
business strategy to have a lot of unused capacity, and DoD has not been
willing to pay for it." Maiya Clark, a research assistant at the
Heritage Foundation's Center for National Defense, said **[the capacity
problem is widespread]{.underline}**. "Generally speaking, I would say
that the U.S. defense industrial base really is poorly positioned for a
production surge at this time," she said. "[We're barely meeting the
needs of our military in peace time. So it's definitely a great concern
in pretty much every sector, although depending on the sector, the
particular issues are different.]{.underline}" Cancian said [replacing
destroyed or damaged ships would be especially challenging because it
takes years to construct major battle force vessels such as destroyers
or aircraft carriers.]{.underline} Clark said another issue is the
shortage of skilled technical labor for people who have the training to
do specialized tasks such as welding and electrical work. [The limited
number of vendors is another problem]{.underline}, noted the Defense
Department's 2018 report titled, "Assessing and Strengthening the
Manufacturing and Defense Industrial Base and Supply Chain Resiliency."
The document is often referred to as the 13806 Report after the
executive order that led to it. Today, the U.S. shipbuilding [industrial
base consists primarily of seven shipyards owned by four companies, plus
their suppliers, the report noted. **The number of vendors supplying
specific types of platforms is even fewer.**]{.underline} For example,
**[only one firm --- Huntington Ingalls Industries --- currently builds
aircraft carriers]{.underline}**. "In the case of a surge, we would be
really poorly placed to increase our production capacity," Clark said.
The aircraft manufacturing sector faces similar workforce and supplier
base issues. Six companies provide the majority of platforms and possess
the full range of capabilities to bring a new weapon system from the
research, design and development phases into full production, according
to the 13806 Report. The big three --- **[Boeing, Lockheed Martin and
Northrop Grumman--- have a virtual monopoly in many
areas,]{.underline}** Clark noted. For example, Northrop Grumman is the
only firm currently building bombers. Industry [consolidation across a
number of sectors is already an issue that would only be exacerbated
during a great power war]{.underline}, Clark noted. "These are all
problems that we can see now ... but if there were to be a surge
required, all those problems would become massively obvious." Vehicle
manufacturing is one sector where the industrial base has recently
demonstrated an ability to ramp up production to meet urgent wartime
requirements. During the Iraq and Afghanistan wars, improvised explosive
devices wreaked havoc on U.S. forces. In response, the Pentagon
contracted for thousands of mine resistant, ambush-protected vehicles to
transport troops around the battlefield. Production increased from 82
trucks per month in June 2007, to 1,300 a month in December of that
year, Clark said. "That was a pretty massive surge that we managed
successfully," she said. "We had multiple manufacturers involved with
that effort and ended up producing around 24,000 vehicles." However,
other platforms wouldn't be as easy to churn out, Cancian noted. "If we
were in a great power conflict with heavy attrition, we would surge all
of the tank production that we could, but of course that's not going to
be able to replace most" of the losses, he said. Technologies that are
also produced in the civilian sector will be less of a problem to
replace such as small arms, trucks and some types of communication
systems, he said. "It's those **[areas that are uniquely military where
there's no civilian analogue that will be most
vulnerable]{.underline}**." **[Munitions]{.underline}** production **[is
another area for concern]{.underline}**. Advanced air-, ground- and
sea-launched weapons are a key component of the military's operating
concepts. In the Trump administration's fiscal year 2020 budget request,
the Defense Department proposed buying several critical munitions at
maximum production rates, Blume noted. "If we are maxing our production
capacity in peace time for critical munitions, what does that say for
our ability to produce those munitions in a moment where we could be
expending many, many, many of them very, very rapidly?" Blume asked.
Cancian said **[the United States can't count on replicating the
production successes it accomplished during the last great power
conflict when civilian industry was converted to military
manufacturing]{.underline}**. "In World War II we had several years to
get ready before we actually got involved in the fighting. And even once
we got involved in the fighting, we had several years before we went
toe-to-toe with the main forces of our opponents," he said. "During that
time it was our allies for the most part who were holding the line, and
we won't have that luxury in a future conflict." The U.S. [**economy has
also changed significantly** since the 1930s and 1940s]{.underline}, and
is now much more oriented toward services than manufacturing, he noted.
Blume said [**defense equipment is** also **more specialized in the 21st
century. "In World War II you had major industrial conglomerates like
Ford producing war material**]{.underline}. They were making tanks and
there was a lot of ... industrial capacity in the United States that
could be thrown towards the war effort," she said. "The composition of
the **[defense industrial base is not the same today]{.underline}**. You
tend to have more highly specialized defense companies ... and there
just aren't that many of them." Cancian said China and Russia would also
face challenges replacing equipment and growing their forces during a
war with the United States. But they might not be in as tough a spot.
"The **[Chinese have, I think, a much larger military industrial base
and they're producing more weapons than the United
States]{.underline}**," he said. "So they might have an advantage
there." **[Russia, meanwhile, might have larger quantities of older
equipment in storage that it could draw from]{.underline}**, he added.
However, there are a number of steps that the U.S. government can take
now to ameliorate the surge problem, analysts say. One is to ensure that
the Defense Department has sustained and consistent funding. Budget
instability, including a series of continuing resolutions and threats of
government shutdowns in recent years, have hurt the industrial base and
driven away suppliers, Clark noted. Multi-year contracts would also help
to establish predictable funding, she said. "Without that reliability,
these companies end up shutting their doors, they end up consolidating
and our capacity to meet current and potentially larger future needs is
compromised," Clark said. While sole-source risk can occur at the prime
level, it more often manifests itself at the sub-tier, the 13806 Report
noted. Clark said: "There's just a lot of different examples where these
**[little companies are very adversely affected]{.underline}** by the
unpredictability of DoD funding. It may look like a little company, but
it **[can have drastic results for U.S. national
security]{.underline}**." Cancian said it would be prudent to identify
and address the most severe bottlenecks in industry so that production
in wartime could be increased as much as possible. Targeted investments
could have an outsized impact on the ability to surge. Clark noted that
the government could provide funding to selected industries that are in
jeopardy under authorities provided in the Defense Production Act. (See
story) For planning purposes, the Pentagon should determine what surge
production capabilities would be needed in a global war with China or
Russia, and where the shortfalls are, Clark said. "You need to know ...
which holes need to be plugged first," she said. "The information that
we have that would lead us to draw conclusions about our surge capacity
would lead us to say we're not all that prepared, but actually the
degree to which we are prepared or unprepared is hard to know without
more information." Tom Spoehr, director of Heritage's Center for
National Defense, said more government visibility into industry's
resourcing needs would also be helpful. [Using contracting to elicit
that information would be one option. "If we're contracting for a
hundred planes a year, the contractor ... \[could be required to\]
advise the government what resources are required to get to 200 a year
or something like that," he said]{.underline}. "Right now that's not
part of it, and so everybody's kind of flying blind on this topic." The
Pentagon will need to give companies financial incentives if it wants
them to boost their production capacity, he noted. Firms are focused on
maximizing shareholder value and profit, and maintaining extra
facilities is generally looked upon as wasteful in that context.
"[Companies will not typically maintain one iota of additional capacity
more than what they've been contracted or can foreseeably need in the
next couple of years]{.underline}," he said. Blume said new
manufacturing techniques could enhance industry's capabilities.
Assistant Secretary of the Air Force for Acquisition, Technology and
Logistics Will Roper is pushing a new Digital Century Series concept
that calls for using digital design and engineering to improve the way
aircraft are produced, she noted. "If he's right and there is a way to
build airplanes, for example, without a lot of heavy, highly specialized
tooling or skilled labor, that has significant implications for ... the
ability to restart or expand production capacity faster," Blume said.
The Defense Department can invest and push for industry to embrace the
kinds of technologies that will make it easier to surge, she added.
"It's not as though the only solution to this problem is just building
more factories and letting them sit unproductive," Blume said. "You can
design weapons systems in a way such that they can be built more quickly
and more easily using technologies like digital \[engineering\], etc."
**[Cancian said if the balloon goes up and the U.S. military finds
itself in a shooting war with China or Russia, it might have to buy
foreign systems or take older, less capable systems out of storage to
help replace equipment losses.]{.underline}** It **[would also
.]{.underline}** Meanwhile, Pentagon officials are well aware of many
challenges the nation would face trying to execute a wartime surge. "I
have a lot of concerns," Assistant Secretary of Defense for Acquisition
Kevin Fahey told reporters recently. "But the other thing I'd tell you
is industry never ceases to amaze ... when you end up with a requirement
that is funded, how quickly they can ramp up." Fahey noted that he
played a role in the effort to surge mine resistant, ambush-protected
vehicle production. However, the [MRAP was basically just "a really big
truck,"]{.underline} he said. **[Other types of equipment surges would
be more difficult.]{.underline}** For example, "we already have
bottlenecks given what we've got at the shipyards," he said. "If you
wanted to ramp our production \[that\] would be harder to do." It
wouldn't be impossible, but it would "probably take a little bit of
time," he added. The Trump administration is trying to tackle the issues
that were highlighted in the 13806 Report, including surge capacity and
supply chain vulnerabilities, he said. "We did a great job of actually
for the first time ... not only identifying what we believe our problems
were in the industrial base, but what were we going to do about it," he
said. "We have a lot of executive orders to actually work on some of
these major problems."

**[Advantage ( ): US-China Coop]{.underline}**

**AI usage is inevitable its only question of what rules will be used to
govern it. Unregulated AI risk global misuse and could easily be
weaponized by rogue actors -- Even a 1% risk of the ADV is untenable.**

**Haenel 18**

June, Fabio Haenel currently works at the Global and European Studies
Institute, University of Leipzig. Fabio does research in Information
Technology and Politics, Human Rights and Foreign Policy. "The Prospects
and Dangers of Artificial Intelligence on International Security: The
Case of a Sino-American Arms Race.",
<https://www.researchgate.net/publication/325542003_The_Prospects_and_Dangers_of_Artificial_Intelligence_on_International_Security_The_Case_of_a_Sino-American_Arms_Race>
-- ECM

Multiple [arguments for]{.underline} the [rapid development
of]{.underline} **[A]{.underline}**rtificial
**[I]{.underline}**ntelligence outpace any skepticism towards the
fledgling technology, their pressing nature however **[showcases the
necessity to do so safely]{.underline}**. First, [delaying the
advancement]{.underline} of a technology that [could help to
solve]{.underline} contemporary and future social and scientific
[problems]{.underline}, e.g. by increasing the efficiency of energy
consumption or outright help to invent entirely new methods and
materials to produce sustainable energy, or by reducing traffic through
automatic and interconnected private and public transportation systems,
carries a high opportunity cost to delay these achievements to occur
later, or never, rather than sooner.43 This becomes even more apparent
if we consider the AI-assisted scientific breakthroughs such as in
medicine where machines already outperform certified and experienced
doctors in detecting selected diseases accurately to the benefits o the
patients.44 Second, **[stalling investments]{.underline}** in research
and development of AI [by]{.underline} individual powerful [actors will
only give **advantage to a competing state**]{.underline} or corporation
which is [willing to fund and pioneer the tech]{.underline}nology.
Reasons to delay include the monetary costs o innovating a field
dependent on highly-skilled labor and benefiting most rom an academic
and industry in restructure that is locally accessible, or the lack o
conviction of its use in the near future among term- or
profit-constrained government and business leadership.

[These contradictions reveal a striking paradox]{.underline} of the
technology's geopolitical quality: Similar to the development and
manipulation of nuclear power in the 1940s, [succeeding
first]{.underline} [in realizing powerful AI]{.underline} capable of
prioritizing the economic or strategic interests of its developers
**[will reset the political spheres of interests
globally]{.underline}**, and [thus]{.underline} now [has captured the
attention of regional and global political]{.underline} and economic
[powers]{.underline}. **[However]{.underline}**, [newly developed
software can]{.underline} also **[be much more easily misused by rogue
actors than nuclear weapons]{.underline}** [because]{.underline} of [its
**decentralized, inexpensive accessibility**, and any]{.underline}
further [delay in developing AI robustly could **invite "bad actors"**
such as **states, terrorist groups**, or corporations to exploit it
unilaterally]{.underline}.

Research on [AI safety thus is necessary to "help maximize the societal
benefit of AI,]{.underline}" both to ensure that the technology is
utilized to ease and enrich human lives while it caters to the political
and economic interests driving its adoption forward notwithstanding the
paramount importance to guarantee that "AI systems must do what
\[humans\] want them to do."45 Among experts it is taken or granted that
its industrial development will be progressed by capital investments
ignorant of policy adjustments, thus theoretical and practical research
is needed to better understand "the nature, risks, and overall outcomes"
and safeguard specific and general AI applications.46 These concerns are
nourished by the logical assumption, borrowing from earlier explanations
why not to anthropomorphize machines, that enabling a machine to
automatically re-program itself would lead to the departure of its
original programming within the rules set or its auto-improvement by the
original programmers. Russel argues that these **[rules mark the
critical juncture between developing AI safely or ailing to do
so]{.underline}** because of the virtually infinite density of the
rules' consequences on the machines' future actions.

[Bostrom illustrates this]{.underline} with an anecdote of tasking an
intelligent machine with generating as many paperclips as possible to
ease a supply shortage.48 However, the wording includes not a finite
number of clips or how it should and should not achieve its goal. Thus,
besides collecting them individually, trading them or money generated
from profits earned in other capacities, the AI will eventually seek to
control the manufacturing of paperclips itself .49 To maximize its
utility function the goal-seeking AI soon will put such factories across
all available space on Earth, effectively eradicating any habitable
space and with it all life on the planet. The machine carried out its
goals within the rules sets by its human developers without knowing how
many clips are enough, or whether sustaining life is more important than
creating paperclips.50 [Researching how to safely align]{.underline}
such most critical human interests with binary [operations is integral
to the robust development of]{.underline} **[A]{.underline}**rtificial
**[I]{.underline}**ntelligence, rendering this research "**[the
essential task of our age]{.underline}**".

Safety [advocates argue that]{.underline} "**[whether the risk is 1 per
cent, 80 per cent]{.underline}**, or anywhere in between" [it
seems]{.underline} **[irresponsible not to take any
precautions]{.underline}**.56

Besides, predicting the impossibility of any technology that has yet to
be developed practically appears to be flawed: Ernest Rutherford, a
respected physicist o his time, proclaimed at a dinner reception in
September 1933 that "anyone who predicted energy could be derived rom
the trans ormation o an atom 'was talking moonshine.' The very next day
\[...\] Leo Szilárd worked out conceptually how it could be done."57
Szilárd's discovery eventually led to the manipulation of nuclear power
or civil and military purposes. In other words, a technology deemed
inconceivable turned out to be the base of the most constructive and
destructive force ever commanded by humans in the very next moment.

**[Upside]{.underline} AND [downside]{.underline} risks of AI are
[existential]{.underline}\-\--effective [governance]{.underline} is
key**

**Tzimas 21**

Themistoklis, Aristotle University of Thessaloniki, Faculty of Law,
"Chapter 2: The Expectations and Risks from AI," Legal and Ethical
Challenges of Artificial Intelligence from an International Law
Perspective, Springer, 2021, pp. 9--32 Open WorldCat,
<https://doi.org/10.1007/978-3-030-78585-7> -- ECM

Therefore, [it is]{.underline} only [natural to be]{.underline} at least
[skeptical towards a future with entities possessing equal or superior
intelligence and levels of autonomy; the prospect even of **existential
risk** looms as **possible**]{.underline}.7

AI that will have reached or surpassed our level of intelligence make us
wonder why would highly autonomous and intelligent AI want to give up
control back to its original creators?8 Why remain contained in
pre-deﬁned goals set for it by us, humans?

[Even AI in its **current**]{.underline} [form]{.underline} and narrow
intelligence [poses risks because of its **embedded-ness** in an
ever-**growing number** of **crucial aspects of our
lives**]{.underline}. [The role of AI in **military**,]{.underline}
ﬁnancial,9 health, educational, environmental, [**governance
networks**-among **others**]{.underline}---[are areas where **risk**
generated by AI---even **limited**]{.underline}--- autonomy [can be
**diffused**]{.underline} [through]{.underline} **[non-linear
networks]{.underline}**, [with **signiﬁcant** impact--- even
**systemic**]{.underline}.10

The answer therefore to the question whether AI brings risk with it is
yes; as Eliezer Yudkowski comments the greatest of them all is that
people conclude too early that they understand it11 or that they assume
that they can achieve it without necessarily having acquired complete
and thorough understanding of what intelli- gence means.12

Our projection of our---lack of complete---understanding of the concept
of intelligence on AI is owed to our lack of complete comprehension of
human intelligence too, which is partially covered by the prevalent and
until now self- obvious, anthropomorphism because of which we tend to
identify higher intelligence with the human mind.

Yudkowski again however suggests that AI "refers to a vastly greater
space of possibilities than does the term "Homo sapiens." When we talk
about "AIs" we are really talking about minds-in-general, or
optimization processes in general. Imagine a map of mind design space.
In one corner, a tiny little circle contains all humans; within a larger
tiny circle containing all biological life; and all the rest of the huge
map is the space of minds-in-general. The entire map ﬂoats in a still
vaster space, the space of optimization processes."13

Regardless of what our well-established ideas are, there are many,
different intelligences and even more signiﬁcantly, there are
potentially, different intelli- gences equally or even more evolved than
human.

From such a perspective, the unprecedented---ness of potential AI
developments and the mystery surrounding them emerges as not only the
outcome of pop culture but of a radical transformation of our---until
recently---self---obvious identiﬁcation of humanity with highly evolved
and dominant intelligence.14

[The **lack of understanding** of intelligence and therefore of AI may
be **frightening**]{.underline} [but]{.underline} [**does not lead
necessarily to regulation**---at least to a **proper** one. We could
**even** be led into **mak**ing potentially **catastrophic choices**, on
the basis of **false assumptions**.]{.underline}

[On top of our lack of understanding, we should add a sentiment of
**anxiety**]{.underline} as well as of expectations, [which intensiﬁes
as an atmosphere of emergency]{.underline} and of expected
groundbreaking developments [grows]{.underline}. The most graphic
description of this feeling is the potential of a moment of singularity,
as mentioned above according to the description by Vinge and Kurzweil.

As the mathematician I. J. Good--Alan Turing's colleague in the team of
the latter during World War II---has put it: "Let an ultraintelligent
machine be deﬁned as a machine that can far surpass all the intellectual
activities of any man however clever. Since the design of machines is
one of these intellectual activities, an ultraintelligent machine could
design even better machines; there would then unquestionably be an
"intelligence explosion," and the intelligence of man would be left far
behind. Thus the ﬁrst ultraintelligent machine is the last invention
that man need ever make, provided that the machine is docile enough to
tell us how to keep it under control."15 This is in a nutshell the
moment of singularity.

The estimates currently foresee the emergence of ultra or super
intelligence---as it is currently labelled---or in other words of
singularity, somewhere between 20 and 50 years from today, further
raising the sentiment of emergency.16 We cannot even foretell with
precision how singularity would look like but we know that because of
its expected groundbreaking impact, both states and private entities
compete towards gaining the upper hand in the prospect of the
singularity.17

Despite the fact that such predictions have been proven rather
optimistic in the past18 and therefore up to some extent inaccurate,
there are reasons to assume that their materialization will take place
and that the urgency of regulation will be proven realistic.

After all, part of the disappointments from AI should be blamed on the
fact that certain activities and standards, which were considered as
epitomes of human intelligence have been surpassed by AI, only to
indicate that they were not eventu- ally satisfactory thresholds for the
surpassing of human intelligence.19 Partially because of AI progress we
realize that human intelligence and its thresholds are much more
complicated than assumed in the past.

The vastness's of deﬁnitions of intelligence, as well as its
etymological roots are enlightening of the difﬁculties: "to gather, to
collect, to assemble or to choose, and to form an impression, thus
leading one to ﬁnally understand, perceive, or know".20

As with other relevant concepts, the truth is that until recently our
main way to approach intelligence for far too long was "we know it, when
we see it". AI is an additional reason for looking deeper into
intelligence and the more we examine it, the most complicated it seems.

The combination of lack of complete understanding of intelligence, the
unpredictability of AI, its rapid evolution and the prospect of
singularity explain both the fascination and the fear from AI. Once the
latter emerges, we have no real knowledge about what will happen next
but only speculations, which until recently belonged to the area of
science ﬁction.

We are for example pretty conﬁdent that the speed of AI intelligence
growth will accelerate, once self---improvement will have been achieved.
The expected or possible chain of events will begin from AI capacity to
re-write its own algorithms and exponentially self---improve, surpassing
human intelligence, which lacks the capacity of such rapid
self---improvement and setting its own goals.21

We can somehow guess the speed of AGI and ASI evolution and possibly
some of its initial steps but we cannot guess the directions that such
AI will choose to follow and the characteristics that it will
demonstrate. Practically, we credibly guess the prospects of AI beyond a
certain level of development.

Two **[existential issues]{.underline}** [could emerge: ﬁrst, an
imbalance of intelligence at **our expense**]{.underline}---with us,
humans becoming the inferior species---[in favor of non-biological
entities and secondly a lack of even fundamental conceptual
communication between the two most intelligent "species". Both of them
heighten the fear of **irreversible changes**]{.underline}, once we lose
the possession of the superior intelligence.22

[However, we need to consider the **expectations as well**]{.underline}.
[The]{.underline} **[positive side]{.underline}** [focuses on the
so-called **friendly** AI]{.underline}, [meaning AI which will
**beneﬁt** and **not harm** humans, thanks to its advanced
intelligence]{.underline}.23

[AI bears the promise of signiﬁcantly enhancing human life on various
aspects, beginning from the already existing, narrow
applications]{.underline}. The [**enhance**d
**automation**]{.underline}24 in the industry [and the shift
to]{.underline} **[autonomy]{.underline}**,25 [the take---over by AI of
tasks]{.underline} even at [the]{.underline} **[service
sector]{.underline}** which can be considered as "tedious"---i.e. in the
banking sector---**[climate]{.underline}** [and]{.underline} **[weather
forecasting]{.underline}**, **[disaster]{.underline}**
[response]{.underline},26 [the potentially better **coop**eration among
different actors in complicated matters such as in matters of
**information**]{.underline}, **[geopolitics]{.underline}**
[and]{.underline} [**i**nternational **r**elations]{.underline},
**[logistics]{.underline}**, **[resources]{.underline}** ex.27

[The realization of the positive expectations depends up to some extent
upon the **complementarity** or not, of AI with **human**
intelligence]{.underline}. However, what friendly AI will bring in our
societies constitutes a matter of debate, given our lack of unanimous
approach on what should be considered as beneﬁcial and therefore
friendly to humans---as is analyzed in the next chapter.

[Friendly AI for example bears the prospect of freeing us from hard
labor or even further from **unwanted** labor; of generating further
economic **growth**; of dealing in unbiased, speedy, effective and
cheaper ways with sectors such as **policing**]{.underline},
**[justice]{.underline}**, **[health]{.underline}**, [**environment**al
**crisis**, natural **disasters**]{.underline},
**[education]{.underline}**, **[governance]{.underline}**,
**[defense]{.underline}** [and several more of them which necessitate
decision-making, with the involvement of sophisticated
intelligence]{.underline}.

[The synergies between human intelligence and AI "promise" the
**enhancement of humans in most of their aspects**]{.underline}. Such
synergies may remain external---humans using AI as external to
themselves, in terms of analysis, forecasts, decision---making and in
general as a type of assistant-28 or may evolve into the merging of the
two forms of intelligence either temporarily or permanently.

The second profoundly enters humanity, existentially---speaking, into
uncharted waters. Elon Musk argues in favor of "having some sort of
merger of biological intelligence and machine intelligence" and his
company "Neuralink" aims at implanting chips in human brain. Musk argues
that through this way humans will keep artiﬁcial intelligence under
control.29 The proposition is that of "mind design", with humans playing
the role that God had according to theologies.30

While the temptation is strong---exceeding human mind's capacities, far
beyond what nature "created", by acquiring the capacity for example to
connect directly to the cyberspace or to break the barriers of
biology31---the risks are signiﬁcant too: what if a microchip
malfunction? Will such a brain be usurped or become captive to
malfunctioning AI?

The merging of the two intelligences is most likely to evolve initially
by invoking medical reasons, instead of human enhancement. But the
merging of the two will most likely continue, as after all the limits
between healing and enhancement are most often blurry. This development
will give rise, as is analyzed below, to signif- icant questions and
issues, the most of crucial of which is the setting of a threshold for
the prevalence of the human aspect of intelligence over the artiﬁcial
one.

Human nature is historically improved, enhanced, healed and now,
potentially even re-designed in the future.32 Can a "medical science"
endorsing such a goal be ethically acceptable and if yes, under what
conditions, when, for whom and by what means? The answers are more
difﬁcult than it seems. As the World Health Organi-
zation---WHO---provides in its constitution, "Health is a state of
complete physical, mental and social well-being and not merely the
absence of disease or inﬁrmity".33

Therefore, why discourage science which aims at human-enhancement, even
reaching the levels of post-humanism?34 Or if restrictions are to be
imposed on human enhancement, on what ethics and laws will they be
justiﬁed? How ethically acceptable is it to prohibit or delay
technological evolution, which among several other magniﬁcent
achievements, promises to treat death as a disease and cure it, by
reducing soul to self, self to mind, and mind to brain, which will then
be preserved as a "softwarized" program in a hardware other than the
human body?35

After all, "According to the strong artiﬁcial intelligence program there
is no fundamental difference between computers and brains: a computer is
different machinery than a person in terms of speed and memory
capacity."36

While such a scientiﬁc development and the ones leading potentially to
it will be undoubtedly, groundbreaking technologically-speaking, is it
actually---ethically- speaking---as ambivalent as it may sound or is it
already justiﬁed by our well--- rooted human-centrism?37

Secular humanism may have very well outdated religious beliefs about
afterlife in the area of science but has not diminished the hope for
immortality; on the contrary, science, implicitly or explicitly predicts
that matter can in various ways surpass death, albeit by means which
belong in the realm of scientiﬁc proof, instead of that of metaphysical
belief.38

If this is the philosophical case, the quest for immortality becomes
ethically acceptable; it can be considered as embedded both in the
existential anxiety of humans, as well as in the human-centrism of
secular philosophical and political victory over the dei-centric
approach to the world and to our existence.

From another perspective of course and for the not that distant
philosophical reasons, the quest for immortality becomes ethically
ambiguous or even unacceptable.39 By seeking endless life we may miss
all these that make life worth living in the framework of ﬁniteness. As
the gerontologist Paul Hayﬂick cautioned "Given the possibility that you
could replace all your parts, including your brain, then you lose your
self-identity, your self-recognition. You lose who you are! You are who
you are because of your memory."40

In other words, once we begin to integrate the two types of
intelligence, within ourselves, until when and how we will be sure that
it is human intelligence that guides us, instead of the AI? And if we
are not guided completely or---even further---at all by human
intelligence but on the contrary we are guided by AI which we have
embodied and which is trained by our human intelligence, will we be
remaining humans or we will have evolved to some type of meta-human or
transhumant species, being different persons as well?41

AI promises tor threatens to offer a solution by breaking down our
consciousness into small "particles" of information---simplistically
speaking---which can then be "software-ized" and therefore "uploaded"
into different forms of physical or non-physical existence.

Diane Ackerman states that "The brain is silent, the brain is dark, the
brain tastes nothing, the brain hears nothing. All it receives are
electrical impulses\--not the sumptuous chocolate melting sweetly, not
the oboe solo like the ﬂight of a bird, not the pastel pink and lavender
sunset over the coral reef\--only impulses."42 Therefore, all that is
needed---although it is of course much more complicated than we can
imagine---is a way to code and reproduce such impulses.

Even if we consider that without death, we will no more be humans but
something else, why should we remain humans once technologies allow us
be something "more", in the sense of an enhanced version of "being"? Why
are we to remain bound by biological evolution if we can re-design it
and our future form of existence?

Why not try to achieve the major breakthrough, the anticipated or hoped
digita- lization of the human mind, which promises immortality of
consciousness via the cyberspace or artiﬁcial bodies: the uploading of
our consciousness so that it can live on forever, turning death into an
optional condition.43

Either through an artiﬁcial body or emulation-a living, conscious
avatar---we hope---or fear---that the domain of immortality will be
within reach. It is the prospect of a "substrate-independent minds," in
which human and machine consciousness will merge, transcending
biological limits of time, space and mem- ory" that fascinates us.44

As Anders Sandberg explained "The point of brain emulation is to
recreate the function of the original brain: if 'run' it will be able to
think and act as the original," he says. Progress has been slow but
steady. "We are now able to take small brain tissue samples and map them
in 3D. These are at exquisite resolution, but the blocks are just a few
microns across. We can run simulations of the size of a mouse brain on
supercomputers---but we do not have the total connectivity yet. As
methods improve, I expect to see automatic conversion of scanned tissue
into models that can be run. The different parts exist, but so far there
is no pipeline from brains to emulations."45

The emulation is different from a simulation in the sense that the
former mimics not only the outward outcome but also the "internal causal
dynamics", so that the emulated system and in this particular case the
human mind behaves as the original.46 Obviously, this is a challenging
task: we need to understand the human brain with the help of
computational neuroscience and combine simpliﬁed parts such as simulated
neurons with network structures so that the patterns of the brain are
comprehended. We must combine effectively "biological realism
(attempting to be faithful to biology), completeness (using all
available empirical data about the system), tractability (the
possibility of quantitative or qualitative simulation) and understanding
(producing a compressed representation of the salient aspects of the
system in the mind of the experimenter)".47

The technological challenges are vast. Technologically speaking, the
whole concept is based on some assumptions which must be proven both
accurate and feasible.48 We must achieve technology capable of scanning
completely the human brain, of creating software on the basis of the
acquired information from its scanning and of the interpretation of
information and the hardware which will be capable of uploading or
downloading such software.49 The steps within these procedures are
equally challenging. Their detailed analysis evades the scope of this
book.

Some critical questions---they are further analyzed in the next
chapters---emerge however: how will we interpret free will in emulation?
What will be the impact of the environment and of what environment? How
will be missing parts of the human brain re-constructed and emulated?
What will be the status of the several emulations which will be
created---i.e. failed attempts or emulations of parts of the human
brain---in the course of the search for a complete and functioning
emulation? Will they be considered as "persons" and therefore as having
some right or will they be considered as mere objects in an experimental
lab? How are we going to decode the actual subjective sentiments of
these emulations? Essentially, are emulations the humans "themselves"
who are emulated or a different person? Even further what will human and
person mean in the era of emulation?

From a different perspective, the victory over death may be seen as a
danger of mass extinction, absorption or de-humanization. In this new,
vast universe of emulations will there be place for humans?50

From the above---mentioned discussion, it becomes obvious that at a
large extent, the prospect of risk or of expectation is a matter of
perspective, for which there is no unanimous agreement in the present.
This may be the greatest danger of all, for which Asimov warned us:
unleashing technology while we cannot communicate among us, in the face
of it.

The existential prospect as well as the risks by AI may self-evidently
emerge from technological advances but are determined on the basis of
politico---philosophical or in the wider sense, ethical assumptions.
This is where the need for legal regulation steps in. Such a need was
often underestimated in the past in favor of a solely technologically
oriented approach---although exceptions raising issues other than
technological can be found too.51 The gradual raising of
ethic---political, philosoph- ical and legal issues constitutes a rather
recent development, partially because of the realization of the
proximity of the risks and of the expectations.

The public debate is often divided between two "contradictory" views:
fear of AI or enthusiastic optimism. The opinions of the experts differ
respectively.

Kurzweil, who has come with a prediction for a date for the emergence of
singularity---until 2045---expects such a development in a positive way:
"What's actually happening is \[machines\] are powering all of us,"
Kurzweil said during the SXSW interview. "They're making us smarter.
They may not yet be inside our bodies, but, by the 2030s, we will
connect our neocortex, the part of our brain where we do our thinking,
to the cloud."52

In a well-known article---issued on the occasion of a ﬁlm---Stephen
Hawking, Max Tegmark, Stuart Russell, and Frank Wilczek shared a
moderate position: "[The potential **beneﬁts** are **huge**;
**everything that civilization has to offer** is a product of **human**
intelligence; we cannot **predict** what we might achieve when this
intelligence is **magniﬁed** by the tools **AI** may provide, but the
**eradicat**ion of **war, disease, and poverty**]{.underline} [would be
high on anyone's list. Success in creating AI would be the **biggest
event in human history**. . . Unfortunately, it **might also be the
last, unless we learn how to avoid the risks**]{.underline}."53

**Unregulated AI risks extinction -- defense doesn't assume
[interactions]{.underline} of [multiple simultaneous
threats]{.underline}**

**Pamlin 15**

Dennis Pamlin, Executive Project Manager of the Global Risks Global
Challenges Foundation, and Stuart Armstrong, James Martin Research
Fellow at the Future of Humanity Institute of the Oxford Martin School
at University of Oxford, Global Challenges Foundation, February,
http://globalchallenges.org/wp-content/uploads/12-Risks-with-infinite-impact.pdf

[If a safe **a**rtificial **i**ntelligence is developed, this provides a
**great resource for improving outcomes and mitigating all types of
risk**]{.underline}.585 [**A**rtificial **i**ntelligence risks
**worsening nanotechnology risks**, by allowing nanomachines and weapons
to be designed with intelligence and without centralised control,
**overcoming the main potential weaknesses** of these
machines]{.underline}586 [by putting planning abilities on the other
side]{.underline}. [**Conversely, nanotechnology abilities worsen
artificial intelligence risk**, by giving AI extra tools which it could
use for developing its power base.]{.underline}587 [Nanotechnology and
synthetic biology could allow the efficient creation of vaccines and
other tools to **combat global pandemics**]{.underline}.588
[Nanotechnology's increased industrial capacity could allow the creation
of large amounts of efficient solar panels to **combat climate change**,
or even potentially the efficient scrubbing of CO2 from the
atmosphere]{.underline}.589 [Nanotechnology and synthetic biology are
sufficiently closely related]{.underline} 590 (both dealing with
properties on an atomic scale) [for methods developed in one to be
ported over to the other, potentially **worsening the other
risk.**]{.underline} [They are sufficiently distinct though]{.underline}
(a mainly technological versus a mainly biological approach) [for
countermeasures in one domain not necessarily to be of help in the
other. Uncontrolled or malicious synthetic pathogens could **wreak great
damage on the ecosystem**]{.underline}; [conversely, controlled and
benevolent synthetic creations could act to **improve and heal current
ecological damage**]{.underline}.

**Our scenario isn't too far off. LAWS are *[UNIQUELY]{.underline}*
dangerous in this environment. China seeks to dominate by 2030 and
non-regulation puts safe development at risk. HOWEVER, this isn't
inevitable -- the US should seek ways to cooperate with China instead of
competing. That's key and staves off global escalation and arms
racing.**

- LAWS \-- Lethal Autonomous Weapon Systems

- Current development of AI is spearheaded by US & China

- The Sullivan 10/4/2021 card in the Heg ADV also says "only the United
  States and China have the resources, commercial might, talent pool,
  and innovation ecosystem to lead the world in AI". Which proves our
  scenario is correct and that US-China coop would control the direction
  of AI globally.

**Haenel 18**

June, Fabio Haenel currently works at the Global and European Studies
Institute, University of Leipzig. Fabio does research in Information
Technology and Politics, Human Rights and Foreign Policy. "The Prospects
and Dangers of Artificial Intelligence on International Security: The
Case of a Sino-American Arms Race.",
<https://www.researchgate.net/publication/325542003_The_Prospects_and_Dangers_of_Artificial_Intelligence_on_International_Security_The_Case_of_a_Sino-American_Arms_Race>
-- ECM

2.5. The Ultimate Weapon: Is AI Determined to Fuel a Sino-American Arms
Race?

But [it is not necessary]{.underline} to venture that [far down the
line]{.underline} [of what destructive force might]{.underline} and
might not [be deducted from AI]{.underline} in the future
[as]{.underline} contemporary [autonomous weapons already are an
integral part of]{.underline} the armories of [modern
armies]{.underline}. "[The tech]{.underline}nology to deploy autonomous
weapons [is]{.underline} largely [in place]{.underline}, and the
engineering tasks seem to be easier than those involved in creating self
-driving cars," stated the UK Ministry of Defense in 2016.58
[Non-prolif]{.underline}eration [activists argue that]{.underline} the
development of [Lethal Autonomous Weapon Systems]{.underline}
(**[LAWS]{.underline}**) **[is particularly worrying given
the]{.underline}** parallel **[development of privately accessible
autonomous drones]{.underline}**, effectively [**introducing the use of
precise lethal weapons** anywhere and anytime]{.underline}, not just on
dedicated battlefields, and [thus]{.underline} further **[tear at an
already crumbling sense of security within industrialized
societies]{.underline}**. Three leading computer scientists and
philosophers thus ask, "are autonomous weapons likely to reduce
political aversion to conflict, or perhaps result in accidental battles
or wars? Would such weapons become the tool o choice or oppressors or
terrorists?"59 And, most importantly, who will be held responsible or
autonomous attacks legally, if not ethically, given that it is only
software that calculates who to kill?

Analogue to Google's AlphaGo automatically improving itself in order to
beat the best human players in Go only by following its goal to maximize
the probability o winning no matter the cost, a similarly programmed
autonomous weapon "would see no difference between victories that
required it to kill one or 1,000" men outlining great challenges to
humanitarian law.60 Reducing the amount o humans involved in carrying
out invasive strikes against the defense organs supporting the current
international security system, e.g. by coordinating swarms of autonomous
drones overwhelming an adversary's defense system, will uproot its
equilibrium o prioritized, mutual defense: "This would lead to a very
unstable international configuration, encouraging escalation, arms races
and the replacement o deterrence by preemption."61 The advent of
widespread introduction o LAWS thus echoes the looming threat o the
early Cold War be ore the ratification of the Treaty on the
Non-Proliferation of Nuclear Weapons, especially so today when two
central forces manifested as the catalysts of the weaponization of
Artificial Intelligence: the United States of America and the People's
Republic of China.

The specific characteristics of AI applications cater tremendous
benefits to the relevant power mastering its use in weapon systems
first, or holds the decisive advantage over its trailing adversaries.
Any new generation of weapons invented by humans have become either more
powerful, precise, or both, over time by maximizing the inflicted damage
while minimizing the ef ort needed or its execution. AI-assisted remote
and autonomous weapons will cater to both of these values, effectively
reducing the operational limits of its deployment to a new minimum.
Naturally, this sparks the interests of defense contractors,
governments, and international organizations alike. But unlike the
Manhattan Project of the 1940s[, the current development of AI is
spear-headed]{.underline} by private technology companies using their
wealth, expertise and user databases to steer the challenging task of
funding, researching, developing, and testing their own innovations
internally successfully, and do so "principally [in the US and
China]{.underline}."62 These almost entirely decoupled markets already
experience a parallel augmentation of AI in consumer products, led by
Google, Facebook and Microsoft on the one side, and Baidu, Alibaba, and
Tencent on the other side o the Pacifc.63 But Google's AlphaGo did not
just de eat the world's champion in Go in May 2017, it defeated Ke Jie,
a Chinese citizen, in a game streamed live online rom Hong Kong. Once it
became clear the US-American algorithm would de eat the incumbent
Chinese champion the streaming website was immediately blocked within
China by authorities.64 Shortly after that, the government has announced
an enormous funding program to foster and catalyze Chinese talents and
start-ups to take over the market, and becoming "the global leader in
the field by 2030."65 Already, the trend or Chinese computer scientists
to look to the United States or education and employment is reversing,
boosting Chinese companies with high-skilled expertise and private
connections to Silicon Valley.66

But while [Beijing is rallying financial and political support to help
build up its domestic AI]{.underline} industry **[to become globally
competitive with increasing velocity]{.underline}**, such a centralized
program is missing in the Trump administration's budget plans thus ar.
Commentators are yet undecided if this will help the Chinese companies
to level the playing field with their American counterparts or outright
outpace them, or if China will continue to run a parallel domestic
market large enough to be sufficient without the meddling of foreign
actors. [Their reinforced policy to dominate the sector by
2030]{.underline}, however, [indicates]{.underline} that it will not
only be intended domestically but also to anchor Chinese
high-technology, and the intellectual property **[at its
foundation]{.underline}**, at the core of the interdependent global
economy of the unfolding century. Such a "race dynamic" [favoring
hastened deployment]{.underline} of AI technology [is expected to
**diminish** the interest to invest in its **robust development**,
putting AI Safety researchers on alert]{.underline}.

[Bostrom]{.underline}, or example, [has thus made the case or
collaborating efforts to innovate rather than competing against each
other, allowing for a safer pace of innovation]{.underline}, **[thus
avoiding potential conflict]{.underline}**, [and above all setting a
stepping stone to an international resolution to take the prospects and
dangers of Artificial Intelligence seriously]{.underline}.67
Particularly worrying is the act that most, if not all, calls or robust
development are heeded only by Western academics and their institutions,
defining a linguistic, academic, and political rift between the West and
China. And while both consumer and government adoption of autonomous
technology is slowly taking up pace in Western industries, the Asian
market, and China in particular, appears to welcome drastic innovations
in AI-assisted products much more easily, offering higher potentials to
grow or comparatively less-regulated domestic companies in Asia. [These
developments already outline a]{.underline} "**[very unstable
international configuration, encouraging escalation and arms
races]{.underline}**" from an economic point of view alone. [As their
respective national security bodies ramp up military
programs]{.underline} [to]{.underline} further [implement
AI]{.underline} in their tactical arsenal [the most pressing question
remains]{.underline} **[how]{.underline}**---**[or if]{.underline}** at
all--- **[A]{.underline}**rtificial **[I]{.underline}**ntelligence,
ultimately, **[can be governed]{.underline}**.

**Building interoperability with allies is key. This bolsters the
possibility for coop with China down the road.**

**Sullivan** 10/4/20**21**

Ryan Sullivan Army pilot studied at the prestigious Fudan University in
Shanghai, China, as an Olmsted Scholar graduate-level work in the field
of Artificial Intelligence to deliver an in-depth study of the critical
elements of U.S.-China competition in Artificial Intelligence, "The
U.S., China, and Artificial Intelligence Competition Factors",
<https://www.airuniversity.af.edu/Portals/10/CASI/documents/Research/Cyber/2021-10-04%20US%20China%20AI%20Competition%20Factors.pdf?ver=KBcxNomlMXM86FnIuuvNEw%3D%3D>
-- ECM

Diverging values between the CCP and liberal democracies represent the
greatest obstacle to U.S.-China collaboration or cooperation on AI.
Today, the gulf between these values is widening. While AI itself does
not have values, competition involving technology is not value neutral.
Collaboration between the U.S. and China in AI applications now occurs
in academia and medical research; however, national security concerns
and growing mistrust between our nations puts even these in jeopardy.
[The way forward will require clear boundaries and new mechanisms to
address values competition and the resolution of disputes over
appropriate AI standards]{.underline} will require innovative approaches
to diplomacy. While military-to-military cooperation on humanitarian
assistance and disaster relief seem the most likely area for the U.S.
and China to find common ground and opportunities to collaborate in the
security sphere, in the near-term, [the]{.underline} U.S. Department of
Defense ([DoD]{.underline}) **[should remain focused on building
interoperability with allies]{.underline}** to promote data sharing
**[and pursue AI's ethical applications in these alliance and
partnership military frameworks]{.underline}**. With those agreements,
processes, and standards in place, [then the potential for future
military engagements and outreach involving AI applications with China
would prove more beneficial]{.underline}.

AI competition requires a long-term view, one that should consider that
[the]{.underline} Communist Party-centric [values of Xi]{.underline}
Jinping and the current rulers of China **[do not reflect the broader
societal values of the Chinese people]{.underline}**. **[Xi will not
remain in power forever]{.underline}**, and while we may not know who
will replace him or when that could occur, [change in China will come,
and the U.S. should prepare for all possibilities]{.underline} from a
position of competitive strength. Only [such a position guards **against
unnecessary and unhelpful conflict** and remains open to
coop]{.underline}eration, but from a position of advantage that comes
from standing [with nations aligned on the basis of shared democratic
values]{.underline}.

**[1AC Solvency: Generic]{.underline}**

**The plan solves -- It would establish a 10-year roadmap for using AI
thru annual military exercises. Absent the plan the SQ will become
unsustainable cede control to China**

- NATO has yet to upgrade AI norms, US lead is key

**Ryseff** 10/9/20**20**

James Ryseff is a technical policy analyst at the nonprofit, nonpartisan
RAND Corporation., "The United States Can Only Achieve Ai Dominance With
Its Allies",
<https://warontherocks.com/2020/10/the-united-states-can-only-achieve-ai-dominance-with-its-allies/>
\-- ECM

[As the U]{.underline}nited [S]{.underline}tates [races with China to
apply]{.underline} **[A]{.underline}**rtificial
**[I]{.underline}**ntelligence [for military purposes]{.underline}, many
[experts worry that it may be hampered by a shift in the nature of
AI.]{.underline} The conventional wisdom has been that, until now,
American technologists could depend on elite researchers and faster
computers to outperform their Chinese rivals. However, these advantages
are no longer the keys to harnessing AI most effectively. Data is.
Chinese AI experts believe that China's larger population and lax
privacy controls give China a durable advantage in collecting the best
data sets to teach AI algorithms how to optimize their performance.
Kai-Fu Lee, China's most prominent AI researcher, has dubbed China the
"Saudi Arabia of data" and argues that China's data advantage is
expanding by the day. The Center for Data Innovation, an American think
tank, agrees, calculating that the Chinese population generates
terabytes more information than Americans do.

In reality, determining who holds the advantage in data is far more
complicated than simply counting how many bytes of information are
stored in each country. As a recent Center for Security and Emerging
Technology report rightly points out, the quality of data and how well
it has been curated and labeled usually matter more than simply how much
data one has. Even so, the analysts take for granted that China's size
will ultimately give it the advantage in commercial data, one that may
let its corporations overtake their American counterparts in AI.

However, [these conclusions overlook the primary advantage American
tech]{.underline}nology companies [hold over their Chinese
counterparts]{.underline}: **[its global user base]{.underline}**. For
companies like Google and Facebook, the competition to amass data is not
between the digital activities of 330 million Americans against the
virtual footprint of over one billion Chinese citizens. Instead,
**[their products hold near-monopolies]{.underline}** in the United
States, Europe, Latin America, Africa, and most of Asia. In contrast,
[Chinese equivalents]{.underline} like Baidu and WeChat have [only a
handful of non-Chinese users]{.underline}. [This global reach gives
American tech]{.underline}nology companies [an advantage both
in]{.underline} the total [volume]{.underline} of data they collect
[and]{.underline} in the [diversity of data]{.underline} harvested.
Chinese data sets, for now, are still largely blind to conditions
outside of China. AI algorithms trained on those data sets would
struggle to travel outside its borders.

The success of American technology companies illustrates the most
promising path for the U.S. military to pursue at the dawn of its own AI
age. That does not mean that the Department of Defense should simply
copy Silicon Valley's strategy mindlessly. While data from the
commercial sector --- such as an individual's social connections,
current employer, or personal finances --- will continue to be a gold
mine for global intelligence agencies, data relevant to the future
battlefield will primarily concern soldiers, vehicles, training
exercises, and the like. No organization will have more relevant data
for these use cases than the military itself. Fortunately, the Defense
Department has positioned itself well to become the globally dominant
platform for military data, just as American technology companies
dominate the global marketplace in their realms. [The
U]{.underline}nited [S]{.underline}tates [counts most industrialized
nations as military allies and equipment manufactured by]{.underline}
the United States or its [NATO]{.underline} allies is driven and flown
around the world. However, the Defense Department has yet to capitalize
on this potential. NATO weapons and vehicles were originally designed to
be interoperable in an industrial-age sense, shooting the same bullets
or refueling from the same connectors. Unfortunately, **[NATO has not
yet upgraded for the information age]{.underline}**. The data generated
by U.S. Army tanks cannot easily be accessed or aggregated with data
generated by Marine Corps tanks, let alone British ones. Just as the
Goldwater-Nichols Act once pushed America's separate armed services to
break out of their isolated battlefield domains[, military data must now
discover how to operate jointly]{.underline} as well. **[Three
initiatives could be critical to accomplishing this]{.underline}**.

**[First]{.underline}**, [the Defense Department could create a 10-year
roadmap for upgrading data interoperability]{.underline} that lays out
specific operational objectives to demonstrate improvements. To ensure
these objectives are met, **[they could be incorporated into the major
annual exercises conducted with NATO]{.underline}** and East Asian
allies. For example, American and South Korean units could draw spare
parts and other consumables from each other during their annual training
exercises. Throughout the exercise, [both sides could confirm their
logistics databases can combine to present a unified picture of the
allied logistical situation and provide projections of future needs as
the simulated combat event evolves]{.underline}.

Establishing [tangible objectives and aligning]{.underline} the
timeframe with [existing multinational exercises will be the
key]{.underline} to success. Militaries invest a great deal of time and
effort training their personnel to be ready for the fight. They must now
learn how to "train" and prepare their data as well. This can mean many
things. When training their personnel, militaries spend some of their
time imparting specific skillsets that will be useful in combat. In
other cases, soldiers learn how to work together to solve unforeseeable
problems as they arise --- or simply learn how the operational routines
of other units or allied militaries differ from their own. Regardless,
commanders recognize their soldiers must routinely practice their skills
under real-world conditions if they will be expected to work as an
effective team on the battlefield.

**[Data needs the same types of preparation]{.underline}** to be ready
for its role in the fight. Much as soldiers need to leave the garrison
and work through practical exercises in the field, it is not enough to
develop a technical specification documenting how two data sets are
supposed to work together. Someone needs to actually make the data sets
work together. They must be routinely explored, analyzed, and aggregated
to solve real problems in order to ensure they will remain interoperable
and effective. Similarly, the analysts and engineers responsible for
curating data need opportunities to interact with each other in order to
develop the operational routines necessary to ensure effective
collaboration during a crisis. **[Without these forcing
functions,]{.underline}** [too much military data will remain **isolated
and unusable** at the scale needed to engineer AI
algorithms]{.underline}.

**[Second]{.underline}**, [the military may need to collaborate with
allies to achieve]{.underline} common u[nderstandings about when and how
to share data]{.underline}. European governments in particular have
begun to codify digital norms for the consumer space in frameworks like
the General Data Protection Regulation and the establishment of new
legal concepts like the Right to be Forgotten. **[The
U]{.underline}**nited **[S]{.underline}**tates **[could play a role in
shaping the equivalent norms in the national security and public policy
space]{.underline}**. [Otherwise]{.underline}, [fragmented
data]{.underline} repositories [from the U]{.underline}nited
[S]{.underline}tates [and its allies]{.underline} **[may not be able to
achieve]{.underline}** the **[critical mass]{.underline}** --- that is,
gather enough data --- **[necessary to compete with
China]{.underline}**'s data warehouses.

[Past disagreements]{.underline} between the United States and its
allies [over norms]{.underline} related to atomic weapons [demonstrate
how these considerations can ultimately impact military
op]{.underline}eration[s]{.underline}. In Europe, the United States
managed to forge an agreement that allowed the stationing of tactical
nuclear weapons on the territory of its NATO allies, even in the face of
significant domestic opposition in key nations such as West Germany. In
contrast, the United States was unable to achieve a similar consensus
among its allies in Asia. Both Japan and New Zealand banned the
introduction of nuclear weapons into their territory, causing headaches
for U.S. Navy operations in the region. While in that case Navy ships
could find alternate ports to operate from, a similar divergence in
norms would have much greater consequences for the U.S. military's
ability to develop AI. Data withheld is data lost.

Most [norms about the use of military data]{.underline} **[will likely
be uncontroversial]{.underline}**. Unlike Facebook or Google, whose
business models depend on precisely targeting ads at their user bases,
[militaries in democracies have little reason to exchange personally
identifiable info]{.underline}rmation [or other sensitive
details]{.underline} about their citizens. Norms about controversial
topics such as autonomous systems may prove more difficult to forge a
consensus around. Agreements that data provided by partners would not be
used to train these systems without explicit consent could be a
compromise acceptable to all parties.

**[Finally]{.underline}**, [the U]{.underline}nited [S]{.underline}tates
[could seek deeper integration and coop]{.underline}eration
[with]{.underline} its **[allies who have unique resources to advance
specific applications of AI]{.underline}**. Many, including the National
Security Commission on Artificial Intelligence, have called for the
United States to leverage its existing "Five Eyes" alliance and extend
it to include cooperation in AI. A complementary approach might be to
focus on partners who have unique technical assets to contribute. For
example, East Asian allies such as Japan and South Korea have invested
heavily in robotics and automation, which makes them attractive partners
for developing more capable drones and other autonomous vehicles. [They
may also have fewer hesitations about deploying these technologies than
other potential partners]{.underline}. Similarly, the Israeli government
has carefully incubated a world-class cyber security sector, potentially
positioning it as a valuable collaborator in training AI-enhanced cyber
defenders how to protect critical infrastructure and assets.

Ultimately, close collaborators in any AI alliance must pass two tests:
They must be able to usefully contribute to the work, and they will also
need to be trustworthy enough to share in these cutting-edge technical
advancements. While achieving the kind of close collaboration with
allies that the United States has enjoyed in other realms may be
difficult, [it will be essential if the U]{.underline}nited
[S]{.underline}tates [hopes to achieve the data dominance needed **to
succeed in future combat.**]{.underline}

**Establishing a common set of definitions over how AI should be used
would set the terms of cooperation. That's key to coalition
effectiveness and cohesion**

**Mahoney 4/30**/2022

Casey Mahoney is a U.S. Institute of Peace--DoD Minerva Peace & Security
Scholar and a Ph.D. Candidate in political science at the University of
Pennsylvania. "Shared Responsibility: Enacting Military AI Ethics in
U.S. Coalitions.",
<https://nationalinterest.org/blog/techland-when-great-power-competition-meets-digital-world/shared-responsibility-enacting>
\-- ECM

A Responsible AI Coalition

[It is in the U.S. interest to leverage]{.underline} the creative
potential of [a diverse AI "ecosystem."]{.underline} However, it is also
necessary to establish habits that mitigate the risk that political,
cultural, and organizational differences among future coalition partners
might undermine collective, responsible AI use.

[To do this]{.underline}, [the Defense Department can take steps now to
increase the reliability with which future coalitions will
operationalize]{.underline} the foundations of international cooperation
on [military AI]{.underline}. [The DoD should]{.underline} pursue the
three objectives and consider specific actions to pursue them. Building
these goals into the charter of the DoD's new Office of the Chief Data
and AI Officer (CDAO) that Deputy Secretary Kathleen Hicks directed be
prepared by June 1, 2022, would help align institutional incentives to
accomplish them.

**[Establish a common language]{.underline}**. First, [policymakers,
commanders]{.underline}, and [tech]{.underline}nical and [legal experts
in future coalitions must]{.underline} be able to speak a common
language to [communicate about how AI systems ought to be
used]{.underline} on the battlefield---let alone about how they are
[developed and validated]{.underline}. A December 2021 report by the
Center for Naval Analysis identifies 565 unique policy and ethics "risk
elements" the use of autonomous systems pose in military applications.
But, given the "bias that occurs when operating in coalition and allied
environments ... that stems from different sets of treaties, ROE, or
cultural norms," one imagines that the opportunities for
miscommunication in the absence of agreement on the terms of debate will
grow exponentially.

[Despite China's efforts to lead in setting]{.underline} international
[AI]{.underline} technical [standards]{.underline}, [it is]{.underline}
clearly [in the U.S. interest to pursue its own standards]{.underline}
under which it collaborates with military partners. **[The DoD should
task the CDAO to oversee a process to identify what resources would be
necessary to engage partners to develop and baseline U.S. programs
around a technical glossary for AI]{.underline}**. [Doing so would set
the terms of debate among the international partners DoD seeks to
recruit to the responsible AI ecosystem it seeks to
establis]{.underline}h. [Without shared language]{.underline},
communicating about partners' capabilities and intent to [use AI
responsibly will be difficult]{.underline}, [posing risks for the
strategic effectiveness and political cohesion of future
coalitions]{.underline}.

**Specifically, focusing on military partners is key -- The plan would
shape military behavior, strategies, and planning ensuring a robustly
responsible form of AI**

**Stanley-Lockman & Trabucco 3/22**

Zoe Stanley-Lockman & Lena Trabucco , "NATO's Role in Responsible AI
Governance in Military Affairs", Zoe Stanley-Lockman Nanyang
Technological University, Lena Trabucco University of Copenhagen, Center
for Military Studies The Oxford Handbook of AI Governance Edited by
Justin Bullock, Yu-Che Chen, Johannes Himmelreich, Valerie M. Hudson,
Anton Korinek, Matthew Young , and Baobao Zhang Subject: Political
Science, Political Institutions Online Publication Date: Mar 2022DOI:
10.1093/oxfordhb/9780197579329.013.69 -- ECM

NATO structures around strategic and policy planning both set Allied
ambitions and priorities and have the competency to implement them
through its many consultative bodies, coordination formats, and albeit
to a lesser extent, technology foresight capacities. NATO has
facilitative power among Allies, both for defense planning and for the
conduct of operations. [A cornerstone]{.underline} in modern
architecture of international security [is]{.underline} coalition
warfare---or, more broadly, [joint
op]{.underline}eration[s]{.underline}. **[Working with military partners
has become a critical feature of modern security policy]{.underline}**,
where there is more power in enhancing numbers, but also in having
allies that lend political and practical legitimacy to deterrence and
operations.49 NATO is vital to that effort for many reasons, but also
because NATO's facilitative power is significant to promote coordination
and cooperation. Simply put, [partners and allies are a necessary
feature of modern military behavior, and strategic and policy planning
are necessary functions to encourage and underpin cohesion in alliance
settings]{.underline}. **[This is important for AI
governance]{.underline}** [because the nature of AI poses]{.underline}
**[new strategic challenges and will require multilateral
approaches]{.underline}** and some degree of cohesion to effectively
incorporate RRI frameworks in policy planning. As such, the necessity of
working with security partners extends to the AI-policy frontier.

A number of NATO entities carry out strategic and policy planning,
recognizing the importance of policy alignment to sustain political
strength and military effectiveness. As relates to S&T, allies'
representations to NATO, defense ministries, and policy entrepreneurs
from the relevant entities summarized in Table 69.1 support and
negotiate how the Alliance approaches EDTs. NATO's strategic
documentation and forward-looking policy analysis incorporates hints of
technological determinism, including noting how technological change
inevitably shapes the future strategic and operating environment.
Further, the connections between technology and competitive advantage
over adversaries and competitors are embodied in [the
Alliance's]{.underline} desire to maintain its
"**[tech]{.underline}**nological **[edge]{.underline}**" [as
the]{.underline} "[foundation upon]{.underline} which [NATO's ability to
deter and defend]{.underline} against potential threats ultimately
rests."50 This [places tech]{.underline}nology **[squarely within NATO's
core purpose]{.underline}** of deterrence and defense---and while this
signals NATO's express commitment to technology through these channels,
this reliance on technology also obscures whether NATO's governance
capacity will be adaptive, anticipatory, or participatory. [This
position]{.underline} of technological determinism **[may result in more
limitations for AI governance]{.underline}**.

Standards and certification

To maintain its relevance in a security architecture increasingly
concerned with the way that technology shifts power dynamics and scales
threats to international security, [NATO has an incentive to foster
coop]{.underline}eration, [promote standards]{.underline} of practice,
[and incentivize]{.underline} Allied [AI harmonization]{.underline}. It
is strategically salient to facilitate a dialogue and engagement among
Allies on AI, but it is practically important to use NATO's position to
facilitate Allied cooperation regarding standards to project the
Alliance's ability to interoperate in future operations. NATO standards
aim to enhance interoperability among partners and successful
implementation of strategy.

More specifically, **[standards and certification]{.underline}** [are
used to establish and implement]{.underline} requirements aligned with
**[safe development and responsible use of tech]{.underline}**nology. In
addition to purely technical standards, NATO has operational standards
that specify "conceptual, organizational or methodological requirements
to enable materiel, installations, organizations or forces to fulfil
their functions or missions."51 In line with the definitions from STS
and military innovation scholarship, [standards can]{.underline} thus be
seen as a mechanism to [translate responsibility]{.underline}-derived
state and organizational [AI]{.underline} policy [into actionable
functions]{.underline}. In fact, NATO has set certain standards for the
Allies and these standards subsequently become the norm.

**Creating a process for collecting international channel international
partners to input points of contact creating a "responsible AI
ecosystem". That helps bolster US creditability over AI**

**Mahoney 4/30**/2022

Casey Mahoney is a U.S. Institute of Peace--DoD Minerva Peace & Security
Scholar and a Ph.D. Candidate in political science at the University of
Pennsylvania. "Shared Responsibility: Enacting Military AI Ethics in
U.S. Coalitions.",
<https://nationalinterest.org/blog/techland-when-great-power-competition-meets-digital-world/shared-responsibility-enacting>
\-- ECM

Until now, [the department has not needed to understand how]{.underline}
its vast network of [partner governments and militaries are
absorbing]{.underline} a general-purpose technology like
[AI]{.underline}. A February 1 DoD memorandum identifies roles the CDAO
and the undersecretaries for Policy, Acquisition and Sustainment (A&S),
and Research and Engineering (R&E) will play in international
cooperation on AI. But, [DoD lacks a cross-cutting process for
collecting technical and policy knowledge derived from these
international interactions]{.underline} and integrating it into
coalition policy, planning, or technical cooperation efforts on a
country-by-country or weapons system-by-system basis.

[The DoD should]{.underline} task the CDAO, Policy, A&S, and R&E offices
to [create one]{.underline}. [These offices should establish
metrics]{.underline} in R&D, TEVV, and acquisitions processes [that
incentivize the bureaucracy to prioritize technical and organizational
interoperability]{.underline} and consider unique requirements that
might arise from ethical or policy questions likely to arise in
multinational use scenarios. [This would help channel international
partner input to relevant points of contact across the department,
optimizing the value of the international "responsible AI ecosystem" to
U.S. coalition efforts]{.underline}.

Engage allied publics. Last, [differences in public opinion about
the]{.underline} inherent legitimacy and desired forms of
[accountability for AI]{.underline}-based weapons [reflect real
divides]{.underline} within and between the polities that comprise
America's alliance network. **[Bridging these gaps by monitoring public
discourse and enhancing public diplomacy about military AI would have
the effect of both educating the public at home and abroad and help
raise expectations that transparency is the norm]{.underline}**. In an
era in which states select and enact military strategies before a global
public audience, it is important for Americans, allies, and others to
see that if the U.S. military technological edge must be used in
conflict, its leaders and its partners choose to do so responsibly.

A[s China and Russia continue to use AI tools to enhance authoritarian
control]{.underline} at home, it is becoming commonplace to argue that
the values [America and its allies share for responsible AI can
represent a competitive edge of soft power]{.underline}. This might well
be the case. Only if America and its allies are capable of enacting
these values on the AI-infused battlefield together, though, will
**[this advantage serve to help legitimize U.S.-led operations in the
world's eyes]{.underline}**. A coalition's ability to uphold the laws of
armed conflict is ultimately bounded by the capability and willingness
of its least able members to do so.

**There are no DAs -- The DoD is already engaging to establish
principles for AI development. *[BUT]{.underline}* that won't solve.
*[ONLY]{.underline}*, Military cooperation between the US and Allies can
solve.**

**Mahoney 4/30**/2022

Casey Mahoney is a U.S. Institute of Peace--DoD Minerva Peace & Security
Scholar and a Ph.D. Candidate in political science at the University of
Pennsylvania. "Shared Responsibility: Enacting Military AI Ethics in
U.S. Coalitions.",
<https://nationalinterest.org/blog/techland-when-great-power-competition-meets-digital-world/shared-responsibility-enacting>
\-- ECM

In March 2021, Google's Eric Schmidt and former Department of Defense
(DoD) deputy secretary Bob Work wrote [in]{.underline} their preface to
[the]{.underline} 756-page [report of the bipartisan]{.underline}
National Security Commission on Artificial Intelligence
([NSCAI]{.underline}), "[America is]{.underline} **[not prepared to
defend or compete in]{.underline}** the **[AI]{.underline}** era." As
chair and vice-chair of the NSCAI, respectively, they summarized the
commission's solution: "[America needs]{.underline} to enlist
[its]{.underline} oldest [allies]{.underline} and new partners [to build
a safer and freer]{.underline} world for the [AI era]{.underline}."

Though [the U.S. military]{.underline} is taking pains to ensure AI does
not erode its ideal to fight wars ethically, it [cannot afford to leave
its allies]{.underline} and partners [behind]{.underline} in this
endeavor. DoD is working to ensure the U.S. military can deter and fight
AI-infused armed conflicts as part and likely leader of future
coalitions using ethical, or "responsible," AI. [Efforts have focused on
establishing broad principles for AI development]{.underline} and
[use]{.underline} [and]{.underline} have targeted the technical enablers
of multinational uses of AI, like standardizing data-labeling processes
and pursuing [data-sharing agreements]{.underline} with partners.

**[This is not enough]{.underline}**. On the coalition battlefield, [the
ethics of military AI come down to the choices leaders and commanders
make about how to use AI-enabled weapons]{.underline}. But it is not
clear that coordination and joint decisionmaking practices at the
political and operational levels used in U.S.-led coalitions to date are
well-suited to operations in an AI era. How will coalitions manage a
more complex decision space, where different nations' AI systems pass
algorithm outputs to operators and analysts across a coalition? Will
decisionmaking outcomes be consistent with our ethical ideals?

AI is making human judgment in war more, not less, important. [This
means the U]{.underline}nited [S]{.underline}tates [and its
allies]{.underline} and partners **[will need to innovate
together]{.underline}**, focusing on more than broad ethical principles
and technical solutions. [The U.S. defense enterprise can]{.underline}
take three concrete [steps]{.underline} I describe below t[o ensure its
own and its partners' tech]{.underline}nology [and ideals
align]{.underline} with the organizational structures---that is, in
coalitions---in which AI-enabled weapons will be put to use.

Foundations of AI Responsibility in U.S. Alliances and Partnerships

[Because the U]{.underline}nited [S]{.underline}tates [fights in
coalitions]{.underline} in most armed conflicts, [focusing on developing
partnerships to integrate military AI is]{.underline} a
[prudent]{.underline} approach. The NSCAI charged the DoD with achieving
broad military AI readiness by 2025, including by "promoting AI
interoperability with allies and partners," and the Pentagon is heeding
this call.

In September 2020, DoD had already convened representatives from
thirteen countries from NATO, non-NATO alliances, and other defense
partnerships to socialize its ethical principles for AI and coordinate
on military AI ethics policy. This AI Partnership for Defense (AIPfD)
aims to "promote the responsible use of AI, advance shared interests and
best practices ... establish frameworks to facilitate cooperation, and
coordinate strategic messaging."

Since then, engagement with international defense partners has broadened
and deepened. By June 2021, AIPfD had added three additional member
states to the group; in March 2022, it convened its fifth international
dialogue. AIPfD cooperation has deepened from high-level conversations
to discussions on AI-use scenarios, marking progress toward a key NSCAI
recommendation the DoD focus on specific AI use-cases in exercises and
wargames.

In addition, in October 2021, NATO adopted an alliance-wide AI strategy
focused mostly on responsible use. Biden administration initiatives in
the Indo-Pacific in 2021---reinvigorating the Quadrilateral Security
Dialogue (Quad) with Australia, India, and Japan and concluding the
Australia-U.K.-U.S. (AUKUS) technology-sharing agreement---also targeted
AI cooperation. Early work in the Quad has included collaboration on AI
technical standards more generally, while AUKUS members are cooperating
on capabilities for use in contested military environments.

Finally, [U.S. military services have also begun incorporating new AI
systems into multinational operational exercises]{.underline},
experimentation that can help foresee and overcome the technical and
operational challenges of using novel technology in coalitions.

[Important early steps like these help enact standards]{.underline},
like keeping humans in AI systems' decision loops and having strong
technology-policy review processes, meant to avoid worst-case scenarios
where uncontrolled, unvalidated systems are fielded in armed conflict.

[But]{.underline}, **[the Department has more to do to avoid the misuse
or failure of AI-enabled weapons in future coalition
operations]{.underline}**. Whether the employment of any weapons system
in armed conflict is "ethical" or "responsible" ultimately depends on
the assessments commanders and political leaders make. In multinational
operations with AI tools at the "tip of the spear," non-U.S. leaders and
commanders will also be faced with choices that determine whether they
use such tools to enact values, like proportionality and discrimination,
in fighting alongside U.S. forces. It is in the U.S. interest that they
do this. Guaranteeing that they do, however, is difficult.

**[1AC Solvency: Cyber]{.underline}**

**The plan would solve cyber -- it establishes a new set of guidelines
on Cyber Defense**

- The plan would be implemented thru "sparring sessions" to establish
  defensive tactics and operations which the 1AC Ryseff evidence
  outlines

**Taddeo & Floridi 18**

NATURE \| VOL 556 \| 19 APRIL 2018, Mariarosaria Taddeo is a research
fellow and deputy director of the Digital Ethics Lab at the Oxford
Internet Institute, University of Oxford, UK; and a Turing fellow of the
Alan Turing Institute, London, UK. Luciano Floridi is professor of
philosophy and ethics of information at the University of Oxford, UK;
director of the Digital Ethics Lab at the Oxford Internet Institute; and
chair of the Data Ethics Group at the Alan Turing Institute. "Regulate
artificial intelligence to avert cyber arms race",
<https://media.nature.com/original/magazine-assets/d41586-018-04602-6/d41586-018-04602-6.pdfv>
\--ECM

[International]{.underline} dialogue and [action must
resume]{.underline}. [NATO could pave the way through]{.underline} its
forthcoming [guidelines]{.underline}, although it is currently unclear
what their scope will be.

Meanwhile, research on AI for cyberdefence is progressing quickly. [The
U]{.underline}nited [S]{.underline}tates [is in the lead]{.underline},
technologically. It aims to incorporate AI into its cyberdefence systems
by 2019 (ref. 3). The US Department of Defense (DOD) has earmarked \$150
million for research. The US Defense Advanced Research Projects Agency
(DARPA) is developing the techniques and strategies. Steps have already
been taken. In DARPA's 2016 Cyber Grand Challenge competition, seven AI
systems, developed by teams from the United States and Switzerland,
fought against each other. The systems identified and targeted their
opponents' weaknesses while finding and patching their own.

The DOD will issue the first US report on AI strategies for national
defence in May. There is, as far as we know, no indication of what its
approach will be. Previous documents, such as The DOD Cyber Strategy
from 2015 or the 2016 National Cyber Incident Response Plan, did not
cover autonomous systems, machine learning or AI. The 2012 DOD directive
on 'Autonomy in Weapon Systems' focused on internal procedures for
deploying AI but was silent on when the United States would do so in the
international arena.

AI is a priority for China, which aims to become a world leader in
machine-learning technologies. In July 2017, the Chinese government
issued its Next Generation AI Development Plan. Military implementation
of AI, on the battlefield as well as in cyberspace, is a crucial part of
the strategy. But it is unclear to what degree China plans to deploy AI
actively in cyberdefence.

Russia has not released any public documents about its strategies for AI
in defence. However, in a video message released in 2017, President
Vladimir Putin referred to AI and stated: "Whoever becomes the leader in
this sphere will become the ruler of the world." Experts agree that
Russia is focusing on developing AI-enhanced tools for its conventional
forces. However, since 2014, the Russian National Defense Control Center
has been using machine-learning algorithms to detect online threats.
Allegedly, Russia has pioneered the use of AI to spread disinformation
and intervene in the public debates of other nations, including the 2016
US presidential election and the United Kingdom's EU membership
referendum. Although these operations are not part of national defence
strategies, they indicate Russia's advanced AI capabilities.

North Korea has a history of cyberspace aggression. It was implicated,
for example, in the WannaCry attack in 2016 and in another major breach,
against Sony Pictures, in 2014. The country lacks technical expertise in
AI but is likely to want to catch up with its adversaries.

The EU is stepping up, too. In 2017, it reassessed cybersecurity and
defence policies and launched the European Centre of Excellence for
Countering Hybrid Threats, based in Helsinki. The EU has the most
comprehensive regulatory framework for state conduct in cyberspace so
far. Yet these directives do not go far enough. The EU treats
cyberdefence as a case of cybersecurity, to be improved passively by
making member states' information systems more resilient. It disregards
active uses of cyberdefence and does not include AI.

This is a missed opportunity. The EU could have begun defining red lines
and proportionate responses in its latest rethink. For example, the 2016
EU directive on 'Security of Network and Information Systems' provides
criteria for identifying crucial national infrastructures, such as
health systems or key energy and water supplies that should be
protected. The same criteria could be used to define illegitimate
targets of state-sponsored cyberattacks.

**[Regional forums, such as NATO]{.underline}** and the EU, [must
take]{.underline} the following three **[steps to avoid serious imminent
attacks on state infrastructures]{.underline}**, [and to
maintain]{.underline} international **[stability]{.underline}**.

THREE STEPS

[Define legal boundaries]{.underline}. [The international community
needs to]{.underline} agree urgently on [red lines that distinguish
between legitimate and illegitimate targets]{.underline}. Also needed
are definitions of proportionate responses for cyberdefence strategies.
International consensus at the UN level will ultimately be required.
Until then, [guidelines from]{.underline} regional multilateral bodies,
such as [NATO]{.underline} and the EU, **[must cover these issues and
lead by example]{.underline}**.

Test strategies with allies. **['Sparring' exercises should be organized
between friendly countries to test AI-based defence
tactics]{.underline}**. [These tests should be mandatory before any
system is deployed]{.underline}. They could be in the form of DARPA's
Grand Challenge or the simulation exercises routinely run by NATO and
the EU. Because AI learns by experience, [these matches will improve the
strategies of the alliance, while finding and healing
weaknesses]{.underline}. Fatal vulnerabilities of key systems and
crucial infrastructures should be shared with allies; policy frameworks
should demand disclosure. Agreements and regulations with similar
sharing and disclosure requirements include the EU Electronic
Identification, Authentication and Trust Services Regulation and NATO's
Industry Partnership Agreement.

Monitor and enforce rules. [The international community needs to agree
how to audit and oversee AI-based state cyberdefence
op]{.underline}eration[s]{.underline}. 'Alert and remedy' mechanisms are
needed to address mistakes and unintended consequences. A third-party
authority with teeth, such as the UN Security Council, should rule on
whether red lines, proportionality, responsible deployment or disclosure
norms have been breached. Economic or political sanctions should be
imposed on states that violate rules. [NATO]{.underline} and the EU
[should enforce the norms]{.underline} within their remits.

The solution is difficult, but it is clear. **[There is no time to
waste]{.underline}**.

**2AC -- Cyber ADV**

**[2AC -- Cyber Attack = Article V]{.underline}**

**Yes cyberattacks could trigger article V**

**Reuters 2/28**/2022

"Cyberattack on NATO could trigger collective defence clause --
official",
<https://www.reuters.com/world/europe/cyberattack-nato-could-trigger-collective-defence-clause-official-2022-02-28/>
\-- ECM

LONDON/WASHINGTON, Feb 28 (Reuters) - [A cyberattack on a NATO member
state could trigger Article 5]{.underline}, its collective defence
clause, **[a NATO official said]{.underline}** on Monday, amid concerns
that chaos in cyberspace around Russia\'s invasion of Ukraine could
spill over into other territories.

[The military alliance has for years made clear that a **serious
cyberattack**]{.underline} [could trigger the clause]{.underline}, but
such a scenario has so far been largely hypothetical.

\"Allies also recognise that the impact of significant malicious
cumulative cyber activities might, in certain circumstances, be
considered as an armed attack,\" the official told Reuters.

\"We will not speculate on how serious a cyberattack would have to be in
order to trigger a collective response. [A]{.underline}ny [response
could include]{.underline} diplomatic and economic sanctions, cyber
measures, or even **[conventional forces]{.underline}**, depending on
the nature of the attack,\" the official said.

Whether or not a cyberattack met the threshold of an attack large enough
to trigger Article 5 was a \"political decision for NATO Allies to
make,\" they added.

[Britain and the U]{.underline}nited [S]{.underline}tates [have
warned]{.underline} [of potential]{.underline}
cyber[attacks]{.underline} [on Ukraine which could have **international
consequences**]{.underline} should, for example, malicious software
designed to target networks in Ukraine start to spread elsewhere. read
more

There has also been concern among cybersecurity experts that [Russia
could team up with]{.underline} some of the [gangs and people who
release malicious software]{.underline}, such as malware used [to hold
Colonial Pipeline to ransom in the U]{.underline}nited
[S]{.underline}tates last year.

**[2AC -- Yes Cyber attacks 🡺 War]{.underline}**

**The threshold is low if not unknown -- shouldn't risk it**

- The article cites \-- Tess Bridgeman, co-editor in chief of the
  website Just Security and a former attorney in the Obama White House
  who is an expert on war powers and international law

**CNN 3/22**/2022

"A cyberattack could lead to war. But it is very unlikely",
https://www.cnn.com/2022/03/22/politics/russian-cyberattacks-what-matters/index.html

I called Tess Bridgeman, co-editor in chief of the website Just Security
and a former attorney in the Obama White House who is an expert on war
powers and international law.

"[If a cyberattack causes]{.underline} significant **[death, destruction
or injury]{.underline}**, of the same sort that y[ou would see from a
more traditional attack]{.underline} using kinetic means, like
**[bullets or missiles,]{.underline}** you know, then you would call it
a 'use of force' in international law," she said.

[A cyberattack that targeted a dam or air traffic control towers might
rise to this level]{.underline}, but the government would try very hard
to avoid responding to a cyberattack with a military attack, she said.

The attacks on the US to date have fallen short of the threshold to
justify a military response.

As the government seeks [countermeasures to respond]{.underline},
Bridgeman said, there's a good chance they **[won't be publicly
known]{.underline}**.

**That includes article V**

- The article cites \-- Tess Bridgeman, co-editor in chief of the
  website Just Security and a former attorney in the Obama White House
  who is an expert on war powers and international law

**CNN 3/22**/2022

"A cyberattack could lead to war. But it is very unlikely",
https://www.cnn.com/2022/03/22/politics/russian-cyberattacks-what-matters/index.html

**[A cyberattack could absolutely trigger Article 5]{.underline}**. NATO
Secretary General Jens Stoltenberg made this clear in February just
after Russia's invasion.

"An attack on one will be regarded as an attack on all," Stoltenberg
said at a news conference when asked about a potential Russian
cyberattack.

But he added that NATO would be very careful in assessing an attack and
would make sure a cyberattack on Ukraine -- shutting off electricity,
say -- that accidentally spilled over into Poland or Romania is not
construed as an attack on those countries.

He also said [it's intentionally unclear]{.underline} **[what kind of
cyberattack would rise to the level of invoking Article
5]{.underline}**.

[NATO]{.underline}, he said, **[would not want to "give a potential
adversary the privilege of defining exactly when we trigger Article
5]{.underline}**."

**Cyber escalation is real and possible -- 3 reasons**

- command, control, communication, and intelligence = (C3I) systems

**Acton 20**

Spring, James M. Acton holds the Jessica T. Mathews Chair and is
Co-Director of the Nuclear Policy Program at the Carnegie Endowment for
International Peace. "Cyber Warfare & Inadvertent Escalation",
<https://www.amacad.org/publication/cyber-warfare-inadvertent-escalation>
\-- ECM

[This danger is likely]{.underline} to be [exacerbated by any cyber
vulnerabilities affecting nuclear forces and C3I systems]{.underline}.
Most directly, the existence of such vulnerabilities could intensify
existing fears of being disarmed--fears that are already acute in China
and Russia (as well as in Pakistan and, most likely, North Korea).5
However, because of their unique characteristics and effects, [cyber
threats could create]{.underline} **[at least three qualitatively new
mechanisms by which a nuclear-armed state might come to the incorrect
conclusion that its nuclear deterrent was under threat]{.underline}**.
**[First]{.underline}**, the purpose of [cyber interference could be
misinterpreted]{.underline}. In particular, espionage could be mistaken
for an attack. **[Second]{.underline}**, [a cyberattack could have **a
more significant effect than intended**]{.underline}. Malware implanted
into information technology (IT) systems associated with non-nuclear
weapons could accidentally spread into more sensitive nuclear-related
systems, for instance. **[Third]{.underline}**, [the initiator of a
cyber op]{.underline}eration [could be misidentified]{.underline}. [An
op]{.underline}eration carried out by a third party, for example,
**[could be misattributed by one state in a bilateral
confrontation]{.underline}** to its opponent. [What makes these
pathways]{.underline} so [pernicious is]{.underline} that **[the
catalyst for escalation]{.underline}** [could appear to its initiator to
be a relatively **benign action**]{.underline}.

**[To make matters worse]{.underline}**, [such pathways could lead
to]{.underline} **[inadvertent escalation]{.underline}** even if the
target of the cyber interference were not afraid of being completely
disarmed. Today at least, [this]{.underline} description [fits the
**U**]{.underline}nited **[S]{.underline}**tates. If, **[in a conflict
against Russia]{.underline}**, say, **[the U]{.underline}**nited
**[S]{.underline}**tates [wrongly concluded that its strategic
early-warning system was under cyberattack]{.underline}, **[it might
reason that Moscow was seeking to undermine U.S. missile
defenses]{.underline}**, which use early-warning data, **[prior to
launching a nuclear attack]{.underline}**.6 Given that U.S. declaratory
policy explicitly highlights the option of a nuclear response to
non-nuclear attacks on nuclear C3I assets, [such a "misinterpreted
warning" might lead Washington to **use nuclear weapons**]{.underline}.7
**[But even if it did not]{.underline}**, [its response]{.underline},
which might include nuclear threats, **[could still be
escalatory]{.underline}**.

**Even small-scale cyber ops could trigger escalation**

**Acton 20**

Spring, James M. Acton holds the Jessica T. Mathews Chair and is
Co-Director of the Nuclear Policy Program at the Carnegie Endowment for
International Peace. "Cyber Warfare & Inadvertent Escalation",
<https://www.amacad.org/publication/cyber-warfare-inadvertent-escalation>
\-- ECM

[Surveillance op]{.underline}eration[s]{.underline} [in
cyberspace]{.underline}, [even if conducted]{.underline} exclusively for
[defensive purposes]{.underline}, **[pose unique risks of
escalation]{.underline}**. Cyber surveillance of an adversary's nuclear
forces can serve purposes besides damage limitation. In any dyad
involving two nuclear-armed states, each has a strong incentive to
monitor the status of the other's nuclear forces at all times--and
particularly during a crisis or conflict--including for the exclusively
defensive purpose of spotting any preparations for nuclear use. Several
intelligence collection techniques, including overhead imagery and
signals intelligence, are likely used for this purpose. [Given
the]{.underline} potentially [unique advantages of
surveillance]{.underline} in cyberspace, however, [states may see good
reason to adopt it alongside]{.underline} these [other
approaches]{.underline}, especially if they judge that the likelihood of
cyber espionage being detected is small.

Depending on the sophistication of the malware used and the target's
defenses, the true likelihood of being detected may or may not be small,
but **[the consequences of being caught could be
significant]{.underline}**. In fact, [if the target
detected]{.underline} ongoing [cyber espionage of]{.underline} networks
associated with its **[nuclear forces]{.underline}** or C3I systems,
**[inadvertent escalation could result]{.underline}** from either of two
concerns that are distinct from those that might plausibly be generated
by other forms of surveillance.

**Lack of agreement of what constitutes a cyber-attack causes
[miscalculation]{.underline} and [escalation]{.underline}**

**Hegenbart 14**

Christine, Research Assistant at the Academy for Politics and Current
Affairs of the Hanns Seidel Foundation in Munich. She was a PfP Fellow
at the Research Division at the NATO Defense College in the spring of
2013. "Semantics Matter NATO, Cyberspace and Future Threats." NATO
Defense College (2014). https://www.jstor.org/stable/resrep10385

All in all, [the use of cyber weapons is]{.underline} especially
[problematic and is a very serious issue]{.underline}. Currently most
states, and also NATO as a military alliance, focus on defending against
cyber threats. [This strategic orientation raises concerns about the
**ethical and legal implications** of using cyber tools]{.underline}.
But an increasing number of nation states see cyber capabilities as
important instruments, and as weapons to be used in interstate
conflicts. However, military and political decision-makers will have to
pay close attention to the circumstances under which it is beneficial to
use cyber weapons outside the 'classic' theater of military operations.
[There is the danger of **miscalculating** the result of cyber-attacks,
thereby **escalating the conflict and triggering retaliation** outside
cyberspace with conventional armaments.]{.underline}

Apart from these six types of cyber conflict, [the term
cyber-attack]{.underline} deserves particular notice. The word [takes on
a variety of meanings]{.underline}, according to the specific security
fields. [A precise and narrow definition would help **de-escalate** the
rhetoric. In order to **reduce confusion and uncertainty**]{.underline}
in a military context, the term [cyber-attack should only be used to
describe cyber conflicts with a military dimension]{.underline}. Their
effects have to be significantly damaging: either disruptive (i.e.
drastic, obvious and immediate) or corruptive (i.e. subtle and
persistent).30 Consequently, only instances of cyber sabotage, cyber
terrorism and cyber war(fare) should be identified as cyber-attacks.

[It is important to define, **especially for NATO, what constitutes the
use of force**]{.underline} through cyber technology. The Tallinn Manual
on the International Law Applicable to Cyber Warfare, launched by NATO's
CCDCOE is not an Alliance directive, but provides guidance on the
matter. It defines a militarily relevant cyber-attack as "a cyber
operation, whether offensive or defensive, that is reasonably expected
to cause injury or death to persons or damage or destruction to
objects."31 [The definition is]{.underline} shaped by the result: [if a
cyber operation is followed by significant destructive consequences, it
qualifies]{.underline} both as a cyber-attack and as use of force. [If
hostile cyber activity leads only to inconvenience]{.underline} or
irritation, [it is neither a cyber-attack nor the use of
force]{.underline}. The fundamental understandings of this term have to
be discussed because, in the end, the evaluation will be a political
decision.

**[2AC -- NATO strat fails now]{.underline}**

**NATO strategy leaves the alliance [vulnerable]{.underline} to [attacks
on satellites]{.underline}**

**Goud ND**

Naveen. Writer at Cybersecurity Insiders. "US and NATO Satellites are
vulnerable to Russia and China Cyber Attacks" Cybersecurity Insiders.
https://www.cybersecurity-insiders.com/us-and-nato-satellites-are-vulnerable-to-russia-and-china-cyber-attacks/

But now, new research conducted by a defense think tank says a different
story. It's believed that [US and NATO]{.underline} command and control
systems [are themselves opening up their vulnerabilities to be
**exploited by hackers being funded by their adversaries.**]{.underline}
Yes, what you've read is absolutely true! [Chatham House, a non-profit
organization]{.underline} which helps the world understand international
crisis [has come up with the above-said conclusion after **analyzing
different threat analytics related to space assets.**]{.underline} As
[attacks on satellites can **wreak havoc on communications** and
strategic weapons]{.underline}, nations will for sure interested in
intercepting them for their own means. It is a kind of modern warfare
where vulnerabilities will be scanned to be exploited. Chatham House
says that countries like Iran and [North Korea do not have the expertise
to launch such attacks. But **Russia and China have all the
sophistication** to make things serious.]{.underline} As [the United
States]{.underline} is failing to cut down the influence of China and
Russia on the world. It [is on the verge of inviting a national security
risk.]{.underline} Meanwhile, as the trade conflicts between China and
Donald Trump are deteriorating with every passing day, China is alleged
to have adopted an offensive cyber strategy by having state-sponsored
hackers on a constant backdrop to retaliate to trade and security
conflicts on an international note. As Military of every nation relies
heavily on satellites, intercepting those related to certain countries
can give an upper hand to adversaries during increasing tensions says
the UK think tank. [As nations are **relying heavily on cyber warfare**,
satellites of US and NATO are termed to be **super-vulnerable to cyber
attacks**]{.underline} by 'The Royal Institute of International
Affairs'. [As it leads to a deep impact on decision making of how
different operations are conducted, **proving fatal to military
systems** which in-turn negatively influence the making of political
decisions.]{.underline}

**[2AC -- Satellites Add-on]{.underline}**

**Satellites are [vulnerable]{.underline} to cyberattacks\-\--Russia and
China are [pushing]{.underline} the line**

**Lemos 19**

Robert. Veteran technology journalist of more than 20 years. Former
research engineer. "Cybersecurity Experts Worry About Satellite & Space
Systems" Dark Readings. 07-02-2019.
https://www.darkreading.com/attacks-breaches/cybersecurity-experts-worry-about-satellite-and-space-systems/d/d-id/1335131

[Information from satellites fuel a great deal of today\'s
technology]{.underline}, from the intelligence gathering conducted by
nation-states, to the global positioning system used for vehicle
navigation, to the targeting used by \"smart\" weapons. Little surprise,
then, that [cybersecurity]{.underline} and policy [experts worry that
the relative insecurity of satellite systems **open them to
attack.**]{.underline} In a paper released by The Royal Institute of
International Affairs at the non-profit think-tank Chatham House, Beyza
Unal, a senior research fellow in international security, warned that
[the reliance of space-based systems and satellites on civilian
infrastructure means **greater vulnerability to attack**]{.underline} in
times of conflict and espionage in times of peace. \"[During wartime,
the greatest risk is to **lose operational foresight** and be unable to
rely on data that comes through space]{.underline},\" Unal says.
\"Receiving false or fake information may result in giving an advantage
to the adversary.\" The [warnings come as an increasing number of
nations have ramped up their operations in space.]{.underline} What used
to be a race between the United States and Russia has changed. China
landed a rover on the moon in January and launched a quantum satellite
into orbit in 2016. The European Space Agency has sent probes to Mars
and put a gravitation wave detector into space. Japan launched a probe
that successfully landed on a near-Earth asteroid and intends to bring
back samples. A dozen nations have developed some level of space
capability and have used it to launch satellites into space. The U.S.
military, for example, relies on satellites to direct munitions. In
2003, during its engagement in Iraq, 68 percent of munitions were in
some way guided by satellites or using intelligence from satellites, the
Chatham House paper said. The [importance of satellites make them a
critical part of any nation\'s infrastructure and attacking those
satellites a strategy that most nations need to consider. While kinetic
attacks are possible, **cyber attacks have the benefit of being
inexpensive.**]{.underline} \"The most cost effective type of attack is
the digital cyber vector,\" says John Sheehy, vice president of
strategic services at IOActive, a security firm. \"And, if you can
disrupt satellite operations using cyber, unfortunately that greatly
widens the pool of potential threat actors who have the capability to
disrupt satellite operations.\" The Chatham paper pointed out that both
[China and Russia have both focused on **using cyber attacks as part of
their military and strategic doctrine.** NATO has
encountered]{.underline} GPS jamming and other [cybersecurity attacks
against satellite systems during military exercises]{.underline}, the
report said, citing NATO officials, who attributed the attacks to
Russia. [Historically, satellite systems have only suffered occasional
attacks]{.underline} over the past decade. In its 2011 Report to
Congress, for example, the U.S.-China Economic and Security Review
Commission noted that \"in recent years, two U.S. government satellites
have experience interference apparently consistent with the cyber
exploitation of their control facility.\" The two
satellites---identified as Landsat-7 and Terra EOS AM-1---each
experienced two incidents of interference between October 2007 and
October 2008 lasting a combined 35 minutes, according to the report. The
outages were consistent with attacks against the satellites\' land-based
systems, but no positive evidence was found at the time. However, since
that report, satellites have been both successfully exploited and
attacked. A Russian cyber espionage group known as Turla---as well as at
least two other groups---have used unencrypted satellite links as
command-and-control and exfiltration channels for their operations. At
last year\'s Black Hat conference, one security researcher used
vulnerabilities in satellite equipment to hack into an airplane\'s
in-flight communications equipment from the ground. Finally, Russia has
frequently disrupted the global navigation satellite system (GNSS) for
at least three years to prevent drone attacks and during times of
military operations, such as its invasion of Crimea. The incidents have
happened at least 9,883 times, according to research published earlier
this year. \"There is constant experimentation about pushing the
envelope,\" says David Fidler, adjunct senior fellow for cybersecurity
at the Council on Foreign Relations. \"Because it is a cyber operation,
we don\'t quite know where that line is yet. [Countries are being
cautious about it, but they are **pushing in that line more and
more**.]{.underline}\" In the Chatham House paper, Unal points out that,
while NATO owns some ground-based facilities and components, the group
does not own its own satellites, but gets information from satellites
from its member states. Typical attacks against such infrastructure
includes the \"five Ds\"---attacks that disrupt, deny, degrade, deceive,
and destroy. In addition to actual cyberattacks, [vulnerabilities in
satellite can undermine the faith that member nations have in the
intelligence provided by NATO, raising questions about the root
justifications for action as well as potentially **destabilizing the
relationships between members**]{.underline}, the report stated.

**2AC -- Heg ADV**

**[2AC -- AI key China rise]{.underline}**

**Emerging Tech is key to Chinese power projection**

**Haenel 18**

June, Fabio Haenel currently works at the Global and European Studies
Institute, University of Leipzig. Fabio does research in Information
Technology and Politics, Human Rights and Foreign Policy. "The Prospects
and Dangers of Artificial Intelligence on International Security: The
Case of a Sino-American Arms Race.",
<https://www.researchgate.net/publication/325542003_The_Prospects_and_Dangers_of_Artificial_Intelligence_on_International_Security_The_Case_of_a_Sino-American_Arms_Race>
-- ECM

In contrast to US-American pluralism fragmented between industrial and
political interest groups in the ace of being torn at from both public
debate and the deep state among the intelligence community, China's
growing centralization of its one-party government has recognized and
internalized the of set potential of emerging technologies under the
rule of President Xi more than any other nation-state. Nominally, the
United States are holding an advantage in the numbers o high-tech
startups and global corporations developing AI, an environment also
nourished by long attracting the most eager and intelligent Chinese
students to seek education at American campuses and thus feeding the
need or talent in Silicon Valley and across the US to fill the
telecommunications companies' well-paid and highly competitive
positions.136 But [Beijing's long-term attempts to push back US-American
influence in the]{.underline} Greater [Pacific]{.underline} region [and
to install China]{.underline} not only [as a global economic
power]{.underline} but [a strategic power]{.underline} as well has
recently been [catalyzed by]{.underline} both heavy domestic and foreign
investments in [emerging tech]{.underline}nologies.

[These include]{.underline} the **[rapid modernization]{.underline}**
[of its naval and air force]{.underline} [to]{.underline} gradually
**[expand China's Anti-Access/Area-Denial]{.underline}** zone away from
its coastal borders,137 diversifying their domestically manufactured and
designed state-owned civil and military satellite systems and pioneering
cutting-edge quantum telecommunications in space,138 as well as boosting
Chinese telecommunications companies with favorable budget plans and
topdown state policy changes to cater to the needs o their research and
development departments but also by continuously denying foreign
corporations to enter and capitalize on the quickly growing middle-class
within China.

The growing volume of Chinese foreign investment in US-American
high-tech startups and publicly-held telecom corporations led the Trump
administration to tighten regulatory oversight to shield US-American
intellectual property:140 "The Chinese have found a way around our
protections, our safeguards, on technology transfer in foreign
investment. And they're using it to pull ahead of us, both economically
and militarily," James Lewis from the Center or Security and
International Studies argues.141 China's two-fold strategy to use its
vast capital means to gain influence within foreign AI developers while
cradling and catalyzing its own AI industry within China's barred
domestic economy accumulated in "The Internet Plus and Artificial
Intelligence Plan (2016-18)," the world's most broadly state-supported
policy plan calling or breakthroughs in AI development and its
"expansive applications, including in unmanned systems and
cyber-security," clearly exemplifying the securitized assessment o AI
technology in the eyes of the Chinese government.

As part of the 13th Five-Year-Plan or the years 2016-2020 the Chinese
governments' Artificial Intelligence Plan represented a stepping stone
between prioritizing its development on ministerial level as the sixth
most important task or the country and enshrining it as part of China's
self -identity: The 2017 government work report, the Chinese Premier's
annual report to the People's Congress on the past years' economic
performance and the coming years' challenges featured Artificial
Intelligence or the first time, stressing the need to divest funds into
its adoption, followed by President [Xi enshrin]{.underline}ing [AI
development as a]{.underline} **[key driver to China's hegemonic
ambitions]{.underline}** to become a "science and technology superpower"
in his opening speech to the 19th Party Congress in November 2017 ending
with his reaffirmation as President.143 Precisely, the plan sets the
national goal o expanding its AI industry to RMB 150 billion (\$23.8
billion) gross output by 2020, a ten- fold increase from 2016, in an
overall plan to be the world's leader in AI development by 2025.144 By
2030, the plan envisions, the target gross output is set at RMB 1
trillion (\$150 billion) in core AI industries innovating and developing
the software architecture and hardware infrastructure and RMB 10
trillion (\$1.5 billion) in adjacent AI-enhanced industries developing
applications of automation in all sectors, e.g. self -driving vehicles.
In context to various analyses of the global AI market these targets all
are within the high end of market forecasts.

Experts argue that only the recent defeat of Korean Go master Lee Sedol
in 2016 and the Chinese world-champion Ke Jie in 2017 at the hand of
AlphaGo, Google's own and arguably the world's currently most powerful
Artificial Intelligence, offered the Chinese officials as much a
"Sputnik moment" as the first successful launch of a space probe by the
Soviet Union posed to the US administration in 1957, calling or the
immediate refocusing of funds and energy into the US space program
thereafter.146 The Wuzhen Institute reported the biggest surge o
searches on Baidu, [China's pendant to Google]{.underline}, [on topics
of AI immediately after the]{.underline} 20[16 and]{.underline}
20[17]{.underline} [Go-matches]{.underline},147 [followed by
an]{.underline} [increase in conferences and workshops held both in
academia and]{.underline} in [the military on the impact of AlphaGo's
victory on Chinese interests, including the P]{.underline}eople's
[L]{.underline}iberation [A]{.underline}rmy['s strategic
planners]{.underline}.

In accordance with the monumental effort to modernize the PLA's
capabilities, in particular by researching, developing and producing
nuclear-powered submarines, operational aircraft and helicopter
carriers, as well as China's first domestically produced passenger and
cargo jet on top of its already successful modern generation of fighter
jets, its leadership has closely studied the US Army's concentration on
autonomy and the Defense Department\'s proposed "Third Of set"
strategy.149 In act, China's efforts in researching and developing its
own swarming-capable or solitary UAVs, semi-autonomous missile guiding
systems, and the growing frequency and scope o the PLA's practical
mission experience borrow heavily from the strategic idea of
asymmetrically of setting an otherwise quantitatively too powerful
competitor through technological superiority.150 [The government's work
report cites Lieutenant General Liu]{.underline} Ghuozhi, the Director
of the Central Military Commission's Science and Technology Commission,
[saying]{.underline} that [whichever nation is]{.underline} "[on the eve
of a new scientific and tech]{.underline}nological
[revolution]{.underline}" **[not prepared to engage in developing
A]{.underline}**rtificial **[I]{.underline}**ntelligence applications
**[for its military "will be disrupted]{.underline}**.

**Speed of AI development risk manipulation, arm racing, and ensures
China challenge of US Heg.**

**Haenel 18**

June, Fabio Haenel currently works at the Global and European Studies
Institute, University of Leipzig. Fabio does research in Information
Technology and Politics, Human Rights and Foreign Policy. "The Prospects
and Dangers of Artificial Intelligence on International Security: The
Case of a Sino-American Arms Race.",
<https://www.researchgate.net/publication/325542003_The_Prospects_and_Dangers_of_Artificial_Intelligence_on_International_Security_The_Case_of_a_Sino-American_Arms_Race>
-- ECM

After all, it took Szilárd years to demonstrate the theoretical
discovery of combusting controlled nuclear chain reactions in his lab
but only a relatively insignificant time after that to create the first
nuclear weapon.68 In 2014, the most optimistic forecast on AI beating
human world champions in complex games was set not be ore a decade would
run out, however, AlphaGo beat Ke Jie much earlier than that and long
has taken over numerous other applications: "**[Progress in AI has been
much faster]{.underline}** \[\...\] [than most]{.underline} people
[expected]{.underline}."69 Thus it is argued here that [the rapid
acceleration of development of]{.underline} **[A]{.underline}**rtificial
**[I]{.underline}**ntelligence technology [makes its adoption subjective
to]{.underline} civil and strategic **[manipulation]{.underline}** by
private and state actors alike, prompting a technological landslide of
societal changes **[akin to the development of nuclear
power]{.underline}** in the 1940s or the Industrial Revolution itself .
[Benefiting from an upward power trajectory]{.underline} and the
parallel decline of U.S. global hegemony in the last decade the People's
Republic of **[China will close the strategic gap to the U.S. by heavily
investing in AI]{.underline}** research and development **[challenging
U.S. supremacy in the future]{.underline}**. [This will usher in
a]{.underline} **[new arms race to deploy]{.underline}** [fully
automated weaponry]{.underline} on both sides of the Pacific and might
**[drastically change the geopolitical dynamics]{.underline}** [of the
international system]{.underline} in the unfolding century towards a
bipolarity between Washington and Beijing. [These
developments]{.underline} threaten reckless AI adoption unable to be
policed by civil authorities proactively, and thus [need]{.underline}s
[to be prevented]{.underline} by proliferation [on an international
level]{.underline}.

**[2AC -- Sustainability Debate]{.underline}**

**Yes, Heg maybe in trouble -- BUT it's a self-inflicted wound. US
unilateralism and distancing from NATO acts as root causes which the
plan would resolve.**

- Ataman says distancing from NATO allies on key issues is the problem
  -- SQ cant fix it -- but the plan would spearhead a shift back to heg
  but establishing norms on AI

**Ataman** 9/29/20**21**

Prof. Muhittin Ataman graduated from the Faculty of Political Science in
the Department of International Relations at Ankara University. "Global
leadership crisis: The U.S. hegemony vs. China",
<https://www.dailysabah.com/opinion/columns/global-leadership-crisis-the-us-hegemony-vs-china>
\-- ECM

Today's world is in both a comprehensive transition and a deep crisis.
Not only do rivalries and enmities abound but [today's alliances
are]{.underline} also quite [vulnerable]{.underline}. [The
survival]{.underline}, duration **[and sustainability]{.underline}** [of
all]{.underline} [these]{.underline} alliances, rivalries and conflicts
**[are in question]{.underline}**. In other words, neither conflicting
nor cooperative relations are sustainable over the long term. **[All
foreign policy activities are conducted on slippery
ground]{.underline}**. That is, the direction and pace of any
relationship may change at any time.

Therefore, when we analyze the current global balance of power, we have
to take these conditions into consideration. No global power pursues a
principled foreign policy orientation. Most countries follow an
eclectic, sectoral and compartmentalized foreign policy. In this piece,
I want to briefly analyze the current foreign relations tendencies of
certain global powers.

Leadership crisis

Even though [the U]{.underline}nited [S]{.underline}tates **[is the most
powerful, influential and important international actor]{.underline}**,
[it faces difficulties in maintaining its global
leadership]{.underline}. As U.S. relations with other leading global
powers are in flux, **[U.S. relations with its European allies are not
sustainable]{.underline}**. [The U.S. is neither
comfortable]{.underline} with the current pace of global relations, [nor
it is able to change the pace of these events]{.underline} to
accommodate its national interests.

In this context, it is interesting to examine U.S. relations with other
influential actors. The U.S. prioritizes its relations with China, the
most powerful challenger state to American hegemony.

Successive U.S. governments have not determined what kind of policy to
follow toward China. For instance, only several days after President Joe
Biden declared that the time for "relentless diplomacy" has begun, the
U.S. announced a new alliance with Australia and the United Kingdom
(AUKUS). The U.S. promises carrots but generally uses the stick in its
relations with China.

On the other hand, [the steps taken by the U.S. in the
Indo-Pac]{.underline}ific region **[both directly and
indirectly]{.underline}** **[undermine its trans-Atlantic
allegiances]{.underline}**. It seems [that its]{.underline}
European/**[NATO allies will be of lesser importance for the U.S. for
the foreseeable future]{.underline}**. However, it will continue to
cooperate with European countries against the perceived threat from
Russia, still the main \"other\" of the NATO alliance.

The relations between the U.S. and European Union are increasingly
problematic. There are brief ups and downs, both alliance and rivalry,
in their relationship. European countries do not share many concerns
with the U.S. and vice versa. While European countries prioritize their
relations with Russia, the U.S. prioritizes its relations with China.

Similarly, at a time when the U.S. president has declared that the U.S.
is refocusing on international politics, the U.S. withdrew from
Afghanistan and ended its 20-year invasion. The U.S. left the country to
the Taliban regime, which it had overthrown 20 years ago. The U.S.
continues to withdraw from certain crisis areas. Other global powers
such as China and Russia began to fill the power vacuum created by the
U.S. withdrawal.

[The U.S. will eventually **lose ground** in international
politics]{.underline} [and it does not know how to reverse]{.underline}
or even stop [this]{.underline} damaging [course]{.underline}. **[It
continues to follow unilateral policies that simply otherize its
allies]{.underline}** [causing them to lose their trust]{.underline} in
the U.S. [Its allies have been trying to diversify their
relations]{.underline} by initiating a sectoral foreign policy
understanding. [Some of them have been trying to weigh in against the
U.S. on certain issues]{.underline}.

**[2AC -- Heg Good: Transition Wars]{.underline}**

**Retrenchment triggers great-power aggression, spiraling proliferation,
and nationalist takeover -- heg is sustainable and pursuit is inevitable
-- it's just a question of effectiveness**

**Wright 20**

Thomas, Director of the Center on the United States and Europe and a
Senior Fellow in the Project on International Order and Strategy at the
Brookings Institution, "The Folly of Retrenchment: Why America Can\'t
Withdraw From the World.", Foreign Affairs, Vol. 99, Iss. 2 DB

[Global retrenchment is fast emerging as the most coherent and readymade
alternative to the United States\' postwar strateg]{.underline}y. [Yet
pursuing it would be a grave mistake]{.underline}. **[By dissolving U.S.
alliances and ending the forward presence of U.S. forces, this strategy
would destabilize the regional security orders in Europe and
Asia]{.underline}**. **[It would also increase the risk of nuclear
proliferation, empower right-wing nationalists in Europe, and aggravate
the threat of major-power conflict]{.underline}**. This is not to say
that U.S. strategy should never change. The United States has regularly
increased and decreased its presence around the world as threats have
risen and ebbed. Even though Washington followed a strategy of
containment throughout the Cold War, that took various forms, which
meant the difference between war and peace in Vietnam, between an arms
race and arms control, and between detente and an all-out attempt to
defeat the Soviets. After the fall of the Soviet Union, the United
States changed course again, expanding its alliances to include many
countries that had previously been part of the Warsaw Pact. Likewise,
the United States will now have to do less in some areas and more in
others as it shifts its focus from counterterrorism and reform in the
Middle East toward great-power competition with China and Russia. But
[advocates of global retrenchment are not so much proposing changes
within a strategy as they are calling for the wholesale replacement of
one that has been in place since World War II]{.underline}. [What the
United States needs now is a careful pruning of its overseas
commitments\--not the indiscriminate abandonment of a strategy that has
served it well for decades]{.underline}. RETRENCHMENT REDUX Support for
retrenchment stems from the view that the United States has overextended
itself in countries that have little bearing on its national interest.
According to this perspective, which is closely associated with the
realist school of international relations, the United States is
fundamentally secure thanks to its geography, nuclear arsenal, and
military advantage. Yet the country has nonetheless chosen to pursue a
strategy of \"liberal hegemony,\" using force in an unwise attempt to
perpetuate a liberal international order (one that, as evidenced by U.S.
support for authoritarian regimes, is not so liberal, after all).
Washington, the argument goes, has distracted itself with costly
overseas commitments and interventions that breed resentment and
encourage free-riding abroad. Critics of the status quo argue that the
United States must take two steps to change its ways. The first is
retrenchment itself: the action of withdrawing from many of the United
States\' existing commitments, such as the ongoing military
interventions in the Middle East and one-sided alliances in Europe and
Asia. The second is restraint: the strategy of defining U.S. interests
narrowly, refusing to launch wars unless vital interests are directly
threatened and Congress authorizes such action, compelling other nations
to take care of their own security, and relying more on diplomatic,
economic, and political tools. [In practice, this approach means ending
U.S. military operations in Afghanistan, withdrawing U.S. forces from
the Middle East, relying on an over-the-horizon force that can uphold
U.S. national interests, and no longer taking on responsibility for the
security of other states]{.underline}. As for alliances, [Posen has
argued that the United States should **abandon the mutual-defense
provision of NATO**, replace the organization \"with a new, more limited
security cooperation agreement,\" and **reduce U.S. commitments to
Japan, South Korea, and Taiwan**]{.underline}. On the question of China,
realists have split in recent years. Some, such as the scholar John
Mearsheimer, contend that even as the United States retrenches
elsewhere, in Asia, it must contain the threat of China, whereas others,
such as Posen, argue that nations in the region are perfectly capable of
doing the job themselves. Since Trump\'s election, some progressive
foreign policy thinkers have joined the retrenchment camp. They diverge
from other progressives, who advocate maintaining the United States\'
current role. Like the realists, progressive retrenchers hold the view
that the United States is safe because of its geography and the size of
its military. Where these progressives break from the realists, however,
is on the question of what will happen if the United States pulls back.
While the realists favoring retrenchment have few illusions about the
sort of regional competition that will break out in the absence of U.S.
dominance, the progressives expect that the world will become more
peaceful and cooperative, because Washington can still manage tensions
through diplomatic, economic, and political tools. The immediate focus
of the progressives is the so-called forever wars\--U.S. military
involvement in Afghanistan, Iraq, Syria, and the broader war on
terrorism\--as well as the defense budget and overseas bases. Although
the progressives have a less developed vision of how to implement
retrenchment than the realists, they do provide some guideposts.
**[Stephen Wertheim]{.underline}**, a co-founder of the Quincy
Institute, [has called for bringing home many of the U.S. soldiers
serving abroad, \"leaving small forces to protect commercial sea
lanes,\" as part of an effort to \"deprive presidents of the temptation
to answer every problem with a violent solution.\"]{.underline} He
argues that U.S. allies may believe that the United States has been
inflating regional threats and thus conclude that they do not need to
increase their conventional or nuclear forces. [Another progressive
thinker, **Peter Beinart**, has argued that the United States should
accept Chinese and Russian spheres of influence, a strategy that would
include abandoning Taiwan]{.underline}. IS LESS REALLY MORE? The
realists and the progressives arguing for retrenchment differ in their
assumptions, logic, and intentions. The realists tend to be more
pessimistic about the prospects for peace and frame their arguments in
hardheaded terms, whereas the progressives downplay the consequences of
American withdrawal and make a moral case against the current grand
strategy. But they share a common claim: that the United States would be
better off if it dramatically reduced its global military footprint and
security commitments. This is a false promise, for a number of reasons.
First, **[retrenchment would worsen regional security competition in
Europe and Asia]{.underline}**. [The realists recognize that the U.S.
military presence in Europe and Asia does dampen security competition,
but they claim that it does so at too high a price\--and one that, at
any rate, should be paid by U.S. allies in the regions
themselves]{.underline}. [Although pulling back would invite regional
security competition, realist retrenchers admit, **the United States
could be safer in a more dangerous world because regional rivals would
check one another**]{.underline}. **[This is a perilous gambit, however,
because regional conflicts often end up implicating U.S.
interests]{.underline}**. **[They might thus end up drawing the United
States back in after it has left\--resulting in a much more dangerous
venture than heading off the conflict in the first place by
staying]{.underline}**. **[Realist retrenchment reveals a hubris that
the United States can control consequences and prevent crises from
erupting into war]{.underline}**. The progressives\' view of regional
security is similarly flawed. These retrenchers reject the idea that
regional security competition will intensify if the United States
leaves. [In fact, they argue, U.S. alliances often promote competition,
as in the Middle East, where U.S. support for Saudi Arabia and the
United Arab Emirates has emboldened those countries in their cold war
with Iran]{.underline}. **[But this logic does not apply to Europe or
Asia, where U.S. allies have behaved responsibly]{.underline}**. **[A
U.S. pullback from those places is more likely to embolden the regional
powers]{.underline}**. **[Since 2008, Russia has invaded two of its
neighbors that are not members of NATO, and if the Baltic states were no
longer protected by a U.S. security guarantee, it is conceivable that
Russia would test the boundaries with gray-zone warfare]{.underline}**.
**[In East Asia, a U.S. withdrawal would force Japan to increase its
defense capabilities and change its constitution to enable it to compete
with China on its own, straining relations with South
Korea]{.underline}**. **[The second problem with retrenchment involves
nuclear proliferation]{.underline}**. **[If the United States pulled out
of NATO or ended its alliance with Japan, as many realist advocates of
retrenchment recommend, some of its allies, no longer protected by the
U.S. nuclear umbrella, would be tempted to acquire nuclear weapons of
their own]{.underline}**. Unlike the progressives for retrenchment, the
realists are comfortable with that result, since they see deterrence as
a stabilizing force. Most Americans are not so sanguine, and rightly so.
[There are good reasons to worry about nuclear proliferation: **nuclear
materials could end up in the hands of terrorists**, **states with less
experience might be more prone to nuclear accidents**, and **nuclear
powers in close proximity have shorter response times and thus conflicts
among them have a greater chance of spiraling into
escalation**]{.underline}. Third, **[retrenchment would heighten
nationalism and xenophobia]{.underline}**. **[In Europe, a U.S.
withdrawal would send the message that every country must fend for
itself]{.underline}**. **[It would therefore empower the far-right
groups already making this claim\--such as the Alternative for Germany,
the League in Italy, and the National Front in France\--while
undermining the centrist democratic leaders there who told their
populations that they could rely on the United States and
NATO]{.underline}**. [As a result, Washington would lose leverage over
the domestic politics of individual allies, particularly younger and
more fragile democracies such as Poland]{.underline}. And **[since these
nationalist populist groups are almost always protectionist,
retrenchment would damage U.S. economic interests, as
well]{.underline}**. [Even more alarming, many of the right-wing
nationalists that retrenchment would empower have called for greater
accommodation of China and Russia]{.underline}. A fourth problem
concerns **[regional stability after global retrenchment]{.underline}**.
**[The most likely end state is a spheres-of-influence system, whereby
China and Russia dominate their neighbors, but such an order is
inherently unstable]{.underline}**. **[The lines of demarcation for such
spheres tend to be unclear, and there is no guarantee that China and
Russia will not seek to move them outward over time]{.underline}**.
Moreover, [the United States cannot simply grant other major powers a
sphere of influence\--the countries that would fall into those realms
have agency, too]{.underline}. If the United States ceded Taiwan to
China, for example, the Taiwanese people could say no. The current U.S.
policy toward the country is working and may be sustainable. Withdrawing
support from Taiwan against its will would plunge cross-strait relations
into chaos. [The entire idea of letting regional powers have their own
spheres of influence has an imperial air that is at odds with modern
principles of sovereignty and international law]{.underline}. A fifth
problem with **[retrenchment is that it lacks domestic
support]{.underline}**. **[The American people may favor greater burden
sharing, but there is no evidence that they are onboard with a
withdrawal from Europe and Asia]{.underline}**. [As a survey conducted
in 2019 by the Chicago Council on Global Affairs found, seven out of ten
Americans believe that maintaining military superiority makes the United
States safer, and almost three-quarters think that alliances contribute
to U.S. security]{.underline}. [A 2019 Eurasia Group Foundation poll
found that over 60 percent of Americans want to maintain or increase
defense spending]{.underline}. **[As it became apparent that China and
Russia would benefit from this shift toward retrenchment, and as the
United States\' democratic allies objected to its withdrawal, the
domestic political backlash would grow]{.underline}**. **[One result
could be a prolonged foreign policy debate that would cause the United
States to oscillate between retrenchment and reengagement, creating
uncertainty about its commitments and thus raising the risk of
miscalculation by Washington, its allies, or its rivals]{.underline}**.
Realist and progressive retrenchers like to argue that the architects of
the United States\' postwar foreign policy naively sought to remake the
world in its image. But the real revisionists are those who argue for
retrenchment, a geopolitical experiment of unprecedented scale in modern
history. **[If this camp were to have its way, Europe and Asia\--two
stable, peaceful, and prosperous regions that form the two main pillars
of the U.S.-led order\--would be plunged into an era of
uncertainty]{.underline}**.

**[2AC -- Heg Good AT: Endless War]{.underline}**

**No endless war impact.**

**Mazarr 20**

Michael J., Senior political scientist at the RAND corporation.
Previously he worked at the U.S. National War College, where he was
professor and associate dean of academics; as president of the Henry L.
Stimson Center; senior fellow at the Center for Strategic and
International Studies; senior defense aide on Capitol Hill; and as a
special assistant to the Chairman of the Joint Chiefs of Staff,
"Rethinking Restraint: Why It Fails in Practice," The Washington
Quarterly, Vol. 43, Issue 2, pg. 9-14, Summer 2020, T&F. edited for
language.

US Foreign Policy: Caricature versus Reality

In the eyes of proponents of restraint, the reigning concepts that guide
America's role in the world embody a limitless drive for supremacy and
power that has produced an infatuation with militarism and a litany of
interventions and wars. "There is one dominant grand strategy in US
politics," two [advocates for restraint **contend**]{.underline}, "which
is primacy, also known as liberal hegemony." 4 "The vast majority of [US
foreign policy makers are **devotees of primacy**]{.underline},"
concludes another recent essay. 5 The historian Stephen Wertheim refers
to a post-Cold War US approach that "gave pride of place to military
threats and methods" and that "spares no expense for military hegemony."
6 The scholar Barry **[Posen]{.underline}**, in one of the defining
works of the restraint literature, [points to an overriding
implication]{.underline}: "[the United States has grown **incapable of
moderating its ambitions** in international politics]{.underline}." 7

Immediately, [this portrait of militarized]{.underline} liberal
[hegemony in search of primacy simplifies a]{.underline} more [complex
reality]{.underline}: the [concepts of **primacy** and]{.underline}
liberal [**interventionism** overlap on]{.underline} [some issues but
diverge starkly]{.underline} [on others]{.underline}. More importantly,
much of [the literature on]{.underline} [restraint blends]{.underline}
these **[various concepts]{.underline}** in order [to fuel]{.underline}
what quickly becomes [an **essentialist critique** of US
foreign]{.underline} and security [policy]{.underline}. [Proponents
argue that US policy]{.underline} is not merely imperfect at the
margins---its basic [**assumptions** and **impulses**]{.underline} are
fundamentally unsound, and it [must be]{.underline} not merely pruned
but substantially [uprooted]{.underline}. Yet, [by
depicting]{.underline} the [**guiding concepts** of US policy
with]{.underline} such [**extreme** and **unconditional**]{.underline}
[language]{.underline}, these [diagnoses]{.underline} tend to [deal in
**caricatures** and **straw people** rather than]{.underline}
[realities]{.underline}.

This polemical approach emerges in restraint proponents' treatment of
the basic US foreign policy record. It has had its share of excesses,
but [the record betrays]{.underline} far [more]{.underline} [**limits**,
**hesitation**, and]{.underline}, in fact, [**restraint**
than]{.underline} the [labels of **primacy** and **liberal
hegemony**]{.underline} would [suggest---something apparent in the
**repeated tendency** to avoid **interventions**]{.underline},
[major]{.underline} post-Cold War [cuts in **defense
spending**]{.underline} and global posture, [and]{.underline} the
[constraints]{.underline} [on **liberal value promotion**]{.underline}.

The Frequent Impulse to Moderation

The [restraint]{.underline} literature [downplays the]{.underline}
often-[**powerful reluctance** with which successive]{.underline} [US
administrations]{.underline} have [grappled with]{.underline} most
[decisions to intervene]{.underline}. [US action in]{.underline} cases
like [the **Balkan wars** and]{.underline} even **[Libya]{.underline}**
only [came with great hesitancy and]{.underline} after [fierce internal
debates]{.underline}.8 The [United States]{.underline} has
[shunned]{.underline} many [opportunities for large-scale]{.underline}
[interventions]{.underline} in the last generation alone---[in
**Somalia**, **Rwanda**, **Syria**, and **elsewhere**]{.underline}.9 US
administrations did not act in crises in the Great Lakes region of
Africa and two major examples of Russian aggression in Georgia and
Ukraine.10 An infamous case of non-intervention was the Darfur tragedy
in the Sudan, when credible accusations of genocide did not prompt US
action.11 The [United States would never have invaded]{.underline}
either [**Afghanistan** or **Iraq** had it not been for
9/11]{.underline}; indeed, then-NSC official Richard Clarke and others
begged two administrations to strike al-Qaeda camps in Afghanistan for
months beforehand, to no avail.12 [In regard to humanitarian
intervention]{.underline} broadly speaking, [the **selectivity of US
action**]{.underline}, rather than a general impulse to intervene, [is
the **dominant** lesson]{.underline}.13

Even [with regard to **Vietnam**]{.underline}, two [US
presidents]{.underline} (Kennedy and Eisenhower) [struggled
to]{.underline} [avoid an **open-ended** US commitment]{.underline};
when the United States did engage, it was because Lyndon Johnson felt a
need to stand up to communist aggression and protect his personal
reputation, but he was hardly enthusiastic about the prospect. He was
painfully conflicted about the war and deeply regretted having to fight
it.14 In other words, [when US interventionism]{.underline} has
[occurred, it has]{.underline} often [been **reactive** and]{.underline}
[**halfhearted** rather than aggressively ambitious]{.underline}.

In fact, [the **alleged epicenter** of US]{.underline} global [military
power---the **Department of Defense**]{.underline} [and the **military
services**]{.underline}---have [forcefully opposed **many
interventions** in]{.underline} places like [the]{.underline} [Balkans,
Somalia, and Libya]{.underline}, believing they should \[conserve\]
~~husband~~ their power for major wars. The two [leading]{.underline}
modern conceptual [articulations]{.underline} of criteria [for going to
war---the **Weinberger and Powell** **Doctrines**---came from **senior
defense officials**, and]{.underline} both represented efforts to
[constrain]{.underline}, not liberate, [the **use of
force**]{.underline}.15 Former Secretary of Defense Robert Gates told a
graduating class at West Point that "any future defense secretary who
advises the president to again send a big American land army into Asia
or into the Middle East or Africa should 'have his head examined,' as
General MacArthur so delicately put it," 16 reflecting a widely held
view at Defense---one far afield from the ideas of unrestrained primacy.
A similar impulse for limits has emerged in major diplomatic
initiatives. In a recent essay outlining a restraint agenda, Stephen
Wertheim suggests that the United States should "seek to normalize
relations with North Korea" in part with a nuclear deal, and that it
should "end its grudge match" with Iran.17 In fact, the United States at
one time embraced both these ideas in the form of the Agreed Framework
with North Korea and the Joint Comprehensive Plan of Action (JCPOA) with
Iran. The later US desertion of these accords was prompted by hawkish
factions in two Republican administrations, not an indiscriminate
national hegemonic inclination.18

Nor can US involvement in foreign wars and interventions usually be
traced to a hegemonic desire to spread liberal values. A missionary
attitude in foreign policy and liberal value promotion agenda may help
lay the groundwork or justify the public case for unnecessary
commitments and may be responsible for a few of them. But the largest
interventions---Korea, Vietnam, the Gulf War, the Balkan wars,
Afghanistan, and Iraq---were all primarily motivated by security
considerations.19 Some of these actions may have been excessive to begin
with or become so over time, and the security concerns that drove them
may have been based on bad information or inflated fears. But they were
not fueled by the boundless commitment to primacy and liberal value
promotion described by many advocates of restraint. Limits to Ambition:
By the Numbers Broadly speaking, then, [the **default setting** of US
foreign policy is hardly one of fervent]{.underline}
[interventionism]{.underline}. In terms of actual military posture and
spending, [if the United States]{.underline} had [truly embraced
hegemonic policies, there would be a trajectory of continually
rising]{.underline} **[commitments]{.underline}**, military
[**spending**, and **interventions**]{.underline} since 1945. Yet [the
actual record is]{.underline} **[starkly different]{.underline}**.
[Table 1 tells an interesting story about]{.underline} one key focus of
the restraint proponents---[global **military presence**]{.underline}.
Between the late 1980s and roughly 2018, [US troop levels
**declined**]{.underline} slightly [in **Japan**]{.underline}, more than
40 percent in [**Korea**, and]{.underline} 80 percent in
**[Europe]{.underline}**. The result was that, as the Pew Research
Center put it, by 2016 the "U.S. military overseas presence \[was\] at a
60-year low," falling well below 200,000 after having reached a peak of
1.2 million in the late 1960s and remaining at over 600,000 as recently
as 1990. In 2016, only 15 percent of active-duty US military troops were
deployed overseas---the lowest proportion since 1957.21 One partial
exception to this trend, of course, is the Middle East, where after a
history of "extremely light force presence" 22 before 1990, US regional
deployments expanded across the region in the wake of the Gulf War and
ramped up dramatically during the Iraq War. Various factors---including
the flow of units into and out of the region, the use of private
contractors to fulfill some functions, and limits on public
information---make it impossible to put a precise figure on US
deployments; the Congressional Research Service has estimated that as of
2019, there were 60,000 to 80,000 US troops in the Central Command

**[2AC -- AT: LIO]{.underline}**

**Put away your LIO defense -- China actions in AI are both offensive
and defensive. China DOESN'T SEEK to replace LIO BUT its actions are
signs that China intends to establish a multipolar world**

**Sullivan** 10/4/20**21**

Ryan Sullivan Army pilot studied at the prestigious Fudan University in
Shanghai, China, as an Olmsted Scholar graduate-level work in the field
of Artificial Intelligence to deliver an in-depth study of the critical
elements of U.S.-China competition in Artificial Intelligence, "The
U.S., China, and Artificial Intelligence Competition Factors",
<https://www.airuniversity.af.edu/Portals/10/CASI/documents/Research/Cyber/2021-10-04%20US%20China%20AI%20Competition%20Factors.pdf?ver=KBcxNomlMXM86FnIuuvNEw%3D%3D>
-- ECM

Very few countries benefitted more from the current international system
than China. [Many]{.underline} in the West [worry about China's efforts
to undermine or replace the current system]{.underline} with one that
better represents Chinese values and interests. **[Those concerns are
warranted]{.underline}**, [though]{.underline} it is important to
highlight that [China]{.underline} [purportedly]{.underline} [does not
seek to replace the current liberal world]{.underline} order or promote
an alternative structure. Reviewing Chinese declarations about the
standing world order indicates that the CCP reportedly finds its key
elements more than acceptable, desiring to emphasize some key features
that traditionally have been underplayed by the U.S. and other western
countries. However, [these claims]{.underline} or reports **[should not
be accepted at face value]{.underline}**, [given the CCP and Xi's
history of backtracking on promises not to militarize the
SCS]{.underline}. Rather, [a prudent approach would be to assume
that]{.underline} China is unwilling to disrupt the current world order
at this point in history; however, [as China strengthens its economy
and]{.underline} pursues [legitimacy on the global leadership
stage]{.underline}, **[China could pursue a restructuring of
the]{.underline}** present **[world order]{.underline}** from a position
of greater strength.

Chinese Foreign Minister Wang [Yi acknowledged]{.underline} the
legitimacy and value of the current international system, which "is like
a well-designed building with multilateralism as its cornerstone and the
UN and other international organizations as important pillars" which
plays "an irreplaceable role in promoting world peace and
development."387 Wu Xinbo adds that "[China has been a strong supporter
of Westphalian norms]{.underline}," which he defined as "respect for
sovereignty and territorial integrity of the nation-state, sovereign
equality among states, non-aggression, and non-interference in internal
affairs."388 Wang, like other Chinese leaders, finds value in the
aspects of the system that constrain world dominance by the United
States or any single dominant state. China does value the [system but
feels it is suffering under U.S. leadership]{.underline}, as CASS
researcher Xu Xiujun wrote in the lead-up to the National People's
Congress's recent two sessions. Xu wrote,

"With the emergence of global problems and the rise of emerging
economies, this system is increasingly difficult to meet the needs of
the international community, and it seriously lacks in
representativeness, fairness, legitimacy, and effectiveness. Under the
obstruction of the United States and other Western powers, it is
difficult for the World Trade Organization, International Monetary Fund,
World Bank, and other traditional global multilateral mechanisms to make
substantial progress in reforming and cannot adapt to the emerging
fields of digital trade, digital finance, digital currency, and digital
development."

Xu adds the need for improved global governance mechanisms to
effectively enable the G20 to play a constructive role and overcome "a
small number of Western powers who ignore rules...and shirk their
responsibilities" by promoting unilateralism and rely on small groups to
resolve global problems.390 [China's willingness to co-opt certain
aspects of international norms and laws while selectively ignoring
others that run counter to their interests is a common
practice]{.underline}. As China expert Elizabeth Economy points out,
"[Xi's objective in promoting a China model]{.underline} and calling for
reform of global governance institutions **[are both
defensive]{.underline}** -- [to protect China from international
criticism]{.underline} -- **[and offensive]{.underline}** [-- to ensure
that international norms and values align with and serve Chinese values
and political and economic priorities]{.underline}."391 However, China
will not rush into reform and is very strategic where and when they
apply their influence and pursue their values and interests. As Wu Xinbo
notes, China wants to be a "rule-maker, not a rule-taker," prioritizing
"international economy and finance, regional cooperation, and emerging
areas" such as AI, to further its international organization voting
rights, to promote various forms of regional economic and security
cooperation, and to establish mechanisms that serve Chinese interests
and preferences.392 [China's desire to make the rules on AI demonstrates
its clear desire to establish legitimacy]{.underline} beyond economics,
pursuing political and technological power [through influencing norms
and standards globally]{.underline}.

**[1AR -- Heg Good: Transition Wars]{.underline}**

**Retrenchment causes nationalism, war, and protectionism -- optimists
[falsely assume]{.underline} current cooperative trends will continue
without the [US security guarantee]{.underline}**

**Fay 17**

Matthew Director of Defense and Foreign Policy Studies @ The Niskanen
Center, 11/16/17, "America Unrestrained?: Engagement, Retrenchment, and
Libertarian Foreign Policy,"
https://niskanencenter.org/wp-content/uploads/2017/11/America-Unrestrained.pdf

A number of the arguments libertarians make in favor of retrenchment
have merit, but the cost-benefit analysis derived from them is based on
a deterministic view of international politics. Libertarian [retrenchers
assume that international politics would remain more or less the same
absent American engagement and that America's domestic politics would
remain the same even if the international system become more
conflict-]{.underline}prone. [Given the **inherent uncertainty of
forecasting**, the costs and benefits of engagement and retrenchment
need to be considered in a more probabilistic fashion]{.underline}.86
This section begins by exploring a number of scenarios that could occur
should the United States adopt a grand strategy of retrenchment. It then
reassesses the costs and benefits of retrenchment for a free society. In
a system with more independent states balancing against one another, is
war more or less likely? Libertarians are placing a bet that all else
would remain equal in international politics if the United States
retrenches. [While they assume a world where an increased number of
states are balancing against one another would remain peaceful, the
reality is not entirely clear]{.underline}. Using basic realist premises
about state behavior under international anarchy, it is easy to identify
a number of scenarios less rosy than the one libertarians assume would
occur [should the United States retrench]{.underline}. These
[scenarios]{.underline} might [include]{.underline} a world of
[**increased nationalism, eroding norms against military aggression,
increased economic autarky, and the further spread of nuclear weapons as
states look to produce security for themselves**. Some states
may]{.underline} also [fail to balance against threats in the wake of
American retrenchment, increasing the likelihood the **U**nited
**S**tates will be **drawn into a major war**]{.underline}. Libertarians
assume that in the absence of an alliance with the United States, other
countries would simply increase their defense spending if they felt
threatened. However, [internal balancing is not a mechanical
process]{.underline}. According to John Mearsheimer, [leaders of states
facing security competition are likely to **use nationalism to garner
support** from their populations for the necessary regeneration of
military capabilities.87]{.underline} Writing at the end of the Cold
War, Mearsheimer suggested that Europe would revert to a pattern of
recurrent warfare. The absence of the United States and the Soviet Union
would leave Europe, once again, an anarchic multipolar system. The
structure of the system would force the states to compete with one
another, as they had prior to the Cold War. Mearsheimer argued that
pre-1945 "hypernationalism" was a product of "security competition among
the European states, which compelled elites to mobilize public support
for national defense efforts."88 American [retrenchment]{.underline}
could similarly [lead to an anarchic, **multipolar Europe**---thus
increasing the chances of war on the continent. Such a system could
engender nationalist sentiments among the populations of
Europe]{.underline}, heightening animosities between national groups.
These heightened animosities could help erode norms against military
aggression that have facilitated the decline in interstate war.
Nationalist groups within a country can seize on these sentiments to
pursue confrontational and expansionist policies.89 [Encouraging support
for increased military capabilities through nationalism might lead
populations to see war as once again a means to national glory or
maintaining national honor]{.underline}. Matters of national prestige
and honor can lead to the initiation of wars when bound up in
territorial claims, while at the same time increasing the intensity and
duration of a conflict.90 Nationalism and [security
competition]{.underline} might also **[erode the pacifying effects of
economic openness]{.underline}**. Realism suggests states are concerned
about relative gains.91 [States in security competition might be wary of
trading with one another due to concerns about how a potential rival's
economic gains might provide it with an advantage if
translate]{.underline}d [into military power]{.underline}. They may also
adopt autarkic policies for fear of undermining their economic and
military self-sufficiency.92 Territorial conquest has become increasing
anachronistic in international politics. However, the proliferation of
protectionist policies might once again make aggression and preventive
war seem like strategically sensible ways for states to secure the
resources necessary to reduce the ability of potential rivals to cut
them off economically. If the risk of territorial aggression increases,
the possession of nuclear weapons would become an attractive option for
some states whose security was previously guaranteed by the United
States. Nuclear weapons are most useful for deterring major territorial
aggression, meaning their potential utility increases as the potential
for war does.93 A number of U.S. allies have either previously pursued
nuclear weapons or have the capability to do so. [They might choose to
obtain a nuclear arsenal once responsible for their own
security.]{.underline}

**Yes transition wars -- realism makes it inevitable**

**Zarnett 17**

(David, University of Toronto, "What Does Realist Foreign Policy
Activism Tell Us About Realist Theory?", Foreign Policy Analysis, Vol.
13) DB

Mearsheimer's critique of Waltz's is premised on the idea that
[international outcomes cannot be explained without explaining state
behavior, especially the behavior of six great powers during the
nineteenth and twentieth centuries: Japan from 1868 to 1945, Germany
from 1862 to 1945, the Soviet Union from 1917 to 1991, Italy from 1861
to 1945, Great Britain from 1792 to 1945 and the United States from 1800
to 1990]{.underline}. [In examining the policies of these **great
powers**, Mearsheimer finds that they **consistently select offensive
policies, taking advantage of opportunities to increase their power and
achieve regional, and potentially international,
hegemony**]{.underline}. In distinguishing his view from other realist
theories, Mearsheimer explains that [offensive realists "believe that
status quo powers are rarely found in world politics, because the
international system creates powerful incentives for states to look for
opportunities to gain power at the expense of rivals, and to take
advantage of those situations when the benefits outweigh the costs. **A
state's ultimate goal is to be the hegemon in the system**"]{.underline}
(Mearsheimer 2001:21). In other words, **[the dominant pattern in
international politics is not a recurring balance of power but rather
the constant drive for hegemony by great powers]{.underline}**. **[By
pursuing offensive strategies, states act in concert with what the
system demands of them]{.underline}**. Mearsheimer claims that his
theory is "mainly a descriptive theory." Depicting Waltz's theory as a
theory of how states ought to act enables him to present offensive
realism as a more empirically valid substitute. But Mearsheimer does not
leave it there. He also notes that his offensive realism "is also a
prescriptive theory." That is, it not only asserts that **[great powers
are "primed for offense" but also that they are right in doing
so]{.underline}**. **[The more powerful a rational state is relative to
the other states in the system, the less likely it is that a reckless
state would attack it]{.underline}**. **[There is no guarantee that a
state prone to foolish behavior would not start a losing war, but it is
less likely if that potential aggressor is badly
outgunned]{.underline}**. **[Plus, if deterrence fails and there is a
war, the rational state would be well positioned to win it quickly and
decisively]{.underline}**. [Finally, a rational state that is the
preponderant power in the system is likely to be able to contain a
misguided aggressor by itself and not need a balancing coalition to do
the job]{.underline}. This takes the problem of inefficient balancing
off the table, as the rational state no longer has to worry about
unreliable allies. (Mearsheimer 2009:252) Noting that states can act in
foolish ways, Mearsheimer writes that "[states should behave according
to the dictates of offensive realism, because it outlines the best way
to survive in a dangerous world]{.underline}" (Mearsheimer 2001:11--12).
If his goal were to develop a scientific theory of how states do behave,
a different approach to state behavior would have been taken based on
identifying the conditions under which states act offensively or
defensively (Snyder 2002:173). But, Mearsheimer's goal was to provide a
realist theory of state behavior which, to remain consistent with
realist tradition, includes a prescriptive component. In this tradition,
theorizing is not simply for explanation's sake. While good explanation
is important, it is often sacrificed for good prescription. The result
is a theory of international politics that uses a selection of state
behaviors to identify the types of policies and strategies that increase
the chances of success. While Mearsheimer's prescription raises question
about his theory's empirical validity, as well as its methodological and
ontological positions, it is overall remarkably consistent with the
realist tradition. As Robert Gilpin explains, it is [a "dual commitment,
to practice and to theory, that sets realism apart from idealism and the
abstract theorizing that characterizes so much of the contemporary study
of international relations"]{.underline} (Gilpin 1984:303).

**2AC -- US-China Coop ADV**

**[2AC -- AT: US -- China coop dead]{.underline}**

**Yes, relations are low -- BUT, redefining the relationship toward
cooperation solves**

**Haenle & Bresnick 2/21**/2022

**[Complicating matters further]{.underline}**, **[the U.S. and Chinese
publics are increasingly distrustful of each other]{.underline}**. A
whopping 89 percent of American respondents to a recent survey from the
Pew Research Center consider China a competitor or enemy, while around
two-thirds of Chinese respondents view the United States unfavorably or
very unfavorably. Such negative mutual perceptions would likely hamper
each side's ability to recalibrate its approach to the other.

Finally, [the two sides' divergent framings of the relationship are
contributing to the ongoing stalemate]{.underline}. Discussions with
high-level Chinese scholars and former government officials have
revealed that Beijing prefers to define the bilateral relationship as a
peaceful coexistence guided by shared principles, consensus, and
possible cooperation. **[China is frustrated]{.underline}** [that the
U]{.underline}nited [S]{.underline}tates [is more focused on **competing
with** **and confronting** Beijing]{.underline}. In Washington, however,
great power rivalry, [defined more by]{.underline} competition and
[confrontation than cooperation]{.underline}, **[has become the central
framework for bilateral ties]{.underline}**.

**[2AC -- AT: Defense (Long)]{.underline}**

**It's [easily possible]{.underline} and [doesn't require
AGI]{.underline}**

Karina **Vold &** Daniel R. **Harris 21**, Vold is a philosopher of
cognitive science and artificial intelligence & an assistant professor
at the University of Toronto\'s Institute for the History and Philosophy
of Science and Technology; Harris is a retired lawyer and Foreign
Service Officer at the US Department of State, "How Does Artificial
Intelligence Pose an Existential Risk?," Oxford Handbook of Digital
Ethics, Ed. C. Veliz., pp 1-34

3\. The Control Problem Argument for Xrisk

The earliest line of thinking that AI poses an Xrisk warns that [AI
might become both]{.underline} **[powerful]{.underline}**
[and]{.underline} [**indifferent to human values**, leading to
**dangerous consequences**]{.underline} for human beings. Despite it
being a longstanding concern, the structure of this argument is rarely,
if ever, explicitly laid out.3 By presenting the control problem
argument for Xrisk (henceforth CPAX) in this way, our aim is to capture
what we understand to be the line of reasoning while also making the
epistemic moves more explicit.

CPAX rests on two central theses: the Orthogonality Thesis and the
Instrumental Convergence Thesis, both of which were first explicitly
articulated by Bostrom (2012, 130-132; 2014).

> Orthogonality Thesis: The intelligent capacities of any system are
> logically independent from any goals the system might have.
>
> Instrumental Convergence Thesis: Almost any intelligent system is
> likely to converge upon certain instrumental (sub)goals.

We will discuss each of these theses, as well as the premises and
central inferences of the argument (below) in §3.1--§3.4.

> P1. It is possible to build an AI system that has a decisive strategic
> advantage over all other forms of intelligence.
>
> P2. If an AI system has a decisive strategic advantage over human
> intelligence, then we may not be able to control that system.
>
> C1. It is possible to build an AI system that we are not able to
>
> control (from P1 and P2).
>
> P3. The intelligent capacities of an AI system are logically
> independent from any goals the system might have (supported by the
> Orthogonality Thesis).
>
> C2. Therefore, it is possible to build an AI system that human beings
> are not able to control and that has goals that do not align with
> human values (from C1 and P3).
>
> P4. AI systems are likely to converge upon certain instrumental
> (sub)goals that are inimical to human interests (supported by the
> Instrumental Convergence Thesis).
>
> C3. It is possible to build AI systems that pose an existential threat
> to humanity (from C2 and P4).

This reconstruction of the argument is by no means uncontroversial, and
we will discuss some of the disagreements and objections as we go
through the argument.

3.1 Intelligence Explosion and Decisive Strategic Advantages

P1 states that [it is possible to build an AI system that has
a]{.underline} **[decisive strategic advantage]{.underline}**
[over]{.underline} **[all other]{.underline}** forms of
**[intelligence]{.underline}** (including human intelligence).
Historically, CPAX was introduced as arising from an intelligence
explosion that would lead to the creation of a superintelligent AI---a
system that by definition has a decisive strategic advantage over human
intelligence. More recently, some have argued that an intelligence
explosion is not the only pathway to AI gaining a decisive strategic
advantage. We will begin by explaining the pathway to a loss of control
over AI (C1) from an intelligence explosion (in this section, §3.1) and
consider some potential objections (§3.1.1). We will then, in §3.2,
discuss P2 and some more contemporary takes on how C1 could result.

[An intelligence]{.underline} **[explosion]{.underline}** [is a
hypothetical event in which an AI system enters]{.underline} a
**[rapid]{.underline}** cycle of **[recursive
self-improvement]{.underline}**, whereby [each new iteration creates
a]{.underline} **[more intelligent version]{.underline}** of itself,
[culminating in]{.underline} the creation of a
**[superintelligence]{.underline}**. Here, a superintelligence is "any
intellect that greatly exceeds the cognitive performance of humans in
virtually all domains of interest" (Bostrom 2014, 22). The concept of an
intelligence explosion was first articulated by I.J. Good (1965, 33),
who argued that [an AI system whose intelligence exceeds humanity's in
all intellectual activities would necessarily also exceed it in terms of
designing machine intelligence. Hence, if such a system were initially
engineered]{.underline} by humans, [it would possess the capability to
design a machine more intelligent than itself. The subsequent new
iteration, being more intelligent than its predecessor, would by the
same logic also be capable of **design**ing a machine more intelligent
than itself. If each new generation of AI were to utilize its improved
design capability, an intelligence explosion would occur]{.underline}
(Chalmers, 2010).

Importantly, [an intelligence explosion need not begin with the creation
of a machine with]{.underline} **[greater than human]{.underline}**
[intelligence]{.underline}, as Good's argument suggests. In principle,
[it]{.underline} **[could]{.underline}** [be sparked via the creation of
a more]{.underline} **[modest]{.underline}** type of [machine
intelligence]{.underline}. Some might hold, for example, that an
intelligence explosion merely requires a system with artificial general
intelligence, where general intelligence is the ability to deploy the
same core suite of cognitive resources to complete a wide range of
different tasks (Shevlin et al., 2019). An even more modest possibility
is that [an intelligence explosion could spark from a]{.underline}
[mere]{.underline} artificial **[narrow]{.underline}**
[intelligence]{.underline}, that is, a system [that excels]{.underline}
**[only]{.underline}** [at **specific tasks**]{.underline} and lacks the
ability to use its resources to solve problems outside of its narrow
domains.4 Bostrom (2014, 29), for example, suggests that a system
"[capable of improving its own architecture]{.underline}", what he calls
a "seed AI", would be a sufficient starting point. For example,
DeepMind's AlphaZero, a current narrow AI system, has already shown the
capacity to iteratively self-improve by repeatedly playing against
itself. This illustrates how, under certain conditions, this process of
recursive self- improvement might generate an intelligence explosion
that begins from a mere narrow AI, in particular, any narrow AI system
that enjoys a decisive strategic advantage (i.e., well above human level
capacity) in some relevant domains, coupled with sufficient capacities
for real-world modification.5,6

**Prefer our ev:**

**1. Profit motive**

Seth D. **Baum 18**, Global Catastrophic Risk Institute,
"Superintelligence Skepticism as a Political Tool," 09/2018,
Information, vol. 9, no. 9, p. 209

[As]{.underline} is [discussed in more detail below, certain factors
suggest the potential for superintelligence to be a **focus of
risk--profit politicized skepticism**. First]{.underline} and foremost,
[superintelligence could be developed by]{.underline} **[major
corporations]{.underline}** [with a strong]{.underline}
**[financial]{.underline}** [incentive to]{.underline} [**avoid
regulation**. Second, there **already**]{.underline}
[exists]{.underline} a lot of [skepticism about superintelligence, which
could be]{.underline} **[exploited]{.underline}** [for]{.underline}
[**political purposes**. Third, as an unprecedented class of technology,
it is]{.underline} **[inherently]{.underline}** [uncertain, which
suggests that superintelligence skepticism may be
especially]{.underline} **[durable]{.underline}**, even within
apolitical scholarly communities. [These]{.underline} and other [factors
do not guarantee that superintelligence skepticism will be
politicized]{.underline}, or that its politicization would follow the
same risk--profit patterns as the tobacco strategy. [However, these
factors are]{.underline} at least **[suggestive]{.underline}** of the
possibility.

[Superintelligence skepticism may also be politicized in a different
way: to protect the]{.underline} **[reputations and funding of
the]{.underline}** broader **[AI field]{.underline}**. This form of
politicized skepticism is less well-documented than the tobacco
strategy, and appears to be less common. However, [there
are]{.underline} at least **[hints]{.underline}** of it [for fields of
technology involving both grandiose future predictions and more mundane
near-term work. AI is one such field]{.underline} of technology, [in
which grandiose predictions of superintelligence and other future AI
breakthroughs contrast with more modest forms of near-term
AI]{.underline}. Another example is nanotechnology, in which grandiose
predictions of molecular machines contrast with near-term nanoscale
science and technology \[3\].

**2. Empirics**

Allan **Dafoe &** Stuart **Russell 16**, Dafoe is an assistant professor
of political science at Yale University; Russell is a professor of
computer science at the University of California, Berkeley, "Yes, We Are
Worried About the Existential Risk of Artificial Intelligence," MIT
Technology Review, 11-02-16,
https://www.technologyreview.com/s/602776/yes-we-are-worried-about-the-existential-risk-of-artificial-intelligence/

[Etzioni]{.underline} then [repeats the dubious argument that
"doom-and-gloom predictions often fail to consider the
potential]{.underline} **[benefits]{.underline}** [of AI]{.underline} in
preventing medical errors, reducing car accidents, and more." The
argument does not even apply to Bostrom, who predicts that success in
controlling AI will result in "a compassionate and jubilant use of
humanity's cosmic endowment." [The argument is]{.underline} also
[**nonsense**. It's like arguing that]{.underline} **[nuclear
engineers]{.underline}** [who]{.underline} **[analyze]{.underline}** the
possibility of **[meltdowns]{.underline}** in nuclear power stations
[are]{.underline} **["failing to consider]{.underline}** the potential
benefits" of [**cheap electricity**, and that because nuclear power
stations might one day generate really cheap electricity, we should
**neither mention, nor work on preventing**, the possibility of a
**meltdown**.]{.underline}

[Our experience with Chernobyl suggests it may be
**unwise**]{.underline} [to claim that a powerful technology
entails]{.underline} [**no risks**. It may also be unwise to claim that
a powerful technology **will never come to fruition**]{.underline}. On
September 11, 1933, Lord **[Rutherford]{.underline}**, perhaps the
world's most eminent nuclear physicist, [described the prospect of
extracting energy from atoms as nothing but]{.underline}
**["moonshine."]{.underline}** [Less than]{.underline} **[24 hours
later]{.underline}**, Leo **[Szilard]{.underline}** [invented
the]{.underline} neutron-induced **[nuclear chain
reaction]{.underline}**; detailed designs [for]{.underline} nuclear
reactors and **[nuclear weapons]{.underline}** followed a few years
later. [Surely it is better to **anticipate** human ingenuity than to
**underestimate**]{.underline} [it]{.underline}, better to acknowledge
the risks than to deny them.

**Control failures [guarantee]{.underline} [every]{.underline} scenario
for [extinction]{.underline}**

Karina **Vold &** Daniel R. **Harris 21**, Vold is a philosopher of
cognitive science and artificial intelligence & an assistant professor
at the University of Toronto\'s Institute for the History and Philosophy
of Science and Technology; Harris is a retired lawyer and Foreign
Service Officer at the US Department of State, "How Does Artificial
Intelligence Pose an Existential Risk?," Oxford Handbook of Digital
Ethics, Ed. C. Veliz., pp 1-34

4.1 AI Race Dynamics: Corner-cutting Safety

[An AI]{.underline} **[race]{.underline}** between powerful actors
[could have an]{.underline} **[adverse effect]{.underline}** [on
AI]{.underline} **[safety]{.underline}**, a subfield [aimed
at]{.underline} finding technical solutions to [building]{.underline}
"advanced [AI]{.underline} systems [that are]{.underline}
**[safe]{.underline}** [and]{.underline} **[beneficial]{.underline}**"
(Dafoe, 2018, 25; Cave & Ó hÉigeartaigh, 2018; Bostrom, 2017; Armstrong
et al., 2016; Bostrom, 2014). Dafoe (2018, 43), for example, argues that
it is plausible that [such a race would provide strong incentives for
researchers to]{.underline} **[trade-off safety]{.underline}** in order
[to increase]{.underline} the chances of gaining a **[relative
advantage]{.underline}** over a competitor.21 In Bostrom's (2017) view,
competitive races would disincentivize two options for a frontrunner:
(a) slowing down or pausing the development of an AI system and (b)
implementing safety-related performance handicapping. Both, he argues,
have worrying consequences for AI safety.

\(a\) Bostrom (2017, 5) considers a case in which a solution to the
control problem (C1) is dependent upon the components of an AI system to
which it will be applied, such that it is only possible to invent or
install a necessary control mechanism after the system has been
developed to a significantly high degree. He contends that, in
situations like these, it is vital that a team is able to pause further
development until the required safety work can be performed (ibid). Yet,
if implementing these controls requires a substantial amount of
additional time and resources, then in a tight competitive race dynamic,
any team that decides to initiate this safety work would likely
surrender its lead to a competitor who forgoes doing so (ibid). If
competitors don't reach an agreement on safety standards, then it is
possible that a "risk-race to the bottom" could arise, driving each team
to take increasing risks by investing minimally in safety (Bostrom,
2014, 247).

\(b\) Bostrom (2017, 5-6) also considers possible scenarios in which the
"mechanisms needed to make an AI safe reduces the AI's effectiveness".
These include cases in which a safe AI would run at a considerably
slower speed than an unsafe one, or those in which implementing a safety
mechanism necessitates the curtailing of an AI's capabilities (ibid). If
the AI race were to confer large strategic and economic benefits to
frontrunners, then teams would be disincentivized from implementing
these sorts of safety mechanisms. The same, however, does not
necessarily hold true of less competitive race dynamics; that is, ones
in which a competitor has a significant lead over others (ibid). Under
these conditions, it is conceivable that there could be enough of a time
advantage that frontrunners could unilaterally apply performance
handicapping safety measures without relinquishing their lead (ibid).

It is relatively uncontroversial to suggest that reducing investment in
AI safety could lead to a host of associated dangers.
[Improper]{.underline} safety [precautions could produce **all
kinds**]{.underline} [of unintended harms from]{.underline} **[misstated
objectives]{.underline}** [or]{.underline} from **[specification
gaming]{.underline}**, for example. [They could also lead to a higher
prevalence of AI]{.underline} **[system vulnerabilities]{.underline}**
which are **[intentionally exploited]{.underline}** [by]{.underline}
**[malicious actors]{.underline}** for destructive ends, as in the case
of adversarial examples (see Brundage et al., 2018). But does AI safety
corner-cutting reach the threshold of an Xrisk? Certainly not directly,
but there are at least some circumstances under which it would do so
indirectly. Recall that Chalmers (2010) argues [there could be
**defeaters** that **obstruct** the **self-amplifying** capabilities of
an advanced AI, which could in turn forestall the occurrence of an
intelligence explosion]{.underline}. Scenario (a) above made the case
that [a]{.underline} competitive [AI]{.underline} **[race]{.underline}**
[would]{.underline} **[disincentivize]{.underline}** [researchers
from]{.underline} investing in [developing safety precautions aimed at
preventing]{.underline} an [intelligence explosion]{.underline} (e.g.,
motivational defeaters). [Thus, in cases in which an AI race is centred
on the development of artificial general intelligence, a **seed
AI**]{.underline} with the capacity to self-improve, or even an advanced
narrow AI (as per §3.1), a competitive race dynamic [could pose
an]{.underline} **[indirect Xrisk]{.underline}** [insofar as it
contributes to a set of conditions that]{.underline} **[elevate the risk
of a control problem]{.underline}** occurring (Bostrom, 2014, 246; 2017,
5).

4.2 AI Race Dynamics: Conflict Between AI Competitors

[The]{.underline} **[mere]{.underline}** narrative of an AI
**[race]{.underline}** [could also]{.underline}, under certain
conditions, increase the [risk]{.underline} of
**[military]{.underline}** [conflict]{.underline} between competing
groups. Cave & Ó hÉigeartaigh (2018) argue that AI race narratives which
frame the future trajectory of AI development in terms of technological
advantage could "increase the risk of competition in AI causing real
conflict (overt or covert)". The militarized language typical of race
dynamics may encourage competitors to view each other "as threats or
even enemies" (ibid, 3).22 If a government believes that an adversary is
pursuing a strategic advantage in AI that could result in their
technological dominance, then this alone could provide a motivating
reason to use aggression against the adversary (ibid; Bostrom, 2014). An
AI race narrative [could]{.underline} thus [lead to]{.underline}
**[crisis escalation]{.underline}** between states. However, the
resulting conflict, should it arise, need not directly involve AI
systems. And it\'s an open question whether said conflict would meet the
Xrisk threshold. Under conditions where it does ([perhaps]{.underline}
**[nuclear war]{.underline}**), the contributions of AI as a technology
would at best be indirect.

4.3 Global Disruption: Destabilization of Nuclear Deterrents

Another type of crisis escalation associated with [AI]{.underline} is
the potential destabilizing impact the technology [could]{.underline}
have on global strategic stability;23 in particular, its capacity to
[destabilize]{.underline} **[nuclear deterrence]{.underline}**
strategies (Giest & Lohn, 2018; Rickli, 2019; Sauer, 2019; Groll, 2018;
Zwetsloot & Dafoe, 2019). In general, deterrence relies both on states
possessing secure second-strike capabilities (Zwetsloot & Dafoe, 2019)
and, at the same time, on a state\'s inability to locate, with
certainty, an adversary's nuclear second-strike forces (Rickli, 2019).
This could change, however, with advances in AI (ibid). For example,
AI-enabled surveillance and reconnaissance systems, unmanned underwater
vehicles, and data analysis could allow a state to both closely track
and destroy an adversary's previously hidden nuclear-powered ballistic
missile submarines (Zwetsloot & Dafoe, 2019). [If]{.underline} their
[second-strike]{.underline} nuclear [capabilities were to become
**vulnerable**]{.underline} to a first strike, then a pre- emptive
nuclear strike would, in theory, become a viable strategy under certain
scenarios (Giest & Lohn, 2018).

In Zwetsloot & Dafoe's (2019) view, "the fear that nuclear systems
[could]{.underline} be insecure would, in turn, [create
pressures]{.underline} for states--- including defensively motivated
ones---[to **pre-empt**]{.underline}ively escalate [during]{.underline}
a [crisis]{.underline}". What is perhaps most alarming is that the
aforementioned AI systems need not actually exist to have a
destabilizing impact on nuclear deterrence (Rickli, 2019; Groll, 2018;
Giest & Lohn, 2018). As Rickli (2019, 95) points out, "\[b\]y its very
nature, nuclear deterrence is highly psychological and relies on the
perception of the adversary's capabilities and intentions". Thus, [the
"simple]{.underline} **[misperception]{.underline}** [of the adversary's
AI capabilities is destabilizing]{.underline} in itself" (ibid). This
potential for AI to destabilize nuclear deterrence represents yet
**[an]{.underline}**other kind of indirect global catastrophic, and
perhaps even **[existential]{.underline}**, **[risk]{.underline}**
insofar as the destabilization could contribute to nuclear conflict
escalation.

5\. Weaponization of AI

Much like the more recent set of growing concerns around an AI arms
race, there have also been growing concerns around the weaponization of
AI. We use "weaponization" to encompass many possible scenarios, from
malicious actors or a malicious AI itself, to the use of fully
autonomous lethal weapons. And we will discuss each of these
possibilities in turn. In §5.1 we discuss malicious actors and in §5.2
we discuss lethal autonomous weapons. We have combined this diverse
range of scenarios for two reasons. First, while the previous Xrisk
scenarios discussed (CPAX and an AI race) could emerge without malicious
intentions from anyone involved (e.g., engineers or governments), the
scenarios we discuss here do for the most part assume some kind of
malicious intent on the part of some actor. They are what Zwetsloot &
Dafoe (2019,) call a misuse risk. Second, the threats we discuss here
are not particularly unique to AI, unlike those in previous sections.
The control problem, for example, is distinctive of AI as a technology,
in the sense that the problem did not exist before we began building
intelligent systems. On the other hand, many technologies can be
weaponized. In this respect, AI is no different. It is because AI is
potentially so powerful that its misuse in a complex and high impact
environment, such as warfare, could pose an Xrisk.

5.1 Malicious Actors

In discussing CPAX, we focused on accidental risk scenarios---where no
one involved wants to bring about harm, but the mere act of building an
advanced AI system creates an Xrisk. But AI could also be deliberately
misused. These can include things like exploiting software
vulnerabilities, for example, through automated hacking or adversarial
examples; generating political discord or misinformation with synthetic
media; or initiating physical attacks using drones or automated weapons
(see Brundage et al., 2018). For these scenarios to reach the threshold
of Xrisk (in terms of 'scope'), however, [a]{.underline} **[beyond
catastrophic amount of damage]{.underline}** [would]{.underline} have to
[be done]{.underline}. Perhaps one instructs an [AI]{.underline} system
to [suck up]{.underline} **[all the oxygen in the air]{.underline}**, to
[launch]{.underline} **[all]{.underline}** the [**nuc**lear
weapon**s**]{.underline} in a nation's arsenal, [or]{.underline} to
[invent a]{.underline} [**deadly airborne biological virus**.
Or]{.underline} perhaps [a]{.underline} **[lone actor]{.underline}** is
able to use AI to [hack]{.underline} **[critical
infrastructures]{.underline}**, including some that manage large-scale
projects, such as the satellites that orbit Earth. It does not take much
creativity to drum up a scenario in which [an AI]{.underline} system, if
put [in the]{.underline} **[wrong hands]{.underline}**, could [pose
an]{.underline} **[Xrisk]{.underline}**. But the Xrisk posed by AI in
these cases is likely to be indirect---where AI is just one link in the
causal chain, perhaps even a distal one. This involvement of malicious
actors is one of the more common concerns around the weaponization of
AI. Automated systems that have war- fighting capacities or that are in
anyway linked to nuclear missile systems could become likely targets of
malicious actors aiming to cause widespread harm. This threat is
serious, but the theoretical nature of the threat is straightforward
relative to those posed in CPAX, for example.

One further novel outcome of AI would be if the system itself
malfunctions. Any technology can malfunction, and in the case of an AI
system that had control over real-world weapons systems the consequences
of a malfunction could be severe (see Robillard, this volume). We'll
discuss this potential scenario a bit more in the next section. A final
related possibility here would be for the AI to itself turn malicious.
This would be unlike any other technology in the past. But since AI is a
kind of intelligent agent, there is this possibility. Cotton- Barratt et
al. (2020), for example, describe a hypothetical scenario in which an
intelligence explosion produces a powerful AI that wipes out human
beings in order to pre-empt any interference with its own objectives.
They describe this as a direct Xrisk (by contrast, we described CPAX
scenarios as indirect), presumably because they describe the AI as
deliberately wiping out humanity. However, if the system has agency in a
meaningful sense, such that it is making these kinds of deliberate
malicious decisions, then this seems to assume it has something akin to
consciousness or strong intentionality. In general we are far from
developing anything like artificial consciousness and this is not to say
that these scenarios should be dismissed altogether, but many experts
agree that there are serious challenges confronting the possibility of
AI possessing these cognitive capacities (e.g., Searle, 1980; Koch and
Tonini, 2017; Koch, 2019; Dehaene et al., 2017).

5.2 Lethal Autonomous Weapons

One other form of weaponization of AI that is sometimes discussed as a
potential source of Xrisk are lethal autonomous weapons systems (LAWS).
LAWS include systems that can locate, select, and engage targets without
any human intervention (Roff, 2014; Russell, 2015; Robillard, this
volume). Much of the debate around the ethics of LAWS has focused on
whether their use would violate human dignity (Lim, 2019; Rosert &
Sauer, 2019; Sharkey, 2019), whether they could leave critical
responsibility gaps in warfare (Sparrow, 2007; Robillard, this volume),
or whether they could undermine the principles of just war theory, such
as noncombatant immunity (Roff, 2014), for example. These concerns,
among others, have led many to call for a ban on their use (FLI ,2017).
These concerns are certainly very serious and more near term (as some
LAWS already exist) than the speculative scenarios discussed in CPAX.
But do LAWS really present an Xrisk? It seems that if they do, they do
so indirectly. Consider two possible scenarios.

\(a\) One concern around **[LAWS]{.underline}** is that they [will ease
the **cost** of]{.underline} engaging in [**war**, making
it]{.underline} more [likely that]{.underline}
**[tensions]{.underline}** between rival states [rise to]{.underline}
**[military engagement]{.underline}**. In this case, LAWS would be used
as an instrument to carry out the ends of some malicious actor. This is
because, for now, humans continue to play a significant role in
directing the behaviour of LAWS, though it is likely that we will see a
steady increase in the autonomy of future systems (Brundage et al.,
2018). Now, it could be that this kind of warfare leads to Xrisks, but
this would require a causal chain that includes political disruption,
perhaps failing states, and widespread mass murder. None of these
scenarios are impossible, of course, and they present serious risks. But
we have tried to focus this chapter on Xrisks that are novel to AI as a
technology and, even though we view the risks of LAWS as extremely
important, they ultimately present similar kinds of risks as nuclear
weapons do. To the extent that LAWS have a destabilizing impact on norms
and practices in warfare, for example, we think that scenarios similar
to those discussed in §4.3 are possible---LAWS might escalate an ongoing
crisis, or moreover, the mere perception that an adversary has LAWS
might escalate a crisis.

\(b\) A second scenario, described by Geoffrey Hinton, is that **[killer
drones]{.underline}**, equipped with explosives and deep learning neural
net technology, [could]{.underline} (somehow) [learn to
function]{.underline} **[independently]{.underline}** [of]{.underline}
their **[human controllers]{.underline}** (Robinson, 2016), and [the
system could then]{.underline} **[go on a rampage]{.underline}**
[and]{.underline} **[destroy humanity]{.underline}**. The bracketed
"somehow" here is [a]{.underline} critical piece of the story. [Perhaps
the control system has been]{.underline} [**hack**ed]{.underline}, in
which case we are back to the malicious actor scenario described in
§5.1. [Or]{.underline} perhaps [there is a]{.underline}
**[malfunction]{.underline}**, of the sort also described in §5.1. In
this latter case, the malfunction [could manifest]{.underline} in the
form of a "hard takeoff" in which the system undergoes [rapid recursive
self-improvement]{.underline} (unintended by the designers) and then
develops goals that are inimical to human interests. In such a case, we
would be at the start of an intelligence explosion and would confront
the kind of Xrisk already characterized by CPAX (§3). Our only point
here is that upon closer examination, it\'s hard to see how this
scenario looks distinct from ones previously discussed. Hence, the
weaponization of AI can pose an indirect Xrisk in several different
ways. In general, the more control an automated system has over
weaponized systems that can cause real-world destruction, the greater
risk there is of that system becoming a target for attack by malicious
actors or of there being greater harm due to any accidental system
malfunction.

6\. Conclusion

[Humanity is facing]{.underline} an **[increasing]{.underline}** number
of **[existential threats]{.underline}**, many of which are [of
our]{.underline} [**own creation**. Thankfully, there are]{.underline}
also [an increasing number of]{.underline} **[scholars]{.underline}**,
from a wide range of fields, **[studying the nature of these
risks]{.underline}** [and]{.underline} **[strategizing how to mitigate
them]{.underline}**. But the field of Xrisk studies is still relatively
young. There are significant debates being had over how to define the
concept of Xrisk, how to understand its sources, and what methodologies
should be used to assess these risks. When it comes to Xrisks from AI,
these debates continue. [Early concerns around **AI
Xrisks**]{.underline} [focused on the possibility of an]{.underline}
**[intelligence explosion]{.underline}** [and the subsequent pathway to
a scenario in which a powerful superintelligent AI has misaligned
objectives from humanity. These concerns have **not gone away**, but
they have]{.underline} **[evolved]{.underline}** over time. This chapter
has provided an up- to-date critical survey of these arguments, both old
and new, looking at different foreseeable pathways towards AI Xrisk,
possible global disruptions resulting from the emergence of an AI race
dynamic between nations, and the weaponization of AI. In particular, we
have tried to make the structures of each of these concerns more
explicit, such that readers can begin to critically engage with them.

**Good AI [invents]{.underline} solutions to [present]{.underline} AND
[speculative future]{.underline} risks\-\--but [regs]{.underline} are
key**

Toby **Ord 20**, Senior Research Fellow in Philosophy at Oxford
University, "5. Future Risks," The Precipice: Existential Risk and the
Future of Humanity, First edition, Hachette Books, 2020, pp. 121--158

[Even if]{.underline} these [arguments for risk are]{.underline}
entirely [wrong in the **particulars**, we should pay **close
attention**]{.underline} [to]{.underline} the development of AGI as it
may bring other, [**unforeseen**, risks. The transition to a world where
**humans** are **no longer the most intelligent entities on
Earth**]{.underline} [could]{.underline} easily [be the **greatest ever
change in humanity's place in the universe**]{.underline}. We shouldn't
be surprised if [events surrounding this transition
**determine**]{.underline} how [our]{.underline} **[longterm
future]{.underline}** plays out--- **[for better or
worse]{.underline}**.

One key way in which [AI could help **improve** humanity's longterm
future]{.underline} is [by offering **protection**]{.underline}
[from]{.underline} the **[other existential risks]{.underline}** we
face. For example, [AI]{.underline} may [enable us to find solutions to
**major risks**]{.underline} [or]{.underline} to [identify]{.underline}
**[new]{.underline}** [risks that would have **blindsided** us. AI may
also help make our longterm future **brighter than anything that could
be achieved without it**]{.underline}. So [the idea that developments in
AI **may** pose an **ex**istential risk is **not** an **arg**ument for
**abandoning**]{.underline} [AI, but an argument for proceeding
with]{.underline} due **[caution]{.underline}**.

The case for existential risk from AI is clearly speculative. Indeed, it
is the most speculative case for a major risk in this book. Yet a
speculative case that there is a large risk can be more important than a
robust case for a very low-probability risk, such as that posed by
asteroids. What we need are ways to judge just how speculative it really
is, and a very useful starting point is to hear what those working in
the field think about this risk.

Some outspoken AI researchers, like Professor Oren Etzioni, have painted
it as "very much a fringe argument," saying that while luminaries like
Stephen Hawking, Elon Musk and Bill Gates may be deeply concerned, the
people actually working in AI are not.103 If true, this would provide
good reason to be skeptical of the risk. But even a cursory look at what
the leading figures in AI are saying shows it is not.

For example, Stuart Russell, a professor at the University of
California, Berkeley, and author of the most popular and widely
respected textbook in AI, has strongly warned of the existential risk
from AGI. He has gone so far as to set up the Center for
Human-Compatible AI, to work on the alignment problem.104 In industry,
Shane Legg (Chief Scientist at DeepMind) has warned of the existential
dangers and helped to develop the field of alignment research.105 Indeed
many other leading figures from the early days of AI to the present have
made similar statements.106

There is actually less disagreement here than first appears. The main
points of those who downplay the risks are that (1) we likely have
decades left before AI matches or exceeds human abilities, and (2)
attempting to immediately regulate research in AI would be a great
mistake. Yet neither of these points is actually contested by those who
counsel caution: they agree that the time frame to AGI is decades, not
years, and typically suggest research on alignment, not regulation. So
the substantive disagreement is not really over whether AGI is possible
or whether it plausibly could be threat to humanity. It is over whether
a potential existential threat that looks to be decades away should be
of concern to us now. It seems to me that it should.

One of the underlying drivers of the apparent disagreement is a
difference in viewpoint on what it means to be appropriately
conservative. This is well illustrated by a much earlier case of
speculative risk, when Leo Szilard and Enrico Fermi first talked about
the possibility of an atomic bomb: "Fermi thought that the conservative
thing was to play down the possibility that this may happen, and I
thought the conservative thing was to assume that it would happen and
take all the necessary precautions."107 In 2015 I saw this same dynamic
at the seminal Puerto Rico conference on the future of AI. Everyone
acknowledged that the uncertainty and disagreement about timelines to
AGI required us to use "conservative assumptions" about progress---but
half used the term to allow for unfortunately slow scientific progress
and half used it to allow for unfortunately quick onset of the risk. I
believe much of the existing tension on whether to take risks from AGI
seriously comes down to these disagreements about what it means to make
responsible, conservative, guesses about future progress in AI.

That conference in Puerto Rico was a watershed moment for concern about
existential risk from AI. Substantial agreement was reached and many
participants signed an open letter about the need to begin working in
earnest to make AI both robust and beneficial.108 Two years later an
expanded conference reconvened at Asilomar, a location chosen to echo
the famous genetics conference of 1975, where biologists came together
to pre- emptively agree principles to govern the coming possibilities of
genetic engineering. At Asilomar in 2017, the AI researchers agreed on a
set of Asilomar AI Principles, to guide responsible longterm development
of the field. These included principles specifically aimed at
existential risk:

> Capability Caution: There being no consensus, we should avoid strong
> assumptions regarding upper limits on future AI capabilities.
>
> Importance: Advanced AI could represent a profound change in the
> history of life on Earth, and should be planned for and managed with
> commensurate care and resources.
>
> Risks: Risks posed by AI systems, especially catastrophic or
> existential risks, must be subject to planning and mitigation efforts
> commensurate with their expected impact.109

Perhaps the best window into what those working on AI really believe
comes from the 2016 survey of leading AI researchers. As well as asking
if and when AGI might be developed, it asked about the risks: 70 percent
of the researchers agreed with Stuart Russell's broad argument about why
advanced AI might pose a risk;110 48 percent thought society should
prioritize AI safety research more (only 12 percent thought less). And
half the respondents estimated that the probability of the longterm
impact of AGI being "extremely bad (e.g., human extinction)" was at
least 5 percent.111 I find this last point particularly remarkable---in
how many other fields would the typical leading researcher think there
is a one in twenty chance the field's ultimate goal would be extremely
bad for humanity?

Of course this doesn't prove that the risks are real. But it shows that
many AI researchers take seriously the possibilities that AGI will be
developed within 50 years and that it could be an existential
catastrophe. There is a lot of uncertainty and disagreement, but it is
not at all a fringe position.

There is one interesting argument for skepticism about AI risk that gets
stronger---not weaker---when more researchers acknowledge the risks. If
researchers can see that building AI would be extremely dangerous, then
why on earth would they go ahead with it? They are not simply going to
build something that they know will destroy them.112

[If we were all]{.underline} truly **[wise]{.underline}**, altruistic
[and]{.underline} **[coordinated]{.underline}**, then [this]{.underline}
argument [would]{.underline} indeed [work. But in the **real world**
people tend to develop technologies **as soon as the opportunity
presents itself**]{.underline} and deal with the consequences later. One
reason for this comes from the variation in our beliefs: if even a small
proportion of researchers don't believe in the dangers (or welcome a
world with machines in control), they will be the ones who take the
final steps. This is an instance of the unilateralist's curse (discussed
here). Another reason involves incentives: even if some researchers
thought the risk was as high as 10 percent, they may still want to take
it if they thought they would reap most of the benefits. [This may be
rational in terms of]{.underline} their [self-interest, yet terrible for
the world.]{.underline}

In some cases like this, **[government]{.underline}** [can]{.underline}
**[step in]{.underline}** [to]{.underline} **[resolve]{.underline}**
[these coordination and incentive problems in the public
interest]{.underline}. But here these exact same coordination and
incentive problems arise between states and there are no easy mechanisms
for resolving those. If one state were to take it slowly and safely,
they may fear others would try to seize the prize. Treaties are made
exceptionally difficult because verification that the others are
complying is even more difficult here than for bioweapons.113

[Whether we **survive** the development of **AI** with our **longterm
potential intact**]{.underline} [may **depend** on whether we can
**learn** to]{.underline} align and **[control AI]{.underline}** systems
faster than we can develop systems capable enough to pose a threat.
Thankfully, [researchers are **already** working on a
**variety**]{.underline} [of]{.underline} the [key issues, including
making AI more **secure**]{.underline}, [more **robust**]{.underline}
[and more **interpretable**]{.underline}. But there are still very few
people working on the core issue of aligning AI with human values. This
is a young field that is going to need to progress a very long way if we
are to achieve our security.

Even though our current and foreseeable systems pose no threat to
humanity at large, time is of the essence. In part this is because
progress may come very suddenly: through unpredictable research
breakthroughs, or by rapid scaling-up of the first intelligent systems
(for example by rolling them out to thousands of times as much hardware,
or allowing them to improve their own intelligence).114 And in part it
is because such a momentous change in human affairs may require more
than a couple of decades to adequately prepare for. In the words of
Demis Hassabis, co- founder of DeepMind:

> We need to use the downtime, when things are calm, to prepare for when
> things get serious in the decades to come. The time we have now is
> valuable, and we need to make use of it.115

DYSTOPIAN SCENARIOS

So far we have focused on two kinds of existential catastrophe:
extinction and the unrecoverable collapse of civilization. But these are
not the only possibilities. Recall that an existential catastrophe is
the permanent destruction of humanity's longterm potential, and that
this is interpreted broadly, including outcomes where a small fragment
of potential may remain.

Losing our potential means getting locked into a bad set of futures. We
can categorize existential catastrophes by looking at which aspects of
our future get locked in. This could be a world without humans
(extinction) or a world without civilization (unrecoverable collapse).
But it could also take the form of an unrecoverable dystopia---a world
with civilization intact, but locked into a terrible form, with little
or no value.116

This has not happened yet, but the past provides little comfort. For
these kinds of catastrophes only became possible with the advent of
civilization, so our track record is much shorter. And there is reason
to think that the risks may increase over time as the world becomes more
interconnected and experiments with new technologies and ideologies.

I won't attempt to address these dystopian scenarios with the same level
of scientific detail as the risks we've explored so far, for the
scenarios are diverse and our present understanding of them very
limited. Instead, my aim is just to take some early steps toward
noticing and understanding these very different kinds of failure.

We can divide the unrecoverable dystopias we might face into three
types, on the basis of whether they are desired by the people who live
in them. There are possibilities where the people don't want that world,
yet the structure of society makes it almost impossible for them to
coordinate to change it. There are possibilities where the people do
want that world, yet they are misguided and the world falls far short of
what they could have achieved. And in between there are possibilities
where only a small group wants that world but enforces it against the
wishes of the rest. Each of these types has different hurdles it would
need to overcome in order to become truly locked in.

\[FIGURE 5.2 OMITTED\]

Note that to count as existential catastrophes, these outcomes don't
need to be impossible to break out of, nor to last millions of years.
Instead, the defining feature is that entering that regime was a crucial
negative turning point in the history of human potential, locking off
almost all our potential for a worthy future. One way to look at this is
that when they end (as they eventually must), we are much more likely
than we were before to fall down to extinction or collapse than to rise
up to fulfill our potential. For example, a dystopian society that
lasted all the way until humanity was destroyed by external forces would
be an existential catastrophe. However, if a dystopian outcome does not
have this property, if it leaves open all our chances for success once
it ends---it is a dark age in our story, but not a true existential
catastrophe.

The most familiar type is the enforced dystopia. The rise of
expansionist totalitarianism in the mid-twentieth century caused
intellectuals such as George Orwell to raise the possibility of a
totalitarian state achieving global dominance and absolute control,
locking the world into a miserable condition.117 The regimes of Hitler
and Stalin serve as a proof of principle, each scaling up to become
imperial superpowers while maintaining extreme control over their
citizens.118 However, it is unclear whether Hitler or Stalin had the
expansionist aims to control the entire world, or the technical and
social means to create truly lasting regimes.119

This may change. Technological progress has offered many new tools that
could be used to detect and undermine dissent, and there is every reason
to believe that this will continue over the next century. Advances in AI
seem especially relevant, allowing automated, detailed monitoring of
everything that happens in public places---both physical and online.
Such advances may make it possible to have regimes that are far more
stable than those of old.

That said, technology is also providing new tools for rebellion against
authority, such as the internet and encrypted messages. Perhaps the
forces will remain in balance, or shift in favor of freedom, but there
is a credible chance that they will shift toward greater control over
the populace, making enforced dystopias a realistic possibility.

A second kind of unrecoverable dystopia is a stable civilization that is
desired by few (if any) people. It is easy to see how such an outcome
could be dystopian, but not immediately obvious how we could arrive at
it, or lock it in, if most (or all) people do not want it.120

The answer lies in the various population-level forces that can shape
global outcomes. Well-known examples include market forces creating a
race to the bottom, Malthusian population dynamics pushing down the
average quality of life, or evolution optimizing us toward the spreading
of our genes, regardless of the effects on what we value. These are all
dynamics that push humanity toward a new equilibrium, where these forces
are finally in balance. But there is no guarantee this equilibrium will
be good.

For example, consider the tension between what is best for each and what
is best for all. This is studied in the field of game theory through
"games" like the prisoner's dilemma and the tragedy of the commons,
where each individual's incentives push them toward producing a
collectively terrible outcome. The Nash equilibrium (the outcome we
reach if we follow individual incentives) may be much worse for everyone
than some other outcome we could have achieved if we had overcome these
local incentives.

The most famous example is environmental degradation, such as pollution.
Because most of the costs of pollution aren't borne by the person who
causes it, we can end up in a situation where it is in the self-interest
of each person to keep engaging in such activities, despite this making
us all worse off. It took significant moral progress and significant
political action to help us break out of this. We may end up in new
traps that are even harder to coordinate our way out of. This could be
at the level of individuals, or at the level of groups. We could have
nations, ideological blocs, or even planets or descendent species of
Homo sapiens locked in harmful competition---doing what is best for
their group, but bad for groups on the whole.

I don't know how likely it is that we suffer a sufficiently bad (and
sufficiently intractable) tragedy of the commons like this. Or that we
are degraded by evolutionary pressures, or driven to lives of very low
quality by Malthusian population dynamics, or any other such situation.
I'd like to hope that we could always see such things coming and
coordinate to a solution. But it's hard to be sure that we could.

The third possibility is the "desired dystopia."121 Here it is easier to
see how universal desire for an outcome might cause us to lock it in,
though less clear how such an outcome could be dystopian. The problem is
that there are many compelling ideas that can radically shape our
future--- especially ideologies and moral theories, as these make direct
normative claims about the world we should strive to create. If combined
with the technological or social means for instilling the same views in
the next generation (indoctrination, surveillance), this has the
potential to be disastrous.

The historical record is rife with examples of seriously defective
ideologies and moral views that gripped large parts of the world.
Moreover, even reasonable normative views often recommend that they be
locked in--- for otherwise a tempting rival view may take over, with
(allegedly) disastrous results.122 Even though the most plausible moral
views have a lot of agreement about which small changes to the world are
good and which are bad, they tend to come strongly apart in their
recommendations about what an optimal world would look like. This
problem thus echoes that of AI alignment, where a strong push toward a
mostly correct ideal could instead spell disaster.

Some plausible examples include: worlds that completely renounce further
technological progress (which ensures our destruction at the hands of
natural risks),123 worlds that forever fail to recognize some key form
of harm or injustice (and thus perpetuate it blindly), worlds that lock
in a single fundamentalist religion, and worlds where we deliberately
replace ourselves with something that we didn't realize was much less
valuable (such as machines incapable of feeling).124

All of these unrecoverable dystopias can be understood in terms of
lock-in. Key aspects of the future of the civilization are being locked
in such that they are almost impossible to change. If we are locked into
a sufficiently bad set of futures, we have an unrecoverable dystopia; an
existential catastrophe.

Of course, we can also see lock-in on smaller scales. The Corwin
Amendment to the US constitution provides a disturbing example of
attempted lock-in. In an effort to placate the South and avoid civil
war, the proposed Thirteenth Amendment aimed to lock in the institution
of slavery by making it impossible for any future amendments to the
constitution to ever abolish it.125

I cannot see how the world could be locked into a dystopian state in the
near future.126 But as technology advances and the world becomes more
and more interlinked, the probability of a locked-in dystopia would
appear to rise, perhaps to appreciable levels within the next hundred
years. Moreover, in the further future I think these kinds of outcomes
may come to take up a high share of the remaining risk. For one thing,
they are more subtle, so even if we got our act together and made
preserving our longterm potential a high global priority, it may take
remarkable wisdom and prudence to avoid some of these traps. And for
another, our eventual spread beyond the Earth may make us nearly immune
to natural catastrophes, but ideas travel at the speed of light and
could still corrupt all that we hope to achieve.

A key problem is that the truth of an idea is only one contributor to
its memetic potential---its ability to spread and to stick. But the more
that rigorous and rational debate is encouraged, the more truth
contributes to memetic success. So encouraging a culture of such debate
may be one way we can now help avoid this fate. (For more on this, see
the discussion of the Long Reflection in Chapter 7.)

The idea of lock-in also gives us another useful lens through which to
think about existential risk in general. We might adopt the guiding
principle of minimizing lock-in. Or to avoid the double negative, of
preserving our options.127 This is closely related to the idea of
preserving our longterm potential---the difference being that preserving
our options takes no account of whether the options are good or bad.
This is not because we intrinsically care about keeping options alive
even if they are bad, but because we aren't certain they are bad, so we
risk making an irreversible catastrophic mistake if we forever foreclose
an option that would turn out to be best.

OTHER RISKS

What other future risks are there that warrant our concern?

One of the most transformative technologies that might be developed this
century is nanotechnology. We have already seen the advent of
nanomaterials (such as carbon nanotubes) which are just a few atoms
thick and structured with atomic precision. But much larger vistas would
open up if we could develop machinery that operates with atomic
precision. We have proof that some form of this is possible within our
very own cells, where atomically precise machinery already performs
their essential functions.

In the popular imagination nanotechnology is synonymous with building
microscopic machines. But the bigger revolution may instead come from
using **[nanomachinery]{.underline}** to [create]{.underline}
**[macro-scale]{.underline}** **[objects]{.underline}**. In his
foundational work on the topic, Eric Drexler describes how
nanotechnology could allow desktop fabricators, capable of assembling
anything from a diamond necklace to a new laptop. This atomically
precise manufacturing would be the ultimate form of 3D printing: taking
a digital blueprint for the object and the raw chemical elements, and
producing an atomically precise instance. This may allow us to construct
things beyond our current technological reach, as well as cutting prices
of existing objects such as computers or solar cells to near the cost of
their raw materials, granting the world vastly more computing power and
clean energy.

[Such a powerful technology may pose]{.underline} some **[existential
risk]{.underline}**. Most attention has so far focused on the
possibility of creating [tiny self- replicating machines]{.underline}
that [could]{.underline} **[spread]{.underline}** [to create
an]{.underline} **[ecological]{.underline}** [catastrophe]{.underline}.
This may be possible, but there are mundane dangers that appear more
likely, since [extreme manufacturing power and precision
would]{.underline} probably also [allow the production of **new
w**eapons of **m**ass **d**estruction]{.underline}.128 Indeed the
problems resemble those of [advanced]{.underline}
**[biotech]{.underline}**nology: the democratization of extremely
powerful technology [would allow]{.underline} individuals or small
groups access to the kinds of [power]{.underline} ([both
**constructive** and **destructive**]{.underline}) that was [previously
only available to powerful **nations**]{.underline}.
**[Solutions]{.underline}** to managing this technology [may require
**digital controls**]{.underline} on what can be fabricated or state
control of fabrication (the path we took with nuclear power). While this
technology is more speculative than advanced biotechnology or AI, it may
also come to pose a significant risk.

A very different kind of risk may come from our explorations beyond the
Earth. Space agencies are planning missions which would return soil
samples from Mars to the Earth, with the chief aim of looking for signs
of life. This raises the possibility of "back contamination" in which
microbes from Mars might compromise the Earth's biosphere. While there
is a consensus that the risk is extremely small, it is taken very
seriously.129 The plan is to return such samples to a new kind of BSL-4
facility, with safeguards to keep the chance of any unsterilized
particle escaping into the environment below one in a million.130 While
there are still many unknown factors, this anthropogenic risk appears
comparatively small and well managed.131

The extra-terrestrial risk that looms largest in popular culture is
conflict with a spacefaring alien civilization. While it is very
difficult to definitively rule this out, it is widely regarded to be
extremely unlikely (though becoming more plausible over the extreme long
term).132 The main risk in popular depictions is from aliens traveling
to Earth, though this is probably the least likely possibility and the
one we could do the least about. But perhaps more public discussion
should be had before we engage in active SETI (sending powerful signals
to attract the attention of distant aliens). And even passive SETI
(listening for their messages) could hold dangers, as the message could
be designed to entrap us.133 These dangers are small, but poorly
understood and not yet well managed.

Another kind of anthropogenic risk comes from our most radical
scientific **[experiments]{.underline}**---those which
[create]{.underline} **[truly unprecedented]{.underline}**
[conditions]{.underline}.134 For example, the first nuclear explosion
created temperatures that had never before occurred on Earth, opening up
the theoretical possibility that it might ignite the atmosphere. Because
these conditions were unprecedented we lost the reassuring argument that
this kind of event has happened many times before without catastrophe.
(We could view several of the risks we have already discussed---such as
back contamination, gain of function research and AGI---through this
lens of science experiments creating unprecedented conditions.)

In some cases, scientists confidently assert that it is impossible for
the experiment to cause a disaster or extinction. But [even **core**
scientific certainties have been **wrong before**]{.underline}: for
example, that objects have determinate locations, that space obeys
Euclid's axioms, and that atoms can't be subdivided, created or
destroyed. If pressed, the scientists would clarify that they really
mean it couldn't happen without a major change to our scientific
theories. This is sufficient certainty from the usual perspective of
seeking accurate knowledge, where 99.9 percent certainty is more than
enough. But that is a standard which is independent of the stakes. Here
the stakes are uniquely high and we need a standard that is sensitive to
this.135

The usual approach would be to compare the expected gains to the
expected losses. But that is challenging to apply, as a very low (and
hard to quantify) chance of enormous catastrophe needs to be weighed
against the tangible benefits that such experiments have brought and are
likely to bring again. Furthermore, the knowledge or the technologies
enabled by the experiments may help lower future existential risk, or
may be necessary for fulfilling our potential.

For any given experiment that creates truly unprecedented conditions,
the chance of catastrophe will generally be very small. But there may be
exceptions, and the aggregate chance may build up. These risks are
generally not well governed.136

These [risks posed by **future tech**nologies]{.underline}
[are]{.underline} **[by their]{.underline}** very
**[nature]{.underline}** more **[speculative]{.underline}** than those
from natural hazards or the most powerful technologies of the present
day. And this is especially true as we moved from things that are just
now becoming possible within biotechnology to those that are decades
away, at best. [But one doesn't have to find **all** of these threats to
be **likely**]{.underline} ([or **even plausible**]{.underline}) [to
recognize that there are **serious risks ahead**]{.underline}. [Even if
we **restrict our attention**]{.underline} to engineered pandemics, I
think there is more existential risk than in all risks of the last two
chapters combined, and [those risks were **already
sufficient**]{.underline} [to make safeguarding humanity a **central
priority**]{.underline} of our time.

UNFORESEEN RISKS

[Imagine if the scientific establishment of **1930**]{.underline} [had
been asked to compile a list of the existential risks]{.underline}
humanity would face over the following hundred years. [They would have
**missed most**]{.underline} of the risks covered in this
book---especially the anthropogenic risks.137 Some would have been on
the edge of their awareness, while others would come as complete shocks.
[How much risk lies beyond the limits of our **own**
vision?]{.underline}

We can get some inkling by considering that [there has been no
**slow-down**]{.underline} [in the rate at which we've been
**discovering** risks, **nor** the rate at which we've been
**producing** them. It is thus likely we will face **unforeseen
risks**]{.underline} [over the next hundred years and
beyond]{.underline}. Since humanity's power is still rapidly growing, we
shouldn't be surprised if some of these novel threats pose a substantial
amount of risk.

One might wonder what good can come of considering risks so far beyond
our sight. While we cannot directly work on them, they may still be
lowered through our broader efforts to create a world that takes its
future seriously. [Unforeseen risks are]{.underline} thus [important to
understanding the relative value of **broad** versus **narrowly targeted
efforts**. And they are important for estimating the **total risk** we
face.]{.underline}

Nick Bostrom has recently pointed to an important class of unforeseen
risk.138 Every year as we invent new technologies, we may have a chance
of stumbling across something that offers the destructive power of the
atomic bomb or a deadly pandemic, but which turns out to be easy to
produce from everyday materials. Discovering **[even one]{.underline}**
such technology [might]{.underline} be enough to [make the **continued
existence** of human civilization **impossible**.]{.underline}

**[2AC -- O/W's nukes]{.underline}**

**Outweighs nuke war:**

**1. Unlike AI, [nuke war's]{.underline} not existential**

Karina **Vold &** Daniel R. **Harris 21**, Vold is a philosopher of
cognitive science and artificial intelligence & an assistant professor
at the University of Toronto\'s Institute for the History and Philosophy
of Science and Technology; Harris is a retired lawyer and Foreign
Service Officer at the US Department of State, "How Does Artificial
Intelligence Pose an Existential Risk?," Oxford Handbook of Digital
Ethics, Ed. C. Veliz., pp 1-34

The idea that AI might one day threaten humanity has been around for
some time. In 1863, the novelist Samuel Butler (1863 ,185) suggested
that [machines may one day hold "supremacy over the world]{.underline}
and its inhabitants". By the mid-twentieth century, these concerns had
left the realm of science fiction, as thinkers like Alan Turing (1951,
260) began to warn the public that we should expect intelligent machines
to eventually "take control". Still, for many years, academics did not
spill much ink over these concerns, even while Hollywood filmmakers ran
with them, producing countless blockbusters based on this "AI takeover"
scenario (think: The Terminator or Battlestar Galactica). Over the last
decade or so, however, many leading academics and entrepreneurs have
notably increased their attention to existential risks from AI. These
concerns are, as we will see, more subtle than those depicted in crude
Hollywood-produced AI takeover scenarios. Indeed, those depictions have
largely misrepresented the concrete issues scholars are concerned with
by overly focusing on anthropomorphic concerns of conscious AI systems
deciding to destroy humans.

This renewed scholarly interest in AI safety has been spurred on in part
by [the recent]{.underline} **[deep learning]{.underline}**
[revolution]{.underline}. This period is [defined by major]{.underline}
**[advances]{.underline}** [in the accomplishments of deep **neural
networks**--- artificial neural networks with **multiple
layers**]{.underline} [between the input and output layers---across
a]{.underline} **[wide range of areas]{.underline}**, including
game-playing, speech and facial recognition, and image generation. [Even
with these breakthroughs]{.underline} though, the cognitive capabilities
of [current AI systems remain limited to]{.underline}
**[domain-specific]{.underline}** [applications. Nevertheless, many
researchers are]{.underline} **[alarmed]{.underline}** [by
the]{.underline} **[speed of progress]{.underline}** in AI [and worry
that]{.underline} **[future]{.underline}** [systems, if not]{.underline}
**[managed]{.underline}** [correctly, could present an]{.underline}
**[existential threat]{.underline}**.

Despite the renewed interest in this concern, there remains substantial
disagreement over both the nature and the likelihood of the existential
threats posed by AI. Hence, our aim in this chapter is to explicate the
main arguments that have been given for thinking that AI does pose an
existential risk, and to point out where there are disagreements and
weakness in these arguments. The chapter has the following structure: in
§2, we will introduce the concept of existential risk, the sources of
such risks, and how these risks are typically assessed. In §3--5, we
will critically examine three commonly cited reasons for thinking that
AI poses an existential threat to humanity: the control problem, global
disruption from an AI "arms race", and the weaponization of AI. Our
focus is on the first of these three, because it represents a kind of
existential risk that is novel to AI as technology. While the latter two
are equally important, they have commonalities with other kinds of
technologies (e.g., nuclear weapons) discussed in the literature on
existential risk, and so we will dedicate less time to them.

2\. What Is an Existential Risk?

Many people believe that existential risks (henceforth, Xrisks) are the
greatest threats facing humanity. And whilst there is much common ground
amongst scholars about which scenarios constitute an Xrisk---the most
commonly cited example is extinction risks1---there is not as much
consensus on the precise definition of the concept (Beard et al., 2020;
Torres, 2019). While most Xrisk scholars agree that a risk is
existential if an adverse outcome would bring about human extinction,
few endorse the narrower view that a risk is existential only if it
would cause this outcome.2 Most definitions of Xrisk are broader,
including at times the risk of global civilizational collapse (Rees,
2003; Ó hÉigeartaigh, 2017); scenarios in which the technological and
moral potential of humanity is "permanently and drastically" curtailed
(Bostrom, 2002, 2013); and suffering risks, defined as cases in which
"an adverse outcome would bring about severe suffering on an
astronomical scale, vastly exceeding all suffering that has existed on
Earth so far" (Sotala & Gloor, 2017, 389).

Xrisks are typically distinguished from the broader category of global
catastrophic risks. Bostrom (2013), for example, uses two
dimensions---scope and severity---to make this distinction. Scope refers
to the number of people at risk, while severity refers to how badly the
population in question would be affected (ibid, 16). Xrisks are at the
most extreme end of both of these spectrums: they are pan-generational
in scope (i.e., "affecting humanity over all, or almost all, future
generations"), and they are the severest kinds of threats, causing
either "death or a permanent and drastic reduction of quality of life"
(ibid, 17). Perhaps the clearest example of an Xrisk is an asteroid
impact on the scale of that which hit the Earth 66 million years ago,
wiping out the dinosaurs (Schulte et al., 2010; Ó hÉigeartaigh, 2017).
Global catastrophic risks, by way of contrast, could be either just as
severe but narrower in scope, or just as broad but less severe. Some
examples include the destruction of cultural heritage, thinning of the
ozone layer, or even a large-scale pandemic outbreak (Bostrom, 2013). In
this chapter, we will focus mostly on the least controversial category
of Xrisks--- extinction risks---but will also at times discuss some of
the other scenarios mentioned.

2.1 Sources of Xrisk

For most of human history, the only source of Xrisks facing humanity
were natural causes, such as an asteroid hitting Earth or a global
pandemic (Bostrom, 2002). But the creation of the first atomic bomb in
1945 introduced a new source of existential threat to humanity, one that
was anthropogenic in nature. But since then, humanity has created
numerous other kinds of threats to our own existence, including human-
caused climate change, global biodiversity loss, biological warfare, and
threats from artificial intelligence, for example. In fact, it is widely
thought that most Xrisks today are anthropogenic and that, as a result
of these new threats, this current century is the riskiest one that
humanity has ever faced (Rees, 2003; Bostrom, 2013; Ó hÉigeartaigh,
2017; Ord, 2020).

Not all of these threats pose straightforward Xrisks. Let's consider an
extinction scenario to be the existential outcome in question, and then
[take]{.underline} **[nuclear]{.underline}** [fallout]{.underline} as an
example. Today, [the worldwide arsenal]{.underline} of nuclear weapons
[could lead to unprecedented death]{.underline} tolls and habitat
destruction and, hence, it poses a clear global catastrophic risk.
[Still, experts assign a]{.underline} relatively **[low
probability]{.underline}** [to]{.underline} **[human
extinction]{.underline}** [from nuclear warfare]{.underline} ([Martin,
1982; Sandberg & Bostrom, 2008; Shulman, 2012]{.underline}). This is in
part because it seems more likely that extinction, if it follows at all,
would occur indirectly from the effects of the war, rather than
directly. This distinction has appeared in several discussions on Xrisks
(e.g., Matheny, 2007, Liu et al., 2018; Zwetsloot & Dafoe, 2019), but it
is made most explicitly in Cotton-Barratt et al. (2020, 6), who explain
that a global catastrophe that causes human extinction can do so either
directly by "killing everyone", or indirectly, by "removing our ability
to continue flourishing over a longer period." A nuclear explosion
itself is unlikely to kill everyone directly, but the resulting effects
it has on the Earth could lead to lands becoming uninhabitable, in turn
leading to a scarcity of essential resources, which could (over a number
of years) lead to human extinction. Some of the simplest examples of
direct risks of human extinction, by way of contrast, are "\[i\]f the
entire planet is struck by a deadly gamma ray burst, or enough of a
deadly toxin is dispersed through the atmosphere" (ibid, 6). What's
critical here is that for an Xrisk to be direct it has to be able to
reach everyone.

**2. AI's [millions of times]{.underline} more powerful**

Alexey **Turchin &** David **Denkenberger 18**, Turchin is a researcher
at the Science for Life Extension Foundation; Denkenberger is with the
Global Catastrophic Risk Institute (GCRI) @ Tennessee State University,
Alliance to Feed the Earth in Disasters (ALLFED), "Classification of
Global Catastrophic Risks Connected with Artificial Intelligence," AI &
SOCIETY, 05/03/2018, pp. 1--17

According to Yampolskiy and Spellchecker (2016), [the **probability**
and **seriousness** of AI failures will **increase with
time**]{.underline}. We estimate that they will reach their peak between
the appearance of the first self-improving AI and the moment that an AI
or group of AIs reach global power, and will later diminish, as
late-stage AI halting seems to be a low-probability event.

[AI is an **extremely powerful** and **completely unpredictable**
technology, **millions of times more powerful than nuc**lear
weapon**s**. Its existence could create **multiple individual global
risks**, most of which we **can not currently imagine**]{.underline}. We
present several dozen separate global risk scenarios connected with AI
in this article, but it is likely that some of the most serious are not
included. [The **sheer number of possible failure modes** suggests that
there are more to come.]{.underline}

**[1AR -- AT: US -- China Relations High]{.underline}**

**China will not accept coop with US political obstacles ensure.**

**Sullivan** 10/4/20**21**

Ryan Sullivan Army pilot studied at the prestigious Fudan University in
Shanghai, China, as an Olmsted Scholar graduate-level work in the field
of Artificial Intelligence to deliver an in-depth study of the critical
elements of U.S.-China competition in Artificial Intelligence, "The
U.S., China, and Artificial Intelligence Competition Factors",
<https://www.airuniversity.af.edu/Portals/10/CASI/documents/Research/Cyber/2021-10-04%20US%20China%20AI%20Competition%20Factors.pdf?ver=KBcxNomlMXM86FnIuuvNEw%3D%3D>
-- ECM

AI Competition between the U.S. and China is not irredeemably zero-sum;
in fact, collaboration and cooperation are not only necessary, but it is
beneficial to both nations and carries the potential of helping all of
humanity. In helping humanity address transnational issues, "power
becomes a positive-sum game" as the U.S., according to Joseph Nye,
approaches "power in terms of the ability to accomplish joint goals"
where "empowering others can help us accomplish our own goals."441
Competition does equate to conflict. Finding commonalities in this
"inevitable and inescapable rivalry" allows our nations to accept our
differences and search out commonalities or areas where values may
align, much like companies such as Apple and Samsung.442 The idea of
"rivalry partners" put forward by Graham Allison, or "coopetition" or
"coevolution" by Elizabeth Economy, are alternative perspectives for the
U.S.-China relationship, which with certain assumptions, retains
competition as the centerpiece of the relationship while opening up
opportunities for cooperation in areas that benefit all of humankind.
The risk, however, is if cooperation becomes the objective, not the
means, thus it "encourages the actor more committed to cooperation to
excuse or even ignore the other's missteps or malign actions out of fear
that cooperation otherwise will not ultimately be realized."443 [A
better approach to coop]{.underline}eration **[focuses on allies and
partners]{.underline}**, [where values naturally align]{.underline} and
working through the difficult challenges [that AI presents may yield
results more quickly]{.underline}. While China has a long history of
pursuing bilateral agreements, especially on trade, they remain flexible
in adapting to changing environments where their participation offers an
opportunity for leadership roles or offsets U.S. interests in regional
agreements. In the current geopolitical climate, **[China is unlikely to
accept bilateral agreements or arrangements with the U.S. on
AI]{.underline}**, preferring multilateral engagements to further their
platform for multipolarity and reserving bilateral agreements for
economic trade or when opportunities appear to entice developing nations
to the BRI or other China-led efforts. The U.S. should not avoid
bilateral engagements with Beijing on critical security issues but
prioritizing the needs of allies and recruiting nations with shared
values presents a path to a more inclusive and diverse alliance. Such an
arrangement should not exclude non-democratic countries such as Vietnam
or Singapore, nor should it exclude China by design. [The U.S. gains
legitimacy through leadership that focuses]{.underline} not
[on]{.underline} division or conflict but by relying [on clear values
and norms to attract like-minded nations across geographical boundaries
and political ideologies]{.underline}. Values more than any other
element of competition impede cooperation with China [and
demonstrat]{.underline}ing [to the world that the U.S. will stand up to
China on human rights]{.underline}, [while not closing the door on
collaboration]{.underline} or cooperation on issues such as climate
change, [keeps the door open for China to participate, without giving
them the power to block, delay or disrupt efforts]{.underline}.

**Even If they win relations are high the plan is necessary to maintain
a workable floor -- that's key to collapse**

**Haenle & Bresnick 2/21**/2022

Paul Haenle holds the Maurice R. Greenberg Director's Chair at the
Carnegie Endowment for International Peace and is a visiting senior
research fellow at the East Asian Institute, National University of
Singapore.. Sam Bresnick is assistant editor and research assistant.
"Why U.S.-China Relations Are Locked in a Stalemate",
<https://carnegieendowment.org/2022/02/21/why-u.s.-china-relations-are-locked-in-stalemate-pub-86478>
\-- ECM

[By committing to]{.underline} this [pragmatic approach]{.underline},
[the U]{.underline}nited [S]{.underline}tates [and China may be able to
find a way to put **a floor under deteriorating
relations**]{.underline}, begin to build goodwill, and lay the
foundation for taking on the larger structural issues in areas, like
trade and technology, that will be key to determining the future health
and welfare of the U.S.-China relationship over the long term. Despite
the two nations' differing mindsets and approaches to bilateral ties,
starting small could prove the best method through which to, eventually,
realize large gains.

**The plan would be a boost to US-China relations**

**Haenle & Bresnick 2/21**/2022

Paul Haenle holds the Maurice R. Greenberg Director's Chair at the
Carnegie Endowment for International Peace and is a visiting senior
research fellow at the East Asian Institute, National University of
Singapore.. Sam Bresnick is assistant editor and research assistant.
"Why U.S.-China Relations Are Locked in a Stalemate",
<https://carnegieendowment.org/2022/02/21/why-u.s.-china-relations-are-locked-in-stalemate-pub-86478>
\-- ECM

Biden has opted to use a calmer, more restrained tone with Beijing than
did his predecessor, with the aim of avoiding escalation. Moreover,
unlike some Trump administration officials, Biden's team has made it
clear that Washington is not seeking regime change in China. And though
Biden criticized Trump's lack of a clear set of goals or a coherent
interagency policy framework for addressing the China challenge, his
administration has yet to release its long-awaited China strategy
(though China does figure prominently in its recently issued
Indo-Pacific Strategy). Until that document is issued, the finer points
of the administration's plans to compete with Beijing, as well as the
end goal of such competition, will remain fuzzy. [A clear articulation
of U.S. aims would be helpful in Washington's efforts to secure
greater]{.underline} **[international cooperation from allies and
partners in addressing the challenges China poses]{.underline}**. [It
would also provide Chinese and U.S. leaders a starting
point]{.underline} from which [to negotiate]{.underline} the future of
[bilateral ties.]{.underline}

**2AC -- Solvency**

**[2AC -- Solvency]{.underline}**

**Cyber dialogue creates technical standards and secures
interoperability for quantum computing and AI**

**Mazzucchi &** **Desforges 19**

Nicolas Alix Nicolas Mazzucchi is a research fellow at the Foundation
for Strategic Research and Alix Desforges is a postdoctoral fellow at
Geopolitics of the Datasphere (GEODE), "Web Wars: Preparing for the Next
Cyber Crisism" Carnegie Europe, 11/28/19,
https://carnegieeurope.eu/2019/11/28/web-wars-preparing-for-next-cyber-crisis-pub-80420

INTRODUCTION

Over the past decades, cyberspace has transformed societies around the
world, reshaping economies, politics, social affairs, and, increasingly,
militaries. The first cyber attacks launched as part of a military
conflict are now twenty years old.1 In the last decade, [cyberspace has
become a **central aspect** of military operations]{.underline}.

The [acceleration of the military use of cyber capabilities]{.underline}
[and]{.underline} the simultaneous **[militarization]{.underline}** [of
cyberspace create]{.underline} **[new threats]{.underline}**
[and]{.underline} **[opportunities]{.underline}** [for]{.underline}
**[NATO]{.underline}**. [The alliance must]{.underline} respond in a
number of ways, including by increasing investment, strengthening
technical cooperation with the European Union (EU), and
[seek]{.underline}ing **[political consensus]{.underline}** [on the
attribution of, and **responses to,** **cyber attacks**]{.underline}.

ISSUES AT STAKE

Armed forces and vital civilian organizations, such as operators of
energy networks, rely more and more on computer systems for their
operations. This increases both their efficacy and their vulnerability.
NATO saw the significance of this trend some time ago, and [since 2016,
the allies have recognized cyberspace as a **domain** in
itself]{.underline}. [The alliance integrates cyber capabilities into
its thinking and planning for operations]{.underline}, even if mainly in
defensive terms. The alliance's 2016 Cyber Defense Pledge helped member
states strengthen their national cyber defense capabilities by working
together.2

[Twenty-four of NATO's twenty-nine member states have issued **public
cyber doctrines**]{.underline} [that deal with military
issues]{.underline}.3 Dedicated units are being created across NATO
countries, either with a unified cyber command, as in France and the
United States, or with a devoted cyber force, like in Germany. [This is
the right step overall, although allies' **differing
approaches**]{.underline} [to cyber strategy and organization could
**cause challenges**]{.underline} [when it comes to **joint**
and]{.underline} **[combined]{.underline}** [operations]{.underline}.

NATO is responsible for protecting its networks and infrastructure, as
well as promoting cooperation among allies and with partner nations. For
the moment, the alliance's most important prerogatives and capabilities
lie in the defensive use of cyber capabilities, although individual
countries can volunteer various cyber services---not only defensive
ones---to NATO commanders. In 2018, the alliance set up the Cyberspace
Operations Center in its command structure to help nations and
commanders better understand these possible national contributions and
their uses. NATO also strengthened its cooperation on cyber matters with
the EU through a joint declaration at the alliance's 2016 summit in
Warsaw.4

There is often little difference in offensive cyber capabilities between
criminal groups and some military forces. Hacking tools are becoming
more accessible. In 2017, the U.S. National Security Agency's
sophisticated offensive suite was stolen or leaked and subsequently used
in attacks.5 In parallel, critical civilian infrastructure, such as the
networks that govern energy or water distribution, is becoming more
dependent on the internet, making it a target in potential conflicts.
This infrastructure could even be used as a tool for a large attack: if
corrupted by hackers, it could be turned into a botnet---a network of
computers linked by malware. It has become possible, in theory, to
achieve a strategic effect with cyber attacks on civilian facilities and
infrastructure, which tend to be less protected than military equipment.
As a result, the line between the defense of military and nonmilitary
assets in cyberspace is becoming increasingly blurred.

One consequence of this trend is closer military cooperation with
civilian authorities, including law enforcement. However, military
organizations and armed forces tend to invest more than civilian
ministries or agencies in cyber defense and cybersecurity. In the United
States, for example, the Department of Defense accounted for more than
50 percent of the 2018 federal cybersecurity budget, representing \$8.5
billion out of \$15 billion.6 Unchecked, this trend creates a growing
gap between military and civilian spending.

Several international organizations and, more recently, companies have
decided to address stability in cyberspace and the regulation of cyber
conflicts. Some states and nonstate actors are even suggesting the
adoption of a treaty on the use of information technology and
international security. After meetings of the United Nations (UN) Group
of Governmental Experts failed in 2017 to reach a consensus on what
constitutes states' responsible behavior in cyberspace, the UN initiated
two new negotiation processes. One is a resolution, sponsored by the
United States and European countries, to create a new group of
governmental experts.7 The other is a Russia- and China-sponsored
resolution to set up an open-ended working group.8 The two tracks have
different calendars and mandates, including on consultative meetings.
The outcomes of their work, and the potential codes of conduct for cyber
conflict they could generate, will provide guidance for how all
countries, including NATO allies, should behave in the future regarding
cyber operations

RECOMMENDATIONS

Research and development policies and investment strategies in cyber and
military technologies are key elements to ensure that armed forces are
equipped with up-to-date capabilities. The fast pace of technological
evolution requires NATO member states to make significant, continuous
investments to avoid falling behind in terms of capabilities.

Alongside investments in technology, [allies need to strengthen
education in cyber matters, not only in engineering, but also in
strategic thinking and social use]{.underline}. All military personnel
have to be involved to ensure greater cybersecurity awareness and a
better integration of cyber capabilities into military operations. [The
most important challenge for NATO as an alliance is to **bridge the
gap**]{.underline} [between those states with **first-rate cyber
capabilities**]{.underline} [and awareness and those that **lag
behind**]{.underline}. Currently, [a handful of member states are
**pulling away from the others** in terms of the mass **integration** of
connected devices, **quantum computing**, and **A**rtificial
**I**ntelligence--based systems. This **gap** could have a]{.underline}
**[major impact]{.underline}** [on]{.underline} **[burden
sharing]{.underline}** [in NATO,]{.underline} because a low level of
spending by one or more countries would need to be compensated by the
others to maintain a satisfactory global level for the alliance.

[Allies should draw up national cyber rules of engagement for offensive
operations in accordance with principles of international
law]{.underline}. Certain policies espoused by some member states, such
as hack-back, which allows private firms to pursue attackers into other
companies' networks, or cyber deterrence, could lead to uncontrolled
escalation.9 International law tends to limit this escalation to mainly
economic responses, such as sanctions and countermeasures. [All NATO
allies also need to ensure that their rules of engagement are
**compatible** with the alliance's]{.underline} agreed [approach to
cyber defense]{.underline}. [At present, **different countries** have
**different views** on]{.underline} offensive [cyber
policies,]{.underline} in particular.

The alliance should give technical assistance to member states that are
willing to share information and national best practices. NATO should
expand its rapid-response system to cover attacks that blur the line
between the military and nonmilitary realms, such as an attack on
critical nonmilitary networks in the context of a NATO military mission.

**[Unity]{.underline}** [is important when it comes to **external
communications**]{.underline} [by the allies,]{.underline} or by NATO's
secretary general, on attribution. While the decision to attribute an
attack to a particular entity remains a sovereign and political one,
allies should discuss any such communication from individual capitals
before it is made. This would not only prevent uncontrolled escalation
but also preserve the strength and unity of the alliance.

[NATO should develop **standards** on the security of **emerging cyber
technologies**]{.underline} in close partnership with the EU. [Allies
could address the **interoperability**]{.underline} [and]{.underline}
**[security]{.underline}** [of connected devices]{.underline} in the
defense sector [by devising a **common policy** in the
alliance]{.underline}. NATO [should]{.underline} also [impose a minimum
**standard of cybersecurity** in products]{.underline}, such as
connected devices and systems; computer-based technologies; and command,
control, communications, computers, intelligence, surveillance, and
reconnaissance (C4ISR) systems during the acquisition process.

[Quantum computers deserve **particular attention** from NATO, because
they can be **game changers** in the military domain. The alliance
should act as a **gateway** between **member states'** militaries and
**defense companies** to promote further **industrial cooperation**,
notably]{.underline} [on]{.underline} **[technical
standards]{.underline}**. Such cooperation should be based on the NATO
Industry Cyber Partnership, which provides platforms for the exchange of
information, threat trends, and best practices. [The alliance must
foster the **maximum possible level of cooperation**]{.underline} [to
ensure that NATO countries are the **first to implement this
technology.**]{.underline}

**[2AC -- NATO is Key]{.underline}**

**NATO is key to shape AI norms**

- EDTs = Emerging and Disruptive Technologies

**Stanley-Lockman & Trabucco 3/22**

Zoe Stanley-Lockman & Lena Trabucco , "NATO's Role in Responsible AI
Governance in Military Affairs", Zoe Stanley-Lockman Nanyang
Technological University, Lena Trabucco University of Copenhagen, Center
for Military Studies The Oxford Handbook of AI Governance Edited by
Justin Bullock, Yu-Che Chen, Johannes Himmelreich, Valerie M. Hudson,
Anton Korinek, Matthew Young , and Baobao Zhang Subject: Political
Science, Political Institutions Online Publication Date: Mar 2022DOI:
10.1093/oxfordhb/9780197579329.013.69 -- ECM

[NATO's increasing interest in EDTs introduces the need to consider how
governance priorities can help reinforce the Alliance's
influence]{.underline}. The STS and military innovation literature
provide the theoretical foundations for NATO's stewardship of AI as they
place attention on "the role that institutions play in shaping
technological trajectories."45 **[As AI development continues, the
actions that NATO and its members take will have important
implications]{.underline}** for their capacity to adopt, respond to, and
shape their future operating environment. Particularly for democracies,
this confers to military stakeholders a dual responsibility to prevent
and manage risks, as well as to proactively shape their approach to
technological development anchored in democratic values and security.
[As a multinational alliance with an incentive to drive
coop]{.underline}eration and alignment, **[NATO is situated to define
and operationalize norms, as well as promote standards that help shape
the contours of future military effectiveness and technological
competition]{.underline}**.

In a RRI framework, not only is this an institutional role, but it also
becomes an institutional responsibility. To apply this responsibility to
NATO's stewardship of AI, [the institutional interplay between
tech]{.underline}nology, [structure, and concepts is a form of
socio-technical system with important implications for AI governance
because they link the ways that an institution uses its power to adopt
and shape AI trajectory to its respective ends]{.underline}.

Already, **[several mechanisms are built into military bureaucracies to
ensure that technology is adopted in alignment with]{.underline}**
responsible engineering practices and responsible state behavior.46 [The
Alliance]{.underline} is organized to harmonize between Allies so that
their contributions enhance military effectiveness and political
cohesion between like-minded democracies. We argue that
[these]{.underline} effectiveness-centric [mechanisms]{.underline}
likewise empower **[NATO to exert its influence in
tech]{.underline}**nology **[governance]{.underline}**. More
specifically, this entails the Alliance helping steward technological
development [for a more]{.underline} predictable [strategic environment
and enhanced democratic clout around the exploitation of
tech]{.underline}nology [reinforcing rule of law.]{.underline} For NATO,
we focus on strategic and policy planning, as well as standards and
certification because they reflect the Alliance's particular strengths
and interests in S&T. These practices are relevant to governance insofar
as they exemplify an institution's power to shape the trajectory of
technological development---but this selection is by no means
exhaustive.

**[2AC -- Coop w/ Allies key]{.underline}**

**Cooperating with allies is key to rebuff China -- US only policies
risk turning our allies off and decreases the possible to check China**

**Sullivan** 10/4/20**21**

Ryan Sullivan Army pilot studied at the prestigious Fudan University in
Shanghai, China, as an Olmsted Scholar graduate-level work in the field
of Artificial Intelligence to deliver an in-depth study of the critical
elements of U.S.-China competition in Artificial Intelligence, "The
U.S., China, and Artificial Intelligence Competition Factors",
<https://www.airuniversity.af.edu/Portals/10/CASI/documents/Research/Cyber/2021-10-04%20US%20China%20AI%20Competition%20Factors.pdf?ver=KBcxNomlMXM86FnIuuvNEw%3D%3D>
-- ECM

[The U.S. should rely more on allies and international
institutions]{.underline}, such as the UN, [to deliver criticism and
press the CCP]{.underline} on human rights issues. Such an approach
requires not just shared values and desired end states but close
coordination to synthesize and produce statements promptly. [If the U.S.
is]{.underline} always [the loudest voice criticizing the regime and if
every infraction meets with aggressive overtures, even our staunchest
allies could grow weary and struggle to discern significant issues
amongst the white noise]{.underline}. The delivery mechanism and the
tone of delivery matter. **[Trusting our allies]{.underline}**, those
with shared values[, to find their voice and offer broader criticism of
China is another means of achieving the desired end of holding the
regime accountable]{.underline}. [The byproduct]{.underline} of such an
approach [is the perceived messaging to younger Chinese]{.underline}, as
the "worldview they're exposed to is one in [which foreign
criticism]{.underline} of the Chinese government [is often]{.underline}
reflexively [thought to be backed by the U.S.]{.underline} government"
and criticism of the CCP is viewed as anti-Chinese.

**Offcase**

**Kritiks**

**[2AC -- Our research is good]{.underline}**

**Our research is good -- The 1AC's focus on responsible ways to govern
AI fuses STS research into military studies. This is
*[UNIQUELY]{.underline}* good because it spills over into NATO military
planning.**

- STS studies = Science, technology, and society studies

- RRI = responsible research and innovation---Focused on responsible
  innovation

- Military focus on deterrence and defense -- core to its mission

- A interdisciplinary approach would bridge the divide and promote
  desired goals at the expense of undesired goals

- That creates spillover effects to NATO overall

**Stanley-Lockman & Trabucco 3/22**

Zoe Stanley-Lockman & Lena Trabucco , "NATO's Role in Responsible AI
Governance in Military Affairs", Zoe Stanley-Lockman Nanyang
Technological University, Lena Trabucco University of Copenhagen, Center
for Military Studies The Oxford Handbook of AI Governance Edited by
Justin Bullock, Yu-Che Chen, Johannes Himmelreich, Valerie M. Hudson,
Anton Korinek, Matthew Young , and Baobao Zhang Subject: Political
Science, Political Institutions Online Publication Date: Mar 2022DOI:
10.1093/oxfordhb/9780197579329.013.69 -- ECM

AI Governance and Military Affairs: Tensions in Existing Literature

[Academic lit]{.underline}erature [has long grappled with]{.underline}
the intersection of **[emerging technology and security]{.underline}**
organizations.13 [Two branches of lit]{.underline}erature that **[tackle
core questions]{.underline}** [of tech]{.underline}nological
trajectories [and its relationship to human and social
structures]{.underline}---a critical question of governance for military
technology---**[are STS studies and military innovation
scholarship]{.underline}**. Although the theoretical approaches in STS
and military innovation studies differ, they [both share the important
assumption that tech]{.underline}nology does not have its own innate
logic, and instead measure technological change by its impact on social
structures and interactions with humans. In other words, both fields
treat technology **[as an enabler in broader structures]{.underline}**.
The term [tech]{.underline}nology **[is ubiquitous enough that it does
not have a single definition]{.underline}**, but it is often defined in
relation to human intention and purpose. Alex [Roland describes
tech]{.underline}nology [as a "**purposeful human manipulation of the
material world**]{.underline}" [to "**serve some human
purpose**."]{.underline}14 If extending this basic idea of technology to
technological innovation, then both STS studies and military-innovation
scholarship lend relevant criteria.

Both academic fields are also relevant because, [in the policy
space]{.underline}, [AI governance stakeholders are pursuing responsible
research and innovation (**RRI**)]{.underline}, [which comes from STS
studies]{.underline}, [and defense]{.underline} stakeholders
[are]{.underline} similarly [focused on responsible
innovation]{.underline} and responsible use. More traditionally, the
direct study of **[military adoption of tech]{.underline}**nology [is
considered]{.underline} in the [separate]{.underline} scholarship of
military innovation, which includes a school of thought that focus on
cultural and organizational factors. Between these two fields, **[an
interdisciplinary approach is helpful here to carry STS approaches to AI
governance]{.underline}**, including RRI, **[over to the space of
military innovation]{.underline}**.

However, [this is complicated by]{.underline} the [reality]{.underline}
[that military organizations]{.underline} that [see
tech]{.underline}nological superiority **[as a core element of
deterrence and defense]{.underline}**, [including NATO]{.underline},
[engage in forms of tech]{.underline}nological [determinism that STS
scholars squarely reject]{.underline}. Respective views on technological
determinism---which considers that technology shapes society as a
largely autonomous process with limited human agency---[thus creates a
tension for governance prospects]{.underline}.15 To spotlight the
aspects of military innovation related to governance, this section
briefly expands on the overlaps and tensions between STS and military
innovation literature.

Science, technology, and society (STS) studies

[STS studies]{.underline} is [help]{.underline}ful [to understand how
tech]{.underline}nologies such as AI develop [relative to the human,
social, and political structures]{.underline} that shape it, rather than
as an independent entity to which humans have to adapt.16 In this vein,
[AI is not just a computational process]{.underline} involving software,
hardware, and data,17 so much it is a socio-technical system that
encompasses "human, social, and organizational factors."18 Together,
these factors enable a focus on the trajectory of technological
development relative to social structures and power dynamics.
[STS]{.underline} scholars [have]{.underline} also **[helped develop RRI
frameworks]{.underline}** [that seek to guide tech]{.underline}nological
[development in]{.underline} **[anticipatory, participatory, and
adaptive frameworks to achieve desirable outcomes and prevent
undesirable ones]{.underline}**.19 RRI is a structured approach to
innovation in which stakeholders identify and act on their "collective
commitment of care for the future through responsive stewardship of
science and innovation in the present."20 **[It drives civilian AI
ecosystems for NATO Allies that will also indirectly affect
NATO]{.underline}**.21

**[2AC -- Perm Solvency]{.underline}**

**Perm solves -- military planners will dominate SQ research absent the
aff. This turns all their link arguments. The perm research a necessary
blueprint not to reconcile but to harness the best of both worlds to
develop effective governance strategies which NATO is uniquely receptive
too.**

- Norms for AI remain immature

- RRI drives stakeholders to act responsibility

- Military stakeholders shape military research based on military
  advantages

- The refusal to engage BOTH risk alternative failure -- the 1AC
  research method provides a necessary blueprint not to reconcile but to
  harness the best of both worlds to develop effective governance
  strategies.. this is uniquely good because NATO is receptive to these
  types of tactics

- corrigibility = capable of being corrected, reformed, or improved.

**Stanley-Lockman & Trabucco 3/22**

Zoe Stanley-Lockman & Lena Trabucco , "NATO's Role in Responsible AI
Governance in Military Affairs", Zoe Stanley-Lockman Nanyang
Technological University, Lena Trabucco University of Copenhagen, Center
for Military Studies The Oxford Handbook of AI Governance Edited by
Justin Bullock, Yu-Che Chen, Johannes Himmelreich, Valerie M. Hudson,
Anton Korinek, Matthew Young , and Baobao Zhang Subject: Political
Science, Political Institutions Online Publication Date: Mar 2022DOI:
10.1093/oxfordhb/9780197579329.013.69 -- ECM

[Responsible]{.underline} stewardship, or [governance]{.underline}, of
science and technology (S&T) [requires stakeholders to change their
approaches to tech]{.underline}nological development as the
circumstances themselves change.22 In his book The Social Control of
Technology, David Collingridge identified the double bind that makes
technology governance (what he then referred to as social control)
difficult: exerting social control or governing nascent technology is
easy, but impossible because its evolution and eventual impacts are
unknowable, and by the time the technology matures and its impact is
realized, entrenched decisions will make future control more
difficult.23 For now, [AI remains]{.underline} a [relatively
immature]{.underline} technology, **[meaning
circumstances]{.underline}** will **[change as knowledge emerges and
norms]{.underline}** progressively **[develop]{.underline}**.
Collingridge also suggested the necessity of "[corrigibility of
innovation]{.underline}," which refers to [the]{.underline} "[capacity
to change shape or direction in response to]{.underline} stakeholder and
public values and changing [circumstances]{.underline}."24 [When applied
t]{.underline}o current **[RRI]{.underline}** frameworks, [the concept
of corrigibility obligates]{.underline} governance [stakeholders to
shape the trajectory of a tech]{.underline}nology's development and
impact **[in ways based on social structures]{.underline}**, both in
anticipation of change and in response to decisions made in error.25 In
short, [stakeholders have to]{.underline} adopt corrigible practices to
responsibly [govern tech]{.underline}nology [as it develops, and thus
must claim their agency in guiding innovation even as]{.underline}
technological [development appears increasingly entrenched]{.underline}
in previously made decisions and their subsequent outcomes.

This is important for AI governance because [tech]{.underline}nological
**[advancement is making AI-accelerated risks clearer, including in the
military space]{.underline}**.
[Risks]{.underline}---[especially]{.underline} as related to AI-enabled
[autonomous systems]{.underline}, [poisoning of info]{.underline}rmation
environments, **[cyberattacks, unpredictable failure modes, and emergent
behavior]{.underline}**---will evolve in form and scale as the
technology matures and diffuses. If AI evolution means more entrenchment
and less corrigibility, the STS foundations remind governance
stakeholders how to course-correct and adapt to changing risk
assessments and the overall impact of AI in the international system.26

Nevertheless, [while STS scholars study]{.underline} how
[decision-making]{.underline} that shapes the trajectory of
technological innovation becomes entrenched, [the field largely rejects
the premise of]{.underline} technological [determinism]{.underline}.
Maintaining the centrality of human agency, as exerted also through
social structures and institutions, is antithetical to determinist
perspectives on technology developing on its own path independent of
intervention. As Allan Dafoe, another contributor to this Handbook, has
argued, the STS academic community's refusal to engage with
technological determinism severely limits STS applicability to
empirics.27 As discussed below, [this has implications for]{.underline}
the ability of the STS field to impart [responsibility to
govern]{.underline}ance stakeholders in an area such as **[AI and
international security]{.underline}**.

Military innovation literature

The scholars that examine [the way]{.underline} that [military
stakeholders manage tech]{.underline}nology and shape its development
trajectory **[predominantly write on military
innovation]{.underline}**.28 [These scholars measure
tech]{.underline}nology adoption [in changes to doctrine, organizational
structures, and operational concepts, rather than seeing the
tech]{.underline}nology [as an end in and of itself]{.underline}.29 From
this perspective, technology subsequently shapes human and social
structures and organizations. To take an example similar to Roland's
definition of technology, Jonathan Shimshoni's concept of "military
entrepreneurship" involves the active manipulation of technology,
doctrine, and war plans.30 In this sense, new technology adoption has
tangible and observable effects on the operational environment.
Similarly, Thomas Mahnken illustrates that **[military services shape
tech]{.underline}**nology **[to their respective purposes, rather than
the other way around]{.underline}**.31 [The purpose]{.underline} that
this manipulation, or molding, of technology [serves]{.underline} is
[the creation, and]{.underline} ideally [sustainment]{.underline}, [of
a]{.underline} comparative [military advantage]{.underline}.32

Still, the way that this military advantage is defined is relevant here
because metrics of success differ from other scholarship dealing with
innovation. Military innovation importantly constitutes the relationship
and social structures that form between technology and military
bureaucracies. Yet as a field, it does not necessarily extend these
relationships to their status as stakeholders in wider technology
governance regimes.33 For instance, in his review of the different
schools of military innovation, Adam Grissom offers a consensus
definition of military innovation that inherently links it to
effectiveness in the battlespace.34 Grissom clarifies that "measures
that are administrative or bureaucratic in nature, such as acquisition
reform, are not considered legitimate innovation unless a clear link can
be drawn to operational praxis."35 This reinforces the idea that
technology on its own does not constitute an innovation if it is not
observable in military operational practice or in battlefield advantage.

The relatively narrow operational focus of military innovation
scholarship means that management structures miss out on some of the
uses of military power implicit in the governance of military
technology. This means that both the bureaucratic entrenchment of
technological advancement and the literature focusing on it do not
necessarily address governance as an instrument of power in the military
context. This may make sense for purely military technologies, but
whether it discounts the agency that military bureaucracies have in
governance of a pervasive, general-purpose technology like AI is worth
separate consideration. As such, the operational measurement of the
adoption and diffusion of technology as an instrument of military power
likewise limits an understanding of how military technology management
structures relate to governance.

Implications for military AI governance

Overall, [STS offers]{.underline} much of [the necessary groundwork for
governance]{.underline} mechanisms and the impact of social structures
on technology governance; **[however]{.underline}**, [it refuses to
engage with]{.underline} technological [determinism]{.underline}, or the
independent influence of technology, that is often **[a driving force in
military innovation]{.underline}**. Recognizing that a comprehensive
governance regime also needs to transpose to stakeholders that are
engaged in the practices of governing AI, **[this study on NATO sees
military innovation scholarship as a helpful complement to apply these
STS foundations to practitioners' perspectives]{.underline}**. But
scholarship on military innovation also has its own flaws, in that it
looks at the management of technology exclusively formulated to exploit
a comparative operational advantage. Measuring military innovation in
relation to operational praxis makes sense to detect how military
adoption of technology impacts operational excellence and upstream
impacts on military strategy, but also makes it challenging for the
empirics to apply to non-operational ways that military organizations
exert their influence. Non-operational influence includes governance,
the core topic that this chapter addresses.

Despite differences, [borrowing from]{.underline} the layered
**[frameworks in STS and military innovation studies still helps
contextualize innovation trajectories]{.underline}**. Indeed, select
scholars have attempted to bridge the gap between the social
constructivist angle in STS studies and the technologically
"optimistic"36 assumptions that frame technologically deterministic
undercurrents, as seen in case studies on military innovation.37 Thomas
Hughes examined these undercurrents in the defense sector as part of his
theory of "technological momentum,"38 which argued military
organizations are subject to inaction in S&T decision-making because the
entrenchment of previous investments and decisions constrain the course
of future technological development. Steven Fino expands on Hughes with
the idea that "technological dislocations," are an alternative
reconciliation mechanism that acknowledges that technological
determinism may operate beneath the surface of a technology's maturation
trajectory, while still allowing for socially driven perturbations that
"dislocate" the "otherwise logical evolutionary patterns" of that
technology.39

Dafoe similarly attempts to widen the scope of technological determinism
by placing it as an endpoint on a spectrum, with social constructivism
on the other end. The purpose of this spectrum is to create the space
for engagement with disciplines that heavily emphasize power dynamics,
including military affairs and business in what he terms
"military-economic adaptationism."40 Unfortunately, both Fino and Dafoe
concede that attributing agency and causality to technological
developments are best "conducted after the fact"41 or "on longer
timescales," respectively.42 AI governance cannot benefit from such
hindsight, as it is fundamentally a question of how to project and adapt
to forces of ongoing change. For governance, this inertia places
military organizations at odds with the responsiveness required to guide
responsible technology governance frameworks. **[Our aim is not to
reconcile]{.underline}** these differences in this chapter,
[but]{.underline} rather to [highlight how they frame one current
governance challenge for]{.underline} military stakeholders such as
[NATO]{.underline}: [how can they engage with]{.underline} the
socio-technical foundations in [RRI frameworks to shape, adapt to, and
respond to tech]{.underline}nology-accelerated [changes]{.underline},
**[while simultaneously]{.underline}** pursuing their traditional aims
of **[adopting tech]{.underline}**nology **[to deter and
defend]{.underline}**?

On this note, it is worth mentioning that **[NATO]{.underline}** itself
[has historically convened scholars from both]{.underline} STS and
military innovation [backgrounds to understand socio-technical changes
to their]{.underline} operating [environment]{.underline}.43 The
Alliance also takes socio-technical factors into account in its S&T work
on emerging technologies---including human--systems integration,
technology monitoring, and forecasting work.44 This interest in
socio-technical systems relating to effectiveness suggests scope for the
Alliance to leverage technology governance as an instrument of its
influence, as picked up in the next section.

**Case Neg -- Mean Green Debate**

**Case -- Cyber**

**[1NC vs Cyber ADV]{.underline}**

**New Russian attacks wont reach the threshold of article V**

**The Hill 6/14**/2022

"Finland, Sweden's NATO moves prompt fears of Russian cyberattacks",
<https://thehill.com/policy/cybersecurity/3488518-finland-swedens-nato-moves-prompt-fears-of-russian-cyber-attacks/>

[Finland and Sweden's move to join NATO]{.underline} has [raised
concerns about potential cyber retaliation from Russia]{.underline},
which sees the expansion of the alliance as a direct threat.

While [**it is too early to judge** how Russia might try to use its
cyber capabilities against]{.underline} **[Finland, Sweden or other NATO
members]{.underline}**, including the [U.S., experts said it will likely
launch unsophisticated and small-scale cyberattacks as a form of
protest]{.underline} against the expansion.

**[Such attacks would not have the severity of cyber
efforts]{.underline}** Moscow **[launched against Ukraine]{.underline}**
amid the Russian invasion of that country.

**No cyber war or retaliation**

**Rodet 18**

Jasmine, Master's Degree in Cyber Security, Strategy, and Diplomacy from
the University of New South Wales, Cyber Security Program Manager at
Fortescue Metals Group, "The Threat of Cyber War is Exaggerated",
11/11/2018,
linkedin.com/pulse/threat-cyber-war-exaggerated-jasmine-rodet/

For the regular person on the street, the term 'cyber war' is more
likely to bring to mind the 1983 movie "WarGames" and the [doomsday
articles]{.underline} that [appear regularly in the media about the
'cyber battlefield' and]{.underline} an [impending World War
III]{.underline}. This essay argues that [the threat of cyber war is
**exaggerated**]{.underline} [and]{.underline} although it can, by
definition, be stated that we are already in a state of cyber war, the
impact on states is **[negligible]{.underline}** compared to
conventional war domains.

The argument is presented in 3 steps. The first step is to define cyber
war and cyber weapons, referencing scholars and experts in the area of
conventional war and the cyber domain. The second step is to explore who
has been exaggerating the threat of cyber war and what their motivations
might be. The third is to explore the evidence and quantify the
probability and impact that cyberwar has had on states to date.

'Cyber war' is a term often used interchangeably in media with
cyber-crime, cyber-attacks, cyber-conflict and cyber-incidents, creating
confusion amongst the public and scholars alike. Clausewitz (1989, 75),
in his book, On War, defines war as 'an act of force to compel the enemy
to do our will'. Rid (2012, 7) on the other interprets Clausewitz use of
'force' as meaning 'violent' force. According to Rid, if an act is not
potentially violent, it is not an act of war. However, Stone (2013, 107)
describes 'cyber war' as a politically motivated act of force, not
necessarily lethal and not necessarily attributable. The definition by
Powers and Jablonski states more simply that cyber war is the
utilisation of digital networks for geopolitical purposes (Nocetti 2016,
464). Neither of the latter two definitions requires violence to qualify
as cyber war. Under these definitions, the Stuxnet cyber-incident in
2010 and the Estonia incident in 2007 would constitute an act of cyber
war, and as such we could say that nations have been at cyber war in the
past and are likely to continue to engage in cyber war in years to come.

For this essay, I will use Stones definition to argue that even though
states may engage in cyber war, the concept of cyber war is exaggerated.
It seems that [cyber war is **deliberately exaggerated** in the media
and by politicians for **financial** and **political**
gains]{.underline}. There are countless examples in the media and in
politics of the exaggeration of the threat of cyber war and the language
used plays a big factor in creating a sense of fear in the community.

The Four Corners report, Hacked, is a classic example where the
reporter, Andrew Fowler describes the current situation in Australia as
'... a secret war where the body count is climbing every day' (Fowler
2013). The documentary reveals nothing violent or lethal about cyber
incidents. The documentary is actually about hackers working from
locations overseas, having targeted key Federal Government departments
and major corporations in Australia.

In another example, NATO may be interpreted as exaggerating the threat
of Cyber War when they invited Charlie Millar to present at their
Conference for Cyber Conflict at the NATO Cooperative Cyber Defence
Centre of Excellence in 2017. Millar is an independent security
evaluator, and his presentation was titled 'Kim Jong-il and me: How to
build a cyber army to attack the US'. He later presented similar content
at Def Con 2018. His presentation described the steps he would take to
mount a cyber war, including the types of people he would engage, how
much he would pay them, what his strategy would be and how much it would
cost in total.

Who stands to gain from the exaggeration and hype? Logically, [one group
would be those that gain financially from the sale of cyber protective
services and software]{.underline}. According to Valerino, 57% of
technical experts surveyed said that we are currently in a cyber arms
race and 43% said that the worst-case scenarios are inevitable
(Valeriano and Ryan 2015). Translate this into sales and Gartner
projects worldwide security spending will reach \$96 Billion in 2018, up
8 Percent from 2017 and to top \$113 billion by 2020 (Gartner 2017).

Additionally, [there may be **political motivations** to exaggerate the
threat of cyber war]{.underline}. Cyberspace is not well understood by
the general public and fear is natural. In the US's cyber security
debate, observers have noted there is a tendency for policymakers,
[military leaders, and media]{.underline}, among others, [to use
frightening 'cyber-doom scenarios' when making a case for action on
cyber security]{.underline} (Dunn 2008, 2).

There is some evidence to suggest that more recently in the political
arena; we may be maturing in our understanding of the real threat of
cyber war. The Tallinn Manual, an academic, non-binding study on how
international law applies to cyber conflicts and cyber warfare, was
written at the invitation of the Tallinn-based NATO Cooperative Cyber
Defence Centre of Excellence. It was first published in 2013 with the
title 'The Tallinn Manual on the International Law of Cyber War'. In
2017, it was re-released with the revised title 'Tallinn Manual 2.0 on
the International Law of Cyber Operations'. The change in title from
'war' to 'operations' signifies a more moderate use of language from
NATO and is an acknowledgement that cyber incidents generally fall below
the threshold at which International Law would declare them to be a
formal act of war. Experience over the 4 short years from 2013 to 2017
has demonstrated that cyber incidents tend to have a low-level impact on
the target state. As the book's authors put it 'the focus of the
original Manual was on the most severe cyber operations, those that
violate the prohibition of the use of force in international relations,
entitle states to exercise the right of self-defence, and/or occur
during armed conflict' while the new version 'adds a legal analysis of
the more common cyber incidents that states encounter on a day-to-day
basis and that fall below the thresholds of the use of force or armed
conflict' (Leetaru 2017).

To get a better sense if cyber war is exaggerated, we must also consider
the probability of cyber war in the future. The probability of cyber war
should be weighed up against the probability of conventional war. Where
tensions are already high, for example, between North Korea and the US
or Russia and Estonia, I would argue that cyber war is more likely than
conventional war. This is due to factors including; cyber warfare is
less costly than conventional warfare, states are less rational in their
decision space in the cyber realm, states find cyber attribution very
difficult to achieve so attacks can be undertaken covertly and cyber war
is considered 'a challenge' and central to the hackers' ethos (Junio
2013, 128). Further, Sanger describes in his book, The Perfect Weapon,
cyber weapons (such as cyber vandalism, Distributed Denial of Service
(DDOS), intrusions and advanced persistent threat (APT)) as the 'perfect
weapons' for the following reasons;

They are cheap: When compared to Nuclear weapons, there are only a
handful of nations globally that can afford the technology to create a
nuclear weapon.

They are easily accessible: Unlike a Nuclear bomb that requires uranium,
a highly protected metal, in the production process, a cyber weapon can
be created with minimal investment and highly available IT
infrastructure.

They can be dialled-up or dialled-down relatively easily. A ballistic
missile, the force of the explosion cannot be adjusted as easily as a
DDOS attack. A DDOS attack can be adjusted to last an hour, a few days
or a few weeks.

They have a huge range in how they are used: Sabotage as with Stuxnet,
Espionage as with the Chinese industrial spying on the US, North Korea's
infiltration of Sony, the Iranians attack on Las Vegas Sands Corp.
casino operators.

The significant factor is that cyber weapons can and are being used
every day for discrete, [**low-level** cyber conflicts]{.underline} to
undermine and disrupt rivals, but historically it [has **not
progressed** to open conflict, nor has it **warranted** a **military
response**]{.underline} (Sanger 2018). [Additionally, massive cyber
operations would necessarily impact the civilian population and violate
the immunity of non-combatants. The conditions of war dictate that this
is **"taboo"** and to date, rival states have **shown restraint** in
their use of cyber weapons for this reason]{.underline} (Valeriano and
Ryan 2015). [It appears that the threat that cyber weapons represent to
national security is overstated and the threat of cyber war is
**overstated**]{.underline}.

[The US and]{.underline} likely [other **highly networked nations**
appear **reticent**]{.underline} about using cyber weapons for
significant cyber conflict [given their
**vulnerabilities**]{.underline}. Ironically, NSA programs such as PRISM
have made the US more of a target given the sheer volume of sensitive
information stored in one place. Regardless of US defences, there is no
way to make this information completely secure from intrusion, and as
such, the very act of storing the information makes them more
vulnerable.

Rid (2012) is among some academics who argue that [cyber
war]{.underline} has never and [will likely **never
eventuate**]{.underline}. The benefits of being on this side of the
debate mean that public funding can be allocated away from offensive
cyber security initiatives to other, potentially more important
initiatives, such as public health and housing. The government is
constantly under pressure to prioritise public spending and it is
imperative that they have realistic, accurate projections regarding the
risk of cyber war, the probability and the impact, to allow them to
focus spending on the most important areas.

**Cyber threats are *[OVERBLOWN]{.underline}* -- most recent studies
prove**

**Maschmeyer & Kostyuk 2/8**/2022

Lennart Maschmeyer is a senior researcher at the Center for Security
Studies at ETH Zurich. He holds a Ph.D. from the University of Toronto
and co-chairs the FIRST Threat Intel Coalition as well as the European
Cybersecurity Seminar. Nadiya Kostyuk is an assistant professor at the
School of Public Policy and the School of Cybersecurity and Privacy at
the Georgia Institute of Technology. She directs the Cybersecurity
Summer Institute and co-chairs the Digital Institute Discussion Group.
She holds a Ph.D. from the University of Michigan. "THERE IS NO CYBER
'SHOCK AND AWE': PLAUSIBLE THREATS IN THE UKRAINIAN CONFLICT",
<https://warontherocks.com/2022/02/there-is-no-cyber-shock-and-awe-plausible-threats-in-the-ukrainian-conflict/>
\-- ECM

[The specter of cyber war is back]{.underline}. Not only does Russia's
massive military buildup along Ukraine's borders bring a growing risk of
the largest-scale military clash since World War II, but many analysts
stress the potential for destabilizing and devastating cyber-attacks in
its wake. Jason Healey predicts that if Russia invades, "the opening
salvo is likely to be with offensive cyber capabilities." William
Courtney and Peter A. Wilson from RAND warn of the "massive employment"
of cyber warfare tools to create "shock and awe causing Ukraine's
defenses or will to fight to collapse." Accordingly, the United States
and the United Kingdom have deployed cyber warfare teams to help Ukraine
defend against an impending strategic cyber strike against critical
infrastructure. [Some]{.underline} go further, [suggest]{.underline}ing
[that Russia may not need to use military force]{.underline} at all,
[because cyber strikes can]{.underline} "achieve much **[the same
effect]{.underline}** from across the border." [This assessment
is]{.underline} apparently [shared by]{.underline} policymakers working
on countering [the]{.underline} Russian threat to Ukraine, with an
(anonymous) senior [Biden administration]{.underline} official recently
stating as much.

These predictions suggest that cyber operations will provide significant
strategic advantages to Russia either as complements to military force,
or as standalone instruments --- or at least that policymakers and
commentators think that they will. Current [warnings of escalating cyber
warfare conjure deep-seated fears of cyber doom and the]{.underline}
recurring [specter of a]{.underline} "**[cyber Pearl
Harbor]{.underline}**" strategic surprise attack. In practice,
**[however]{.underline}**, **[cyber warfare has been a
failure]{.underline}**. Our [research shows]{.underline} **[that cyber
operations have remained irrelevant on the battlefield]{.underline}**,
while standalone operations to weaken Ukraine through election
interference, critical infrastructure sabotage, and economic disruption
largely failed to contribute to Russia's strategic goals of making
Ukraine abandon its pro-European Union and pro-NATO foreign policy.
Consequently, current fears of cyber warfare defy not only Russia's
track record in Ukraine, but also strategic logic. [Given that Russia's
cyber op]{.underline}eration[s]{.underline} **[have
failed]{.underline}** to produce significant strategic value to date,
**[why would we expect this to suddenly change now]{.underline}**? Or,
to put it more pointedly: If cyber operations offer such effective and
potent instruments, why did Russia go through the trouble (and costs) to
mobilize its troops? **[Current predictions of cyber onslaught do not
offer a persuasive answer]{.underline}**.

Giving in to these fears risks fighting phantom threats, playing into
Russia's hands by distracting from the need to counter its military
threat and sowing fear and confusion --- at least among Western
audiences. A level-headed analysis of the threat that distinguishes what
is theoretically possible from what is practically feasible is urgently
needed. Our [research suggests]{.underline} that, [contrary to
hysteria]{.underline}, [cyber op]{.underline}eration[s **will remain of
secondary importance**]{.underline} and at best provide marginal gains
to Russia.

**[2NC/1NR -- Cyber Attacks wont trigger Article V]{.underline}**

**New attacks against NATO, Finland, or Sweden are
*[UNLIKELY]{.underline}* to trigger article V**

**The Hill 5/14**/2022

"Finland, Sweden's NATO moves prompt fears of Russian cyberattacks",
<https://thehill.com/policy/cybersecurity/3488518-finland-swedens-nato-moves-prompt-fears-of-russian-cyber-attacks/>

"I think [it's unlikely that Russia will launch]{.underline} the types
of [cyberattacks against Finland and Sweden like]{.underline} it did
with [Ukraine]{.underline}, primarily **[because the aims are
different]{.underline}**," said Jason Blessing, a fellow at the American
Enterprise Institute.

Blessing said that since [Russia has no intention]{.underline}, at least
for the moment, [to invade]{.underline} Finland or Sweden, it may use
different cyber tactics than it did with Ukraine to get its message
across.

He added that it's likely [that Russia will launch
unsophisticated]{.underline} types of [attacks]{.underline} including
website defacement and distributed denial-of-service attacks to disrupt
its enemies' networks [rather than]{.underline} starting a **[full-scale
cyber warfare]{.underline}**.

**Russian cyberattacks on Finland and Sweden wont trigger follow-up
military actions**

**Orenstein 6/7**/2022

Mitchell Orenstein is a Senior Fellow at FPRI's Eurasia Program and
Professor and Chair of Russian and Eastern European Studies at the
University of Pennsylvania, "Russia's Use of Cyberattacks: Lessons from
the Second Ukraine War",
<https://www.fpri.org/article/2022/06/russias-use-of-cyberattacks-lessons-from-the-second-ukraine-war/>
\-- ECM

[Russia]{.underline} also [deploys cyberattacks as a]{.underline}
poignant warning or **[threat]{.underline}**, often to put more force
behind diplomatic actions.

For instance, [on April 8]{.underline}, 2022, while Ukrainian President
Zelensky gave an invited address to the Finnish Parliament, [the Finnish
foreign and defense ministries were hit by a distributed denial of
service attack]{.underline}. Finnish government systems were back up in
an hour, but given the circumstances, this cyberattack appears to have
been designed to signal Russia's displeasure with Finland's plans to
join NATO and its support of Ukraine. [This attack was presaged by
Russian diplomatic statements warning Finland of]{.underline}
"**[retaliatory steps" to joining NATO]{.underline}**. To date, it
remains the only significant cyberattack against Finland or Sweden as
they planned their applications to join the alliance. [This attack bears
similarities to other instances where Russia used
cyberattacks]{.underline} to emphasize diplomatic warnings.

Following the 2015 doping scandal that resulted in the Russian Olympic
team being banned from the Olympics through 2022, Russian military
intelligence launched a significant cyberattack against the Swedish
Sports Confederation while Sweden was issuing a bid to host the 2026
Winter Olympics. These cyberattacks were part of a "systematic campaign"
targeting FIFA, the World Anti-Doping Agency, and the United States
Anti-Doping Agency in furtherance of diplomatic goals rather than
military or societal disruption.

Three Distinct Uses of Cyberattacks

Russia uses cyberattacks in three different ways. First, it deploys
cyberattacks to prepare and facilitate military conflict by attacking
critical infrastructure such as government websites, IT servers, banks,
media outlets, and power plants. [As the]{.underline} Second [Ukraine
War shows]{.underline}, [Russia seeks to disrupt]{.underline} and
disable **[critical infrastructure to advance its military
goals]{.underline}**.

[Russia]{.underline} also deploys cyberattacks **[as part of a hybrid
war strategy]{.underline}** that substitutes for war. These attacks may
be persistent over longer periods of time. However, Russia deploys
cyberattacks in smaller quantities and often combined with other hybrid
or political war techniques, such as disinformation campaigns and civil
actions in targeted countries. **[In these instances]{.underline}**,
**[Russia does not]{.underline}** [appear to intend imminent military
action]{.underline}, but may seek to degrade defensive capabilities.

Cyberattacks may also be deployed as a more isolated threat signal and
complement to diplomatic warnings, when a country takes actions that
Russia interprets as unfriendly. For these purposes, [cyberattacks are
more frequently combined with traditional diplomacy]{.underline}.

**[2NC/1NR -- XT 2 & 3 No Escalation]{.underline}**

**Empirics prove -- You should subscribe a low risk to their advantage**

**Orenstein 6/7**/2022

Mitchell Orenstein is a Senior Fellow at FPRI's Eurasia Program and
Professor and Chair of Russian and Eastern European Studies at the
University of Pennsylvania, "Russia's Use of Cyberattacks: Lessons from
the Second Ukraine War",
<https://www.fpri.org/article/2022/06/russias-use-of-cyberattacks-lessons-from-the-second-ukraine-war/>
\-- ECM

**[The empirical record of cyber conflict]{.underline}**, however,
[suggests that what is feasible]{.underline} in practice
[is]{.underline} far more **[limited]{.underline}**. [Ukraine has been
a]{.underline} "giant [test lab]{.underline}" where Russia, one of the
world's foremost cyber powers, has experimented with cyber operations
for eight years. Yet [these op]{.underline}eration[s]{.underline}
**[have failed]{.underline}** [to produce significant strategic
value]{.underline} either as force complements or standalone tools.

The substitutability argument --- that states can or do substitute cyber
operations for the use of force --- has little empirical support since
Russia levied no major cyber operations against Ukraine in the runup to
the military escalation of the conflict in 2014. While it is possible
that we do not know about such operations given their veil of secrecy,
it is clear that any attempted but undetected cyber surprise strike
failed to produce any measurable effects.

Evidence supporting the complementarity perspective is similarly
sobering. One of us has examined the role of low-level disruptive cyber
operations in the military conflict and their relevance for battlefield
events (and outcomes). [Disruptive attacks can]{.underline} directly
[affect military op]{.underline}eration[s]{.underline} as they seek to
sabotage an opponent's ability to fight. For example, the Russia-backed
separatists in the Donbas and Luhansk regions used malware to retrieve
data from mobile devices on the locations of Ukrainian artillery troops,
facilitating better reconnaissance against these troops. Pro-Ukrainian
hackers hijacked CCTV cameras behind enemy lines to obtain intelligence
on the movement of Russian artillery in the separatist-controlled
territories.

Focusing on the period of the most intense fighting, between 2014 and
2016 --- the time when, if cyber tools are an effective complement to
armed force, Russia would have been most likely to use them --- we
applied a series of statistical tests to thousands of cyber and military
operations. **[The findings showed a strong, escalatory dynamic between
military operations by both sides but no significant correlation in
either direction between military and cyber operations]{.underline}**,
**[and no reciprocity between cyber
op]{.underline}**eration**[s]{.underline}**. This evidence demonstrates
that in one of the first armed conflicts where both sides used low-level
cyber operations extensively, digital operations unfolded independently
from the events on the ground and had no discernible effect on them.
Hence, in stark contrast to expectations about the force-multiplying
advantages of cyber operations, [these findings suggest hacking groups
faced considerable difficulties in responding to battlefield events,
much less shaping them]{.underline}.

**Limiting challenges mean no risk of cyber doom**

**Orenstein 6/7**/2022

Mitchell Orenstein is a Senior Fellow at FPRI's Eurasia Program and
Professor and Chair of Russian and Eastern European Studies at the
University of Pennsylvania, "Russia's Use of Cyberattacks: Lessons from
the Second Ukraine War",
<https://www.fpri.org/article/2022/06/russias-use-of-cyberattacks-lessons-from-the-second-ukraine-war/>
\-- ECM

[Considering the underwhelming track record of cyber
warfare]{.underline} in Ukraine to date, **[there is little reason to
expect cyber doom of the kind]{.underline}** that some now predict. For
these warnings of a Russian cyber onslaught to become reality, cyber
operations would need to produce effects at a scope and scale that they
have previously failed to attain. Importantly, [current warnings fail to
make a persuasive case on why we should expect such a
transformation]{.underline}.

Rather, they rest on the implicit assumption that with the change in
strategic context, the role of cyber operations will change as well.
This comes out clearest in Maggie Miller's recent commentary suggesting
that [military escalation in Ukraine would finally herald "**a true
cyberwar**"]{.underline} where Russia could "take down the power grid"
or launch a disinformation campaign to undermine the government in Kyiv.
Dmitri Alperovitch offers a more level-headed analysis, underlining that
cyber operations alone will fall short of achieving Russia's goals.
However, he also suggests that they can complement force as an
"extension of warfare itself," disrupting command and control to provide
battlefield advantages, sabotaging critical infrastructure, and
undermining public trust in the government to "send a powerful signal
that resistance is futile." **[Yet]{.underline}**, as we have seen,
[Russia has]{.underline} attempted most of these objectives in the past
and has [failed. Even in a full-scale invasion]{.underline}, we have the
same aggressor, with the same hacking groups, with the same skill level
going after the same sets of possible targets. [Why would we expect
different]{.underline} results?

Changing the strategic context of deployment does not change the
mechanism of action that cyber operations rely upon to produce outcomes
--- and its intrinsic constraints. [Cyber
op]{.underline}eration[s]{.underline} [rely on a mechanism of
subversion]{.underline} that exploits vulnerabilities in adversary
systems to use them against the adversary. [This mechanism
holds]{.underline} great strategic promise but poses **[significant
operational challenges]{.underline}**. It requires creativity and
cunning to remotely manipulating complex systems that others designed
and operate without alerting the victim to one's presence. These
challenges produce an operational trilemma between the speed, intensity
of effects, and level of control that actors have over these effects.
This trilemma limits strategic value, since **[in most
circumstances]{.underline}** [cyber
op]{.underline}eration[s]{.underline} [will be **too slow, too weak, and
too volatile**]{.underline} [to contribute]{.underline} measurably [to
strategic goals]{.underline}. The constraining role of this trilemma is
evident across all five of Russia's disruptive cyber operations against
Ukraine thus far, underlining their relevance. Importantly, [**all
available** evidence indicates that]{.underline} these [intrinsic
constraints limit the strategic value of cyber operations]{.underline}
regardless of strategic contexts.

**No large-scale cyber-attacks or retaliation**

**Nye 19**

Dr. Joseph S., Jr., University Distinguished Service Professor and
Former Dean of the Kennedy School of Government at Harvard University,
"Global Cyber Conflicts Will Be Hard To Control", The Statesman
(Pakistan), 10/14/2019, Lexis

[The problem of perceptions and controlling escalation is not
new]{.underline}. In August 1914, the major European powers expected a
short and sharp "Third Balkan War." The troops were expected to be home
by Christmas. After the assassination of the Austrian archduke in June,
Austria-Hungary wanted to give Serbia a bloody nose, and Germany gave
its Austrian ally a blank check rather than see it humiliated. But when
the Kaiser returned from vacation at the end of July and discovered how
Austria had filled in the check, his efforts to de-escalate were too
late. Nonetheless, he expected to prevail and almost did.

Had the Kaiser, the Czar, and the Emperor known in August 1914 that a
little over four years later, all would lose their thrones and see their
realms dismembered, they would not have gone to war. Since 1945, nuclear
weapons have served as a crystal ball in which leaders can glimpse the
catastrophe implied by a major war. After the Cuban Missile Crisis in
1962, leaders learned the importance of de-escalation, arms-control
communication, and rules of the road to manage conflict.

Cyber technology, of course, lacks the clear devastating effects of
nuclear weapons, and that poses a different set of problems, because
there is no crystal ball. During the Cold War, the great powers avoided
direct engagement, but that is not true of cyber conflict. And yet [the
threat of cyber **Pearl Harbor**s has been **exaggerated**. Most cyber
conflicts occur **below the threshold** established by the rules of
armed conflict. They are **economic** and **political**, rather than
**lethal**. It is **not credible** to threaten a **nuclear
response**]{.underline} [to cyber theft]{.underline} of intellectual
property by China [or cyber meddling]{.underline} in elections by
Russia.

According to American doctrine, [deterrence is not limited to a cyber
response]{.underline} (though that is possible). [The US will respond to
cyberattacks across domains or sectors, with any weapons of its choice,
**proportional** to the damage that has been done. That can range from
**naming** and **shaming** to economic sanctions to kinetic
weapons]{.underline}. Earlier this year, a new doctrine of "persistent
engagement" was described as not only disrupting attacks, but also
helping to reinforce deterrence. But the technical overlap between
intrusion into networks to gather intelligence or disrupt attacks and to
carry out offensive operations often makes it difficult to distinguish
between escalation and de-escalation. Rather than relying on tacit
bargaining, as proponents of "persistent engagement" sometimes
emphasize, explicit communication may be necessary to limit escalation.

**Case -- Heg**

**[1NC vs Heg ADV]{.underline}**

**Hegemony is unsustainable -- a peaceful transition toward offshore
balancing prevents economic crisis, prolif, terrorism**

**Walt 19**

Stephen - Robert and Renée Belfer Professor of International Affairs at
the Harvard Kennedy School and the author of **Error! Hyperlink
reference not valid.**, \"The End of Hubris,\" Foreign Affairs,
https://www.foreignaffairs.com/articles/2019-04-16/end-hubris

Today\'s world presents a seemingly endless array of challenges: a more
powerful and [[assertive
China]{.underline}](https://www.foreignaffairs.com/articles/china/china-plan-rule-asia),
novel threats from cyberspace, a rising tide of refugees, resurgent
xenophobia, persistent strands of violent extremism, climate change, and
many more. But the more complex the global environment, the more
Washington needs clear thinking about its vital interests and foreign
policy priorities. Above all, a successful [[U.S. grand
strategy]{.underline}](https://www.foreignaffairs.com/topics/grand-strategy)
must identify where the United States should be prepared to wage war,
and for what purposes. [For all the talk of how U.S. foreign policy and
the country\'s place in the world will never be the same after the
presidency of Donald Trump, the best strategic road map for the United
States is a familiar one. Realism-the hard-nosed approach to foreign
policy that guided the country throughout most of the twentieth century
and drove its rise to great power-remains the [best
option](https://www.foreignaffairs.com/articles/world/2018-06-14/realist-world).]{.underline}
[A quarter century ago, after the Cold War ended, foreign policy elites
abandoned realism in favor of an unrealistic grand strategy-liberal
hegemony-that has weakened the country and caused considerable harm at
home and abroad.]{.underline} To get back on track, [Washington should
return to the realism and restraint that served it so well in the past.
If Washington rediscovered realism, the United States would seek to
preserve the security and prosperity of the American people and to
protect the core value of liberty in the United States.]{.underline}
Policymakers would recognize the importance of military strength but
also take into account the country\'s favorable geographic position, and
they would counsel restraint in the use of force. [The United States
would embrace a strategy of \"offshore balancing\" and abstain from
crusades to remake the world in its image, concentrating instead on
maintaining the balance of power in a few key regions. Where possible,
Washington would encourage foreign powers to take on the primary burden
for their own defense, and it would commit to defend only those areas
where the United States has vital interests and where its power is still
essential.]{.underline} [Diplomacy would return to its rightful place,
and Americans would promote their values abroad primarily by
demonstrating democracy\'s virtues at home]{.underline}. IF IT AIN\'T
BROKE\... In the eighteenth and nineteenth centuries, when the United
States was weak, leaders from George Washington to William McKinley
mostly avoided foreign entanglements and concentrated on building power
domestically, expanding the country\'s reach across North America and
eventually expelling the European great powers from the Western
Hemisphere. In the first half of the twentieth century, U.S. presidents
such as Woodrow Wilson and Franklin Roosevelt used the country\'s
newfound strength to restore the balance of power in strategically
critical regions outside the Western Hemisphere. But they let other
great powers do most of the heavy lifting, and thus the United States
emerged relatively unscathed-and stronger than ever-from the world wars
that devastated Asia and Europe. Letting other states shoulder the
burden was not possible during the Cold War, so the United States
stepped up and led the alliances that contained the Soviet Union.
American leaders paid lip service to democracy promotion, human rights,
and other idealistic concerns, but U.S. policy was [[realist at its
core]{.underline}](https://www.foreignaffairs.com/articles/2018-08-28/truth-about-liberal-order).
Through the Bretton Woods system and its successors, the United States
also helped foster a more open world economy, balancing economic growth
against the need for financial stability, national autonomy, and
domestic legitimacy. Put simply, for most of U.S. history, American
leaders were acutely sensitive to the balance of power, passed the buck
when they could, and took on difficult missions when necessary. But when
the Soviet Union collapsed and the United States found itself, as the
former national security adviser Brent Scowcroft put it in 1998,
\"standing alone at the height of power . . . with the rarest
opportunity to shape the world,\" U.S[. leaders rejected the realism
that had worked well for decades and tried to remake global politics in
accordance with American values. A new strategy-[liberal
hegemony](https://www.foreignaffairs.com/articles/world/2018-06-14/liberal-world)-sought
to spread democracy and open markets across the globe. That goal is the
common thread linking President Bill Clinton\'s policy of \"engagement
and enlargement]{.underline},\" President George W. Bush\'s \"freedom
agenda,\" and President Barack Obama\'s embrace of the Arab revolts of
2010-11 and his declaration that \"there is no right more fundamental
than the ability to choose your leaders and determine your destiny.\"
Such thinking won broad support from both political parties, the federal
bureaucracies that deal with international affairs, and most of the
think tanks, lobbies, and media figures that constitute the foreign
policy establishment. [At bottom, liberal hegemony is a highly
revisionist strategy. Instead of working to maintain favorable balances
of power in a few areas of vital interest, the United States sought to
transform regimes all over the world and recruit new members into the
economic and security institutions it dominated. The results were
dismal: failed wars, financial crises, staggering inequality, frayed
alliances, and emboldened adversaries.]{.underline} HEGEMONIC HUBRIS
When Clinton took office in 1993, the United States was on favorable
terms with the world\'s other major powers, including China and Russia.
Democracy was spreading, Iraq was being disarmed, and Iran had no
nuclear enrichment capacity. The Oslo Accords seemed to herald an end to
the Israeli-Palestinian conflict, and Washington seemed well positioned
to guide that process. [The European Union was adding new members and
moving toward a common currency, and the U.S. economy was performing
well. Americans saw terrorism as a minor problem, and the U.S. military
seemed unstoppable. The wind was at the country\'s back. Life was good.
But those circumstances fueled a dangerous overconfidence among American
elites.]{.underline} Convinced that the United States was \"the
indispensable nation,\" as Secretary of State Madeleine Albright
famously put it in 1998, they believed they had the right, the
responsibility, and the wisdom to shape political arrangements in every
corner of the world. That vision turned out to be a hubristic fantasy.
Repeated attempts to broker peace between the Israelis and the
Palestinians all failed, and the two-state solution sought by three U.S.
presidents is no longer a viable option. [Al Qaeda attacked the U.S.
homeland on September 11, 2001, and Washington responded by launching a
global war on terrorism, including invasions of Afghanistan and Iraq.
Those campaigns were costly failures and shattered the U.S. military\'s
aura of invincibility. Much of the Middle East is now embroiled in
conflict, and violent extremists operate from Africa to Central Asia and
beyond. Meanwhile, India, Pakistan, and North Korea tested and deployed
nuclear weapons, and Iran become a latent nuclear weapons state. The
collapse of the U.S. housing market in 2008 exposed widespread
corruption in the country\'s financial institutions and triggered the
[worst economic
crisis](https://www.foreignaffairs.com/articles/2018-09-13/crisis-next-time)
since the Great Depression-a calamity from which the global economy has
yet to fully recover. In 2014, Russia seized Crimea]{.underline}, and it
has interfered in a number of other countries since then-and its
relations with the West are now worse than at any time since the Cold
War. [China\'s power and ambitions have expanded, and cooperation
between Beijing and Moscow has deepened. The eurozone crisis, the United
Kingdom\'s decision to withdraw from the EU, and energetic populist
movements have raised doubts about the EU\'s future. Democracy is in
retreat worldwide;]{.underline} according to Freedom House, 2018 was the
13th consecutive year in which global freedom declined. Illiberal
leaders govern in Hungary and Poland, and the Economist Intelligence
Unit\'s annual Democracy Index has downgraded the United States from a
\"full\" to a \"flawed\" democracy. [The United States was not solely
responsible for all these adverse developments, but it played a major
role in most of them. And the taproot of many of these failures was
Washington\'s embrace of liberal hegemony. For starters, that strategy
expanded U.S. security obligations without providing new resources with
which to meet them.]{.underline} The policy of \"dual containment,\"
aimed at Iran and Iraq, forced the United States to keep thousands of
troops on the Arabian Peninsula, an additional burden that also helped
convince Osama bin Laden to strike at the U.S. homeland. [NATO expansion
committed Washington to defend weak and vulnerable new members, even as
France, Germany, and the United Kingdom let their military forces
atrophy.]{.underline} Equally important, U.S. efforts to promote
democracy, the open-ended expansion of NATO, and the extension of the
alliance\'s mission far beyond its original parameters poisoned
relations with Russia. [And fear of U.S.-led regime change encouraged
several states to pursue a nuclear deterrent-in the case of North Korea,
successfully. When the United States did manage to topple a foreign foe,
as it did in Afghanistan, Iraq, and Libya, the results were not thriving
new democracies but costly occupations, failed states, and hundreds of
thousands of dead civilians]{.underline}. It was delusional for U.S.
leaders to expect otherwise: creating a functional democracy is a
difficult process under the best of circumstances, but trying to do it
in fractured societies one barely understands is a fool\'s errand.
Finally, globalization [[did not
deliver]{.underline}](https://www.foreignaffairs.com/articles/united-states/2018-10-15/how-save-globalization)
as promised. Opening up markets to trade and investment brought great
benefits to lower and middle classes in China, India, and other parts of
the developing world. It also further magnified the already staggering
wealth of the world\'s richest one percent. But lower- and middle-class
incomes in the United States and Europe remained flat, jobs in some
sectors there fled abroad, and the global financial system became much
more fragile. This sorry record is why, in 2016, when Trump called U.S.
foreign policy \"a complete and total disaster\" and blamed out-of-touch
and unaccountable elites, many Americans nodded in agreement. They were
not isolationists; they simply wanted their government to stop trying to
run the world and pay more attention to problems at home. Trump\'s
predecessors seemed to have heard that message, at least when they were
running for office. In 1992, Clinton\'s mantra was \"It\'s the economy,
~~stupid~~.\" In 2000, Bush derided Clinton\'s efforts at \"nation
building\" and called for a foreign policy that was \"strong but
humble.\" Obama pledged to end foreign wars and focus on \"nation
building at home.\" [These expressions of restraint were understandable,
as surveys had repeatedly shown that a majority of Americans believed
the country was playing the role of global policeman more than it should
and doing more than its share to help others.]{.underline} According to
the Pew Research Center, in 2013, 80 percent of Americans agreed that
\"we should not think so much in international terms but concentrate
more on our own national problems and building up our strength and
prosperity here at home,\" and 83 percent wanted presidents to focus
more on domestic issues than on foreign policy. Clinton, Bush, and Obama
all understood what the American people wanted. But they failed to
deliver it. So has Trump. Although his Twitter feed and public
statements often question familiar orthodoxies, [the United States is
still defending wealthy NATO allies, still fighting in Afghanistan,
still chasing terrorists across Africa, still giving unconditional
support to the same problematic Middle Eastern clients, and still hoping
to topple a number of foreign regimes. Trump\'s style as president is
radically different from those of his predecessors, but the substance of
his policies is [surprisingly
similar](https://www.foreignaffairs.com/articles/united-states/2017-06-13/trump-traditionalist).
The result is the worst of both worlds: Washington is still pursuing a
misguided grand strategy, but now with an incompetent vulgarian in the
White House]{.underline}. REALISM IN PRACTICE [Four presidents have now
pursued a grand strategy built around the goal of American hegemony, and
all four have fared poorly.]{.underline} As the political scientist John
Mearsheimer and I have argued previously [[in these
pages]{.underline}](https://www.foreignaffairs.com/articles/united-states/2016-06-13/case-offshore-balancing),
it is time for the United States to return to its traditional approach
of offshore balancing. This strategy begins by recognizing that the
United States remains the most secure power in modern history. [It has
thousands of nuclear weapons and powerful conventional forces, and it
faces no serious rivals in the Western Hemisphere. The Atlantic and
Pacific Oceans still insulate the country from many threats, giving U.S.
leaders enormous latitude in choosing where and when to fight. In
addition to working to maintain U.S. hegemony in the Western Hemisphere,
American policymakers have long sought to prevent other great powers
from imitating the United States by dominating their own
regions.]{.underline} A peer competitor with no serious rivals nearby
would be free to project power around the world-as Washington has for
decades. From an American perspective, it is better if the major powers
in Eurasia have to keep a wary eye on one another, making it harder for
them to interfere near American shores. The United States intervened in
the world wars to prevent Wilhelmine Germany, Nazi Germany, and imperial
Japan from dominating Europe and Asia. This same principle inspired the
Cold War strategy of containment, although in that case, the United
States could not pass the buck and had to bear most of the costs itself.
[Today, there is no potential regional hegemon in Europe, whose states
should gradually take [full
responsibility](https://www.foreignaffairs.com/articles/europe/2017-08-15/pay-europe)
for their own defense. The countries of the European Union are home to
more than 500 million people and boast a combined annual GDP exceeding
\$17 trillion, whereas Russia-the main external threat to EU states-has
a population of just 144 million and an annual GDP of only \$1.6
trillion.]{.underline} Moreover, NATO\'s European members together
annually spend more than three times what Russia does on defense. [The
idea that the EU (whose roster includes two nuclear-armed powers) lacks
the wherewithal to defend itself against a neighbor whose economy is
smaller than Italy\'s is risible. NATO still has ardent defenders on
both sides of the Atlantic, but they are living in the past. The
alliance played an invaluable role in containing the Soviet Union and
preventing the return of an aggressive, expansionist
Germany]{.underline}. But the Soviet Union is long gone, and Germany is
now a liberal democracy firmly committed to the status quo. NATO\'s
leaders have worked overtime to devise new missions since the Berlin
Wall came down, but the alliance\'s attempts at nation building in the
Balkans, Afghanistan, and Libya have not gone well. Unless NATO\'s
European members decide to back a U.S.-led effort to balance against
China (and it is not clear that they will or should), it is time for the
United States to gradually disengage from NATO and turn European
security over to the Europeans by beginning a coordinated withdrawal of
U.S. military forces from Europe, allowing a European officer to serve
as NATO\'s supreme allied commander, and making it clear that the United
States will no longer be Europe\'s first line of defense. Washington
should take these steps not with rancor or resentment but with a sense
of accomplishment and a commitment to cooperate on issues on which
American and European interests align, such as climate change,
counterterrorism, and the management of the world economy. Washington
should also return to its traditional approach to the Middle East. To
ensure access to the energy supplies on which the world economy depends,
the United States has long sought to prevent any country from dominating
the oil-rich Persian Gulf. But until the late 1960s, it did so by
relying on the United Kingdom. After the British withdrew, Washington
relied on regional clients, such as Iran, Israel, and Saudi Arabia. U.S.
forces stayed offshore until January 1991, a few months after Saddam
Hussein, the leader of Iraq, seized Kuwait. In response, the George H.
W. Bush administration assembled a coalition of states that liberated
Kuwait, decimated Iraq\'s military, and restored balance to the region.
[Today, Washington\'s primary goal in the Middle East remains preventing
any country from impeding the flow of oil to world markets. The region
is now deeply divided along several dimensions, with no state in a
position to dominate.]{.underline} Moreover, the oil-producing states
depend on revenue from energy exports, which makes all of them eager to
sell. [Maintaining a regional balance of power should be relatively
easy, therefore, especially once the United States ends its
counterproductive efforts to remake local politics. U.S. forces in Iraq
and Syria would be withdrawn, although the United States might still
maintain intelligence-gathering facilities, prepositioned equipment, and
basing arrangements in the region as a hedge against the need to return
in the future.]{.underline} But as it did from 1945 to 1991, Washington
would count on local powers to maintain a regional balance of power in
accordance with their own interests. As an offshore balancer, the United
States would establish normal relations with all countries in the
region, instead of having \"special relationships\" with a few states
and profoundly hostile relations with others. No country in the Middle
East is so virtuous or vital that it deserves unconditional U.S.
support, and no country there is so heinous that it must be treated as a
pariah. The United States should act as China, India, Japan, Russia, and
the EU do, maintaining normal working relationships with all states in
the region-[[including
Iran]{.underline}](https://www.foreignaffairs.com/articles/iran/2018-10-24/pompeos-dangerous-delusions).
Among other things, this policy would encourage rival regional powers to
compete for U.S. support, instead of taking it for granted. For the
moment, Washington should also make it clear that it will reduce its
support for local partners if they repeatedly act in ways that undermine
U.S. interests or that run contrary to core U.S. values. [Should any
state threaten to dominate the region from within or without in the
future, the United States would help the rest balance against it,
calibrating its level of effort and local presence to the magnitude of
the danger. With its relationships with Europe and the Middle East
right-sized and rationalized, an offshore-balancing United States could
focus primarily on the country that is its only potential peer
competitor and the world\'s only other would-be regional hegemon: China.
If China\'s power continues to grow, it is likely to press its neighbors
to distance themselves from Washington and accept China as the dominant
power in the Asia-Pacific.]{.underline} [Were China to become a regional
hegemon in Asia, it would be better positioned to project power around
the world and extend its influence into the Western Hemisphere. To
counter this possibility, the United States should maintain and deepen
its current security ties with Australia, Japan, the Philippines, and
South Korea and continue to nurture its strategic partnerships with
India, Singapore, and Vietnam. Once the United States is no longer
subsidizing its wealthy European allies or squandering trillions of
dollars on costly quagmires in the greater Middle East, it can more
readily afford the military capabilities needed to balance
China.]{.underline} Maintaining an effective Asian coalition will not be
easy, however. Washington\'s Asian allies are separated from one another
by water and vast distances, and they are reluctant to jeopardize their
commercial ties with China. [The relationship between Japan and South
Korea has a troubled history that makes close cooperation difficult.
Local powers will be tempted to let Washington do most of the work, and
sophisticated U.S. leadership will be necessary to hold this coalition
together and ensure that each member contributes its fair
share.]{.underline} Trump\'s missteps-abandoning the Trans-Pacific
Partnership, starting trade disputes with Japan and South Korea, and
indulging in an amateurish flirtation with North Korea-have not helped.
OFFSHORE VENTURE Defenders of the status quo will no doubt
mischaracterize this course of action as a return to isolationism. That
is nonsense. [As an offshore balancer, the United States would be deeply
engaged diplomatically, economically, and, in some areas, militarily. It
would still possess the world\'s mightiest armed forces, even if it
spent somewhat less money on them. The United States would continue to
work with other countries to address major global issues such as climate
change, terrorism, and cyberthreats. But Washington would no longer
assume primary responsibility for defending wealthy allies that can
defend themselves, no longer subsidize client states whose actions
undermine U.S. interests, and no longer try to spread democracy via
regime change, covert action, or economic pressure.]{.underline}
Instead, [Washington would use its strength primarily to uphold the
balance of power in Asia-where a substantial U.S. presence is still
needed-and would devote more time, attention, and resources to restoring
the foundations of U.S. power at home.]{.underline} By setting an
example that others would once again admire and seek to emulate, an
offshore-balancing United States would also do a better job of promoting
the political values that Americans espouse. This approach would also
involve less reliance on force and coercion and a renewed emphasis on
diplomacy. [Military power would remain central to U.S. national
security, but its use would be as a last resort rather than a first
impulse. It is worth remembering that some of Washington\'s greatest
foreign policy achievements-the Marshall Plan, the Bretton Woods system,
the Egyptian-Israeli peace treaty, and the peaceful reunification of
Germany-were diplomatic victories, not battlefield ones.]{.underline} In
recent years, however, both Democratic and Republican administrations
have tended to eschew genuine diplomacy and have relied instead on
ultimatums and pressure. Convinced they hold all the high cards, too
many U.S. officials have come to see even modest concessions to
opponents as tantamount to surrender. So they have tried to dictate
terms to others and have reached for sanctions or the sword when the
target state has refused to comply. But even weak states are reluctant
to submit to blackmail, and imposing one-sided agreements on others
makes them more likely to cheat or renege as soon as they can. For
diplomacy to work, both sides must get some of what they want.
[Moreover, offshore balancing requires a sophisticated understanding of
regional politics, which only knowledgeable diplomats and area
specialists can provide. In particular, creating an effective coalition
to check China\'s ambitions in Asia will be as much a diplomatic task as
a military mission, and success would depend on a deep bench of
officials who are intimately familiar with the history, languages,
cultures, and sensitivities of the region.]{.underline} A return to
offshore balancing should also be accompanied by a major effort to
rebuild and professionalize the U.S. diplomatic corps. Ambassadorships
should be reserved for qualified diplomats rather than VIPs or campaign
donors, and the State Department must develop, refine, and update its
diplomatic doctrine-the ways the United States can use noncoercive means
of influence-much as the armed services continually refine the military
doctrines that guide their conduct in war. The ranks of the Foreign
Service should be significantly increased, and as their careers advance,
career diplomats should receive the same opportunities for professional
education that senior military officers currently enjoy. OUT WITH THE
OLD Despite the disappointments of the past 25 years, the American
foreign policy elite remains convinced that global leadership is their
birthright and that Washington must continue trying to force other
countries to conform to U.S. dictates. This perspective is an article of
faith at almost every foreign policy think tank inside the Beltway and
is repeatedly invoked in task-force reports, policy briefs, and op-eds.
A similar groupthink pervades the U.S. media, where unrepentant
neoconservatives and unchastened liberal internationalists monopolize
the ranks of full-time pundits; proponents of realism, restraint, and
nonintervention appear sporadically at best. The result is that foreign
policy debates are heavily skewed in favor of endless intervention.
[Moving back to a more realist grand strategy will require broadening
the parameters of debate and challenging the entrenched interests that
have promoted and defended a failed foreign policy.]{.underline} The
clubbiness of the foreign policy establishment has also produced a
disturbing lack of accountability. Although the community contains many
dedicated, imaginative, and honorable individuals, it is dominated by a
highly networked caste of insiders who are reluctant to judge one
another lest they be judged themselves. As a result, error-prone
officials routinely fail upward and receive new opportunities to repeat
past mistakes. [Consider the officials responsible for (and the
commentators who cheered on) the bungled Middle East peace process, the
misguided expansion of NATO, the botched wars in Afghanistan and Iraq,
the CIA\'s torture of detainees in the war on terrorism, the National
Security Agency\'s warrantless surveillance of Americans, the disastrous
NATO intervention in Libya, and the American machinations in Ukraine
that gave Russia a pretext to seize Crimea.]{.underline} None of those
officials or commentators has suffered significant professional
penalties for his or her mistakes or malfeasance. Indeed, nearly all of
them still enjoy prominent positions in government, think tanks, the
media, or academia. No one is infallible, of course, and a desire to
hold people accountable could be taken too far. Policymakers often learn
from past mistakes and become more effective over time. But when the
same people keep making the same errors and neither recognize nor regret
them, it is time to look for new people with better ideas. [Despite the
stagnation within the foreign policy establishment, the prospects for a
more realist, more restrained U.S. foreign policy are better today than
they have been in many years. For all his flaws, Trump has made it
easier to propose alternatives to liberal hegemony by expressing such
disdain for the elite consensus.]{.underline} Younger Americans are more
skeptical of their country\'s imperial pretensions than are their
elders, and some new members of Congress seem bent on clawing back some
of the control over foreign policy that presidents have amassed over the
past 70 years. [Furthermore, powerful structural forces are working
against liberal hegemony and in favor of offshore balancing. China\'s
rise and the partial revival of Russian power are forcing the United
States to pay closer attention to balance-of-power politics, especially
in Asia.]{.underline} The intractable problems of the Middle East will
make future presidents reluctant to squander more blood and treasure
there-especially in chasing the siren song of democracy promotion.
Pressure on the defense budget is unlikely to diminish, especially once
the costs of climate change begin to bite, and because trillions of
dollars\' worth of domestic needs cry out for attention. For these
reasons, the foreign policy elite will eventually rediscover the grand
strategy that helped build and sustain American power over most of the
nation\'s history. The precise path remains uncertain, and it will
probably take longer to get there than it should. But the destination is
clear.

**China will never match US hegemony -- but maintaining offensive
postures makes war from Chinese decline inevitable**

**Beckley 20**

Michael, Tufts University; American Enterprise Institute, "Conditional
Convergence and the Rise of China: A Political Economy Approach to
Understanding Global Power Transitions", Journal of Global Security
Studies DB

[The conventional wisdom about current trends in the balance of power
relies heavily on power transition theory, which assumes that economic
convergence is an unconditional process in which poorer countries
inevitably catch up with richer countries]{.underline}.
**[Economists]{.underline}**, however, **[have shown that convergence is
rare and conditional on a set of geographic, institutional, and
demographic factors that, so far, have not been incorporated into major
theories of international change]{.underline}**. In this article, I have
discussed these factors and analyzed the growth prospects of the United
States and China in light of them. **[The results cast doubt on China's
ability to rival the United States as an economic and military
superpower]{.underline}**. The good news is that **[the world is
unlikely to experience a full-blown hegemonic rivalry anytime
soon]{.underline}**. This is an extraordinary development for global
security. [In the past five hundred years alone, there have been sixteen
hegemonic competitions in which a rising power challenged a ruling power
for top-dog status]{.underline}. [Twelve of them ended in catastrophic
wars, and even some of the peaceful cases were brutal cold wars that
inflicted tremendous harm]{.underline}. During the Cold War, for
example, the United States and the Soviet Union divided the globe into
rival blocs, waged proxy wars that killed millions of people, and
brought the world to the brink of nuclear Armageddon. [Today, by
contrast, the United States does not face a peer competitor, and the
world, though far from perfect, is more peaceful and prosperous than
ever before]{.underline}. The bad news is that **[China may become more
authoritarian at home and aggressive abroad as its economic growth
slows, and this shift may undermine global security in numerous
areas]{.underline}**. **[History suggests that when a rising power peaks
and starts to decline before its ambitions have been fulfilled, its
people tend to become disgruntled, and its leaders usually respond by
suppressing domestic dissent and demonizing foreign
adversaries]{.underline}**. [Russia]{.underline}, for example, [has
become more hostile, revanchist, and disruptive since the collapse in
world oil prices in the late 2000s gutted the Russian economy and
crimped President Vladimir Putin's popularity]{.underline}. [China seems
to be going down a similar path]{.underline}. Over the past decade,
[China's economic growth rates have been cut in half, and the Chinese
government has responded by massively expanding its internal security
system, exporting parts of that system to other countries, waging
information warfare on democratic countries, promoting "internet
sovereignty," flouting international trade rules, and ramping up its
military presence on and around disputed features in the East and South
China Seas in flagrant violation of international law]{.underline}.
These actions may be just a preview of what is to come in the years
ahead, as the economic, geographic, and demographic problems highlighted
above grow worse. Trade disputes and territorial conflicts are only the
most obvious risks posed by a stagnating and recalcitrant China. Less
obvious are transnational problems, such as climate change and disease,
which may fester without Chinese cooperation. [Avoiding this fate
requires other countries, and especially the United States, to handle
China with a blend of reassurance and deterrence]{.underline}.
**[Unfortunately, the widespread view that China is an emerging
superpower has caused the United States to abandon engagement in favor
of unbridled competition]{.underline}**. In just the past few years, the
United States has labeled China a rival, imposed steep tariffs on
Chinese goods and severe restrictions on Chinese investment and
immigration, **[inserted US forces into East Asian territorial
disputes]{.underline}**, and made plans to hit China early and hard in
the event of war. **[This competition has not only increased the risk of
US--China conflict but also threatened global security by hamstringing
the World Trade Organization and effectively killing the Paris Climate
Accord and the Intermediate Nuclear Forces Treaty]{.underline}**. Thus,
**[the stage has been set for tragic conflict: China is becoming more
recalcitrant as it suffers slowing growth, while the United States,
consumed by false prophecies of China's inexorable rise, is becoming
more confrontational]{.underline}**. **[The main threat to global
security, therefore, is not a US-China power transition driven by
economic convergence but divergence in US and Chinese perceptions about
the long-term trends in the balance of power]{.underline}**. **[China
may not be able to stem its growth slowdown, but Americans can take note
of it and recalibrate US policy accordingly]{.underline}**.

**Unipolarity is statistically the most conflict-prone system.**

**Monteiro 14**

Assistant Professor of Political Science at Yale \[Nuno, *Theory of
Unipolar Politics*, p. 181-184

At the same time, [the first two-and-a-half decades of our unipolar
system have been anything but peaceful in what concerns U.S, involvement
in interstate conflict. U.S. forces have been employed in four
interstate wars]{.underline} -- Kuwait (1991), Kosovo (1999),
Afghanistan (2001-), and Iraq (2oo3-2011) -- [in addition to many
smaller interventions]{.underline} including Bosnia, Haiti, Somalia, and
Sudan.5 As a result, [the U]{.underline}nited [S]{.underline}tates [has
been at war for **fifteen of the twenty-five years** since the end of
the Cold War]{.underline}, In fact, [the first two-and-a-half decades of
unipolarity]{.underline} --- representing around 1o percent of U.S.
history [account for more than 30 percent of the nation\'s total
wartime.]{.underline}6 For critics of U.S. interventionism, \"**[the
central question]{.underline}** \[of contemporary international
politics\] [is how to **contain and moderate the use of military force
by the** **U**]{.underline}nited **[S]{.underline}**tates.\"8

Table 5 presents a list of great powers divided into three periods: from
1816 to 1945, multipolarity; from 1946 to 1989, bipolarity; and
unipolarity since 1990.9 Table 6 then presents summary data about the
incidence of war during each of these periods. [Unipolarity is by far
**the most conflict prone of all systems** according to]{.underline} two
important criteria: [the percentage of years that great powers spend at
war and the incidence of war involving great powers]{.underline}. In
multipolarity, 18 percent of great-power years were spent at war versus
16 percent in bipolarity. [In unipolarity]{.underline}, in contrast, a
remarkable [**64 percent** of great-power years have been]{.underline}
until now [spent at war]{.underline} -- by far [the **highest**
percentage **in all systems**]{.underline}. Furthermore, [during
multipolarity and bipolarity the probability that war]{.underline}
involving a great power [would, break out in any given year
was]{.underline}, respectively, [4.2 percent and 3.4 percent. Under
unipolarity, it is]{.underline} 16.o percent -- or around **[four times
higher]{.underline}**.

[It might be argued that the higher number of years]{.underline} that
great powers spent at war under unipolarity [are]{.underline} merely
[the result of]{.underline} the long, grinding, and unforeseen
[occupations of Afghanistan and Iraq]{.underline} by U.S. forces.11 [But
even if these two wars had gone according to]{.underline} U.S.
[plans]{.underline} -- if the Afghanistan War had ended in the spring of
2002 and the Iraq War in the summer of 2003 -- [unipolarity would still
be particularly **prone to great-power involvement in
war**]{.underline}. [Even if the U]{.underline}nited
[S]{.underline}tates [had not occupied either Afghanistan or Iraq, it
would]{.underline} still [have spent 16.0 percent of the post-Cold War
years at war]{.underline}, which is about the same as the respective
percentages for bipolar and multipolar systems. [In other words, even if
the U]{.underline}nited [S]{.underline}tates [had refrained from any
military occupations, the frequency of its use of military force in
major operations]{.underline} would still [give us **no reason to
believe that unipolarity is any more peaceful** than any
other]{.underline} past configuration of the [international
system.]{.underline}

As things turned out in both Afghanistan and Iraq, [the last
two-and-a-half decades saw a sharp increase in]{.underline} both [the
incidence of conflict and]{.underline} the [percentage of]{.underline}
great-power [years spent at war.]{.underline} This is a particularly
puzzling finding given that the current unipole -- the United States --
is a democracy in a world populated by more democracies than at any time
in the past. In light of arguments about how democracies are better able
to solve disputes peacefully, choose to engage only in those wars they
can win, and tend to fight shorter wars, the United States should have
spent fewer years at war than previous nondemocratic great powers.12

[As we can see, post-Cold War history can be used in support
of]{.underline} both [the]{.underline} widespread [claim]{.underline}
that the overall level of conflict has declined and of the claim [that
the U]{.underline}nited [S]{.underline}tates [has experienced an
**unprecedented level of involvement in interstate war**]{.underline}.
[Reality seems to be chafing against the view that unipolarity produces
no incentives for conflict]{.underline}; at least in what concerns the
unipole\'s involvement in interstate wars, [the past two-and-a-half
decades]{.underline} seem to [point in the opposite
direction.]{.underline}

**[2NC/1NR -- Unipolarity Bad]{.underline}**

**Heg doesn't solve stability \-- empirical analysis proves it
destabilizes the world and multipolar systems aren't worse.**

**Cambanis 12** \[Thanassis - Fellow at The Century Foundation and
Professor at Columbia University's School of International and Public
Affairs "The lonely superpower,"
http://bostonglobe.com/ideas/2012/01/22/the-lonely-superpower/FRkSf1s5n9lXku4VqvEtqJ/story.html\]

Now, however, with a few decades of experience to study, a young
international relations theorist at Yale University has proposed a
provocative new view: [American dominance has destabilized the world in
new ways, and the United States is no better off in the wake of the Cold
War]{.underline}. In fact, he says, [a world with a single superpower
and a crowded second tier of distant competitors encourages, rather than
discourages, violent conflict\--not just among the also-rans, but even
involving the single great power itself.]{.underline} In a paper that
appeared in the most recent issue of the influential journal
International Security, political scientist Nuno P. Monteiro lays out
his case. [America]{.underline}, he points out, [has been at war for 13
of the 22 years since the end of the Cold War, about double the
proportion of time it spent at war during the previous two
centuries]{.underline}. "I'm trying to debunk the idea that a world with
one great power is better," he said in an interview. "If you don't have
one problem, you have another." Sure, Monteiro says, the risk of
apocalyptic war has decreased, since there's no military equal to
America's that could engage it in mutually assured destruction. But, he
argues, the lethal, expensive wars in the Persian Gulf, the Balkans, and
Afghanistan have proved a major drain on the country. Even worse,
Monteiro claims, [America's position as a dominant power, unbalanced by
any other alpha states actually exacerbates dangerous tensions rather
than relieving them]{.underline}. Prickly states that Monteiro calls
["recalcitrant minor powers" (think Iran, North Korea, and Pakistan),
whose interests or regime types clash with the lone superpower, will
have an incentive to provoke a conflict. Even if they are likely to
lose, the fight may be worth it, since concession will mean defeat as
well. This is the logic by which North Korea and Pakistan both acquired
nuclear weapons, even during the era of American global dominance, and
by which Iraq and Afghanistan preferred to fight rather than surrender
to invading Americans.]{.underline} Of course, few Americans long for
the old days of an arms race, possible nuclear war, and the threat of
Soviet troops and missiles pointed at America and its allies. Fans of
unipolarity in the foreign policy world think that the advantages of
being the sole superpower far outweigh the drawbacks \-- a few regional
conflicts and insurgencies are a fair price to pay for eliminating the
threat of global war. But Monteiro says that [critics exaggerate the
distinctions between the wars of today and yesteryear]{.underline}, and
many top thinkers in the world of security policy are finding his
argument persuasive. If he's right, it means that the most optimistic
version of the post-Cold War era \-- [a "pax Americana"]{.underline} in
which the surviving superpower can genuinely enjoy its ascendancy \--
[was always illusory. In the short term, a dominant United States should
expect an endless slate of violent challenges from weak
powers]{.underline}. And [in the longer term, it means that Washington
shouldn't worry too much about rising powers]{.underline} like China or
Russia or the European Union; [America might]{.underline} even [be
better off with a rival powerful enough to provide a
balance]{.underline}. You could call it the curse of plenty: [Too much
power attracts countless challenges, whereas a world in which power is
split among several superstates might just offer a paradoxical
stability. From the 1700s until the end of World War II in 1945, an
array of superpowers competed for global influence in a multipolar
world, including imperial Germany and Japan, Russia, Great Britain, and
after a time, the United States. The world was an unstable place, prone
to wars minor and major. The Cold War era]{.underline} was far more
stable, with only two pretenders to global power. It [was]{.underline},
however, [an age of anxiety. The threat of nuclear Armageddon hung over
the world]{.underline}. Showdowns in Berlin and Cuba brought America and
the Soviet Union to the brink, and the threat of nuclear escalation hung
over every other superpower crisis. Generations of Americans and Soviets
grew up practicing survival drills; for them, the nightmare scenario of
thermonuclear winter was frighteningly plausible. [It was also an age of
violent regional conflicts.]{.underline} Conflagrations in Asia, Africa,
and Latin America spiraled into drawn out, lethal wars, with the
superpowers investing in local proxies (think of Angola and Nicaragua as
well as Korea and Vietnam). On the one hand, superpower involvement
often made local conflicts far deadlier and longer than they would have
been otherwise. On the other, the balance between the United States and
the USSR reduced the likelihood of world war and kept the fighting below
the nuclear threshold. By tacit understanding, the two powers had an
interest in keeping such conflicts contained. When the Soviet Union
began its collapse in 1989, the United States was the last man standing,
wielding a level of global dominance that had been unknown before in
modern history. Policy makers and thinkers almost universally agreed
that dominance would be a good thing, at least for America: It removed
the threat of superpower war, and lesser powers would presumably choose
to concede to American desires rather than provoke a regional war they
were bound to lose. That is what the 1991 Gulf War was about:
establishing the new rules of a unipolar world. Saddam Hussein invaded
Kuwait, Monteiro believes, because he miscalculated what the United
States was willing to accept. After meeting Saddam with overwhelming
force, America expected that the rest of the world would capitulate to
its demands with much less fuss. [Monteiro compared the conflicts of the
multipolar 18th century to those of the Cold War and current unipolar
moment]{.underline}. What he found is [that the unipolar world isn't
necessarily better than what preceded it,]{.underline} either [for the
United States or for the rest of the world. It might even be
worse.]{.underline} ["Uncertainty increases in
unipolarity,"]{.underline} Monteiro says. ["If another great power were
around, we wouldn't be able to get involved in all these wars." In the
unipolar period, a growing class of minor powers has provoked the United
States, willing to engage in brinkmanship up to and including violent
conflict. Look no further than Iran's recent threats to close the Strait
of Hormuz]{.underline} to oil shipping and to strike the American Navy.
Naturally, Iran wouldn't be able to win such a showdown. But Iran knows
well that the United States wants to avoid the significant costs of a
war, and might back down in a confrontation, thereby rewarding Iran's
aggressive gambits. And if [(or once) Iran crosses the nuclear
threshold, it will have an even greater capacity to deter the United
States]{.underline}. During the Cold War, on the other hand, regional
powers tended to rely on their patron's nuclear umbrella rather than
seeking nukes of their own, and would have had no incentive to defy the
United States by developing them. [Absent a rival superpower to check
its reach, the United States has felt unrestrained, and at times even
obligated, to intervene as a global police officer or arbiter of
international norms against crimes such as genocide]{.underline}. [Time
and again in the post-Cold War age, minor countries that were supposed
to meekly fall in line with American imperatives instead defied them,
drawing America into conflicts in the Balkans, Somalia, Haiti, Iraq, and
Afghanistan]{.underline}. This wasn't what was supposed to happen: [The
world was supposed to be much safer for a unipolar superpower, not more
costly and hazardous.]{.underline}

**[2NC/1NR -- No Impx to Heg]{.underline}**

**No impact to heg -- it's unsustainable and causes war**

**Mearsheimer 18**

John J, smartest man alive, "The Great Delusion: Liberal Dreams and
International Realities", National Interest, 10/5,
[[https://nationalinterest.org/feature/great-delusion-liberal-dreams-and-international-realities-32737]{.underline}](https://nationalinterest.org/feature/great-delusion-liberal-dreams-and-international-realities-32737)
DB

[Liberal hegemony is an ambitious strategy in which a state aims to turn
as many countries as possible into liberal democracies like itself while
also promoting an open international economy and building international
institutions]{.underline}. In essence, **[the liberal state seeks to
spread its own values far and wide]{.underline}**. My goal in this book
is to describe what happens when a powerful state pursues this strategy
at the expense of balance-of-power politics. [Many in the West,
especially among foreign policy elites, consider liberal hegemony a wise
policy that states should axiomatically adopt]{.underline}. Spreading
liberal democracy around the world is said to make eminently good sense
from both a moral and a strategic perspective. For starters, it is
thought to be an excellent way to protect human rights, which are
sometimes seriously violated by authoritarian states. And because the
policy holds that liberal democracies do not want to go to war with each
other, it ultimately provides a formula for transcending realism and
fostering international peace. Finally, proponents claim it helps
protect liberalism at home by eliminating authoritarian states that
otherwise might aid the illiberal forces that are constantly present
inside the liberal state. **[This conventional wisdom is
wrong]{.underline}**. **[Great powers are rarely in a position to pursue
a full-scale liberal foreign policy]{.underline}**. **[As long as two or
more of them exist on the planet, they have little choice but to pay
close attention to their position in the global balance of power and act
according to the dictates of realism]{.underline}**. [Great powers of
all persuasions care deeply about their survival, and there is always
the danger in a bipolar or multipolar system that they will be attacked
by another great power]{.underline}. In these circumstances, [liberal
great powers regularly dress up their hard-nosed behavior with liberal
rhetoric]{.underline}. **[They talk like liberals and act like
realists]{.underline}**. [Should they adopt liberal policies that are at
odds with realist logic, they invariably come to regret it]{.underline}.
But occasionally a liberal democracy encounters such a favorable balance
of power that it is able to embrace liberal hegemony. That situation is
most likely to arise in a unipolar world, where the single great power
does not have to worry about being attacked by another great power since
there is none. Then the liberal sole pole will almost always abandon
realism and adopt a liberal foreign policy. Liberal states have a
crusader mentality hard-wired into them that is hard to restrain.
[Because liberalism prizes the concept of inalienable or natural rights,
committed liberals are deeply concerned about the rights of virtually
every individual on the planet]{.underline}. **[This universalist logic
creates a powerful incentive for liberal states to get involved in the
affairs of countries that seriously violate their citizens'
rights]{.underline}**. To take this a step further, the best way to
ensure that the rights of foreigners are not trampled is for them to
live in a liberal democracy. **[This logic leads straight to an active
policy of regime change, where the goal is to topple autocrats and put
liberal democracies in their place]{.underline}**. [Liberals do not shy
from this task, mainly because they often have great faith in their
state's ability to do social engineering both at home and
abroad]{.underline}. Creating a world populated by liberal democracies
is also thought to be a formula for international peace, which would not
just eliminate war but greatly reduce, if not eliminate, the twin
scourges of nuclear proliferation and terrorism. And lastly, it is an
ideal way of protecting liberalism at home. [This enthusiasm
notwithstanding, **liberal hegemony will not achieve its goals, and its
failure will inevitably come with huge costs**]{.underline}. [The
liberal state is likely to end up fighting endless wars, which will
increase rather than reduce the level of conflict in international
politics and thus aggravate the problems of proliferation and
terrorism]{.underline}. Moreover, [the state's militaristic behavior is
almost certain to end up threatening its own liberal
values]{.underline}. **[Liberalism abroad leads to illiberalism at
home]{.underline}**. Finally, **[even if the liberal state were to
achieve its aims---spreading democracy near and far, fostering economic
intercourse, and creating international institutions---they would not
produce peace]{.underline}**. The key to understanding liberalism's
limits is to recognize its relationship with nationalism and realism.
This book is ultimately all about these three isms and how they interact
to affect international politics. [Nationalism is an enormously powerful
political ideology]{.underline}. It revolves around the division of the
world into a wide variety of nations, which are formidable social units,
each with a distinct culture. Virtually every nation would prefer to
have its own state, although not all can. Still, [we live in a world
populated almost exclusively by nation-states, which means that
liberalism must coexist with nationalism]{.underline}. Liberal states
are also nationstates. [There is no question that liberalism and
nationalism can coexist, but when they clash, nationalism almost always
wins]{.underline}. [The influence of nationalism often undercuts a
liberal foreign policy]{.underline}. For example, **[nationalism places
great emphasis on self-determination, which means that most countries
will resist a liberal great power's efforts to interfere in their
domestic politics---which, of course, is what liberal hegemony is all
about]{.underline}**. These two isms also clash over individual rights.
Liberals believe everyone has the same rights, regardless of which
country they call home. Nationalism is a particularist ideology from top
to bottom, which means it does not treat rights as inalienable. In
practice, the vast majority of people around the globe do not care
greatly about the rights of individuals in other countries. They are
much more concerned about their fellow citizens' rights, and even that
commitment has limits. Liberalism oversells the importance of individual
rights. **[Liberalism is also no match for realism]{.underline}**. At
its core, [liberalism assumes that the individuals who make up any
society sometimes have profound differences about what constitutes the
good life, and these differences might lead them to try to kill each
other]{.underline}. [Thus a state is needed to keep the
peace]{.underline}. But **[there is no world state to keep countries at
bay when they have profound disagreements]{.underline}**. **[The
structure of the international system is anarchic, not hierarchic, which
means that liberalism applied to international politics cannot
work]{.underline}**. [Countries thus have little choice but to act
according to balance-of-power logic if they hope to
survive]{.underline}. There are special cases, however, where a country
is so secure that it can take a break from realpolitik and pursue truly
liberal policies. The results are almost always bad, largely because
nationalism thwarts the liberal crusader. My argument, stated briefly,
is that [nationalism and realism almost always trump
liberalism]{.underline}. Our world has been shaped in good part by those
two powerful isms, not by liberalism. [Consider that five hundred years
ago the political universe was remarkably heterogeneous; it included
city-states, duchies, empires, principalities, and assorted other
political forms]{.underline}. [That world has given way to **a globe
populated almost exclusively by nation states**]{.underline}. Although
many factors caused this great transformation, two of **[the main
driving forces behind the modern state system were nationalism and
balance-of-power politics]{.underline}**. The American Embrace of
Liberal Hegemony This book is also motivated by a desire to understand
recent American foreign policy. The United States is a deeply liberal
country that emerged from the Cold War as by far the most powerful state
in the international system. 1 The collapse of the Soviet Union in 1991
left it in an ideal position to pursue liberal hegemony. 2 The American
foreign policy establishment em braced that ambitious policy with little
hesitation, and with abundant optimism about the future of the United
States and the world. At least at first, the broader public shared this
enthusiasm. The zeitgeist was captured in Francis Fukuyama's famous
article, "The End of History?," published just as the Cold War was
coming to a close. 3 Liberalism, he argued, defeated fascism in the
first half of the twentieth century and communism in the second half,
and now there was no viable alternative left standing. The world would
eventually be entirely populated by liberal democracies. According to
Fukuyama, these nations would have virtually no meaningful disputes, and
wars between great powers would cease. The biggest problem confronting
people in this new world, he suggested, might be boredom. [It was also
widely believed at the time that the spread of liberalism would
ultimately bring an end to balance-of-power politics]{.underline}. The
harsh security competition that has long characterized great-power
relations would disappear, and realism, long the dominant intellectual
paradigm in international relations, would land on the scrap heap of
history. "In a world where freedom, not tyranny, is on the march," Bill
Clinton proclaimed while campaigning for the White House in 1992, "the
cynical calculus of pure power politics simply does not compute. It is
ill-suited to a new era in which ideas and information are broadcast
around the globe before ambassadors can read their cables." [Probably no
recent president embraced the mission of spreading liberalism more
enthusiastically than George W. Bush, who said in a speech in March
2003, two weeks before the invasion of Iraq]{.underline}: "[The current
Iraqi regime has shown the power of tyranny to spread discord and
violence in the Middle East]{.underline}. [A liberated Iraq can show the
power of freedom to transform that vital region, by bringing hope and
progress into the lives of millions]{.underline}. America's interests in
security, and America's belief in liberty, both lead in the same
direction: to a free and peaceful Iraq." Later that year, on September
6, he proclaimed: "The advance of freedom is the calling of our time; it
is the calling of our country. From the Fourteen Points to the Four
Freedoms, to the Speech at Westminster, America has put our power at the
service of principle. We believe that liberty is the design of nature;
we believe that liberty is the direction of history. We believe that
human fulfillment and excellence come in the responsible exercise of
liberty. And we believe that freedom---the freedom we prize---is not for
us alone, it is the right and the capacity of all mankind." Something
went badly wrong. **[Most people's view of U.S. foreign policy today, in
2018, is starkly different from what it was in 2003, much less the early
1990s]{.underline}**. **[Pessimism, not optimism, dominates most
assessments of America's accomplishments during its holiday from
realism]{.underline}**. [Under Presidents Bush and Barack Obama,
Washington has played a key role in sowing death and destruction across
the greater Middle East, and there is little evidence the mayhem will
end anytime soon]{.underline}. American policy toward Ukraine, motivated
by liberal logic, is principally responsible for the ongoing crisis
between Russia and the West. [The United States has been at war for two
out of every three years since 1989, fighting seven different
wars]{.underline}. We should not be surprised by this. Contrary to the
prevailing wisdom in the West, a **[liberal foreign policy is not a
formula for cooperation and peace but for instability and
conflict]{.underline}**. In this book I focus on [the period between
1993 and 2017, when the Clinton, Bush, and Obama administrations, each
in control of American foreign policy for eight years, were fully
committed to pursuing liberal hegemony]{.underline}. Although President
Obama had some reservations about that policy, they mattered little for
how his administration actually acted abroad. I do not consider the
Trump administration for two reasons. First, as I was finishing this
book it was difficult to determine what President
**[Trump]{.underline}**'s foreign policy would look like, although it is
clear from his rhetoric during the 2016 campaign that he **[recognizes
that liberal hegemony has been an abject failure and would like to
abandon key elements of that strategy]{.underline}**. Second, **[there
is good reason to think that with the rise of China and the resurrection
of Russian power having put great power politics back on the table,
Trump eventually will have no choice but to move toward a grand strategy
based on realism, even if doing so meets with considerable resistance at
home]{.underline}**.

**[2NC/1NR -- Transition Wars]{.underline}**

**Hege is unsustainable and makes Russia/China nuclear war inevitable --
allowing limited Russian/Chinese influence checks revisionism without
risking transition wars**

**Allison 20**

Graham, Douglas Dillon Professor of Government at the Harvard Kennedy
School, "The New Spheres of Influence: Sharing the Globe With Other
Great Powers.", Foreign Affairs, Vol. 99, Iss. 2 DB

COME HOME, AMERICA? In the heady aftermath of the Cold War, American
policymakers pronounced one of the fundamental concepts of geopolitics
obsolete. Secretary of State Condoleezza Rice described a new world \"in
which great power is defined not by spheres of influence ... or the
strong imposing their will on the weak.\" Secretary of State Hillary
Clinton declared that \"the United States does not recognize spheres of
influence.\" Secretary of State John Kerry proclaimed that \"the era of
the Monroe Doctrine is over,\" ending almost two centuries of the United
States staking claim to its own sphere of influence in the Western
Hemisphere. Such pronouncements were right in that something about
geopolitics had changed. But they were wrong about what exactly it was.
U.S. policymakers had ceased to recognize spheres of influence\--the
ability of other powers to demand deference from other states in their
own regions or exert predominant control there\--not because the concept
had become obsolete. Rather, **[the entire world had become a de facto
American sphere]{.underline}**. Spheres of influence had given way to a
sphere of influence. The strong still imposed their will on the weak;
the rest of the world was compelled to play largely by American rules,
or else face a steep price, from crippling sanctions to outright regime
change. **[Spheres of influence hadn\'t gone away; they had been
collapsed into one, by the overwhelming fact of U.S.
hegemony]{.underline}**. **[Now, however, that hegemony is fading, and
Washington has awakened to what it calls \"a new era of great-power
competition,\" with China and Russia increasingly using their power to
assert interests and values that often conflict with those of the United
States]{.underline}**. **[But American policymakers and analysts are
still struggling to come to grips with what this new era means for the
U.S. role in the world]{.underline}**. **[Going forward, that role will
not only be different; it will also be significantly
diminished]{.underline}**. While leaders will continue announcing grand
ambitions, diminished means will mean diminished results. **[Unipolarity
is over, and with it the illusion that other nations would simply take
their assigned place in a U.S.-led international order]{.underline}**.
**[For the United States, that will require accepting the reality that
there are spheres of influence in the world today\--and that not all of
them are American spheres]{.underline}**. THE WORLD AS IT WAS Before
making pronouncements about the new rules of geopolitics, post-Cold War
U.S. secretaries of state should have looked back to the final months of
World War II, when U.S. policymakers were similarly resistant to
accepting a world in which spheres of influence remained a central
feature of geopolitics. Competing views on the issue lay at the core of
a debate between two top Soviet experts in the U.S. government. On
February 4, 1945, President Franklin Roosevelt met with Soviet leader
Joseph Stalin and British Prime Minister Winston Churchill at Yalta. At
Roosevelt\'s side was his translator and principal adviser on the Soviet
Union, Charles Bohlen. Just that morning, Bohlen had opened an urgent
private missive from his close colleague George Kennan in Moscow. Kennan
correctly forecast that the Soviet Union would attempt to maintain
control of as much of Europe as it could. The question was what the
United States should do about that. Kennan asked, \"Why could we not
make a decent and definitive compromise with it\--divide Europe frankly
into spheres of influence\--keep ourselves out of the Russian sphere and
keep the Russians out of ours?\" Bohlen was appalled. \"Utterly
impossible,\" he erupted in response. \"Foreign policy of that kind
cannot be made in a democracy.\" Reflecting on this moment later, Bohlen
explained: \"The American people, who had fought a long, hard war,
deserved at least an attempt to work out a better world.\" Between 1945
and 1947, Bohlen worked alongside other leading figures in the Roosevelt
and then the Truman administration to realize their \"one world\"
vision, in which the allies who had fought together to defeat the Nazis
would remain allied in creating a new global order. But he ultimately
resigned himself to the world as it was\--in short, Kennan had been
right. \"Instead of unity among the great powers on the major issues of
world reconstruction\--both political and economic\--after the war,
there is complete disunity between the Soviet Union and the satellites
on one side and the rest of the world on the other,\" Bohlen
acknowledged in the summer of 1947 in a memo to Secretary of State
George Marshall. \"There are, in short, two worlds instead of one.\"
When he finally came to share Kennan\'s diagnosis, Bohlen did not shrink
from the implications. His memo to Marshall concluded: Faced with this
disagreeable fact, however much we may deplore it, the United States in
the interest of its own well-being and security and those of the free
non-Soviet world must ... draw \[the non-Soviet world\] closer together
politically, economically, financially, and, in the last analysis,
militarily in order to be in a position to deal effectively with the
consolidated Soviet area. This conviction became a pillar of the United
States\' strategy for the coming decades, and it rested on the
acceptance of spheres of influence. There would be areas that would be
subjected to Soviet domination, with often terrible consequences, but
the best course for the United States was to bolster those powers on the
periphery of this Soviet sphere while reinforcing the strength and unity
of its own sphere. For the four decades that followed, the United States
and the Soviet Union engaged in the great-power competition that we know
as the Cold War. In the Soviet sphere, the captive nations of Eastern
Europe remained under the boot of an \"evil empire.\" American
presidents faced repeated crises in which they had to choose between
sending troops into Soviet-dominated nations to support freedom fighters
seeking to exercise rights that the American creed declares universal
and standing by as those freedom fighters were slaughtered or
suppressed. Without exception, U.S. presidents chose to watch instead of
intervene: consider Dwight Eisenhower when Hungarians rose up in 1956
and Lyndon Johnson during the Prague Spring of 1968 (or, after the Cold
War, George W. Bush when Russian troops attacked Georgia in 2008 and
Barack Obama when Russian special forces seized Crimea). Why? Each had
internalized an unacceptable yet undeniable truth: that, as U.S.
President Ronald Reagan once explained in a joint statement with Soviet
leader Mikhail Gorbachev, \"a nuclear war cannot be won and must never
be fought.\" This bit of Cold War history should serve as a reminder: a
nation that is simultaneously idealistic and realistic will always
struggle to reconcile rationales and rationalizations of purpose, on the
one hand, with realities of power, on the other. The result, in the
foreign policy analyst Fareed Zakaria\'s apt summary, has been \"the
rhetoric of transformation but the reality of accommodation.\" Even at
the height of U.S. power, accommodation meant accepting the ugly fact of
a Soviet sphere of influence. TECTONIC SHIFTS After nearly half a
century of competition, when the Cold War ended and the Soviet Union
disappeared, in 1991, the United States was left economically,
militarily, and geopolitically dominant. In the first two decades of the
post-Cold War era, U.S. defense spending exceeded the defense budgets of
the next ten nations combined (five of them U.S. treaty allies).
Operationally, that meant that, as Secretary of Defense James Mattis\'s
2018 National Defense Strategy put it, the United States \"enjoyed
uncontested or dominant superiority in every operating domain. We could
generally deploy our forces when we wanted, assemble them where we
wanted, and operate how we wanted.\" The United States and its allies
could welcome new members into NATO, applying to them its Article 5
security guarantee, without thinking about the risks, since the alliance
faced no real threat. In that world, strategy in essence consisted of
overwhelming challenges with resources. But that was then. The tectonic
shift in the balance of power that occurred in the first two decades of
the twenty-first century was as dramatic as any shift the United States
has witnessed over an equivalent period in its 244 years. To paraphrase
Vaclav Havel, then the president of Czechoslovakia, it has happened so
fast, we have not yet had time to be astonished. The U.S. share of
global GDP\--nearly one-half in 1950\--has gone from one-quarter in 1991
to one-seventh today. (Although GDP is not everything, it does form the
substructure of power in relations among nations.) **[And as the United
States\' relative power has declined, the menu of feasible options for
policymakers has shrunk]{.underline}**. Consider, for example, the U.S.
response to China\'s Belt and Road Initiative. With currency reserves of
almost \$3 trillion, China can invest \$1.3 trillion in infrastructure
linking most of Eurasia to a China-centered order. When Secretary of
State Mike Pompeo announced that the United States would increase its
own investments in the Indo-Pacific in response, he was able to come up
with just \$113 million in new investments. China has, of course, been
the chief beneficiary of this transformation. In the past generation,
its GDP has soared: from 20 percent of the U.S. level in 1991 to 120
percent today (measured by purchasing power parity, the metric that both
the CIA and the International Monetary Fund use to compare national
economies). Although China faces many internal challenges, there are
more reasons to expect this basic economic trend to continue than to bet
that it will stop soon. With four times as many citizens as the United
States, and if Chinese workers become as productive as Portuguese
workers are today (that is, around half as productive as Americans),
China will see its GDP rise to double that of the United States. **[In
Asia, the economic balance of power has tilted especially dramatically
in China\'s favor]{.underline}**. As the world\'s largest exporter and
second-largest importer, China is the top trading partner of every other
major East Asian country, including U.S. allies. (And as an aggressive
practitioner of economic statecraft, Beijing does not hesitate to use
the leverage this provides, squeezing countries such as the Philippines
and South Korea when they resist Chinese demands.) **[Globally, China is
also rapidly becoming a peer competitor of the United States in advanced
technologies]{.underline}**. Today, of the 20 largest information
technology companies, nine are Chinese. Four years ago, when Google, the
global leader in artificial intelligence (AI), the most significant
advanced technology, assessed its competition, Chinese companies ranked
alongside European companies. Now, that state of affairs is barely
visible in the rearview mirror: Chinese companies lead in many areas of
applied AI, including surveillance, facial and voice recognition, and
financial technology. **[China\'s military spending and capabilities
have surged]{.underline}**, as well. A quarter century ago, its defense
budget was one-25th that of the United States; now, it is one-third and
on a path to parity. And whereas the U.S. defense budget is spread
across global commitments, many of them in Europe and the Middle East,
China\'s budget is focused on East Asia. Accordingly, in specific
military scenarios involving a conflict over Taiwan or in the South
China Sea, China may have already taken the lead. Short of actual war,
the best tests of relative military capabilities are war games. In 2019,
Robert Work, a former U.S. deputy secretary of defense, and David
Ochmanek, one of the Defense Department\'s key defense planners, offered
a public summary of the results from a series of classified recent war
games. Their bottom line, in Ochmanek\'s words: \"When we fight Russia
and China, \'blue\' \[the United States\] gets its ass handed to it.\"
As The New York Times summarized, \"In 18 of the last 18 Pentagon war
games involving China in the Taiwan Strait, the U.S. lost.\" Russia is a
different matter. Whatever President Vladimir Putin might want, Russia
will never again be his father\'s Soviet Union. When the Soviet Union
dissolved, the resulting Russian state was left with less than half the
GDP and half the population and saw its borders rolled back to the days
before Catherine the Great. **[Yet Russia remains a nuclear superpower
with an arsenal that is functionally equivalent to that of the United
States; it has a defense industry that produces weapons the world is
eager to buy (as India and Turkey have demonstrated in the past year);
and it boasts military forces that can fight and win\--as they have
demonstrated repeatedly in Chechnya, Georgia, Ukraine, and
Syria]{.underline}**. On a continent where most of the other nations
imagine that war has become obsolete, and maintain military forces more
for ceremonial than combat operations, military prowess may now be
Russia\'s major comparative advantage. BACK TO BASICS **[The claim that
spheres of influence had been consigned to the dustbin of history
assumed that other nations would simply take their assigned places in a
U.S.-led order]{.underline}**. **[In retrospect, that assumption seems
worse than naive]{.underline}**. Yet because many U.S. analysts and
policymakers still cling to images of China and Russia formed during
this bygone era, their views about what the United States should and
should not do continues to reflect a world that has vanished. Over the
course of centuries of geopolitical competition, policymakers and
theorists developed a set of core concepts to help clarify the
complexities of relations among states, including spheres of influence,
balances of power, and alliances. These concepts must be adapted to take
account of specific conditions in the twenty-first century. Yet they
remain the sturdiest building blocks available for understanding and
constructing international order. Where the equilibrium of forces
between one state and another shifts to the point where the first
becomes predominant, the resulting new balance of power casts a shadow
that becomes, in effect, a \"sphere of influence.\" That specific term
entered the vocabulary of diplomacy in the early nineteenth century, but
the concept is as old as international relations itself. (As Thucydides
noted, after the defeat of the Persians in the fifth century BC, Sparta
demanded that Athens not rebuild the walls around its city-state to
leave itself vulnerable.) Traditionally, great powers have demanded a
degree of deference from lesser powers on their borders and in adjacent
seas, and they have expected other great powers to respect that fact.
Recent actions by China and Russia in their respective neighborhoods are
just the most recent examples of that tradition. Spheres of influence
also extend beyond geography. When the United States led the world in
the creation of the Internet, and the hardware and software that
empowered it, the United States enjoyed what Michael Hayden, a former
director of the National Security Agency, later called a \"golden age of
electronic surveillance.\" Since most countries were unaware of the
surveillance capabilities revealed by the former NSA contractor Edward
Snowden, the United States had an unparalleled ability to exploit
technology to listen to, track, and even influence them. But
post-Snowden, many states are resisting the current U.S. campaign to
prevent them from buying their 5G wireless infrastructure from the
Chinese telecommunications giant Huawei. As the leader of a country
currently considering the choice recently put it, Washington is trying
to persuade other countries not to buy Chinese hardware because it will
make it easier for China to spy and instead to buy American hardware,
which would make it easier for the United States to spy. A REALISTIC
RECKONING **[From the perspective of American interests and values, the
consequences of increases in China\'s and Russia\'s power relative to
that of the United States are not good]{.underline}**. As great powers,
China and Russia can use their power to suppress protesters\' freedom in
Hong Kong or block Ukrainian membership in NATO. The South China Sea is
likely to become more like the Caribbean than the Mediterranean\--that
is, China\'s neighbors in Southeast Asia will be as beholden to China as
Latin Americans have been to their hemispheric hegemon. Ukraine will
have to get over the loss of Crimea as countries in Russia\'s \"near
abroad\" learn to be both more fearful of and more deferential to the
Kremlin. For many other nations and individuals around the world who
have found shelter under the American security umbrella and found
inspiration in a vision of an American-led international order that
safeguards core liberties, the consequences will be tragic. Recent
events in Syria offer a preview of what\'s to come. As the Arab Spring
erupted in late 2010 and 2011, Obama famously declared that Syrian
leader Bashar al-Assad \"must go.\" But Putin had other ideas, and he
was willing to act on them. He demonstrated that a nation Obama had
dismissed as a \"regional power\" could use its military forces to defy
the United States and help the Syrian leader consolidate his control.
This has been a horror for Syrians, and the millions of displaced people
have had a major impact on neighboring countries and Europe. But did
Obama, or, later, President Donald Trump, conclude that this outcome was
so costly that it would be better to send large numbers of U.S. troops
to fight and perhaps die in Syria? Can Americans sleep soundly in a
world in which Putin and Assad now smile when they ask visitors who is
gone and who is still standing? U.S. inaction speaks for itself. Sadly,
Americans will come to accept such outcomes as good enough\--at least
for the foreseeable future. Like Assad\'s atrocities, Russia\'s
absorption of Crimea and China\'s militarization of the South China Sea
are now facts on the ground that no one will contest militarily.
**[Acknowledging that other powers have spheres of influence does not,
of course, mean that the United States can do nothing]{.underline}**. It
is a reflection of the recent overmilitarization of U.S. foreign policy
that restraint in the use of military force is often equated with
acquiescence. Washington has other ways in which it can shape other
countries\' calculations of costs and benefits: through the condemnation
of unacceptable actions; the denial of legal status; the imposition of
economic sanctions on countries, companies, and individuals; and support
for local resisters. But such tools can rarely decisively alter a
decision another power has made when interests it sees as vital are at
stake. And it is worth remembering how often a refusal to recognize and
accept realities on the ground in the shadow of other powers has led to
major U.S. policy failures. From General Douglas MacArthur\'s rush to
the Chinese border during the Korean War (which triggered Chinese
intervention and a bloody, inconclusive war) to George W. Bush\'s
insistence that NATO offer membership to Georgia and Ukraine (which led
to Georgian overconfidence, ending in the country\'s partial
dismemberment by Russia), a stubborn disregard of brute facts has been
counterproductive. THE MUSEUM OF RETIRED INTERESTS When it comes to
doing what it can, Washington should focus above all on its alliances
and partnerships. If China is destined to be \"the biggest player in the
history of the world,\" as the longtime Singaporean leader Lee Kuan Yew
once claimed, the United States must work to assemble allied powers who
together will constitute a correlation of forces to which China will
have to adjust. This logic is most evident in the economic arena. Before
the Trump administration ended U.S. participation in the Trans-Pacific
Partnership, that trade agreement promised to bring together countries
accounting for 40 percent of global GDP under a common set of rules on
everything from tariffs to state-owned enterprises to labor and
environmental standards\--providing a counterweight to Chinese economic
might that could have made Beijing a rule-taker rather than a
rule-maker. Thanks to the efforts of Japanese Prime Minister Shinzo Abe,
the TPP is now a reality\--but without the United States. If American
policymakers could find a way to allow strategic interests to trump
politics, the United States could rejoin the TPP. If that new TPP were
combined with the parallel trade agreement between the United States and
the European Union that was being negotiated at the end of the Obama
administration, nearly 70 percent of the world\'s GDP could be on one
side of the balance, versus China\'s approximately 20 percent on the
other. In the military arena, the same logic applies, but with more
complexity. Washington will need partners\--but partners that bring more
in assets than they introduce in risks. Unfortunately, few of the United
States\' current allies meet this standard. The U.S. alliance system
should be subjected to a zero-based analysis: every current ally and
partner, from Pakistan, the Philippines, and Thailand to Latvia, Saudi
Arabia, and Turkey, should be considered in terms of what it is doing to
enhance U.S. security and well-being, and with what risks and costs.
Alliances are not forever. Historically, when conditions have changed,
particularly when a focal enemy has disappeared or balances of power
have shifted dramatically, so, too, have other relationships among
nations. Most Americans today have forgotten an era in which NATO had a
counterpart in Asia, SEATO (the Southeast Asia Treaty Organization), and
even an analogue in the Middle East, CENTO (the Central Treaty
Organization); both of those are now artifacts in the museum of retired
national interests. As Kennan noted, \"There is more respect to be won
... by a resolute and courageous liquidation of unsound positions than
by the most stubborn pursuit of extravagant or unpromising objectives.\"
To understand the risks entailed in the inheritance of current U.S.
alliances, consider two scenarios U.S. defense planners worry about
today. If, watching China\'s suppression of protests in Hong Kong,
Taiwan should make a dramatic move toward independence that leads China
to react violently, would the United States go to war with China to
preserve Taiwan\'s status? Should it? On the European front, if in
response to an uprising of ethnic Russian workers in Riga\'s shipyards,
the Latvian government cracked down on ethnic Russians and sparked
Russia\'s annexation of a swath of Latvia\--Crimea 2.0\--would NATO
launch an immediate military response, in accordance with its Article 5
guarantee? Should it? If the answer to any of those questions is not a
straightforward yes\--and it is not\--then the time has come for an
alliance-focused version of the stress tests for banks used after the
2008 financial crisis. **[Such an approach is all the more important
given the realities of nuclear weapons in this new world]{.underline}**.
**[Both China and Russia have reliable second-strike nuclear
capabilities\--that is, the ability to withstand an initial nuclear
attack and conduct a retaliatory strike that could destroy the United
States]{.underline}**. Accordingly, not only is nuclear war not a viable
option; even a **[conventional war that could escalate to nuclear war
risks catastrophe]{.underline}**. Competition must thus be tempered by
caution, constraints, and careful calculations in risk taking. **[For a
nation that has accumulated a long list of entanglements with nations
that may have, or may imagine they have, a blank check from Washington,
this creates a big problem]{.underline}**. **[The line between
reassuring an ally and emboldening its leadership to act recklessly is a
fine one]{.underline}**. **[If the balance of military power in a
conventional war over Taiwan or the Baltics has shifted decisively in
China\'s and Russia\'s favor, current U.S. commitments are not
sustainable]{.underline}**. **[The gap between those commitments and the
United States\' actual military capabilities is a classic case of
overstretch]{.underline}**. What a zero-based assessment would mean for
the current alliance system, and for U.S. relations with each of more
than 50 treaty allies and partners, should emerge as a result of an
analysis of the evidence. But it would likely lead the United States to
**[shed some allies]{.underline}**, **[double down on
others]{.underline}** whose assets are as important for U.S. security as
U.S. assets are for them, and radically revise the terms of each
commitment to make obligations and restraints as prominent as
reassurances and guarantees. This process would also enhance the
credibility of the commitments that the United States chose to renew.
While the veterans of the Cold War rightly claim that NATO has been the
greatest alliance in the history of the world, neither Trump nor Obama
before him was convinced. Tellingly, American military commanders
doubted that the North Atlantic Council would authorize a military
response to the Russian annexation of Crimea or that the U.S. government
would be able to make a decision about how to respond before the event
was over. **[Rethinking the United States\' commitments to its allies
would enhance American security and make these same pacts
stronger]{.underline}**. PRESENT AT THE (RE-)CREATION Strategy is the
purposeful alignment of means and ends. Among the many ways in which a
strategy fails, the two most common are mismatch\--when the means an
actor can organize and sustain are insufficient to achieve the stated
ends\--and vision blindness, when an actor is mesmerized by an ideal but
unachievable end. The United States\' twenty-first-century wars in the
Middle East offer vivid examples of both. **[Going forward, U.S.
policymakers will have to abandon unattainable aspirations for the
worlds they dreamed of and accept the fact that spheres of influence
will remain a central feature of geopolitics]{.underline}**. That
acceptance will inevitably be a protracted, confusing, and wrenching
process. Yet it could also bring a wave of strategic creativity\--an
opportunity for nothing less than a fundamental rethinking of the
conceptual arsenal of U.S. national security. The basic view of the
United States\' role in the world held by most of today\'s
foreign-policy makers was imprinted in the quarter century that followed
the U.S. victory in the Cold War. That world is now gone. The
consequences are as profound as those that Americans confronted in the
late 1940s. Accordingly, it is worth remembering how long it took
individuals now revered as \"wise men\" to understand the world they
faced. Nearly five years passed between Kennan\'s \"Long Telegram,\" an
early warning of Cold War competition, and the policy paper NSC-68,
which finally laid out a comprehensive strategy. The confusion that
reigns in the U.S. foreign policy community today should thus not be a
cause for alarm. If it took the great strategists of the Cold War nearly
five years to forge a basic approach, it would be beyond hubris to
expect this generation to do better.

**Case -- U.S. -- China Coop**

**[1NC vs US -- China Coop]{.underline}**

**Too many alt causes too coop**

- Multiple reasons = divergence on core issues Biden's antognistic
  approach preferring confrontation rather than cooperation

**Haenle & Bresnick 2/21**/2022

Paul Haenle holds the Maurice R. Greenberg Director's Chair at the
Carnegie Endowment for International Peace and is a visiting senior
research fellow at the East Asian Institute, National University of
Singapore. Sam Bresnick is assistant editor and research assistant.,
"Why U.S.-China Relations Are Locked in a Stalemate",
<https://carnegieendowment.org/2022/02/21/why-u.s.-china-relations-are-locked-in-stalemate-pub-86478>
\-- ECM

Fifty years ago this week, former U.S. President Richard Nixon flew to
China, setting the stage for a dramatic shift in relations between the
two countries. Much has changed since that visit, not always for the
better. [Despite]{.underline} a flurry of [diplomatic activity over the
past year]{.underline}, **[U.S.-China ties remain tense]{.underline}**.
Discussions in Alaska and Tianjin yielded few, if any, breakthroughs.
While friendlier in tone, the recent summit between Chinese President Xi
Jinping and U.S. President Joe Biden led only to agreements to hold yet
more talks, albeit on important issues such as strategic stability. The
lone bilateral bright spot has been some cooperation on climate.

Since the summit, the Biden administration announced its diplomatic
boycott of the Beijing Olympics and added more Chinese companies to its
trade restriction list while Congress passed a bill aimed at countering
China's forced labor abuses in Xinjiang. [The two sides' antagonistic
stances on issues related to **security**]{.underline}, economics,
**[tech]{.underline}**nology, **[and ideology have largely
crystalized]{.underline}**, [leaving little space for]{.underline} the
[adjustments]{.underline} that could relieve simmering tensions. Below,
Paul Haenle and Sam Bresnick analyze how the two countries got here and
how they can move forward.

WHY ARE THE TWO SIDES STUCK?

Former U.S. President Donald Trump ushered in a more confrontational era
in U.S.-China relations, and Biden has largely maintained his
predecessor's approach to Beijing, albeit with a more equanimous tone
and embrace of multilateralism. [The U.S]{.underline}. government [has
for decades been concerned by China's mercantilism, rapid military
modernization, and illiberal approach to human rights]{.underline}, but
it had held out hope that China might liberalize through increasingly
robust contact with the rest of the world. That has not happened, and
the United States and others have lost patience with
[China's]{.underline} state [capitalist system]{.underline},
[militarization of the]{.underline} [S]{.underline}outh
[C]{.underline}hina [S]{.underline}ea, [and increasingly authoritarian
governance]{.underline}.

But **[Beijing is not backing down]{.underline}**. Despite facing
pronounced international pushback during the pandemic, [Xi has become
even more confident in China's economic system]{.underline}, [governance
model]{.underline}, [and approach to international affairs]{.underline}.
"**[Time and momentum are on China's side]{.underline}**," [he
argued]{.underline} last year at a high-level meeting, though many
analysts accuse the party of overconfidence. At the same time, Chinese
officials are increasingly looking askance at their U.S. counterparts.
Many appear to believe that the United States, though still a formidable
power, is in the early stages of an inevitable decline. Just as China
resumes its rightful place atop the hierarchy of Asian nations,
Beijing's thinking goes, the United States' unresolved racial justice
issues, income inequality, and political polarization will catalyze an
irreversible diminution of U.S. power in Asia and across the globe.

**Or -- SQ solves AND collaboration is high**

**Andrews 3/16**/2022

Edmund L. Andrews is a economics reporter for The New York Times, "China
and the United States: Unlikely Partners in AI",
<https://hai.stanford.edu/news/china-and-united-states-unlikely-partners-ai>
\-- ECM

[Despite both rivalry and]{.underline} rising [tensions]{.underline}
between the United States and China, [the two nations have
become]{.underline} **[the world's leading collaborators in research
on]{.underline}** **[A]{.underline}**rtificial
**[I]{.underline}**ntelligence.

The [newly released AI Index Report]{.underline}, **[which tracks AI
trends]{.underline}** on a host of fronts and is published by the
Stanford Institute for Human-Centered Artificial Intelligence, **[finds
that U.S. and Chinese AI researchers teamed up on far more published
articles than collaborators between any other two
nations]{.underline}**.

Overall, U.S.-China [collaborations]{.underline} on AI research **[have
quintupled since 2010]{.underline}** and totaled 9,660 papers in
2021---[much faster than the increase in collaborations between any
other two nations]{.underline}. Collaborations between the United States
and United Kingdom, the second most prolific source of cross-border
research, increased almost threefold to 3,560 papers.

**No emerging tech impact.**

**Sechser** et al. **19**,

Todd S., Pamela Feinour Edmonds and Franklin S. Edmonds, Jr. Discovery
Professor of Politics and Public Policy at the University of Virginia
and Senior Fellow at the Miller Center of Public Affairs, \*\*Neil
Narang, Associate Professor of Political Science at the University of
California, Santa Barbara, \*\*\*Caitlin Talmadge, Associate Professor
of Security Studies in the School of Foreign at Georgetown University. (
"Emerging technologies and strategic stability in peacetime, crisis, and
war", *Journal of Strategic Studies*, 42:6, pg. 728-729

Yet [the **history of technological revolutions** counsels **against**
alarmism]{.underline}. Extrapolating from current technological trends
is problematic, both because [technologies often **do not live up to
their promise**, and because technologies often have **countervailing**
or **conditional effects** that can **temper** their **negative
consequences**]{.underline}. Thus, [the fear that **emerging
technologies** will necessarily cause **sudden** and **spectacular
changes** to international politics should be treated with
**caution**]{.underline}. There are at least two reasons to be
circumspect. First, [very **few** technologies fundamentally reshape the
dynamics of international conflict.]{.underline} Historically, [most
technological innovations have amounted to **incremental
advancements,**]{.underline} [and]{.underline} some have **[disappeared
into irrelevance]{.underline}** despite widespread hype about their
promise. For example, [the introduction of **chemical
weapons**]{.underline} [was widely expected to immediately change the
nature of warfare]{.underline} and deterrence after the British army
first used poison gas on the battlefield during World War I. [Yet
chemical weapons quickly turned out to be less **practical**, easier to
**counter**, and **less effective**]{.underline} than conventional
high-explosives in inflicting damage and disrupting enemy operations.6
Other technologies have become important only after advancements in
other areas allowed them to reach their full potential: until armies
developed tactics for effectively employing firearms, for instance,
these weapons had little effect on the balance of power. And [even when
technologies do have significant strategic consequences, they often take
**decades to emerge**]{.underline}, as the invention of airplanes and
tanks illustrates. In short, [it is easy to **exaggerate** the strategic
effects of nascent technologies]{.underline}.7 Second, even if today's
emerging technologies are poised to drive important changes in the
international system, they are likely to have variegated and even
contradictory effects. Technologies may be destabilising under some
conditions, but stabilising in others. Furthermore, [other factors are
likely to **mediate** the effects of **new technologies** on the
international system, including **geography**, the **distribution of
material power, military strategy**, **domestic** and **organisational
politics**, and social and cultural variables, to name **only a
few**]{.underline}.8 Consequently, [the strategic effects of new
technologies often **defy** simple classification.]{.underline} Indeed,
more than 70 years after [nuclear weapons]{.underline} emerged as a new
technology, their [consequences for stability **continue** to be
debated]{.underline}.9

**[2NC/1NR -- Collab increasing now]{.underline}**

**Collab on AI is *[INCREASING]{.underline}* despite geopolitical
friction.**

**Andrews 3/16**/2022

Edmund L. Andrews is a economics reporter for The New York Times, "China
and the United States: Unlikely Partners in AI",
<https://hai.stanford.edu/news/china-and-united-states-unlikely-partners-ai>
\-- ECM

The startling trend highlights a paradox. Even [as China and the U.S.
race for leadership in]{.underline} what they view as a strategically
important [tech]{.underline}nology, **[researchers on both sides appear
to see benefits in]{.underline}** sharing expertise and **[working
together]{.underline}**.

"What's clear is that the amount of [collaboration between the
**U**]{.underline}nited **[S]{.underline}**tates **[and China has gone
up]{.underline}** dramatically, and it has gone up much more than
collaborations between any two other countries," says Raymond Perrault,
Distinguished Computer Scientist at SRI International in Menlo Park and
co-chair of the AI Index Steering Committee.

To some extent, the surge in U.S.-China research simply reflects the
fact that both nations have poured vast resources into artificial
intelligence and produce huge amounts of research. On top of that, many
Chinese researchers were trained in the United States and retain close
professional ties to their American colleagues.

But [the practice is consistent with patterns observed during previous
tech]{.underline}nological [revolutions]{.underline} in textiles, steel,
and chemical engineering. Research by Jeffrey Ding, a postdoctoral
fellow at Stanford HAI, has shown that the full economic impact of
historic tech advances stemmed less from which nation pioneered a
technology than from which ones were best at applying it across a broad
range of industries. That dispersion of technology requires sharing
information across industries as well as borders, much as the United
States catapulted applied British advances in steel machinery to develop
manufacturing approaches that catapulted it to economic dominance.

That said, **[the collaboration in AI]{.underline}** [comes at a time of
growing friction between the U]{.underline}nited [States and
China]{.underline} [over trade, human rights, and strategic power in the
Pacific Rim]{.underline}. Former President Donald Trump villainized
China over its trade practices, and President Joe Biden imposed a
diplomatic boycott of the Beijing Olympics over China\'s human rights
abuses.

**[2NC/1NR -- Alt Causes]{.underline}**

**Human rights thump**

**East-West Center.Org**

"US-CHINA RELATIONS: IS THERE A WAY OUT OF THE ABYSS?",
<https://www.eastwestcenter.org/news-center/east-west-wire/us-china-relations-there-way-out-the-abyss>
\--ECM

Mingjiang [Li]{.underline}, **[an associate professor and provost's
chair in international relations at Nanyang]{.underline}** Technological
University in Singapore, [said]{.underline} that [US-China relations are
at a]{.underline} "**[very crucial moment]{.underline}**," and many
**[analysts worry that the relationship could]{.underline}** "**[slip
into a new Cold War]{.underline}**."

Li suggested, however, that [the US could smooth tensions by focusing
less attention on human rights]{.underline} issues that China says are
internal matters. "Too much US intervention in China\'s domestic
politics may actually not be helpful in changing China politically," he
said.

[But]{.underline} America's [concerns about]{.underline} China's [human
rights abuses]{.underline} **[are not likely to go away]{.underline}**,
according to Rick Waters, US deputy assistant secretary of state for
China, Taiwan and Mongolia. In addition, he said, "The challenge of
managing this relationship is complicated immensely by the increased
aggressiveness of Chinese foreign and external policies. We face a
competitor potentially capable of combining economic, diplomatic,
military and technological power to mount a type of sustained challenge
that we have not seen in the international system."

**[2NC/1NR -- No AI impx]{.underline}**

**AI impact is fake**

**Miller 17**

Ron, "Artificial intelligence is not as smart as you (or Elon Musk)
think", TechCrunch, 7/25,
<https://techcrunch.com/2017/07/25/artificial-intelligence-is-not-as-smart-as-you-or-elon-musk-think/>
DB

In March 2016, DeepMind's AlphaGo beat Lee Sedol, who at the time was
the best human Go player in the world. It represented one of those
defining technological moments like IBM's Deep Blue beating chess
champion Garry Kasparov, or even IBM Watson beating the world's greatest
Jeopardy! champions in 2011. Yet **[these victories, as mind-blowing as
they seemed to be, were more about training algorithms and using
brute-force computational strength than any real
intelligence]{.underline}**. Former MIT robotics professor Rodney
Brooks, who was one of the founders of iRobot and later Rethink
Robotics, reminded us at the TechCrunch Robotics Session at MIT last
week that **[training an algorithm to play a difficult strategy game
isn't intelligence, at least as we think about it with
humans]{.underline}**. He explained that [as strong as AlphaGo was at
its given task, it actually couldn't do anything else but play Go on a
standard 19 x 19 board]{.underline}. He relayed a story that while
speaking to the DeepMind team in London recently, he asked them what
would have happened if they had changed the size of the board to 29 x
29, and the AlphaGo team admitted to him that had there been even a
slight change to the size of the board, "we would have been dead." "I
think people see how well \[an algorithm\] performs at one task and they
think it can do all the things around that, and it can't," Brooks
explained. Brute-force intelligence As Kasparov pointed out in an
interview with Devin Coldewey at TechCrunch Disrupt in May, [it's one
thing to design a computer to play chess at Grand Master level, but it's
another to call it intelligence in the pure sense]{.underline}. **[It's
simply throwing computer power at a problem and letting a machine do
what it does best]{.underline}**. "**[In chess, machines dominate the
game because of the brute force of calculation and they \[could\] crunch
chess once the databases got big enough and hardware got fast enough and
algorithms got smart enough, but there are still many things that humans
understand]{.underline}**. **[Machines don't have
understanding]{.underline}**. **[They don't recognize strategical
patterns]{.underline}**. **[Machines don't have purpose]{.underline}**,"
Kasparov explained. Gil Pratt, CEO at the Toyota Institute, a group
inside Toyota working on artificial intelligence projects including
household robots and autonomous cars, was interviewed at the TechCrunch
Robotics Session, said that the fear we are hearing about from a wide
range of people, including Elon [Musk, who most recently called AI "an
existential threat to humanity," could stem from science-fiction
dystopian descriptions of artificial intelligence run amok]{.underline}.
"The deep learning systems we have, which is what sort of spurred all
this stuff, are remarkable in how well we do given the particular tasks
that we give them, but they are actually quite narrow and brittle in
their scope. So I think it's important to keep in context how good these
systems are, and actually how bad they are too, and how long we have to
go until these systems actually pose that kind of a threat \[that Elon
Musk and others talk about\]." Brooks said in his TechCrunch Sessions:
**[Robotics talk that there is a tendency for us to assume that if the
algorithm can do x, it must be as smart as humans]{.underline}**.
"**[Here's the reason that people --- including Elon --- make this
mistake]{.underline}**. [When we see a person performing a task very
well, we understand the competence \[involved\]]{.underline}. And [I
think they apply the same model to machine learning]{.underline}," he
said. Facebook's Mark Zuckerberg also criticized Musk's comments,
calling them "pretty irresponsible," in a Facebook Live broadcast on
Sunday. Zuckerberg believes AI will ultimately improve our lives. Musk
shot back later that Zuckerberg had a "limited understanding" of AI.
(And on and on it goes.) It's worth noting, however, that Musk isn't
alone in this thinking. Physicist Stephen Hawking and philosopher Nick
**[Bostrom]{.underline}** also have expressed reservations about the
potential impact of AI on humankind --- but [chances are they are
talking about a more generalized artificial intelligence being studied
in labs at the likes of Facebook AI Research, DeepMind and Maluuba,
rather than the more narrow AI we are seeing today]{.underline}. Brooks
pointed out that **[many of these detractors don't actually work in AI,
and suggested they don't understand just how difficult it is to solve
each problem]{.underline}**. "There are quite a few people out there who
say that AI is an existential threat --- Stephen Hawking, \[Martin
Rees\], the Astronomer Royal of Great Britain...a few other people ---
and **[they share a common thread in that they don't work in AI
themselves]{.underline}**." Brooks went onto say, "**[For those of us
who do work in AI, we understand how hard it is to get anything to
actually work through product level]{.underline}**." AI could be a
misnomer [Part of the problem stems from the fact that we are calling it
"artificial intelligence."]{.underline} **[It is not really like human
intelligence at all]{.underline}**, which Merriam Webster defines as
"the ability to learn or understand or to deal with new or trying
situations." Pascal Kaufmann, founder at Starmind, a startup that wants
to help companies use collective human intelligence to find solutions to
business problems, has been studying neuroscience for the past 15 years.
He says the human brain and the computer operate differently and **[it's
a mistake to compare the two]{.underline}**. "[The analogy that the
brain is like a computer is a dangerous one, and blocks the progress of
AI]{.underline}," he says. Further, Kaufmann believes we won't advance
our understanding of human intelligence if we think of it in
technological terms. "[It is a misconception that \[algorithms\] works
like a human brain]{.underline}. [People fall in love with algorithms
and think that you can describe the brain with algorithms and I think
that's wrong]{.underline}," he said. When things go wrong **[There are
in fact many cases of AI algorithms not being quite as smart as we might
think]{.underline}**. [One infamous example of AI out of control was the
**Microsoft Tay chatbot**, created by the Microsoft AI team last
year]{.underline}. **[It took less than a day for the bot to learn to be
racist]{.underline}**. Experts say that it could happen to any AI system
when bad examples are presented to it. In the case of Tay, it was
manipulated by racist and other offensive language, and since [it had
been taught to "learn" and mirror that behavior, it soon ran out of the
researchers' control]{.underline}. A widely reported study conducted by
researchers at Cornell University and the University of Wyoming found
that **[it was fairly easy to fool algorithms that had been trained to
identify pictures]{.underline}**. [The researchers found that when
presented with what looked like "scrambled nonsense" to humans,
algorithms would identify it as an everyday object like "a school
bus."]{.underline} What's not well understood, according to an MIT Tech
Review article on the same research project, is why the algorithm can be
fooled in the way the researchers found. What we know is that humans
have learned to recognize whether something is a picture or nonsense,
and **[algorithms analyzing pixels can apparently be subject to some
manipulation]{.underline}**. Self-driving cars are even more complicated
because there are things that humans understand when approaching certain
situations that would be difficult to teach to a machine. In a long blog
post on autonomous cars that Rodney Brooks wrote in January, he brings
up a number of such situations, including how an autonomous car might
approach a stop sign at a cross walk in a city neighborhood with an
adult and child standing at the corner chatting. The algorithm would
probably be tuned to wait for the pedestrians to cross, but what if they
had no intention of crossing because they were waiting for a school bus?
A human driver could signal to the pedestrians to go, and they in turn
could wave the car on, but a driverless car could potentially be stuck
there endlessly waiting for the pair to cross because they have no
understanding of these uniquely human signals, he wrote. **[Each of
these examples show just how far we have to go with artificial
intelligence algorithms]{.underline}**. Should researchers ever become
more successful at developing generalized AI, this could change, but for
now **[there are things that humans can do easily that are much more
difficult to teach an algorithm, precisely because we are not limited in
our learning to a set of defined tasks]{.underline}**.
