# \*\*\*\*\*AI Interoperability Affirmative\*\*\*\*\*

## AI Interoperability 1AC

### 1AC -- AI Leadership

#### Advantage 1: AI Leadership

#### China is winning the AI race now with the United States---this will give them the edge in global supremacy.

RUQAYYA **ANWER, 1/18**/20**22** (Academic at Riphah International
University, Pakistan, Ph.D. holder of media and communication studies,
"China is winning the power battle in AI race with US,"
<https://www.dailysabah.com/opinion/op-ed/china-is-winning-the-power-battle-in-ai-race-with-us>,
Retrieved 6/15/2022)

There is a widespread belief that [[**China is establishing itself as a
new superpower**, displacing the U]{.underline}]{.mark}nited
[[S]{.underline}]{.mark}tates [[from the global power
structure]{.underline}]{.mark}. China has undeniably become a worldwide
economic powerhouse, and it is anticipated to overtake the U.S. as the
world\'s largest economy by 2028. With increased spending on weapons
research and the development of multiple covert weapons, [[**China is on
the verge of surpassing the U.S. in military
capability**.]{.underline}]{.mark} [Significantly, [countries that
**lead in the research and application of**]{.mark}]{.underline}
artificial intelligence ([[**AI**) will determine the future of the
tech]{.underline}]{.mark}nology [[and increase their economic
competitiveness greatly, while those **that fall behind** risk losing
competitiveness in critical industries. AI is set to **revolutionize the
world**]{.underline},]{.mark} empowering those countries that fully
realize its promise. [[It will be a key driver of future **economic
growth and national security**]{.mark}.]{.underline} Moreover, AI is
sometimes referred to as a general-purpose technology because of its
wide range of applications in practically every industry -- the GUID
Partition Table (GPT). A GPT is a technology with widespread economic
implications. Only a few examples exist such as steam engines,
electricity and computers. These technologies have had a profound impact
on our civilizations by modifying preexisting economic and social
systems. AI is the newest brilliant, dazzling object on the
technological horizon. It has grown very popular in today\'s globe.
It\'s the simulation of human intellect in computers that have been
programmed to learn and mimic human behavior. AI will have a significant
impact on our quality of life as it develops. It has the potential to
significantly boost the economy of a developed country. For its
technological advancements, [**[China has won the AI battle with the
U.S. and is on its way to world supremacy]{.mark}**.]{.underline}
According to Western intelligence assessments, China, the world\'s
second-largest economy, is expected to dominate many major emerging
technologies, including AI, synthetic biology and genetics, within a
decade or two. Pentagon official's words [The Pentagon\'s first chief
software officer]{.underline}, Nicolas Chaillan [stressed that "[in 15
to 20 years, we have no competing fighting chance against
China.]{.mark}"]{.underline} It\'s already decided; "Whether it requires
a war or not is kind of anecdotal right now." He also claimed that
several government departments in the U.S. had \"kindergarten-level\"
cyber defenses. Moreover, Chaillan also criticized the reluctance of
U.S. firms, such as Google, to collaborate with the government on AI,
and extensive ethical disputes over technology for the U.S.' delayed
innovation. While China was destined to rule the world\'s future,
everything from media narratives to geopolitics is under their control.
One of the reasons China has been able to move more rapidly than the
U.S. is that it is not mired in enormous arguments about AI ethics. But
partly because Chinese businesses are compelled to collaborate with the
government, whereas many American businesses are wary of working with
the Pentagon. Google, for instance, halted working with the Pentagon on
AI in 2018 after a dozen employees departed after the business assisted
the Department of Defense in developing software that could boost drone
attack accuracy. Chaillan, on the other hand, stated that Chinese
corporations were obligated to comply with the Chinese government and
were making \"huge expenditures\" in AI without concern for ethical
considerations. Notably, the U.S. has attempted to curb China\'s
emergence as a digital power by prohibiting Huawei\'s 5G network from
operating in the U.S. and establishing a virtual embargo on U.S.
companies supplying software and components to Chinese tech firms.
Whereas China's President Xi Jinping is pushing China to establish
technological self-sufficiency in fields such as microchip manufacturing
to wean the country off its reliance on the U.S. Significantly, there
will always be economic ups and downs, but the underlying drive that\'s
occurring in Chinese culture right now will continue to create new
prospects and growth. China has announced a five-year plan worth \$1.8
trillion to dominate AI, robotics, 6G and all other technologies by
2035, releasing a five-year plan worth \$1.8 trillion. [[In comparison
to the E]{.underline}]{.mark}uropean [[U]{.underline}]{.mark}nion [[and
the U.S., **China\'s AI capabilities have advanced in several areas**.
China has surpassed the bloc as the world\'s largest AI
publisher]{.underline}.]{.mark} Moreover, [[the quality of its AI
research has **consistently improved over time**]{.underline}]{.mark}.
Its software and computer services companies have increased their R&D
expenditures. China\'s determination to master AI goes far beyond the
recognition that this group of technologies will be the most crucial
driver of economic advancement over the next quarter-century. [[China\'s
data collection and national determination have helped it to close the
gap with American leaders in this area over the last
decade]{.underline}]{.mark}. China now has nearly twice as many
supercomputers ranked in the top 500 for performance as the U.S., even
though the U.S. was once the leader in this category. Furthermore, China
is likely to maintain its advantage in terms of data generation.
Overall, though, [[China has not dramatically narrowed **the AI gap**
with the U.S., but its **steady growth could eventually erode U.S.
dominance over the tech**]{.underline}]{.mark}nology. Consequently,
countries that lead in the research and application use of AI will
determine the future of the technology and increase their economic
competitiveness greatly, while those that fall behind risk losing
competitiveness in critical industries. As a result, **[[China has taken
the lead]{.underline}]{.mark}**. The Chinese government, rules and
regulations, public attitudes toward privacy and strong collaboration
between corporations and the government are all contributing to the
country\'s AI progress. At the same time, American AI confronts
significant challenges, including a culture that prioritizes privacy
over security, distrusts authority and the government; as such, firms
are wary of collaborating with the U.S.

#### US leadership in AI technology is key to protect the liberal international order.

**D**EPARTMENT **O**F **D**EFENSE, 2/12/20**19** ("SUMMARY OF THE 2018
DEPARTMENT OF DEFENSE ARTIFICIAL INTELLIGENCE STRATEGY," Retrieved
6/12/2022 from
<https://media.defense.gov/2019/Feb/12/2002088963/-1/-1/1/SUMMARY-OF-DOD-AI-STRATEGY.PDF>.)

Other nations, particularly [[**China and Russia, are making significant
investments in AI for military purposes**, including in
app]{.underline}]{.mark}lication[[s]{.underline}]{.mark} [[that raise
questions regarding international norms]{.underline}]{.mark} and human
rights. [[These investments **threaten to erode** our
tech]{.underline}]{.mark}nological and operational [[advantages and
**destabilize the free and open international order.** The
U]{.underline}]{.mark}nited [[S]{.underline}]{.mark}tates, [[together
with its allies]{.underline}]{.mark} and partners, [[must adopt AI to
**maintain its strategic position**, prevail on future battlefields,
**and safeguard this order**]{.underline}.]{.mark} We will also seek to
develop and use AI technologies in ways that advance security, peace,
and stability in the long run. We will lead in the responsible use and
development of AI by articulating our vision and guiding principles for
using AI in a lawful and ethical manner. The costs of not implementing
this strategy are clear. Failure to adopt AI will result in legacy
systems irrelevant to the defense of our people, eroding cohesion among
allies and partners, reduced access to markets that will contribute to a
decline in our prosperity and standard of living, and growing challenges
to societies that have been built upon individual freedoms.

#### Chinese power undermines the liberal world order and leads to multiple scenarios for nuclear conflict:

Thomas H. **Henriksen**, 3/23/20**17** (Senior Fellow at Hoover
Institution, Stanford University, USA, "Post-American World Order,"
<https://www.hoover.org/research/post-american-world-order>, Retrieved
8/11/2021)

[[China's Not So Peaceful Rise]{.mark}]{.underline} A series of dramatic
events took place in response to Obama's growing disengagement policies,
as world powers noted Washington's burgeoning inwardness. [[China
switched from its "peaceful rise" policy to **aggressively asserting**
and expanding its **international presence**]{.underline}]{.mark}. Xi
Jinping, the all-powerful Chinese leader, moved to advance Beijing's
political and military suzerainty over the South China Sea (SCS) by
seizing and reconstructing the disputed shoals into artificial islands
with dredged ocean sands in 2014. Next, China militarized three
micro-isles of the Spratly Islands (also claimed by the Philippines,
Malaysia, and Vietnam) with runways, radars, and surface-to-air missile
sites---actions that broke Beijing's earlier promise not to militarize
the waterway. Since then, Chinese officials have made it clear that the
SCS is now their exclusive lake. Other states are expected to recognize
China's claims to most of the energy-rich waters, through which \$5
trillion of trade passes annually, roughly half the world's merchant
fleet tonnage. China backs its assertions by modernizing the arsenals of
its advanced warships, aircraft, missiles, and ground forces. Xi and
company seem bent on restoring the ancient tribute system in which South
Korea and Vietnam would become modern-day vassals, while more distant
Asian states become supplicants in a Sinocentric sphere. In short, China
has become a revisionist juggernaut. Along with its fortifying of these
artificial islands, [[the world's second largest
economy]{.underline}]{.mark} and military spender [[has emerged as an
**economic, political, and ideological competitor** of the
U]{.underline}]{.mark}nited [[S]{.underline}]{.mark}tates not only in
Southeast Asian maritime zones but [[globally]{.underline}]{.mark}.
China is maneuvering to set up bases or harbors in Pakistan, Sri Lanka,
and Greece---and is even extending its reach to the long U.S.-allied
Portuguese Azores in the mid-Atlantic. In reaction to Beijing's SCS
actions, the Trump administration has stepped up America's own show of
force by sending warships, fighter jets, and submarines to the waters.
To underline its not-too-subtle counter-signal to China, the United
States also test-fired four Trident II submarine-launched ballistic
missiles over 4,000 miles into the Pacific Ocean from the California
coast last month, the first four-missile salvo in the post-Soviet era.
The western Pacific is becoming a tinderbox. Russia's Resurgence At the
other end of the Asian continent, Russia longs to restore its lost
prestige and political influence, forfeited with the breakup of the
Soviet Union in 1991. Under Vladimir Putin, Russian forces backed the
seizure of Crimea from Ukraine before taking over its eastern
borderlands. Earlier, Moscow perfected its "frozen war" tactics against
two provinces in the Republic of Georgia, thereby yanking them from
Georgian sovereignty. Russia's bullying and intimidation of its Baltic
and Eastern European neighbors have become commonplace. Meanwhile, the
Russian foreign minister, Sergei Lavrov, called for "a post-West world"
at the Munich Security Conference in mid-February. [[What China and
Russia have in common is that both are engaged in advancing their
spheres of influence in their neighborhoods and beyond. Both also seek
to crack the Western liberal world order]{.underline}]{.mark}. The
United States, meanwhile, has become blasé about its former leadership
position in the Western hemisphere, where China's companies have entered
into business deals, some with strategic implications. Washington,
without a hint of nostalgia, treats the Monroe Doctrine as a relic of
yesteryear's Yankee imperialism in Latin America. These newly assertive
major powers are not alone in shattering the post-Cold War order, which
witnessed the unrivaled predominance of the United States---the
"indispensable nation," in the words of the Clinton administration.
Trouble-making regional powers, such as Iran, Syria, and North Korea
either spread terrorism, provoke instability, or arm themselves with
longer-range missiles and nuclear weapons. While they were independent
actors a few years ago, each of these pariah regimes increasingly aligns
with the two chief U.S. adversaries. Iran and Syria cozy up to Russia,
and North Korea depends for fuel and food on a China that hypocritically
protests that it lacks influence over a nuclear-armed Pyongyang. Western
Europe, once a powerful but independently minded U.S. ally, has
faltered. Its slippage is evident in the refugee crisis, its sagging
economies, its 20 percent youth unemployment rate, and its reluctance to
fund an adequate military defense in the face of Russia's continuing
provocations, including cyber-attacks, disinformation campaigns, and
fake news stories. Europe's paltry defense reflects the continent's lost
belief in its own purpose---and even, some might say, its own
civilization. Sino-Russian Partnering Little of this threatening world
existed when the United States enjoyed its unipolar moment after the
eclipse of its Soviet nemesis, and even after the 9/11 terrorist
attacks. The emergent world, divided between the United States, China,
and Russia, points to the new global order. [[Particularly worrisome are
the warming relations between Beijing and Moscow]{.underline}]{.mark},
despite Chinese designs on Siberian lands and resources. Overcoming a
centuries-old rivalry, the recent Sino-Russian rapprochement compounds
Washington's difficulties. Separating Russia from China, as Kissinger
and Nixon did, would be a sensible goal for President Trump. It has
always been a wise recourse to divide one's adversaries. Besides, the
United States and Russia have worked together in the past. During the
World War II, they collaborated against the Third Reich. And during the
Cold War, they cooperated in nuclear arms treaties and wheat deals,
while mutually trying to skirt a flashpoint that could end in a nuclear
war. Washington can work to steer the Kremlin, as it has done before,
toward acceptable conduct with its neighbors before Russia can be more
than a tactical ally in the great game with China. In the immediate
future, the United States can adopt international and domestic
approaches to cope with Russian and Chinese territorial expansionism.
[[The tensions stoked by the assertive regimes in the Kremlin or
Tiananmen Square could spark a political or military incident that might
set off a chain reaction leading to **a large-scale war**. Historically,
powerful rivalries nearly always lead to]{.underline}]{.mark} at least
skirmishes, if not [[a full-blown war]{.underline}]{.mark}. The
anomalous Cold War era spared the United States and Soviet Russia a
direct conflict, largely from [[concerns that one would trigger a
**nuclear exchange** destroying both states]{.underline}]{.mark} and
much of the world. [[Such a repetition might
reoccur]{.underline}]{.mark} in the unfolding three-cornered
geopolitical world. [[It seems safe to acknowledge that an **ascendant
China**]{.underline}]{.mark} and a resurgent Russia [[will persist in
their geo-strategic ambitions.]{.mark}]{.underline} What Is To Be Done?
The first marching order is to dodge any kind of perpetual war of the
sort that George Orwell outlined in "1984," which engulfed the three
super states of Eastasia, Eurasia, and Oceania, and made possible the
totalitarian Big Brother regime. A long-running Cold War-type
confrontation would almost certainly take another form than the one that
ran from 1945 until the downfall of the Soviet Union. What prescriptions
can be offered in the face of the escalating competition among the three
global powers? First, by staying militarily and economically strong, the
United States will have the resources to deter its peers' hawkish
behavior that might otherwise trigger a major conflict. Judging by the
history of the Cold War, the coming strategic chess match with Russia
and China will prove tense and demanding---since all the countries boast
nuclear arms and long-range ballistic missiles. Next, the United States
should widen and sustain willing coalitions of partners, something at
which America excels, and at which China and Russia fail conspicuously.
There can be little room for error in fraught crises among
nuclear-weaponized and hostile powers. Short- and long-term standoffs
are likely, as they were during the Cold War. Thus, the playbook, in
part, involves a waiting game in which each power looks to its rivals to
suffer grievous internal problems which could entail a collapse, as
happened to the Soviet Union. Some Chinese and Russian experts predict
grave domestic problems for each other. They also entertain similar
thoughts about the United States, which they view as terminally decadent
and catastrophically polarized over politics, ethnicity, and the future
direction of the country. So, the brewing three-way struggle also
involves a systemic contest, which will test the competitors' economic
and political institutions. At this juncture, the world is entering a
standoff among the three great and several not-so-great powers. Averting
war, while defending our interests, will prove a challenge, calling for
deft policy, political endurance, and economic growth, as well as
sufficient military force to keep at bay aggressive states or prevail
over them if ever a war breaks out.

#### Lack of US leadership on emerging technologies risks great power nuclear conflict.

Matthew **Kroenig, 2021** (Professor in the Department of Government and
the Edmund A. Walsh School of Foreign Service at Georgetown University,
"Will Emerging Technology Cause Nuclear War?: Bringing Geopolitics Back
In,"
<https://www.airuniversity.af.edu/Portals/10/SSQ/documents/Volume-15_Issue-4/D-Kroenig.pdf>,
Retrieved 6/15/2022)

In order to fully understand the link between nuclear stability and
emerging technology, the current geopolitical situation must be
accounted for. [**[Incorpo-rating emerging tech]{.mark}**nologies [into
US, Ally, and partner militaries will likely **reinforce the prevailing
global strategic stability.**]{.mark} [Will emerging technology cause
nuclear war?]{.mark}]{.underline} For more than 70 years, the world has
avoided major- power conflict, and many attribute this era of peace to
nuclear weapons.1 In situations of mutually assured destruction, neither
side has an incentive to launch a nuclear first strike because doing so
will only result in self- annihilation. Maintaining secure, second-
strike capabilities---the ability to absorb an enemy nuclear attack and
respond with a devastating counterattack---is the key to deterrence.2
[[Recently, analysts have begun to worry,]{.underline}]{.mark} however,
[[that new military tech]{.underline}]{.mark}nologies [[may call into
question this model of global strategic stability.]{.underline}]{.mark}3
[[The world is experiencing a fourth industrial
revolution]{.underline}]{.mark} (4IR) [[in which a wave of new and
transformative tech]{.mark}nologies [is being developed,
includ¬ing]{.mark}]{.underline} artificial intelligence
([[AI)]{.underline}]{.mark}, additive manufacturing, quantum
informa¬tion technology, hypersonic missiles, biotechnology, and
directed energy.4 While these technologies are expected to have profound
implications for societies and economies, most are dual use and will
also affect national security, including nuclear strategic stability.
According to an emerging conventional wisdom, new technology may upset
nuclear strategic stability by calling into question the survivability
of nuclear forces.5 The solution, according to some analysts, is for
nuclear- armed states to eschew military applications of at least some
of these tech¬nologies and lead an international effort to control their
spread.6 But these studies too often consider new technology and nuclear
strategy in the abstract without adequately considering the prevailing
geopolitical con¬text into which these new technologies have been
introduced. This article argues [[understanding the link between new
tech]{.underline}]{.mark}nology [[and nuclear stability must consider
the prevailing geopolitical context. For the past several decades, the
U]{.underline}]{.mark}nited [[S]{.underline}]{.mark}tates, [[its Allies,
and like- minded part-ners have formed the core of the existing
international order]{.underline}.]{.mark}7 [[They have benefited from
this system and would like to see it strengthened]{.mark},]{.underline}
revital-ized, and defended. **[[If the new
tech]{.underline}]{.mark}**nologies of the 4IR **[[are incorporated into
US, Ally,]{.underline}]{.mark}** and partner [[**militaries**,
then]{.underline}]{.mark} any advantages [[they provide will likely
**reinforce the prevailing distribution of power** and **existing
sources of strategic stability**]{.underline}]{.mark}. [[In contrast,
**China and Russia are revisionist powers** intent on
disrupt-ing]{.mark} or displacing [the US- led system, and they would
likely employ new tech]{.mark}]{.underline}nological [[advantages to
**pursue revisionist aims**. The greatest danger from emerging
tech]{.underline}]{.mark}nology [[for nuclear stability, therefore, may
result from the possibility that new tech]{.underline}]{.mark}nology
[[provides Russia or China **an enhanced military advantage** over
vulnerable US Allies]{.mark} and partners, [leading to a regional
conflict **with a significant risk of nuclear
escalation**]{.mark}]{.underline}.

#### Chinese tech leadership risks war over Taiwan or the East and South China Seas---these scenarios risk nuclear escalation.

Matthew **Kroenig, 2021** (Professor in the Department of Government and
the Edmund A. Walsh School of Foreign Service at Georgetown University,
"Will Emerging Technology Cause Nuclear War?: Bringing Geopolitics Back
In,"
<https://www.airuniversity.af.edu/Portals/10/SSQ/documents/Volume-15_Issue-4/D-Kroenig.pdf>,
Retrieved 6/15/2022)

Similarly, [[Moscow and Beijing would likely use any newfound military
strength to advance their preexisting geopolitical
aims]{.underline}]{.mark}. Given their very different positions in the
international system, however[, [these states are likely to employ new
military tech]{.underline}]{.mark}nologies [[in ways that are
destabilizing]{.underline}]{.mark}. These states have made clear their
dissatisfaction with the existing inter¬national system and their desire
to revise it. Both countries have ongoing border disputes with multiple
neighboring countries. If Moscow developed new military technologies and
operational con-cepts that shifted the balance of power in its favor, it
would likely use this advantage to pursue revisionist aims. If Moscow
acquired a newfound ability to more easily invade and occupy territory
in Eastern Europe, for example (or if Putin believed Russia had such a
capability), it is more likely Russia would be tempted to engage in
aggression. Likewise, [[**if China** acquired an enhanced ability
**through new tech**]{.underline}]{.mark}nology [**[to invade]{.mark}**
and occupy [**Taiwan** or contested islands **in the East or South China
Seas,** Beijing's leaders **might** ]{.mark}]{.underline}also [[**find
this opportunity tempting**. If new tech]{.underline}]{.mark}nology
[[enhances either power's anti- access, area- denial network, then its
leaders **may be more confident in their ability to achieve a fait
accompli attack** against a neighbor and then block a US- led
liberation. These are precisely the types of shifts in the balance of
power **that can lead to war**]{.underline}]{.mark}. As mentioned
previously, the predominant scholarly theory on the causes of war---the
bargaining model---maintains that imperfect in¬formation on the balance
of power and the balance of resolve and credible commitment problems
result in international conflict.52 New technology can exacerbate these
causal mechanisms by increasing uncertainty about, or causing rapid
shifts in, the balance of power. Indeed as noted above, [new military
tech]{.underline}nology and the development of new operational con¬cepts
[have shifted the balance of power and resulted in military conflict
throughout history]{.underline}. Some may argue emerging military
technology is more likely to result in a new tech arms race than in
conflict. This is possible. But Moscow and Beijing may come to believe
(correctly or not) that new technology pro¬vides them a usable military
advantage over the United States and its Al¬lies and partners. In so
doing, they may underestimate Washington. [[If Moscow or Beijing
attacked a vulnerable US Ally or partner in their near abroad,
therefore, **there would be a risk of major war** with the **potential
for nuclear escalation**. The U]{.underline}]{.mark}nited
[[S]{.underline}]{.mark}tates [[has formal treaty commitments with
several frontline states as well as an ambiguous defense obligation to
Taiwan. If Russia or China were to attack these states, it is
likely]{.mark},]{.underline} or at least possible, [[that the
U]{.underline}]{.mark}nited [[S]{.underline}]{.mark}tates [[would come
to the defense]{.mark} of the victims]{.underline}. While many question
the wisdom or credibility of America's global com¬mitments, [[it would
be difficult for the U]{.underline}]{.mark}nited
[[S]{.underline}]{.mark}tates [[to]{.mark} simply [back
down]{.mark}]{.underline}. Abandoning a treaty ally could cause fears
that America's global commit¬ments would unravel. Any US president,
therefore, would feel great pres¬sure to come to an Ally's defense and
expel Russian or Chinese forces. [[Once the U]{.underline}]{.mark}nited
[[S]{.underline}]{.mark}tates [[and Russia or China are at war, **there
would be a risk of nuclear escalation**]{.underline}]{.mark}. As noted
previously, experts assess [[**the greatest risk of nuclear war today**
does not come from a bolt- out- of- the- blue strike but from nuclear
escalation in a regional, conventional conflict]{.underline}]{.mark}.53
Russian leaders may believe it is in their interest to use nuclear
weapons early in a conflict with the United States and NATO.54 Russia
possesses a large and diverse arsenal, including thousands of
nonstrategic nuclear weapons, to support this nuclear strategy. In the
2018 Nuclear Posture Review, Washington indicates it could re-taliate
against any Russian nuclear "de- escalation" strikes with limited
nuclear strikes of its own using low- yield nuclear weapons.55 The
purpose of US strategy is to deter Russian strikes. If deterrence fails,
however, there is a clear pathway to nuclear war between the United
States and Russia. As Henry Kissinger pointed out decades ago, there is
no guarantee that, once begun, a limited nuclear war stays limited.56
There are similar risks of nuclear escalation in the event of a US-
China conflict. China has traditionally possessed a relaxed nuclear
posture with a small "lean and effective" deterrent and a formal "no
first use" policy. But China is relying more on its strategic forces. It
is projected to double---if not triple or quadruple---the size of its
nuclear arsenal in the coming decade.57 Chinese experts have
acknowledged there is a narrow range of contin-gencies in which China
might use nuclear weapons first.58 As in the case of Russia, the US
Nuclear Posture Review recognizes the possibility of limited Chinese
nuclear attacks and also holds out the potential of a lim-ited US
reprisal with low- yield nuclear weapons as a deterrent.59 If the
nuclear threshold is breached in a conflict between the United States
and China, the risk of nuclear exchange is real. In short, [[if a coming
revolution in military affairs provides a]{.mark} real or perceived
[battlefield advantage for Russia or China, such a development raises
the likelihood of **armed aggression against US regional allies**,
**major power war**, **and an increased risk of nuclear
escalation**]{.mark}]{.underline}.

#### Threats to US hegemony lead to nuclear war:

Lu **Yuanzhi**, 2/4/20**21** (journalist, Global Times, "Washington's
reckless attitude toward nuclear war a threat to world peace,"
[https://www.globaltimes.cn/page/
202102/1215044.shtml](https://www.globaltimes.cn/page/%20202102/1215044.shtml),
Retrieved 8/11/2021)

Fox News reported that the head of US Strategic Command Charles Richard
is calling on the US military and federal leaders to reimagine methods
of deterring aggressive action from rivals such as China and Russia. He
wrote in the February issue of Proceedings, the US Naval Institute\'s
monthly magazine, that, \"[[There is a real possibility that a regional
crisis]{.underline}]{.mark} [[with]{.underline}]{.mark} Russia or
[[China could escalate quickly to a conflict **involving nuclear
weapons**]{.underline}]{.mark}.\" It\'s not uncommon to hear the noise
preaching so-called threats of China and Russia. Yet it\'s still
shocking to see a US senior military official publicly urging leaders of
his country to consider a nuclear war. His narratives have drawn wide
attention. Song Zhongping, a Chinese military expert and commentator,
told the Global Times on Thursday that Richard\'s rhetoric may be out of
the following intention. First, he may hope to increase the strategic
value of the Strategic Command in the US military. Second, Richard wants
the US Congress to allocate more funds to create a new US nuclear
weapons system, in a bid to reinforce a new triad of strategic nuclear
forces. Third, he seeks to pursue the Strategic Command\'s larger
control over US nuclear weapons. For whatever reason, a top military
official from the US, the most powerful country and whose new
administration has pledged to restore its global leadership, is
irresponsible to express such a crazy idea, as it poses huge challenges
to world peace and security. It should be condemned by the international
community. Most nuclear-weapon countries including China, tend to keep
their nuclear force for the purpose of safeguarding their national
security. Only when their safety, sovereignty or territory is
threatened, will they consider resorting to using nuclear weapons. But
the principle of the US totally differs. The US military might be the
strongest, possessing the largest and most advanced nuclear arsenal. In
spite of vowing to pursue disarmament, Washington actually spent
trillions of dollars in upgrading its nuclear arsenal. Apart from
terrorists, no country is capable of posing any threat to the US
homeland. Just as Song said, spending trillions of dollars to upgrade
its nuclear arsenal is mainly to maintain its global hegemony. This is
the fundamental difference between the US and other nuclear-weapon
countries in terms of keeping nuclear forces. [[Washington covers a wide
range when it comes to defending its hegemony. It includes safeguarding
its national security as well as its core interests on a global
scale]{.underline}]{.mark}. Just as former US president Barack Obama
said at the US Military Academy at West Point in 2014, \"America must
always lead on the world stage... If we \[the US\] don\'t, no one else
will.\" [[If any country gravely threatens US hegemony, the possibility
cannot be ruled out that the **US may use nuclear weapons** to
remarkably impair its rivals\' military capability]{.underline}]{.mark}.
This is the huge threat of US radical nuclear policy posed to the world.
[[It is a big challenge for all countries, including
China]{.mark}]{.underline} and Russia, and to global peace and safety.
The US is the biggest trouble-maker in the world, which has the
potential to overturn global peace.

#### War with China can happen by miscalculation:

Michèle A. **Flournoy**, 6/18/20**20** (Co-Founder and Managing Partner
of WestExec Advisors. From 2009 to 2012, she served as U.S.
Undersecretary of Defense for Policy, "How to Prevent a War in Asia," ,
Retrieved 8/11/2021)

Amid all the uncertainty about the world that will follow the pandemic,
one thing is almost sure to be true: [[tensions between the
U]{.underline}]{.mark}nited [[S]{.underline}]{.mark}tates [[and China
will be even sharper than they were before the coronavirus outbreak. The
resurgence of U.S.-Chinese competition poses a host of
challenges]{.underline}]{.mark} for policymakers---related to trade and
economics, technology, global influence, and more---[[but none is more
consequential than **reducing the risk of war**.
Unfortunately]{.underline}]{.mark}, thanks to [[today's **uniquely
dangerous mix** of growing Chinese assertiveness]{.underline}]{.mark}
and military strength [[and eroding U.S. deterrence, that risk is higher
than it has been for decades]{.underline}]{.mark}, and it is growing.
[[Neither Washington nor Beijing seeks a military conflict with the
other]{.underline}]{.mark}. Chinese President Xi Jinping and U.S.
President Donald Trump both undoubtedly understand that a war would be
disastrous. [[Yet the U]{.underline}]{.mark}nited
[[S]{.underline}]{.mark}tates [[and China **could all too easily stumble
into conflict**, sparked by a **Chinese miscalculation** of the
U]{.underline}]{.mark}nited [[S]{.underline}]{.mark}tates' willingness
or capability to respond to provocations in disputed areas such as the
South China Sea or to outright aggression against Taiwan or another U.S.
security partner in the region.

#### Their turns are false\--US leadership on advanced technologies will increase deterrence and not threaten aggression.

Matthew **Kroenig, 2021** (Professor in the Department of Government and
the Edmund A. Walsh School of Foreign Service at Georgetown University,
"Will Emerging Technology Cause Nuclear War?: Bringing Geopolitics Back
In,"
<https://www.airuniversity.af.edu/Portals/10/SSQ/documents/Volume-15_Issue-4/D-Kroenig.pdf>,
Retrieved 6/15/2022)

[[The spread of new technology to the U]{.underline}]{.mark}nited
[[S]{.underline}]{.mark}tates [[and its Allies]{.underline}]{.mark} and
partners [[would likely serve]{.underline}]{.mark}, on balance, [[to
reinforce the existing sources of stability in the prevailing
international system. At the end of the Cold War, the
U]{.underline}]{.mark}nited [[S]{.underline}]{.mark}tates [[and its
Allies]{.underline}]{.mark} and partners [[achieved a technological-
military advantage over its great power rivals]{.underline},]{.mark}
with the US using its unipolar position to deepen and expand a rules-
based system. [[They also employed their military dominance to **counter
perceived threats** from rogue states and terrorist networks. The
U]{.underline}]{.mark}nited [[S]{.underline}]{.mark}tates, [[its
Allies]{.underline},]{.mark} and part¬ners [**[did not, however, engage
in military aggression against great power,]{.mark}**]{.underline}
nuclear- armed [[**rivals** or their allies]{.underline}]{.mark}. In the
future, [[these status quo powers are apt to use military advantages to
**reinforce their position in the international system** and to **deter
attacks against Allies**]{.underline}]{.mark} and partners in [Europe
and the Indo- Pacific]{.underline}. These states might also employ
military power to deal with threats posed by terrorist networks or by
regional revisionist powers such as Iran and North Korea. But [[**it is
extremely difficult** to imagine scenarios **in which Washington or its
Allies**]{.underline}]{.mark} or partners [[would use newfound military
advantages provided by emerging tech]{.mark}nology [**to conduct an
armed attack** against Russia or China]{.mark}]{.underline}[.]{.mark}

#### Common standards in NATO are essential to maintaining an AI edge over China---both the domestic counterplan and the EU counterplan will fail to solve the AFF.

MELISSA **HEIKKILÄ**, 3/29/20**21** (Senior reporter for AI
\@techreview, "NATO wants to set AI standards. If only its members
agreed on the basics,"
<https://www.politico.eu/article/nato-ai-artificial-intelligence-standards-priorities/>,
Retrieved 6/15/2022)

[[The Western military alliance has identified
a]{.underline}]{.mark}rtificial [[i]{.underline}]{.mark}ntelligence [[as
a key tech]{.mark}nology [**needed to maintain an edge over
adversaries,** and it wants to lead the way **in establishing common
ground rules for its use**]{.mark}]{.underline}. "We need each other
more than ever. [[No country alone or no continent alone can compete in
this era of great power competition," NATO Deputy
Secretary-General]{.underline}]{.mark} Mircea
[[Geoană,]{.underline}]{.mark} the alliance's second in command,
[[said]{.underline}]{.mark} in an interview with POLITICO. [[The
standard-setting effort comes as China is pressing ahead with AI
applications in the military largely free of democratic
oversight]{.underline}]{.mark}. David van Weel, NATO's assistant
secretary general for emerging security challenges, said Beijing\'s lack
of concern with the tech\'s ethical implications has sped along the
integration of AI into the military apparatus. \"I\'m \... not sure that
they\'re having the same debates on principles of responsible use or
they\'re definitely not applying our democratic values to these
technologies," he said. Meanwhile, [[**the EU** --- which has pledged to
roll out the world\'s first binding rules on AI]{.underline}]{.mark} in
coming weeks --- is seeking closer collaboration with Washington to
oversee emerging technologies, including artificial intelligence. But
[**[those efforts have been slow in getting off the
ground]{.underline}**.]{.mark} For Geoană, [[that collaboration will
happen at NATO]{.underline}]{.mark}, which is working closely with the
European Union as it prepares AI regulation focusing on "high risk"
applications. The pitch NATO does not regulate, but "[[**once NATO sets
a standard**, it becomes in terms of defensive security **the gold
standard in that respective field**]{.mark},]{.underline}" Geoană said.
The alliance\'s own AI strategy, to be released before the summer, will
identify ways to operate AI systems responsibly, identify military
applications for the technology, and provide a "platform for allies to
test their AI to see whether it\'s up to NATO standards," van Weel said.
The strategy will also set ethical guidelines around how to govern AI
systems, for example by ensuring systems can be shut down by a human at
all times, and to maintain accountability by ensuring a human is
responsible for the actions of AI systems. "If an adversary would use
autonomous AI powered systems in a way that is not compatible with our
values and morals, it would still have defense implications because we
would need to defend and deter against those systems," van Weel said.
"We need to be aware of that and we need to flag legislators when we
feel that our restrictions are coming into the realm of \[being
detrimental to\] our defense and deterrence," he continued.

### 1AC -- Conflict Resolution

#### Advantage 2: Conflict Resolution

#### NATO coordination on AI is necessary to prevent accidents and allow de-escalation in conflict.

Zoe Stanley-**Lockman, 2022** (Defense and Strategic Studies, Nanyang
Technological University, "NATO's Role in Responsible AI Governance in
Military Affairs," [https://www.oxfordhandbooks.com/view/
10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69](https://www.oxfordhandbooks.com/view/%2010.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69),
Retrieved 6/11/2022)

Even without being attacked, [[governability of AI in a NATO context
also means understanding how AI]{.underline}]{.mark}-enabled and
autonomous [[systems]{.underline}]{.mark} developed by the 30
Allies---and other partners---[[will interact with one
another]{.underline}. [NATO has expressed interest in governability as a
principle of AI "to]{.underline}]{.mark} disengage or [[**deactivate in
case of unintended behavior**,]{.underline}]{.mark}"85 which echoes the
U.S. Department of Defense definition of governable AI.86 [[Disengaging
adversaries is important to maintain **de-escalation measures in
conflict**. For NATO, interoperability between systems also relates to
governable AI]{.underline}]{.mark} because allies must also consider how
the interactions between the 30 Allies' own AI-enabled and autonomous
systems may result in unintended or emergent behavior.87 [[This means
that NATO has a responsibility to coordinate
activities]{.underline}]{.mark}---be they technical exchanges,
standardization efforts, or training and exercises---to build confidence
that the systems perform as humans intend.88
[[Without]{.underline}]{.mark} this [[coordination, the lack of
interoperability of allied systems **could lead to
accidents**,]{.underline}]{.mark} and separately, the potential loss of
operational effectiveness also presents vulnerabilities for adversaries
to exploit.

#### Advances in AI bolster international arms control.

Jessica **Cox, 2021** (Director of Nuclear Policy at NATO, "The
Unavoidable Technology: How Artificial Intelligence Can Strengthen
Nuclear Stability," WASHINGTON QUARTERLY)

[[These and other applications will contribute to national technical
means]{.underline}]{.mark} (NTM) [[of verification]{.underline}]{.mark}.
Non-interference in NTM for arms control verification protocols is a
well-established tool of most major arms control treaties and is also
used unilaterally by states to observe others' activities and
behaviors[**. [With advances in AI]{.mark}**[, states may invest more
heavily in NTM, which will have **positive implications for future arms
control agreements**]{.mark}.]{.underline} First, [[it could give an
advantage to countries with **more sophisticated AI and NTM
capabilities**. The U]{.underline}]{.mark}nited
[[S]{.underline}]{.mark}tates, for example, [[would have an advantage
over Russia in this area, which might make Russia more interested in
traditional verification activities in **future arms control
agreements**]{.underline}]{.mark}.41 Second, states will have to go to
greater lengths to hide any cheating activities. And finally, [[it might
reduce the need for on-site inspections, which **could make
participation in arms control agree¬ments** with "closed" societies like
China, North Korea, and Russia **more attrac¬tive**]{.underline}]{.mark}
than relying primarily on the current "boots on the ground" procedures.
That said, even with enhanced AI monitoring, there remain important
benefits of "boots on the ground" inspectors, which have proven to be
particularly valu¬able both to observe compliance and build trust
between parties to an arms control agreement. But [[monitoring
particularly sensitive facilities with AI-enhanced
NTM]{.underline}]{.mark}, like nuclear warhead storage sites, [[might be
**especially useful** when nations have traditionally been reluctant to
allow on-site inspections]{.underline}]{.mark}.42

#### Revitalizing international arms control stops multiple scenarios for nuclear conflict.

Michael **Krepon**, 11/8/20**21** (co-founder of the Stimson Center,
"HOW TO AVOID NUCLEAR WAR,"
<https://warontherocks.com/2021/11/how-to-avoid-nuclear-war/>, Retrieved
6/15/2022)

Arms control has become passé. Russian and U.S. leaders have cast aside
treaties as inconvenient to their pursuit of freedom of action.
Republican presidents produced great arms control achievements. At
present, most Republican senators and aspirants for higher office
denigrate arms control and treaty-making as a failed, unnecessary, and
unwise pursuit. Arms control provided necessary guardrails in the past.
Now, [[**dangerous military practices are on the rise**, especially in
Ukraine and across the Taiwan Strait. **U.S.-Chinese relations are
trending toward crisis**. **Four nuclear-armed states in Asia** ---
China, Pakistan, India, and North Korea --- **are increasing their
nuclear arsenals**]{.underline}]{.mark}. Every nuclear-armed competitor
is relying increasingly on deterrence as [[**the diplomacy of arms
control is in the doldrums**. If unaltered, these trend lines **point
toward tragedy**]{.underline}]{.mark}. Many have forgotten what is
crucial to remember: Deterrence is dangerous by design and has a track
record of failure in lesser cases. There have already been two border
wars between nuclear-armed rivals --- the Soviet Union and China in 1969
and India and Pakistan in 1999. India and China as well as India and
Pakistan clash along disputed borders. As rivals sharpen deterrence,
they move toward the next crisis. [[Deterrence has always needed
diplomacy and arms control to **avoid nuclear
tragedy**]{.mark}**.**]{.underline} Deterrence resulted in
five-digit-sized U.S. and Soviet nuclear arsenals. Diplomacy reduced
superpower holdings by 85 percent. The dictates of deterrence led to
almost 2,000 nuclear tests, including over 400 in the atmosphere.
Diplomacy produced treaties limiting and then prohibiting nuclear
testing. Deterrence generated dangerous military practices like
maintaining nuclear weapon delivery vehicles on a high state of alert.
[Diplomacy produced guardrails, codes of conduct, and rules of the
road]{.underline}. When the Soviet Union dissolved, [[deterrence didn't
provide safeguards against "loose nukes" and "dirty" bombs. **The
diplomacy of arms control did**]{.mark}.]{.underline} Diplomacy also
produced treaties curbing nuclear proliferation as well as prohibiting
chemical and biological weapons. No hard problem is ever solved in
perpetuity by either diplomacy or deterrence. Outliers and norm breakers
still exist. Without norms, however, there are no norm breakers. The
diplomacy of arms control has kept their number small. [[Deterrence
didn't establish protective norms. The diplomacy of arms control
did]{.underline}]{.mark}. National leaders will again seek arms control
in its varied forms for the same reasons as their predecessors. They
will reach the conclusion that [[strengthening measures for deterrence
increase nuclear dangers, and]{.underline}]{.mark} that [**[diplomacy is
required to reduce them]{.underline}**.]{.mark} It might take a major
crisis --- or something worse --- for U.S., Chinese, and Russian leaders
to turn to diplomacy the way that John F. Kennedy and Nikita Khrushchev
did after the Cuban missile crisis. The remarkable journey Ronald Reagan
undertook with Mikhail Gorbachev began with Reagan's realization after
the annus horribilis of 1983 --- a year of multiple shocks to
U.S.-Soviet relations --- that a paranoid Kremlin leadership believed
that Armageddon was approaching. Eventually --- and sooner is far better
than later --- nuclear-armed rivals will arrive at the same conclusions
that Kennedy, Khrushchev, Reagan, Gorbachev, and other leaders before
them: [[**Nuclear war has to be avoided**, and deterrence by itself is,
at best, half the solution. **Deterrence needs help that only diplomacy
and arms control can provide**]{.underline}]{.mark}. A new construction
project for nuclear arms control will borrow from the past, but it will
take different shape than during the Cold War because the geometry of
nuclear competition is far more complicated. The measures of reassurance
leaders choose to pursue alongside deterrence will be adapted to suit
domestic political purposes and geopolitical realities.
[Whenever]{.underline} chastened or forward-looking [leaders of
nuclear-armed states turn to [arms control]{.mark}, they will not have
to start from scratch. [Revival is possible because foundational
elements for avoiding nuclear war remain in place]{.mark}]{.underline}.
Deterrence is well funded and national vulnerability between
nuclear-armed rivals remains inescapable. [Key norms continue to
constrain the options of deterrence strategists and national
leaders]{.underline}. The norm of no battlefield use of nuclear weapons
is now over seven decades old. The last tests of nuclear weapon designs
of any military consequence by a pairing of nuclear-armed rivals
occurred over two decades ago. Since every test of a nuclear weapon
constitutes a declaration of military utility, the absence of testing
matters greatly. These norms can be broken tomorrow or next year. But
these two key norms have survived many days and many years. Because they
are the hardest for any national leader to break, their extension is
feasible. [[Leaders who wish to avoid nuclear war can build on these
foundational elements]{.mark}.]{.underline} A third critical norm, that
of nonproliferation, is codified in a treaty that was indefinitely
extended in 1995. This norm requires reinforcement because additional
pairings of nuclear-armed rivals would multiply chances of catastrophe.
Iran poses a serious challenge to this norm. Reaffirmation can be
pursued either through diplomacy or, if diplomacy is vitiated, through
military strikes. The follow-on proliferation consequences of Iran
acquiring nuclear weapons are so great that this stark choice is
unavoidable. [[Those who denigrate arms control forget that, by the end
of the Cold War, **conditions for lasting nuclear peace were in hand**
--- not because of strengthened deterrence, but because **champions of
deterrence adopted the practices of arms control**]{.mark}.]{.underline}
The United States and Russia were no longer enemies. Crucial norms were
in place alongside the Anti-Ballistic Missile Treaty, which codified
national vulnerability, thereby removing one incentive for increased
nuclear force levels. Strategic forces were no longer threatening:
Indeed, Boris Yeltsin agreed in the second Strategic Arms Reduction
Treaty to the prohibition of land-based missiles carrying multiple
warheads. Conditions for strategic, crisis, and arms race stability were
therefore at hand. Deep cuts were envisioned. Dangerous military
practices were absent. Major powers respected the territorial integrity
and national sovereignty of others. This was the inheritance that
Vladimir Putin, George W. Bush, and Donald Trump found unnecessary and
inconvenient. Putin initiated the demise of arms control by disregarding
provisions of the Conventional Forces in Europe Treaty. Bush withdrew
from the Anti-Ballistic Missile Treaty, prompting, as forewarned,
Putin's withdrawal from the second Strategic Arms Reduction Treaty and
its prohibition of land-based missiles carrying multiple warheads. As
NATO expanded, Putin became more blatant in violating treaties, most
notably the Intermediate-Range Nuclear Forces Treaty. Bush announced
plans to deploy missile defenses in new NATO countries and to include
Georgia and Ukraine in the queue for future NATO membership. Then
Putin's army marched on Tbilisi, after which he carried out hybrid
warfare in eastern Ukraine and annexed Crimea. Putin then shed crocodile
tears when Trump withdrew from the Intermediate-Range Nuclear Forces and
Open Skies treaties. Where do we go from here? During the Cold War,
strategic arms control was built on treaties, and treaties were built on
numbers. Treaties and numbers still matter greatly, but they are much
harder to negotiate in a triangular, as opposed to a bilateral, context.
Because of the complex geometry of nuclear competition and because of
domestic politics in the United States, less formal constraints seem
unavoidable. More states will have seats at the table, most importantly
China. All this will take time. In the meantime, norms matter more than
formalities. Norms are easier to extend than new strategic arms
reduction treaties are to negotiate, and nuclear numbers are to reduce.
A hard focus on extending and reaffirming crucial norms can, over time,
establish conditions for far fewer numbers, with or without treaties. If
Beijing and Moscow choose to engage in dangerous military practices,
arms control, whether by means of norm strengthening or numbers, will
not succeed. In this event, the United States will also increasingly
engage in dangerous military practices. The dynamics of this competition
will invite crises, or worse. Perhaps then, the competitors will become
more inclined toward measures of reassurance alongside deterrence. In my
book, Winning and Losing the Nuclear Peace: The Rise, Demise, and
Revival of Arms Control, I propose that we embrace an ambitious goal of
extending the three norms of no use, no testing, and no new
proliferation to the 100th anniversary of Hiroshima and Nagasaki.
Imagine, if you can, a world in which nuclear weapons have not been used
on battlefields for 100 years, and a world in which nuclear weapons have
not been tested by major and regional powers for almost five decades.
Imagine, too, that North Korea remains the last nuclear-armed state. Now
imagine the perceived utility of nuclear weapons in 2045. How many
potential mushroom clouds would be required for deterrence? How high
would the barriers be against use and testing? Aiming for a century of
non-battlefield use, a half-century of not testing nuclear weapons, and
another quarter-century of successful nonproliferation might seem too
ambitious and even otherworldly. Perhaps, but in 1945 it seemed
otherworldly to envision a world in which nuclear weapons would not be
used in warfare for three-quarters of a century. When conversations
began about limiting nuclear testing in the Eisenhower administration,
it was similarly otherworldly to envision a world in which major and
regional powers would not conduct tests for a quarter-century. Those who
conceived of a global nonproliferation compact more than a half-century
ago were rewarded with 62 signatories. Notably absent were China,
France, West Germany, other U.S. allies, Brazil, Argentina, and leading
non-aligned states. This treaty now has 189 adherents, one dropout,
North Korea, and one severe test --- Iran. The hardest part of
establishing these three bedrock norms is behind us. Further extensions
are possible, even in a period of heightened competition, because they
are the most difficult norms for national leaders to break. The national
leader who authorizes the first use a nuclear weapon since 1945 will
live in infamy for the rest of recorded history. The companion norm of
no testing signifies recognition of the dangers associated with use.
Experiments continue, and those who complain about troubling experiments
block on-site inspections by opposing ratification of the Comprehensive
Nuclear-Test-Ban Treaty. Chinese officials have repeatedly said that
they will not ratify the test ban treaty until the U.S. Senate consents
to do so. India won't ratify until China does, and Pakistan will wait
for India to ratify. Republican senators most concerned by China's
nuclear build up can do something about it: They can consent to the
Comprehensive Nuclear-Test-Ban Treaty while demanding that all four
instruments of ratification be deposited together. A cascade of
ratifications could begin with a super-majority vote in the U.S. Senate.
Meanwhile, test moratoria continue because the major power willing to
resume testing would set off a very different cascade, as all four
nuclear-armed rivalries would follow suit. [[**The greatest nuclear
dangers reside** in the increase in dangerous military practices between
the U]{.underline}]{.mark}nited [[S]{.underline}]{.mark}tates [[and
China, Russia and the U]{.underline}]{.mark}nited
[[S]{.underline}]{.mark}tates, [[India and China, and Pakistan and
India. Air and naval operations in the Taiwan Strait and South China Sea
increase the likelihood of crises, as do military operations in eastern
Ukraine]{.underline}]{.mark}. But we've been here before, not just with
the Soviet Union, but also with China. Despite severe crises and because
of diplomacy, the norm of no battlefield use has held, at least so far.
Norm strengthening is a matter of daily occurrence. Success happens one
day at a time and one crisis at a time. What, then, to do about treaties
and numbers? President Joe Biden and Putin quickly agreed to extend
verifiable limits in the 2010 Strategic Arms Reductions Treaty for
another five years. Negotiating next steps will be challenging. U.S. and
Russian negotiators are discussing many agenda items, with some
preferences clearly beyond reach. The greatest threats to nuclear peace
at present relate to ground, air, and naval forces operating in close
proximity, as well as dangerous cyber and space practices. Consequently,
Washington's most challenging and urgent agenda items relate to codes of
conduct rather than numerical arms control. This agenda belongs at the
top of Washington's conversations with Beijing as well as Moscow.
Another U.S.-Russian treaty mandating further reductions becomes harder
to envision as China ramps up its force structure. Trump was right in
calling for Beijing's inclusion and an end to its free riding, but he
proposed a trilateral warhead counting exercise rather than effective
controls and reductions. Whatever appeal this proposal has in conceptual
or visionary terms --- or some downsized variant of this idea, such as
counting tactical nuclear weapons --- it would constitute a very lengthy
digression from reducing nuclear dangers. Norm strengthening is needed
well before counting is completed and reductions can begin. Where can
this most usefully be done? The 65-member Conference on Disarmament in
Geneva is too unwieldy to succeed. Its last hurrahs in treaty making
occurred during the Clinton administration. Ever since, its procedures
have empowered blocking action. There is also scant reason to expect
that the permanent five members of the U.N. Security Council can become
an effective forum to advance important arms control agenda items. The
geometry of nuclear competition suggests creation of a new forum to
focus on norm building and codes of conduct in which all four pairs of
nuclear-armed rivals are represented along with Britain and France,
countries with great expertise and practical experience to offer. I
would exclude Israel and North Korea from this forum because their
addition poses more problems than potential benefits. A seven-nation
forum consisting of the United States, Russia, China, India, Pakistan,
Britain, and France would be hard to steer, but the nuclear dangers we
now face are interconnected and unwieldy. When the nature of a problem
seems intractably complex, the wisest course might just be to expand the
scope of the problem. Even as the four pairs compete, they have the most
to lose if key norms are broken and the most to gain if they are
extended. Existing bilateral conversations on nuclear risk reduction
would, of course, continue, but there are no effective channels of
communication and substantive exchanges between India and China and
between India and Pakistan, where border clashes are becoming more
intense. A non-hierarchical, seven-nation approach to norm building
might just succeed. All seven have significant concerns about the
intentions and capabilities of states with the most dynamic nuclear
modernization programs. Each state has its own reasons to engage, as
well as to be wary. If other states are willing to sit at the table, it
becomes harder for anyone to hold out. The ground rules for seven-nation
talks seem most likely to avoid traps if the agreed focus of
conversation is nuclear risk reduction and norm building. Sidebar
conversations would be encouraged, as they could lay the groundwork for
bilateral agreements. The tabling of bilateral issues would, however, be
prohibited. The first order of business might be to affirm the canonical
Reagan-Gorbachev pledge that a nuclear war cannot be won and must not be
fought. Thematic discussions on dangerous military practices might
suggest common concerns and remedies, whether bilateral or multilateral.
Again, this sounds wildly optimistic. The intensification of rivalries
could well foreclose useful discussions --- even if all seven states
agree to attend. There are many pitfalls, requiring deft multilateral
diplomacy. The U.S. State Department would need reinforcements. And yet,
for all the manifold difficulties involved, there is sufficient
connective tissue to try. Potential benefits include new opportunities
to engage China and to open clogged channels of conversation. Over time,
if this forum proves its worth, topics could evolve from norm building
to the consideration of guardrails, limits, and reductions for nuclear
modernization programs. None of the states with the most dynamic
modernization programs are willing to relax requirements unless others
do. One approach worth considering is a multilateral build-down concept
where all seven states would agree to reduce the size of their arsenals
as they modernize them. A build-down approach has the advantage of
becoming all encompassing, while avoiding a ratio-based, hierarchical,
multilateral system that has been tried before for naval arms control
and that has no practical chance of success. Lengthening and
strengthening norms have to be the first order of business when
dangerous military practices are on the rise. Numerically based arms
control cannot take an extended holiday, however, especially since
Russia is adding new means of delivery to its strategic forces and
Beijing is acting with dispatch to significantly increase its
deployments of land-based missiles. As if the agenda outlined here isn't
ambitious enough, a new negotiating forum to address trilateral nuclear
arms control and reductions seems inescapable. The more China builds up,
the harder it becomes to succeed at bilateral controls. There are, no
doubt, mixed motives behind the speed of Beijing's build up, which is
reminiscent of the Kremlin's actions in preparations for strategic arms
limitation talks in the Johnson and Nixon administrations. Some
deterrence strategists will view Beijing's activities as early evidence
of nuclear war-winning ambitions. Other explanations seem more likely,
including the prosaic impulses of seeking to gain leverage in upcoming
negotiations and to avoid disadvantage. Beijing surely recognizes that
it cannot "just say no" to strategic arms limitations indefinitely.
Because Beijing is in a hurry, the Biden administration is obliged to
speed up preparations for trilateral negotiations on numerical
limitations that serve U.S. national security interests as well as the
interests of friends and allies. As with the U.S.-Soviet strategic arms
limitation talks, trilateral discussions are likely to encounter stalls
and unexpected delays. We have time to do our homework on important
matters of scope and limitation. When the Johnson administration was
first preparing for negotiations with the Kremlin, its plans included
limitations on medium-range, intermediate-range, as well as
ocean-spanning missiles. This approach is worth reconsidering, given
Putin's deployment of these missiles in violation of the
Intermediate-Range Nuclear Forces Treaty, U.S. rejoinders, and China's
heavy investments in missiles of less-than-intercontinental-range. Then
there is the highly contentious matter of including interceptors for
national missile defenses. Depending on what means of delivery are
included and excluded, it might be possible to devise an effective arms
control regime with equal aggregates of nuclear-capable delivery
vehicles and missile defense interceptors. A firestorm of protests to
equal aggregates with China as well as Russia can be expected, but
depending on units of account, counting rules, and range limits, they
might well serve the interests of the United States as well as U.S.
friends and allies. Dozens of loopholes would need to be nailed shut,
and Beijing would have to accept uncomfortable monitoring arrangements.
Success will be very hard to achieve and will likely be followed by
setbacks until leaders arrive on the scene who are willing to buck
deterrence orthodoxy. When they do, the build-down concept of reducing
while modernizing might also apply. If and when norm-strengthening
negotiations evolve into numerical accords, the fluidity of trilateral
relations and opposition on Capitol Hill will preclude treaty making. If
trilateral accords can somehow be reached, they would likely take the
form of executive agreements and be term limited. The arguments in favor
of formality and agreements of indefinite duration are not persuasive
when treaties, like executive agreements, can be discarded after U.S.
national elections. The reaffirmation of norms need not await the
resolution of discussions about numbers. To the contrary: The
reaffirmation of norms is needed if trilateral talks are to succeed over
time. Even if agreements are not reachable or as inclusive as we would
like, preliminary discussions with Moscow and Beijing could still have
utility. At a minimum, it could prod useful assessments of different
limitation parameters and on how best to proceed. Those who didn't
recognize winning the nuclear peace will surely notice its loss.
[[Strengthening deterrence provides no guarantee against catastrophic
loss. **To avoid nuclear war**, **diplomacy and arms control have to
accompany deterrence**]{.mark}.]{.underline} Sooner or later, national
leaders will revive arms control because our lives depend on it.
Reassurance and stabilization begin with lengthening and strengthening
norms and can take many forms. Reinvention depends on diplomatic
adeptness, creativity, and wisdom. It also depends on the state of
relations between major powers. If their competition sharpens, and if
national leaders are content to intensify that competition, then no
proposals to reverse course will succeed. When leaders decide to pursue
course corrections or when leaders change, opportunities will arise.
When conditions permit, they'll need plans on how best to proceed. We
face daunting challenges because policymakers have run out of simple
solutions. We have much ground to cover since the era of grand treaty
making ended with the Cold War. [[It's time to plan once again for a
future in which nuclear weapons aren't used in warfare. We've succeeded
in the past, and we can succeed again by **harnessing deterrence with
arms control**.]{.underline}]{.mark}

#### Integrating AI into nuclear weapons systems helps avoid the risks of nuclear escalation.

Jessica **Cox, 2021** (Director of Nuclear Policy at NATO, "The
Unavoidable Technology: How Artificial Intelligence Can Strengthen
Nuclear Stability," WASHINGTON QUARTERLY)

Traditionally, nuclear deterrence relies on a country having credible
nuclear capabilities plus the political will or resolve to use them if
necessary (and only if necessary), therefore persuading an adversary to
not attack. **[[Integrating AI into nuclear systems can enhance nuclear
decision-making]{.underline}]{.mark}**, improving percep¬tions of both
capability and resolve. Early Warning and Detection: Avoiding
Unnecessary Use and Escalation Most significantly, [[integrating
AI]{.mark} into intelligence, surveillance, and
reconnais¬sance]{.underline} (ISR) systems and using AI as part of the
analytical tool kit for early warning and detection
[[could]{.underline}]{.mark} improve target identification, [**[prevent
false positives or close calls]{.underline}**,]{.mark} and increase
understanding of adversary actions. [[AI can be used to increase a
nation's ability to understand the nature of its
environment]{.underline}]{.mark} as well as speed of analysis and
development of courses of action in a conflict, [thus]{.underline}
improv¬ing its overall capabilities in the nuclear space and
[[**reducing the risk of unin¬tended escalation** in the midst of a
crisis with a nuclear dimension]{.underline}.]{.mark} In a nuclear
exchange, national leadership may have just minutes to assess a
situation and determine whether to launch its own nuclear response.
Nuclear weapons states such as the United States have sought to increase
this decision-making time to reduce the potential for misunderstanding
or miscal- culation in a crisis, given the immense consequences of using
nuclear weapons.21 [[Incorporating AI into early warning and
decision-making analysis may improve both the speed and quality of
info]{.mark}rmation [processing]{.mark}]{.underline} as well as
eliminate potential biases from military leadership, [[which will be
crucial in a crisis **to allow time for de-escalation**]{.mark} and
tension reduction [between sides]{.mark}]{.underline}[. [AI can
similarly enhance the ability to discriminate between real and false
information, **which is critical to preventing
miscalculation**]{.underline}]{.mark} or mistake in a crisis. [[A number
of "close calls" have occurred throughout the years, in which nuclear
weapons use was only avoided through human intervention based on
uncertain information]{.underline}]{.mark}.22 In 1983, NATO undertook
Command Post Exercise Able Archer to "practice command and staff
procedures, with particular emphasis on the transition from conventional
to non-conventional operations, including the use of nuclear weapons."23
At the time, Soviet paranoia about a US nuclear first strike, with
preparations under cover of a war game, was at an all-time high. When
NATO began its Able Archer exercise, Soviet officials thought the
exercise was real and put mobile intercontinental ballistic missiles
(ICBMs) on a three-minute alert.24 The same year, the Soviet early
warning com¬puter system signaled five incoming US Minuteman ICBMs. The
watch officer on duty, Soviet Lt. Col. Stanislav Petrov, did not report
the incident, concluding that it must be a false alarm. If he had
reported that US nuclear missiles were inbound, the Soviets would have
followed their nuclear doctrine and retaliated with no time to
double-check or negotiate with the United States.25 Petrov ulti¬mately
made the right call---as the Soviet early warning system had mistaken
sun shining off clouds for incoming missiles. Even after the end of the
Cold War, in 1995, a Norwegian civilian research rocket launch was
detected by the radar crews from the Russian Missile Attack Warning
System (MAWS) and mistaken for a US Trident II submarine-launched
ballistic missile. Command and control procedures were enacted,
including notification of President Boris Yeltsin and activation of the
Russian "cheget" system---essentially its nuclear football. Russian
authorities eventually determined that this was not a nuclear-armed
ballistic missile launch after reviewing satellite and other
intelligence information.26 While these and other incidents were
ultimately resolved successfully through the intervention of military
experts and political leaders,27 they illustrate the dangers of
imperfect systems that rely on human analysts with potentially
inac¬curate or inadequate information. As defense researcher Jaganath
Sankaran argues, "future applications of AI to nuclear command and
control should aspire to create an algorithm that could argue in the
face of overwhelming fear of an impending attack that a nuclear launch
isn't happening."28 Such an approach could both reduce the fog of war
and reassure decision-makers that their course of action is correct in
the face of uncertain information, either using nuclear weapons or
refraining from it. Although most nuclear-armed nations now use multiple
systems to reduce the chances of a false positive warning signal,
advancements in AI could significantly improve confidence in and
functionality of these systems when integrated with human
decision-making. AI tools could play a significant role in helping to
ident¬ify patterns of life and reduce potential operator biases in
conducting analysis. For instance, in order to be able to quickly
discriminate between a country's launch of a sounding/research rocket as
opposed to an ICBM, which have very similar radar signatures, big data
analytical tools could be used to collate and process massive amounts of
electronic data---including signals, imagery, and open source
collec¬tion---over time to identify patterns of behavior unique to each
type of launch. Then, if there is an ambiguous or unexpected launch,
these systems would be able to quickly determine whether or not the
current circumstances more closely resemble one type of launch over the
other---actually preventing future close calls or misinterpretations of
data, as occurred in Able Archer in 1983. A human analyst would likely
still need to make a final determination, but through the use of AI and
data analytics, they would have a more accurate, timely, and complete
picture on which to base any decisions.

#### Integration of AI into defense bolsters cybersecurity of critical infrastructure.

**D**EPARTMENT **O**F **D**EFENSE, 2/12/20**19** ("SUMMARY OF THE 2018
DEPARTMENT OF DEFENSE ARTIFICIAL INTELLIGENCE STRATEGY," Retrieved
6/12/2022 from
<https://media.defense.gov/2019/Feb/12/2002088963/-1/-1/1/SUMMARY-OF-DOD-AI-STRATEGY.PDF>.)

Protect our country and safeguard our citizens. [[AI will be used
to]{.underline}]{.mark} protect the safety and security of U.S. citizens
and to [[enable a **stronger defense of U.S. critical
infrastructure**]{.underline}]{.mark}. Specifically, [[AI can enhance
our ability to predict, identify, and **respond to
cyber**]{.underline}]{.mark} and physical [[**threats** from a range of
sources]{.underline}, [**strengthening the defense of the homeland from
attack** and discouraging attempts to disrupt U.S.
infrastructure]{.underline}]{.mark} such as financial networks, electric
grids, election processes, and medical systems.

#### Cyberattacks against infrastructure risk escalation to a nuclear conflict:

Michael T. **Klare,** 11/20**19** (professor emeritus of peace and world
security studies at Hampshire College and senior visiting fellow at the
Arms Control Association, "Cyber Battles, Nuclear Outcomes? Dangerous
New Pathways to Escalation,"
<https://www.armscontrol.org/act/2019-11/features/cyber-battles-nuclear-outcomes-dangerous-new-pathways-escalation>,
Retrieved 9/4/2021)

Yet [[another **pathway to escalation** could arise from a cascading
series of cyberstrikes]{.underline}]{.mark} and counterstrikes [[against
**vital national infrastructure**]{.underline}]{.mark} rather than on
military targets. All major powers, along with Iran and North Korea,
have developed and deployed cyberweapons designed to disrupt and destroy
major elements of an adversary's key economic systems, such as power
grids, financial systems, and transportation networks. As noted, Russia
has infiltrated the U.S. electrical grid, and it is widely believed that
the United States has done the same in Russia.12 The Pentagon has also
devised a plan known as "Nitro Zeus," intended to immobilize the entire
Iranian economy and so force it to capitulate to U.S. demands or, if
that approach failed, to pave the way for a crippling air and missile
attack.13 [[The danger here is that]{.underline}]{.mark} economic
[[attacks of this sort]{.underline}]{.mark}, if undertaken during a
period of tension and crisis, [[could lead to an escalating series of
**tit-for-tat attacks**]{.underline}]{.mark} against ever more vital
elements of an adversary's critical infrastructure, producing widespread
chaos and harm and eventually leading one side to initiate kinetic
attacks on critical military targets, [[risking the slippery slope to
**nuclear conflict**]{.underline}]{.mark}. For example, a Russian
cyberattack on the U.S. power grid could trigger U.S. attacks on Russian
energy and financial systems, causing widespread disorder in both
countries and generating an impulse for even more devastating attacks.
At some point, [[such attacks "could lead to major conflict and possibly
**nuclear war**]{.underline}]{.mark}."14

### Plan

#### The United States federal government should substantially increase security cooperation with NATO by establishing standards to interoperate Artificial Intelligence technology into future NATO operations.

### 1AC -- Solvency

#### Solvency

#### Facilitating NATO cooperation regarding standards to interoperate AI technology into future operations allows safe development and responsible use of AI technology.

Zoe Stanley-**Lockman, 2022** (Defense and Strategic Studies, Nanyang
Technological University, "NATO's Role in Responsible AI Governance in
Military Affairs," [https://www.oxfordhandbooks.com/view/
10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69](https://www.oxfordhandbooks.com/view/%2010.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69),
Retrieved 6/11/2022)

To maintain its relevance in a security architecture increasingly
concerned with the way that technology shifts power dynamics and scales
threats to international security, [[NATO has an incentive to foster
cooperation]{.underline}]{.mark}, promote standards of practice, [[and
incentivize **Allied AI harmonization**. It is]{.mark}]{.underline}
strategically salient to facilitate a dialogue and engagement among
Allies on AI, but it is [[**practically important** to use NATO's
position to facilitate Allied cooperation regarding standards to
**project the Alliance's ability to interoperate in future
operations**]{.mark}.]{.underline} NATO standards aim to enhance
interoperability among partners and successful implementation of
strategy. More specifically, [[standards and certification are used to
establish and implement requirements aligned with **safe development and
responsible use of tech**]{.underline}]{.mark}nology. In addition to
purely technical standards, [[NATO has operational standards
that]{.underline}]{.mark} specify "conceptual, organizational or
methodological requirements to [[enable]{.underline}]{.mark} materiel,
installations, organizations or [[forces to fulfil their
functions]{.mark} or missions]{.underline}."51 In line with the
definitions from STS and military innovation scholarship, [[standards
can thus be seen as a mechanism to translate]{.underline}]{.mark}
responsibility-derived state and organizational **[[AI policy into
actionable functions]{.underline}]{.mark}**. In fact, [[NATO has set
certain standards for the Allies and **these standards subsequently
become the norm**]{.underline}]{.mark}. Within NATO, it is [[the NATO
Standardization Office]{.underline}]{.mark} (NSO) that [coordinates
thousands of experts to align tech]{.underline}nological development
with military requirements [that [can help enhance effectiveness,
interoperability,]{.mark}]{.underline} and cohesion.52 While the NSO is
primarily responsible for setting standards, other NATO
entities---including in the NATO Science and Technology Organization
(STO)---play important roles in implementing them and coordinating
between national approaches.53 Certification frameworks and the
promulgation of best practices can similarly help incentivize the
transposition of RRI into military organizations, even if
standardization is by no means a purely military governance tool. Both
mechanisms, strategic policy planning and standards and certification,
provide options for NATO to participate in AI governance regimes
focusing on international security. [[NATO's operationalization of these
tools may hold important implications while **implementing successful AI
governmental regimes** for Allies and other defense
stakeholders]{.underline}.]{.mark} In the next section, we consider each
mechanism within foundational issues, or pillars, to illustrate NATO's
role in AI governance.

#### NATO standards on AI are critical to prevent Chinese AI dominance.

Karlijn **Jans,** 7/10/20**18** (holds Masters degrees from Maastricht
University and King's College London, "NATO Needs to Get Smarter About
AI,"
<https://www.atlanticcouncil.org/blogs/new-atlanticist/nato-needs-to-get-smarter-about-ai/>,
Retrieved 6/15/2022)

The potential large-scale impact of AI has only been acknowledged on the
fringes of security debates and by technology experts. The assessment
and impact of AI systems, however, cannot be left to the "nerds." [[NATO
must begin to understand the impact of AI and have discussions about its
potential use by and against the Alliance]{.underline}]{.mark}. US
Secretary of Defense James Mattis said in his January 19 announcement of
the US National Defense Strategy: "[[success does not go to the country
that develops a new tech]{.underline}]{.mark}nology [[first, but rather,
to the one that better integrates it and more swiftly adapts its way of
fighting]{.underline}."]{.mark} AI debates often devolve into arguments
over "killer robots." [[**AI**,]{.underline}]{.mark} however, [[will
have a profound impact on NATO's]{.mark} organization,
[operations,]{.mark} and cooperation. [**Its successful adoption** will
help the Alliance **maintain its competitive edge** and deterrence
capability]{.mark}]{.underline}. For example, AI will profoundly change
military organizational planning and coordination. The implementation of
AI in the battlefield would mean advancing into a "hyper war" where
current decision-making processes will be disrupted by the enormous
speed of development and the ability of machine learning by AI
applications. It is, therefore, key for the Alliance to implement AI
applications into their militaries' planning, operations, and
coordination. AI also has huge potential for NATO's intelligence,
surveillance, and reconnaissance (ISR) activities. NATO is already
leveraging AI to sift through and exploit the massive amounts of data
generated by new and advanced weapon systems. New fifth-generation
fighter planes are not only traditional weapon systems, but also
important data collectors. AI could also assist in tracking down missile
sites. These examples and the few initiatives started by NATO's Allied
Command Transformation (ACT) are pursued mainly on the Alliance's
operational and tactical levels. There have still been no direct
deliberations about the implications of AI amongst NATO's top political
and strategic leaders. [[NATO is also at risk of AI being used against
it by potential adversaries]{.underline}.]{.mark} As Tomáš Valášek of
Carnegie Europe argued, "AI can be effectively deployed to undermine
trust among countries fighting on the same side by discrediting their
intelligence." NATO missions and operations, which involve a high number
of different countries and military organizations, are already heavily
dependent on data and information exchange. Adversarial AI applications
could influence, and even alter, information and communication amongst
NATO allies while an operation is ongoing, creating confusion and
distrust. [[NATO's lack of action on AI is in stark contrast to the rise
of China as a global AI leader]{.mark}. China]{.underline} released its
2020 AI ambitions and aims to be world leader by 2030. It [is already
developing complex sensor networks in the private sector with disrupting
potential for the military domain. [There is a real risk that China will
be setting universal]{.mark}]{.underline} legal and technical
[[standards for the use of AI if the Alliance]{.underline}]{.mark}, or
nations by themselves, [[do not set out a clear AI
strategy]{.underline}]{.mark} and have a real discussion on AI
implementation and exploitation. For example, China requires Apple to
adhere to different privacy settings for Chinese iPhone users. Data must
be stored on Chinese servers, meaning Chinese intelligence services will
have access to this information. Beijing has few privacy and ethical
concerns about using AI, for example, facial recognition and
surveillance by AI applications, which allows it to implement these
technologies in the security sector much faster. [Russia also recognizes
the disruptive potential of AI, not just on the battlefield, but also in
global power relations]{.underline}. Russian President Vladimir Putin
said: "artificial intelligence is the future, not only for Russia but
for all humankind...**[[Whoever becomes the leader in this sphere will
become the ruler of the world]{.mark}."]{.underline}** Russia is still
lagging behind China and the United States in AI, but it has great
ambitions. The Kremlin's Military Industrial Committee has set a target
of making 30 percent of military equipment robotic---and hence
(partially) run by AI---by 2025. There are ongoing efforts by some
member states to utilize AI and the United States has been ramping up
its activities. The Pentagon's Maven project aims to utilize the latest
technology from Silicon Valley for military purposes (despite heavy
criticism from the private sector over implementation of AI for lethal
purposes) and the United States recently announced it will establish an
official AI hub for its military, the Joint Artificial Intelligence
Center. In Europe, individual European Union (EU) member states have
been working on their individual AI strategies, with one of the most
notable being the French. As for the European Union, only this year
twenty-five of its members signed a Declaration of Cooperation on AI,
declaring their intentions to join forces and engage in a European
approach to deal with AI. But is it all too little, too late? "AI is on
the verge of becoming a critical part of our societies" says former
German State Secretary of Defense Katrin Suder. At the same time, AI and
its implications have never been on the agenda at a NATO Summit. As the
late French Prime Minister Georges Clemenceau once said: "War is too
important a matter to be left to the military." The same rings true for
AI: AI is too important to be relegated to discussions on NATO's
operational and tactical levels. [[NATO's political and strategic
leaders need to lay out a vision for AI's role in the Alliance, **before
it is too late.**]{.underline}]{.mark}

#### Common ground among NATO on AI is key to ensuring tech leadership on a global scale.

Sebastian **Sprenger**, 4/27/20**21** (Europe editor for Defense News,
"NATO tees up negotiations on artificial intelligence in weapons,"
<https://www.c4isrnet.com/artificial-intelligence/2021/04/27/nato-tees-up-negotiations-on-artificial-intelligence-in-weapons/>,
Retrieved 6/15/2022)

COLOGNE, Germany --- [[NATO officials are kicking around a new set of
questions for member states on a]{.underline}]{.mark}rtificial
[[i]{.underline}]{.mark}ntelligence in defense applications, [[as the
**alliance seeks common ground**]{.underline}]{.mark} ahead of a
strategy document planned for this summer. [[The move comes amid a grand
effort to sharpen NATO's edge in what officials call
emerging]{.underline}]{.mark} and disruptive
[[technologies]{.underline}]{.mark}, or EDT. Autonomous and
[[**artificial intelligence-enabled weaponry** is a **key element** in
that push, aimed at ensuring **tech leadership on a global
scale**]{.underline}]{.mark}.

#### Allies will adopt NATO standards on AI beyond NATO structures and operations.

Zoe Stanley-**Lockman, 2022** (Defense and Strategic Studies, Nanyang
Technological University, "NATO's Role in Responsible AI Governance in
Military Affairs," [https://www.oxfordhandbooks.com/view/
10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69](https://www.oxfordhandbooks.com/view/%2010.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69),
Retrieved 6/11/2022)

[[To enhance legal interoperability, **NATO can exert its influence** on
how Allies **can develop**]{.underline}]{.mark} and deploy [[**AI**
consistent with their legal obligations through its **unique
standardization capacities**. Historically, NATO has taken **significant
steps to bridge the legal gap** between Allies on critical
procedures]{.underline}]{.mark} that bridge responsible state behavior
with such "troop-to-task" considerations. [[One instructive example from
past operations is detention policies]{.underline}]{.mark} in
non-international armed conflicts.78 The promulgation of detention
standards illustrates the operational significance of NATO's common
legal procedures, even for coalitions of the willing that formally
operate outside NATO structures. By way of background, the U.S.-led
coalition in Afghanistan had internal debates regarding the 96-hour
security detention time period.79 The United States advocated extending
the 96-hour rule, where coalition partners insisted adhering to the NATO
standard, even though it was not a NATO operation.80 Generally [[the
detention example **illustrates NATO legal standards providing clarity
to non-NATO operations**]{.underline}]{.mark}; in some cases, [[Allies
adopt NATO standards as accepted thresholds that continue to inform
coalition policies **beyond NATO structures and
operations**]{.underline}. [Implementing AI in future military
operations will almost certainly complicate legal
interoperability]{.underline}]{.mark} as there is a lack of uniform
standards, as in the detention example. Even some of the more basic
implementation measures will garner legal uncertainty and Allies will
inevitably navigate with minimal legal clarity and no standard
procedures. Despite the roots of the legal debate stemming from the
question of lethality, the most pressing (and urgent) legal issues will
address the integration of necessary AI-enablers, such as data gathering
and sharing. Furthermore, NATO has coordinated initiatives to promote
awareness of Allies' legal obligations and has a dedicated office
focusing on legality. This centralizes the institutional capacity to
focus on alignment not only between the policies of NATO Allies, but
coherence with the international community more broadly. Among others,
the NATO Legal Practitioners' Workshop and inter-organizational dialogue
between NATO, the UN, and the International Committee of the Red Cross
(ICRC), the latter of which has a delegation to NATO that provides legal
training and education to practitioners.81 The NATO Office of Legal
Affairs (OLA) itself can also play a central role in navigating the
challenges to legal interoperability. As the example of detention
standards illustrates, [[NATO has been successful in implementing legal
standards which translated into]{.mark} operational clarity and
**[coalition policy outside NATO operations]{.mark}**]{.underline}.

#### NATO cooperation on AI sets important precedents to significantly boost AI development.

Robert HP **Engels, 2022** (Vice President and CTO in Global Business
Line Insights & Data, "NATO's outlook on a responsible military adoption
of AI,"
<https://www.capgemini.com/no-no/2022/01/natos-outlook-on-a-responsible-military-adoption-of-ai/>,
Retrieved 6/15/2022)

Or as Ulrike Franke, a senior policy fellow at the European Council on
Foreign Relations, stated: "[[It's better for the alliance to focus on
the basics, like increased data sharing to develop and train military AI
and **cooperating on using a**]{.mark}rtificial
**[i]{.mark}**ntelligence [in logistics]{.mark}]{.underline}. (..)
[[**If NATO countries were to cooperate on that,** that could create
good procedures and **set precedents**]{.underline}]{.mark}."\[2\]
Training, at all levels of command, is certainly a key factor to
cooperatively synchronize the development of maturity in both AI
algorithms and operators, [[thus gradually building increased capacity
and professionalism]{.underline}]{.mark}. NATO stresses the importance
of an ethical approach and points out that "Allies and NATO must strive
to protect the use of AI from such interference, manipulation, or
sabotage, in line with the Reliability Principle of Responsible Use,
also leveraging AI-enabled Cyber Defence applications.". Furthermore,
they point out the need to develop adequate security certification
requirements for AI due to the fact that AI can impact critical
infrastructure, capabilities and civil preparedness creating potential
vulnerabilities, such as cyberspace, that could be exploited by certain
state and non-state actors. [[The principles mentioned in the NATO
strategy allow for modernization and use of AI without stifling
innovation, on the contrary even: **they might significantly boost the
development of areas in a**]{.underline}]{.mark}rtificial
**[[i]{.underline}]{.mark}**ntelligence [[that have not been in focus
until now]{.underline}]{.mark}. The AI strategy can point the direction
how AI play a decisive role in how NATO's partners cooperate, analyze
and provide vital decision-making information faster and more
comprehendible relevant to a wide range of potential challenges and
threat situations.

#### Cooperation and alignment among NATO is critical for the alliance to maintain a competitive edge in AI:

Zoe Stanley-**Lockman, 2022** (Defense and Strategic Studies, Nanyang
Technological University, "NATO's Role in Responsible AI Governance in
Military Affairs," [https://www.oxfordhandbooks.com/view/
10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69](https://www.oxfordhandbooks.com/view/%2010.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69),
Retrieved 6/11/2022)

**[[As NATO]{.underline}]{.mark}** bodies and [[**Allies prepare for the
impact of AI** on future military operations, the Alliance has its own
responsibility to steward AI in ways that]{.underline}]{.mark}, inter
alia, [[promote cohesion between democratic
countries]{.mark},]{.underline} prevent risks, [[shore up
interoperability, project deterrence, and ensure
stability]{.underline}]{.mark}.7 To achieve these aims, [[**cooperation
and alignment are critical for the Alliance** to **maintain a
competitive edge** and **promote further innovation** in alignment with
shared values]{.underline}.]{.mark}

## Case -- Top Level

### UQ -- NATO Role In AI Uncertain 

#### NATO's current role in emerging AI regimes is uncertain.

Zoe Stanley-**Lockman, 2022** (Defense and Strategic Studies, Nanyang
Technological University, "NATO's Role in Responsible AI Governance in
Military Affairs," [https://www.oxfordhandbooks.com/view/
10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69](https://www.oxfordhandbooks.com/view/%2010.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69),
Retrieved 6/11/2022)

In this chapter, we explore a role for the North Atlantic Treaty
Organization (NATO) in the emerging military AI governance architecture.
NATO (or the Alliance) is a military and political alliance among 30
contributing member states that are committed to collective security.
[[Much of NATO's]{.underline}]{.mark} original purpose and [[current
core tasks]{.underline}]{.mark} arguably [[**leave the Alliance's role
uncertain** in international governance regimes contending with the
impact of emerging tech]{.mark}nology [on international
politics]{.mark}]{.underline}.1 As global powers compete for the
economic and military capabilities that AI can offer, the Alliance has
the enormously challenging task of navigating varying political
realities and capabilities of Allies, all while effectively
recalibrating strategic relationships in the coming years. Recognizing
technological change as a key variable, NATO has begun to adapt its
organizational composition and strategic footing to increase the
Alliance's capacity to meet emerging security challenges for military
capability development trends of both its own members and those of
competitors or adversaries.

### Solvency -- Interoperability

#### Interoperability is necessary to prevent disruptions from attacks.

Zoe Stanley-**Lockman, 2022** (Defense and Strategic Studies, Nanyang
Technological University, "NATO's Role in Responsible AI Governance in
Military Affairs," [https://www.oxfordhandbooks.com/view/
10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69](https://www.oxfordhandbooks.com/view/%2010.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69),
Retrieved 6/11/2022)

The third pillar identifies safety and security of AI systems as
prerequisite to trustworthy and responsible AI in any context, but
especially so for the conduct of military activity. [[At the NATO level,
Allied forces must ensure their systems **interoperate safely** and
predictably both to ensure effective command and
control]{.underline}]{.mark} (C2) internally, [[and to prevent
disruptions from attacks. It is a foundational facet of coordination
that shows the overlap between NATO interests in military effectiveness
and incentivization for responsible innovation]{.underline}.]{.mark}

### Solvency -- NATO Key to AI Development

#### NATO's resources and leadership allow for safe and secure AI development.

Zoe Stanley-**Lockman, 2022** (Defense and Strategic Studies, Nanyang
Technological University, "NATO's Role in Responsible AI Governance in
Military Affairs," [https://www.oxfordhandbooks.com/view/
10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69](https://www.oxfordhandbooks.com/view/%2010.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69),
Retrieved 6/11/2022)

[[**NATO has an important role to play** in military standardization and
Allied policy planning for **safe, secure, and interoperable
AI**.]{.underline}]{.mark} This includes the coordinating role of the
Conference of National Armaments Directors and the Command, Control and
Consultation Board to implement complementary acquisition processes that
fuse AI adoption measures with safety responsibilities. Furthermore,
entities including STO and NSO have a significant role setting the
technical baseline and promulgating materiel standards that provide the
technical framework for safety and security. Although their staffs are
themselves small, they both convene hundreds, if not thousands, of
subject matter experts in working groups. As such they both offer unique
technical networks to help shape safety and security in a way that
minimize risk in operations. [[**NATO's resources and leadership are
vital** to using standards and coalition policy to instill safe and
secure tech]{.underline}]{.mark}nological [[development, a necessary
condition to interoperable and successful future
operations.]{.underline}]{.mark}

#### The NATO framework allows NATO to maintain its technological edge.

Rob **Murray,** 9/1/20**20** (head of the Innovation Unit in NATO's
Emerging Security Challenges Division, "Building a resilient innovation
pipeline for the Alliance," Retrieved 6/12/2022 from
[https://www.nato.int/docu/review/articles/
2020/09/01/building-a-resilient-innovation-pipeline-for-the-alliance/index.html](https://www.nato.int/docu/review/articles/%202020/09/01/building-a-resilient-innovation-pipeline-for-the-alliance/index.html))

The first step towards fixing the fragmentation of Allied disruptive
innovation is for Allies, through [[the NATO
framework]{.underline},]{.mark} to focus on agreed innovation
priorities. This [[will allow them to pick winners and invest public
patient capital -- the private sector is unlikely to invest venture
capital as the risk is simply too high]{.underline}]{.mark} (nations
tend not to go out of business and can take on such uncertainty). [[This
direction and investment will help to maintain NATO's overarching
tech]{.underline}]{.mark}nological [[edge]{.underline}.]{.mark} Indeed,
as Keynes and Weber argued, the ability to make things happen that
otherwise would not needs a combination of technological, policy and
bureaucratic skills matched by investment. Step 2: leverage the
comparative advantage of the Alliance If Allies are to achieve most
defence at less cost with least delay built with wisdom and efficiency,
then it is logical to leverage those natural advantages that geography
and skill sets afford NATO member states. A network of the finest
universities across the Alliance should be established and resourced to
allow cutting-edge multinational research to take place across multiple
disruptive technologies simultaneously. Perhaps Stanford could lead on
relevant AI research, while Delft and the University of Chicago partner
on quantum; maybe Imperial College London looks at biotechnologies with
Johns Hopkins University, while Tallinn University centres its efforts
on next generation cyber defences; and the École Polytechnique and
Massachusetts Institute of Technology examine future telecommunication
needs. The point is Allies will need to leverage such networks of
universities in conjunction with national government research labs to
provide maximum innovation coherence. [[The diversity of
multinational]{.underline}]{.mark}, multi-disciplined defence and
[[security innovation research teams, which NATO can engender, is a huge
asset and is the Alliance's competitive advantage]{.underline}]{.mark}.

### Solvency -- Plan Allows Building Up of AI

#### Interoperability of AI with allied partners is key to developing the full potential of AI.

DEPARTMENT **O**F **D**EFENSE, 2/12/20**19** ("SUMMARY OF THE 2018
DEPARTMENT OF DEFENSE ARTIFICIAL INTELLIGENCE STRATEGY," Retrieved
6/12/2022 from
<https://media.defense.gov/2019/Feb/12/2002088963/-1/-1/1/SUMMARY-OF-DOD-AI-STRATEGY.PDF>.)

Become a pioneer in scaling AI across a global enterprise. [[We
recognize the tremendous utility of AI to a wide range of capabilities.
To realize this potential fully, we must pioneer AI approaches **across
the full scale of our global defense enterprise** in a manner **that is
Joint and interoperable** with]{.underline}]{.mark} interagency,
[[allied, and coalition partners.]{.underline}]{.mark} Specifically, DoD
will identify and implement new organizational approaches, establish key
AI building blocks and standards, develop and attract AI talent, and
introduce new operational models that will enable DoD to take advantage
of AI systematically at enterprise scale.

#### International alliance partnerships allow the overcoming of AI challenges.

DEPARTMENT **O**F **D**EFENSE, 2/12/20**19** ("SUMMARY OF THE 2018
DEPARTMENT OF DEFENSE ARTIFICIAL INTELLIGENCE STRATEGY," Retrieved
6/12/2022 from
<https://media.defense.gov/2019/Feb/12/2002088963/-1/-1/1/SUMMARY-OF-DOD-AI-STRATEGY.PDF>.)

Evolving international alliances and partnerships. [[An extended network
of **mutually beneficial alliances** and partnerships provides a
**durable means of overcoming global AI challenges**, deterring
aggression, and supporting stability through cooperation. **Foreign
allies**]{.underline}]{.mark} and partners [[offer critical perspectives
and talent **that can be leveraged**]{.underline}]{.mark} through
personnel exchanges, combined portfolio planning, [[and the deepened
interoperability and trust that comes from collaborative AI development
and deployment]{.underline}.]{.mark}

### Solvency -- China/Russia Counterweight

#### American leadership in AI is necessary to reclaim the global AI leadership position from China.

Christie **Lawrence &** Sean **Cordey,** 20**20**, (Belfer Center for
Science and International Affairs, Harvard Kennedy School, "The Case for
Increased Transatlantic Cooperation on Artificial Intelligence,"
<https://www.belfercenter.org/publication/case-increased-transatlantic-cooperation-artificial-intelligence>,
Retrieved 6/12/2022)

United States: [[The U]{.underline}]{.mark}nited
[[S]{.underline}]{.mark}tates [[views American leadership in AI as
necessary to]{.underline}]{.mark} safeguard American values and
[[maintain defense and economic superiority. Recognizing the need
to]{.underline}]{.mark} develop a national AI approach and **[[reclaim
the AI R&D global leadership position from China]{.underline}]{.mark}**,
which had already surpassed the US in several research output metrics by
2016,10 the Obama Administration developed an AI R&D prioritization in
October 2016.11 Building on this urgency, the Trump Administration has
prioritized AI and established the American AI Initiative in February
2019.12 This Initiative identified the need for a whole-of-government
approach to prioritize AI R&D and deployment throughout the entire
federal government. The Initiative also identifies [[the need to grow
the US AI workforce, set national and global norms and standards, and
work with industry and allies to promote an AI environment favorable to
the U]{.underline}]{.mark}nited [[S]{.underline}]{.mark}tates.13

#### A unifying strategy with European allies is necessary to provide a counter-weight to Chinese and Russian AI military innovation.

Lena **Trabucco,** 10/5/20**20** (Research Assistant at the Centre for
Military Studies at the University of Copenhagen, "AI Partnership for
Defense is a Step in the Right Direction -- But Will Face Challenges,"
<http://opiniojuris.org/2020/10/05/ai-partnership-for-defense-is-a-step-in-the-right-direction-but-will-face-challenges/>,
Retrieved 6/14/2022)

Few solutions have been offered to the US for maneuvering Europe's
competing visions for military AI, and how to effectively court hesitant
European nations. And the current absence of Germany from the AI
partnership suggests the US still hasn't figured it out. [[If the goal
is to expand the partnership **as a counter-weight** to Chinese and
Russian AI military innovation, then the US will have to address the
foundational differences that some European allies have regarding the
role of military AI in order to **bring the partnership under a unifying
strategy**]{.underline}]{.mark}.

## Case -- AI Leadership Advantage 

### UQ -- US is losing AI Arms Race to China

#### The US is losing the AI arms race to China.

Benjamin **Boudreaux,** 1/11/20**19** (professor at the Pardee RAND
Graduate School, "Does the U.S. Face an AI Ethics Gap?"
[https://www.realcleardefense.com/articles/2019/01/11/
does_the_us_face_an_ai_ethics_gap_114095.html](https://www.realcleardefense.com/articles/2019/01/11/%20does_the_us_face_an_ai_ethics_gap_114095.html),
Retrieved 6/12/2022)

[[Members of Congress, the U.S. military, and prominent technologists
have raised the alarm that **the U.S. is at risk of losing
an**]{.mark}]{.underline} Artificial Intelligence ([[**AI) arms race**.
China already has leveraged strategic investment and
planning]{.mark},]{.underline} access to massive data, [[and suspect
business practices to surpass the U.S. in some aspects of AI
implementation. There are worries that this **competition could extend
to the military sphere**]{.underline}]{.mark} with serious consequences
for U.S. national security.

#### China is catching the US in the AI field.

John R. **Allen**, 3/24/20**21** (President of the Brookings
Institution, "It is time to negotiate global treaties on artificial
intelligence,"
<https://www.brookings.edu/blog/techtank/2021/03/24/it-is-time-to-negotiate-global-treaties-on-artificial-intelligence/>,
Retrieved 6/15/2022)

The U.S. National Security Commission on Artificial Intelligence
recently made the news when its members warned that [[America faces a
national security crisis due to insufficient investment in
a]{.underline}]{.mark}rtificial [[i]{.underline}]{.mark}ntelligence and
emerging technologies. Commission Vice Chair Robert Work argued "we
don't feel this is the time for incremental budgets ... This will be
expensive and requires significant change in the mindset at the
national, and agency, and Cabinet levels." Commission Chair Eric Schmidt
extended those worries by saying "[[**China is catching the US**" and
"competition with China will increase]{.underline}."]{.mark}

### UQ -- NATO Faces Global AI Tech Race

#### The US & China are engaged in an AI arms race that will determine the future balance of power.

Rod **Thornton,** 6/17/20**19** (Senior Lecturer in the Centre for
Defence Education Research and Analysis, UK Defence Academy/Defence
Studies Department, King's College London, "One to ponder: the UK's
ethical stance on the use of Artificial Intelligence in weapons
systems," [https://defenceindepth.co/2019/06/17/
one-to-ponder-the-uks-ethical-stance-on-the-use-of-artificial-intelligence-in-weapons-systems/](https://defenceindepth.co/2019/06/17/%20one-to-ponder-the-uks-ethical-stance-on-the-use-of-artificial-intelligence-in-weapons-systems/),
Retrieved 6/12/2022)

[[Among the world's major states **an AI arms race is underway**. The US
and China,]{.mark}]{.underline} with their huge spending on AI and with
their ability to draw on the expertise of indigenous high-tech firms
(such as Google, Amazon, Huawei, Tencent, etc), [[**are way ahead** of
other states in the development of AI systems for their militaries. They
understand that to be left behind in such development risks
facing]{.underline}]{.mark} not just battlefield disadvantage but also
[[actual strategic defeat. Weapons based on AI have the potential to
become even more powerful than nuclear weapons]{.underline}]{.mark}. One
Russian source, for instance, sees a future 'Third Word War' being won
'within seconds' by using AI-enabled cyber warfare. As Vladimir Putin
has said on several occasions, '[[whoever becomes the leader in this
\[AI\] sphere will become **ruler of the world'.**]{.underline}]{.mark}

#### NATO faces a global AI tech race.

Edward Hunter **Christie,** 11/24/20**20** (Deputy Head of the
Innovation Unit, Emerging Security Challenges Division @ NATO,
"Artificial Intelligence at NATO: dynamic adoption, responsible use,"
Retrieved June 12, 2022 from
<https://www.nato.int/docu/review/articles/2020/11/24/artificial-intelligence-at-nato-dynamic-adoption-responsible-use/index.html>)

As noted in the first article in this series on innovation at
[[NATO]{.underline}]{.mark}, the Alliance [[faces a global
tech]{.underline}]{.mark}nology [[adoption race. Rival powers are
leveraging new tech]{.underline}]{.mark}nologies [[to pursue the dual
goal of greater economic competitiveness alongside greater military
capabilities. **The Allies face a range of challenges** as they seek to
exploit emerging]{.mark} and disruptive
[tech]{.mark}]{.underline}nologies. These challenges are based on two
interrelated pillars of work: ensuring a dynamic adoption of new
technologies and governing them responsibly. Artificial Intelligence
([[**AI) is at the heart** of these considerations]{.underline}]{.mark}.

### IL -- Competitors in AI Undermine LIO

#### Competitors investments in AI threaten to destabilize the international liberal order.

**D**EPARTMENT **O**F **D**EFENSE, 2/12/20**19** ("SUMMARY OF THE 2018
DEPARTMENT OF DEFENSE ARTIFICIAL INTELLIGENCE STRATEGY," Retrieved
6/12/2022 from
<https://media.defense.gov/2019/Feb/12/2002088963/-1/-1/1/SUMMARY-OF-DOD-AI-STRATEGY.PDF>.)

Thoughtful, responsible, and [[human-centered adoption of AI in the
D]{.underline}]{.mark}epartment [[o]{.underline}]{.mark}f
[[D]{.underline}]{.mark}efense [[has the potential to strengthen our
national security and transform the speed and agility of our operations.
Our adversaries]{.underline}]{.mark} and competitors [[are aggressively
working to define the future of these powerful technologies according to
their interests,]{.underline}]{.mark} values, and societal models.
[[Their investments threaten to erode U.S. military advantage,
**destabilize the free and open international order**, and challenge our
values and traditions]{.underline}]{.mark} with respect to human rights
and individual liberties.

### IL -- Tech Key to US Heg

#### The US will use new technology to cement its hegemonic lead in international relations.

Matthew **Kroenig, 2021** (Professor in the Department of Government and
the Edmund A. Walsh School of Foreign Service at Georgetown University,
"Will Emerging Technology Cause Nuclear War?: Bringing Geopolitics Back
In,"
<https://www.airuniversity.af.edu/Portals/10/SSQ/documents/Volume-15_Issue-4/D-Kroenig.pdf>,
Retrieved 6/15/2022)

In emphasizing the divergent positions of the United States of America
and its nuclear- armed rivals in the international system, this article
also contributes to a growing body of literature that takes seriously
hierarchy in international relations theory.9 [[The
U]{.underline}]{.mark}nited [[S]{.underline}]{.mark}tates, the
international sys¬tem's leader for the past several decades, [[is likely
to use new tech]{.underline}]{.mark}nology [[to **reinforce its
advantageous position** within the existing international order. China
and Russia will most likely employ new tech]{.mark}nology [in bids to
**erode America's privileged position**]{.mark}]{.underline}. Analyses
not grounded in an understanding of these states' different positions in
the prevailing international order risk overlooking this important
source of variation in conflict behavior and nuclear-escalation
dynamics. This framing of the problem leads to a different set of policy
implica-tions. [[The U]{.underline}]{.mark}nited
[[S]{.underline}]{.mark}tates [[and its Allies]{.underline}]{.mark} [and
partners [must retain]{.mark}]{.underline} second- strike capabilities,
preserve [[current power distributions, maintain an in-novation edge,
and prevent the proliferation of destabilizing military technologies to
revisionist powers]{.underline}]{.mark}.

### IL -- AI Co-op Solves ILO

#### International AI Cooperation bolsters the liberal international order.

Christie **Lawrence &** Sean **Cordey,** 20**20**, (Belfer Center for
Science and International Affairs, Harvard Kennedy School, "The Case for
Increased Transatlantic Cooperation on Artificial Intelligence,"
<https://www.belfercenter.org/publication/case-increased-transatlantic-cooperation-artificial-intelligence>,
Retrieved 6/12/2022)

Health-related joint R&D is already a top priority within existing EU-US
S&T collaboration and benefits from a reciprocal funding agreement
between the US NIH and the EU.42 Covid-19 and prioritization by both the
US and the EU to develop AI applications for healthcare further the
potential for stronger US-EU AI collaboration in this sector. The
environmental sciences sector similarly benefits from preexisting strong
transatlantic collaboration and increased focus for AI-related research.
The EU's focus on developing a "European Green New Deal" will only raise
the importance and quantity of European R&D in this field.43 [[Greater
defense-related AI cooperation is increasingly viewed as an imperative
by the US, with the DOD]{.underline}]{.mark} Artificial Intelligence
Strategy [[highlighting the need for international AI cooperation to
"**safeguard a free and open international
order.**"]{.underline}]{.mark}44 Recent positive visits and
collaboration between the JAIC, NATO, and European allies indicate AI
collaboration in the defense sector will grow.45

### Solvency -- AI Leadership Solves

#### NATO is a unique position to win the international tech race.

Rob **Murray,** 9/1/20**20** (head of the Innovation Unit in NATO's
Emerging Security Challenges Division, "Building a resilient innovation
pipeline for the Alliance," Retrieved 6/12/2022 from
[https://www.nato.int/docu/review/articles/
2020/09/01/building-a-resilient-innovation-pipeline-for-the-alliance/index.html](https://www.nato.int/docu/review/articles/%202020/09/01/building-a-resilient-innovation-pipeline-for-the-alliance/index.html))

[[**The Alliance's transatlantic nature places it in a unique position**
within the international order to provide both demand-side policies and
supply-side resources that can genuinely build such a pipeline, creating
not only innovations but entirely new markets]{.underline}]{.mark} -- as
Eisenhower noted: the foundation of military strength is economic
strength. Recent history would suggest, [[the model of democracy and
Allied governments' willingness to make big bets on mission-oriented
technology does indeed create new markets and it is this
model]{.underline},]{.mark} underpinned by shared values, [[which will
be key to NATO's longer term success]{.underline}]{.mark}.

#### NATO's operationalization of AI ethics allows NATO to shape technological innovation against illiberal regimes.

Zoe Stanley-**Lockman, 2022** (Defense and Strategic Studies, Nanyang
Technological University, "NATO's Role in Responsible AI Governance in
Military Affairs," [https://www.oxfordhandbooks.com/view/
10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69](https://www.oxfordhandbooks.com/view/%2010.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69),
Retrieved 6/11/2022)

We explore how [[NATO can operationalize the debate around ethics and
values of military AI to garner coordination and continue progress
of]{.underline}]{.mark} EDT [[harmonization among
partners]{.underline}]{.mark}. Building on the theoretical discussion
from STS and military innovation literature above, [[the adoption of
tech]{.underline}]{.mark}nologies [[that reinforce values serves the
strategic interest of NATO to shape tech]{.underline}]{.mark}nological
[[innovation **against current waves of
illiberalism**.]{.underline}]{.mark}

### Solvency -- A2: China/Russia Say No

#### The technologically advanced democracies must come together to create effective norms for AI---crucial to get Russia and China on board.

John R. **Allen**, 3/24/20**21** (President of the Brookings
Institution, "It is time to negotiate global treaties on artificial
intelligence,"
<https://www.brookings.edu/blog/techtank/2021/03/24/it-is-time-to-negotiate-global-treaties-on-artificial-intelligence/>,
Retrieved 6/15/2022)

That said, [[there are increasingly calls for the technologically
advanced democracies to **come together to aggregate their capacities**,
as well as leveraging their accumulated moral strength, to **create the
norms and ethical behaviors** essential to governing the applications of
AI]{.underline}]{.mark} and other technologies. [[Creating a reservoir
of humanitarian commitment among the democracies will be **vital to
negotiating from a position of moral strength with the Chinese,
Russians,** and other authoritarian states whose views on the future of
AI vary dramatically from ours]{.underline}.]{.mark}

## Case -- Conflict Resolution Advantage 

### Solvency -- AI Solves Conflict Resolution

#### Building AI safety is necessary to develop countermeasures against enemy attacks.

Zoe Stanley-**Lockman, 2022** (Defense and Strategic Studies, Nanyang
Technological University, "NATO's Role in Responsible AI Governance in
Military Affairs," [https://www.oxfordhandbooks.com/view/
10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69](https://www.oxfordhandbooks.com/view/%2010.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69),
Retrieved 6/11/2022)

Mitigating these types of risks is typically done in testing,
evaluation, validation and verification (TEVV) and in experimentation
activities.92 Yet AI cannot be validated and verified the way
traditional software systems are because there is no guarantee that an
AI system will perform in the real world as it does in a testing
environment, and because lifelong-learning systems will perform
differently over their lifecycle. Having robust assurance and TEVV
processes in place are also important for operators to build trust in
the systems they are meant to use, as well as for citizenries and
coalition partners at large to see that accountability procedures still
apply. As such, [[building institutional procedures to govern AI safety
and security is necessary to build trust in the use of the
tech]{.underline}]{.mark}nology---[[as well as to **develop
countermeasures** and defensive systems that **protect against
adversarial threats**.]{.underline}]{.mark}

### Solvency -- AI Integration Solves Nuclear Stability

#### US and allied leadership in new technology enhances nuclear strategic stability.

Matthew **Kroenig, 2021** (Professor in the Department of Government and
the Edmund A. Walsh School of Foreign Service at Georgetown University,
"Will Emerging Technology Cause Nuclear War?: Bringing Geopolitics Back
In,"
<https://www.airuniversity.af.edu/Portals/10/SSQ/documents/Volume-15_Issue-4/D-Kroenig.pdf>,
Retrieved 6/15/2022)

The next section provides a novel framework, grounded in the prevail¬ing
geopolitical context, for understanding how new technology might affect
nuclear strategic stability. Namely, [[the spread of new
tech]{.underline}]{.mark}nology [[to the U]{.underline}]{.mark}nited
[[S]{.underline}]{.mark}tates [[and its Allies]{.underline}]{.mark} and
partners---[[status quo powers at the core of the existing international
system---will tend to **shore up sources of strategic stability**.
Conversely, the spread of new tech]{.underline}]{.mark}nology [[to
revisionist powers China and Russia **presents the greatest risk of
conventional con¬flict that might escalate and threaten nuclear
strategic stability**]{.mark}**.**]{.underline}

#### Integration of AI into military systems can affect crisis stability and nuclear weapons.

Michael C. **Horowitz, 2018** (Professor at the University of
Pennsylvania, "Artificial Intelligence, International Competition, and
the Balance of Power," Retrieved 6/11/2022 from
<https://tnsr.org/2018/05/artificial-intelligence-international-competition-and-the-balance-of-power/>)

From a research perspective, one limitation of this article is its focus
on the balance of power and international competition, as opposed to
specific uses of AI. Future research could investigate particular
implementations of AI for military purposes or other critical questions.
Specific implementations could include the use of autonomous weapon
systems able to select and engage targets on their own. These systems
could raise ethical and moral questions about human control,116 as well
as practical issues surrounding war that is fought at "machine
speed."117 [[The integration of AI into early-warning systems and its
ability to aid in rapid targeting **could also affect crisis stability
and nuclear weapons**]{.underline}]{.mark}.118 In the broader security
realm, AI will affect human security missions.119 By laying out an
initial framework for how military applications of narrow AI could
structure international competition and the balance of power, this
article lays the groundwork for thinking through these questions in the
future.

## Case -- Add-Ons

### Democracy Add-On -- 2AC

#### Transatlantic AI cooperation is necessary to bolster democratization.

Christie **Lawrence &** Sean **Cordey,** 20**20**, (Belfer Center for
Science and International Affairs, Harvard Kennedy School, "The Case for
Increased Transatlantic Cooperation on Artificial Intelligence,"
<https://www.belfercenter.org/publication/case-increased-transatlantic-cooperation-artificial-intelligence>,
Retrieved 6/12/2022)

The Case for Transatlantic Cooperation There are three critical,
interconnected arguments for **[[transatlantic cooperation to ensure AI
innovation protects the security]{.underline}]{.mark}**, values, and
economic [[**interests** of the U]{.underline}]{.mark}nited
[[S]{.underline}]{.mark}tates [[and the E]{.underline}]{.mark}uropean
[[U]{.underline}]{.mark}nion. 1.Global Good: Transatlantic AI
partnerships and cooperation encourages innovation and applications that
enhance human welfare, strengthen the economies of the US and the EU,
and advance global security. 2.Great Power Competition: [[US-EU
leadership of like-minded nations is needed in this age of great power
competition to **tip the scales against efforts** by authoritarian
governments]{.underline}]{.mark}---particularly, China and
Russia---**[[to undermine democracies]{.underline}]{.mark}**. 3.Shared
Values: The US and the EU share fundamental values and would benefit
from joint efforts to establish AI norms that would more effectively
advance their common vision of AI and ripple throughout the global AI
ecosystem. Although the US consistently sounds the alarm bells around
China's AI aspirations and the EU urges international efforts against AI
that violates fundamental rights, increasingly noting China's actions
with concern,8 little concrete international action has taken place.
[[The U]{.underline}]{.mark}nited [[S]{.underline}]{.mark}tates
[[and]{.underline}]{.mark} the [[E]{.underline}]{.mark}uropean
[[U]{.underline}]{.mark}nion[['s]{.mark} [ongoing reassessment of their
respective AI strategies]{.mark}]{.underline} and legislation9
[[**provides a window of opportunity** to align and collaborate.
Transatlantic AI cooperation is at a critical juncture and the
U]{.underline}]{.mark}nited [[S]{.underline}]{.mark}tates
[[and]{.underline}]{.mark} the [[E]{.underline}]{.mark}uropean
[[U]{.underline}]{.mark}nion [[should seize this opportunity to take
concrete actions]{.underline}.]{.mark}

#### Preserving democracy is the [only way]{.underline} to avert [existential catastrophe.]{.underline}

Noam **Chomsky,** 5/27/20**19** (American linguist, philosopher,
cognitive scientist, historian, social critic, and political activist.
Sometimes called \"the father of modern linguistics\", Chomsky is also a
major figure in analytic philosophy and one of the founders of the field
of cognitive science, "Chomsky: Nuclear Weapons, Climate Change & the
Undermining of Democracy Threaten Future of Planet,"
[https://www.democracynow.org/2019/5/27/
chomsky_nuclear_weapons_climate_change_the](https://www.democracynow.org/2019/5/27/%20chomsky_nuclear_weapons_climate_change_the),
Retrieved 8/4/2021)

NOAM CHOMSKY: I want to make a couple of remarks below about the severe
difficulty of maintaining and instituting democracy, the powerful forces
that have always opposed it, the achievements of somehow salvaging and
enhancing it, and the significance of that for the future. But first, a
couple of words about the challenges that we face, which you heard
enough about already and you all know about. I don't have to go into
them in detail. To describe these challenges as "extremely severe" would
be an error. The phrase does not capture the enormity of the kinds of
challenges that lie ahead. And any serious discussion of the future of
humanity must begin by recognizing a critical fact, that [[the human
species is now facing a question]{.underline}]{.mark} that has never
before arisen in human history, question that has to be answered
quickly: [[Will human society survive for long?]{.mark}]{.underline}
Well, as you all know, for 70 years we've been living under [[**the
shadow of nuclear war**. Those who have looked at the record can only be
amazed that we've survived this far.]{.underline}]{.mark} Time after
time it's come extremely close to terminal disaster, even minutes away.
It's kind of a miracle that we've survived. Miracles don't go on
forever. This has to be terminated, and quickly. The recent Nuclear
Posture Review of the Trump administration dramatically increases the
threat of conflagration, which would in fact be terminal for the
species. We may remember that this Nuclear Posture Review was sponsored
by Jim Mattis, who was regarded as too civilized to be retained in the
administration---gives you a sense of what can be tolerated in the
Trump-Pompeo-Bolton world. Well, there were three major arms treaties:
the ABM Treaty, Anti-Ballistic Missile Treaty; the INF Treaty,
Intermediate Nuclear Forces; the New START treaty. The U.S. pulled out
of the ABM Treaty in 2002. And anyone who believes that anti-ballistic
missiles are defensive weapons is deluded about the nature of these
systems. The U.S. has just pulled out of the INF Treaty, established by
Gorbachev and Reagan in 1987, which sharply reduced the threat of war in
Europe, which would very quickly spread. The background of that signing
of that treaty was the demonstrations that you just saw depicted on the
film. Massive public demonstrations were the background for leading to a
treaty that made a very significant difference. It's worth remembering
that and many other cases where significant popular activism has made a
huge difference. The lessons are too obvious to enumerate. Well, the
Trump administration has just withdrawn from the INF Treaty; the
Russians withdrew right afterwards. If you take a close look, you find
that each side has a kind of a credible case saying that the opponent
has not lived up to the treaty. For those who want a picture of how the
Russians might look at it, the Bulletin of Atomic Scientists, the major
journal on arms control issues, had a lead article a couple weeks ago by
Theodore Postol pointing out how dangerous the U.S. installations of
anti-ballistic missiles on the Russian border---how dangerous they are
and can be perceived to be by the Russians. Notice, on the Russian
border. Tensions are mounting on the Russian border. Both sides are
carrying out provocative actions. We should---in a rational world, what
would happen would be negotiations between the two sides, with
independent experts to evaluate the charges that each is making against
the other, to lead to a resolution of these charges, restore the treaty.
That's a rational world. But it's unfortunately not the world we're
living in. No efforts at all have been made in this direction. And they
won't be, unless there is significant pressure. Well, that leaves the
New START treaty. The New START treaty has already been designated by
the figure in charge, who has modestly described himself as the greatest
president in American history---he gave it the usual designation of
anything that was done by his predecessors: the worst treaty that ever
happened in human history; we've got to get rid of it. If in fact---this
comes up for renewal right after the next election, and a lot is at
stake. A lot is at stake in whether that treaty will be renewed. It has
succeeded in very significantly reducing the number of nuclear weapons,
to a level way above what they ought to be but way below what they were
before. And it could go on. Well, meanwhile, [[**global warming**
proceeds on its inexorable course]{.underline}]{.mark}. During this
millennium, every single year, with one exception, has been hotter than
the last one. There are recent scientific papers, James Hansen and
others, which indicate that the pace of global warming, which has been
increasing since about 1980, may be sharply escalating and may be moving
from linear growth to exponential growth, which means doubling every
couple of decades. We're already approaching the conditions of 125,000
years ago, when the sea level was about roughly 25 feet higher than it
is today, with the melting, the rapid melting, of the Antarctic, huge
ice fields. We might---that point might be reached. The consequences of
that are almost unimaginable. I mean, I won't even try to depict them,
but you can figure out quickly what that means. Well, meanwhile, while
this is going on, you regularly read in the press euphoric accounts of
how the United States is advancing in fossil fuel production. It's now
surpassed Saudi Arabia. We're in the lead of fossil fuel production. The
big banks, JPMorgan Chase and others, are pouring money into new
investments in fossil fuels, including the most dangerous, like Canadian
tar sands. And this is all presented with great euphoria, excitement.
We're now reaching energy independence. We can control the world,
determine the use of fossil fuels in the world. Barely a word on what
the meaning of this is, which is quite obvious. It's not that the
reporters, commentators don't know about it, that the CEO of the banks
don't know about it. Of course they do. But these are kind of
institutional pressures that just are extremely hard to extricate
themselves from. You can put yourself in the---try to put yourself in
the position of, say, the CEO of JPMorgan Chase, the biggest bank, which
is spending large sums in investment in fossil fuels. He certainly knows
everything that you all know about global warming. It's no secret. But
what are the choices? Basically he has two choices. One choice is to do
exactly what he's doing. The other choice is to resign and be replaced
by somebody else who will do exactly what he's doing. It's not an
individual problem. It's an institutional problem, which can be met, but
only under tremendous public pressure. And [[we've recently
seen]{.underline}]{.mark}, very dramatically, how it can---[[how the
solution can be reached]{.underline}]{.mark}. A group of young people,
Sunrise Movement, organized, got to the point of sitting in in
congressional offices, aroused some interest from the new progressive
figures who were able to make it to Congress. Under a lot of popular
pressure, Alexandria Ocasio-Cortez, joined by Ed Markey, actually placed
the Green New Deal on the agenda. That's a remarkable achievement. Of
course, it gets hostile attacks from everywhere: It doesn't matter. A
couple of years ago it was unimaginable that it would be discussed. As
the result of the activism of this group of young people, it's now right
in the center of the agenda. It's got to be implemented in one form or
another. It's essential for survival, maybe not in exactly that form,
but some modification of it. Tremendous change achieved by the
commitment of a small group of young people. That tells you the kind of
thing that can be done. Meanwhile, the Doomsday Clock of the Bulletin of
Atomic Scientists last January was set at two minutes to midnight.
That's the closest it's been to terminal disaster since 1947. The
announcement of the settlement---of the setting mentioned [[the two
major familiar threats: the **threat of nuclear war**, which is
increasing, **threat of global warming**, which is increasing further.
And it added a third for the first time: the **undermining of
democracy**. That's the third threat, along with global warming and
nuclear war]{.underline}]{.mark}. And that was quite appropriate,
because [[functioning democracy offers **the only hope** of overcoming
these threats. They are not going to be dealt with by major
institutions]{.underline}]{.mark}, state or private, acting [[without
massive public pressure, which means that the means of democratic
functioning have to be kept alive]{.underline}]{.mark}, used the way the
Sunshine Movement did it, the way the great mass demonstration in the
early '80s did it, and the way we continue today.

### Democracy Add-On -- Solves War

#### The best and newest studies verify the link between democratization and peace:

Kosuke **Imai 20**, PhD in Political Science @ Harvard, Professor in the
Department of Government and the Department of Statistics at Harvard
University, "Robustness of Empirical Evidence for the Democratic Peace:
A Nonparametric Sensitivity Analysis",
https://imai.fas.harvard.edu/research/files/dempeace.pdf

Abstract **[[The democratic peace]{.underline}]{.mark}**---the idea
[[that democracies rarely fight one another]{.underline}]{.mark}---
[[has been called "**the closest thing we have to an empirical law** in
the study of i]{.underline}]{.mark}nternational
[[r]{.underline}]{.mark}elations." Yet, some contend that this
relationship is spurious and suggest alternative explanations.
Unfortunately, in the absence of randomized experiments, we can never
rule out the possible existence of such confounding biases. Rather than
commonly used regression-based approaches, we apply a nonparametric
sensitivity analysis. [[We show that overturning the negative
association between democracy and conflict would require a confounder
that is **forty-seven times** more prevalent in democratic dyads than in
other dyads]{.underline}]{.mark}. To put this number in context, [[the
relationship between **democracy and peace** is at least **five times as
robust** as that between **smoking and lung
cancer**]{.underline}]{.mark}. To explain away the democratic peace,
therefore, scholars would have to find far more powerful confounders
than those already identified in the literature.

### NATO Add-On -- 2AC

#### Adapting to emerging AI technologies is key to keeping NATO as a relevant institution.

Zoe Stanley-**Lockman, 2022** (Defense and Strategic Studies, Nanyang
Technological University, "NATO's Role in Responsible AI Governance in
Military Affairs," [https://www.oxfordhandbooks.com/view/
10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69](https://www.oxfordhandbooks.com/view/%2010.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69),
Retrieved 6/11/2022)

**[[New power distributions around AI]{.underline}]{.mark}** and
adjacent dual-use technologies [[are among the motivating factors
causing the Alliance to reconsider whether its
tech]{.underline}]{.mark}nological [[superiority may be threatened in
the years ahead,]{.mark}]{.underline} as reflected in the 2019 Emerging
and Disruptive Technologies (EDTs) Roadmap2 and, more recently, the NATO
2030 process.3 NATO navigates these changes and then approaches
AI-accelerated changes to the international security environment in a
highly political context. Notably, in 2019, French President Emmanuel
Macron surprised many European counterparts by declaring NATO
"brain-dead," a warning wrapped in an even larger warning of
trans-Atlantic security divisions.4 The critique that NATO is a
"brain-dead" or "irrelevant" institution has existed in some form since
the end of the Cold War.5 [**[As NATO combats global perceptions
of]{.mark}** organizational [**irrelevance**, there is a reason to
**push for bureaucratic adaptation to better manage
tech**]{.mark}]{.underline}nology-[[**driven changes** in the
future]{.underline}]{.mark}. As such, despite some warnings to the
contrary, [[Allies have an incentive to keep NATO a relevant military
institution and ensure that it **adapts to emerging threats** and for
future military contexts]{.underline}]{.mark}. The comment from
President Macron helped prompt the NATO 2030 agenda, which is currently
taking shape to increase the Alliance's role as a political actor and as
an organization with a greater focus on EDTs.6

#### Strong NATO solves nuclear war

**Beauchamp '18** (Zack Beauchamp, senior reporter at Vox, where he
covers global politics and ideology, and a host of Worldly, Vox\'s
podcast on covering foreign policy and international relations, "How
Trump is killing America's alliances", Vox,
<https://www.vox.com/world/2018/6/12/17448866/trump-south-korea-alliance-trudeau-g7>,
2018)

How the [[weakening]{.underline}]{.mark} of [[American alliances could
lead to a massive war]{.mark}**.**]{.underline} [There has **never, in
human history, been an era as peaceful as our own**]{.underline}. This
is a hard truth to appreciate, given the horrible violence ongoing in
places like Syria, Yemen, and Myanmar, yet [the evidence is **quite
clear.**]{.underline} Take a look at this chart from the University of
Oxford's Max Roser. It tracks the number of years in a given time period
in which "great powers" --- meaning the militarily and economically
powerful countries at that time --- were at war with each other over the
course of the past 500 years. The decline is unmistakable: \[\[TABLE
OMITTED\]\] This data should give you some appreciation for how unique,
and potentially precarious, our historical moment is. For more than 200
years, from 1500 to about 1750, major European powers like Britain and
France and Spain were warring constantly. The frequency of conflict
declined in the 19th and 20th centuries, but the wars that did break out
--- the Napoleonic conflicts, both world wars --- were particularly
devastating. The past 70 years without great power war, a period
scholars term "the Long Peace," is one of history's most wonderful
anomalies. The question then becomes: Why did it happen? And could Trump
mucking around with a pillar of the global order, American alliances,
put it in jeopardy? The answer to the second question, ominously,
appears to be yes. [[There is significant evidence that strong]{.mark}
**American** [alliances]{.mark} --- [most notably]{.mark} **the**
[NATO]{.mark} alliance and US agreements to defend Japan and South Korea
---]{.underline} [[have been **instrumental in putting an end to great
power war**]{.mark}**.**]{.underline} "[As [this alliance system]{.mark}
spreads and expands, it [correlates with]{.mark} this dramatic decline,
this **[unprecedented drop, in warfare]{.mark}**]{.underline}," says
Michael Beckley, a professor of international relations at Tufts
University. "[It's a really, really strong correlation]{.underline}." A
2010 study by Rice's Leeds and the University of Kentucky's Jesse C.
Johnson surveyed a large data set on alliances between 1816 and 2000.
They found that [countries in defensive alliances were **20 percent less
likely**]{.underline} [to be involved in a conflict, on average, than
countries that weren't]{.underline}. This holds true even after you
control for other factors that would affect the likelihood of war, like
whether a country is a democracy or whether it has an ongoing dispute
with a powerful neighbor. In a follow-up paper, Leeds and Johnson looked
at the same data set to see whether certain kinds of alliances were more
effective at protecting its members than others. Their conclusion is
that alliances deter war best when their members are militarily powerful
and when enemies take seriously the allies' promise to fight together in
the event of an attack. The core US alliances --- NATO, Japan, and South
Korea --- fit these descriptors neatly. A third study finds evidence
that [alliances allow allies to **restrain each other** from going to
war]{.underline}. Let's say Canada wants to get involved in a conflict
somewhere. Typically, it would discuss its plans with the United States
first --- and if America thinks it's a bad idea, Canada might well
listen to them. There's strong statistical evidence that countries don't
even try to start some conflicts out of fear that an ally would
disapprove. These three findings all suggest that NATO and America's
East Asian alliances very likely are playing a major role in preserving
the Long Peace --- which is why Trump's habit of messing around with
alliances is so dangerous. According to many Russia experts, Vladimir
Putin's deepest geostrategic goal is "breaking" NATO. The member states
where anyone would expect him to test NATO's commitment would be the
Baltics --- Estonia, Latvia, and Lithuania --- small former Soviet
republics that recently became NATO members. We can't predict if and
when a rival like Putin would conclude that America's alliances seemed
weak enough to try testing them. Hopefully, it never happens. But the
more Trump attacks the foundations of America's allies, the more likely
things are to change. [The absolute risk of a Russian invasion of a NATO
state or a North Korean attack on the South is relatively low, but
**[the consequences are]{.mark}** so potentially **[catastrophic ---
nuclear war!]{.mark}**]{.underline} [--- that it's worth **taking
anything that increases the odds of such a conflict
seriously.**]{.underline} The crack-up of the West? The world order is a
little like a game of Jenga. In the game, there are lots of small blocks
that interlock to form a stable tower. Each player has to remove a block
without toppling the tower. But each time you take out a block, the
whole thing gets a bit less stable. Take out enough blocks and it will
collapse. The international order works in kind of the same way. There
are lots of different interlocking parts --- the spread of democracy,
American alliances, nuclear deterrence, and the like --- that work
together to keep the global peace. But take out one block and the other
ones might not be strong enough to keep things together on their own. At
the end of the Cold War, British and French leaders worried that the
passing of the old order might prove destabilizing. In a January 1990
meeting, French President François Mitterrand told British Prime
Minister Margaret Thatcher that he feared a united Germany could seize
control of even more territory than Hitler. Some experts feared that in
the absence of the external Soviet threat, Western European powers might
go back to waging war with each other. Thankfully, those predictions
turned out to be wrong. There are multiple reasons for that, but one big
one --- one that also helped keep relations between other historical
enemies, like South Korea and Japan, peaceful --- is a shared
participation in US alliance networks. The US serves as the ultimate
security blanket, preventing these countries from having to build up
their own armaments and thus risk a replay of World War I. But if
American alliance commitments become and remain less credible, it's
possible this order could crack up. America's partners aren't stupid.
They understand that Trump is the product of deep forces in American
politics, and that his victory might not be a one-off. If they think
that this won't be the last "America First" president in modern history,
depending on America the way that they have in the past could quickly
become a nightmare. [The worst-case scenarios for a collapse in the US
alliance system are terrible. [Imagine **full**]{.mark}]{.underline}
[[**Japanese and German rearmament**, alongside **rapid-fire
prolif**]{.mark}eration of nuclear weapons. [Imagine a **crack-up of
NATO**]{.mark}, with **European powers at loggerheads** [while **Russia
gobbles up the Baltic states**]{.mark} and the **rest of
Ukraine**]{.underline}. [Imagine **[South Korea's historical tensions
with Japan reigniting]{.mark}**]{.underline}, **[[and a war between
those two countries]{.underline}]{.mark}** or any combination of them
and China. All of this seems impossible to imagine now, almost absurd.
And indeed, in the short run, it is. There is no risk --- zero --- of
American allies turning on each other in the foreseeable future. And
it's possible that the next president after Trump could reassure
American allies that nothing like this could ever happen again. But the
truth is that there's just no way to know. [When a fundamental force for
world peace starts to weaken, no one can really be sure how well the
system will hold up. Nothing like this --- the leader of the world's
hegemon rounding on its most important allies --- has ever happened
before.]{.underline} What Donald Trump's presidency has done, in effect,
is start up another geopolitical Jenga game. Slowly but surely, he's
removing the blocks that undergird global security. It's possible the
global order survives Trump --- but it's just too early for us to say
for sure. **[Given the stakes, it's a game we'd rather not
play.]{.underline}**

### NATO Add-On -- Plan Bolsters NATO

#### Legal interoperability in AI is crucial to future NATO operations.

Zoe Stanley-**Lockman, 2022** (Defense and Strategic Studies, Nanyang
Technological University, "NATO's Role in Responsible AI Governance in
Military Affairs," [https://www.oxfordhandbooks.com/view/
10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69](https://www.oxfordhandbooks.com/view/%2010.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69),
Retrieved 6/11/2022)

[[One vital and unique contribution for NATO is facilitating legal
interoperability among the Allies to resolve some of the most pressing
legal barriers for AI implementation in future Allied operations. Legal
interoperability]{.mark},]{.underline} a subset of larger coalition
interoperability, [[refers to the operational coordination around
partner legal obligations and interpretations]{.underline}]{.mark}.75
[[It ensures "that within a military alliance, military operations can
be conducted effectively consistent with the legal obligations of each
nation]{.underline}]{.mark}."76 [[Legal interoperability is a critical
component of multilateral operations]{.underline}]{.mark} that has thus
far been under-examined, despite [**[its centrality to successful
military operations]{.underline}**.]{.mark} This is largely because
"[[legal factors have a bearing on everything in alliances and coalition
operations]{.underline}]{.mark}---from determining basic 'troop-to-task'
considerations to decisions regarding the targets to be engaged---and
the types of ordinances that may be used."77

#### Interoperability on AI is key to respond to threats that would undermine NATO.

CENTER FOR **E**UROPEAN **P**OLICY **A**NALYSIS, 2/17/20**21** ("NATO
Leadership on Ethical AI is Key to Future Interoperability,"
<https://cepa.org/nato-leadership-on-ethical-ai-is-key-to-future-interoperability/>.,
Retrieved 6/15/2022)

[[If individual nations]{.mark} or groups [are left to develop their own
ethical principles without wider alignment to NATO, the result will be a
number of AI-based systems with varying tech]{.mark}nical
[specifications based on the]{.mark} legal and policy [decisions made by
individual governments when answering the key
questions]{.mark}]{.underline}. As has been demonstrated in areas such
as facial recognition and policing algorithms, the assumptions made by
those developing the tools and answering the key questions have a
significant impact on the real-world functioning of the tool and
societal acceptance of its ethics. The risk of tools failing to gain
acceptance depends on the legal and ethical decisions made by
governments. For the military, this may mean one state using an AI-based
system that is seen as unacceptable by another, and in a joint operation
one state fielding a system that cannot be used by another. Or worse
yet, [[this could render a joint operation impossible. Without the
ability to interoperate across NATO, the inability to effectively and
efficiently respond to future threats would undermine the
Alliance]{.underline}]{.mark}.

#### Political oversight of AI operations adds legitimacy and military effectiveness to the alliance.

Zoe Stanley-**Lockman, 2022** (Defense and Strategic Studies, Nanyang
Technological University, "NATO's Role in Responsible AI Governance in
Military Affairs," [https://www.oxfordhandbooks.com/view/
10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69](https://www.oxfordhandbooks.com/view/%2010.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69),
Retrieved 6/11/2022)

The political dimension of the Alliance rests on the bedrock of a shared
commitment to the "principles of democracy, individual liberty and the
rule of law," as enshrined in the foundational North Atlantic Treaty of
1949.60 [[Shared values are important for NATO operations because they
help constitute their legitimacy]{.mark}.]{.underline} In addition to
the North Atlantic Council exerting civilian oversight over NATO
operations, legitimacy also includes respect for international legal
principles including the core principles of international humanitarian
law, or the laws of armed conflict, distinction, proportionality, and
necessity. [[Without **political oversight** and legitimacy, **NATO's
military power would be less effective** at shaping norms and promoting
stability in the international system. **The introduction of AI** means
that NATO has the moral and strategic imperative to adopt
tech]{.underline}]{.mark}nologies **[[that confer
legitimacy]{.underline}]{.mark}** and responsible innovation.61 [[Acting
on a shared commitment to democratic values is]{.underline}]{.mark}
vital to the political cohesion of the NATO Alliance, just as much as it
is [[**a determinant of military effectiveness**]{.underline}]{.mark} in
a predictable security environment.

#### AI is key to the speed and effectiveness of US military operations.

DEPARTMENT **O**F **D**EFENSE, 2/12/20**19** ("SUMMARY OF THE 2018
DEPARTMENT OF DEFENSE ARTIFICIAL INTELLIGENCE STRATEGY," Retrieved
6/12/2022 from
<https://media.defense.gov/2019/Feb/12/2002088963/-1/-1/1/SUMMARY-OF-DOD-AI-STRATEGY.PDF>.)

[[AI]{.mark}]{.underline} is rapidly changing a wide range of businesses
and industries. It [[is]{.underline}]{.mark} also [[poised to change the
character of the future battlefield and the pace of threats we must
face. We will harness the potential of AI to]{.underline}]{.mark}
transform all functions of the Department positively, [[thereby
supporting and protecting U.S. servicemembers]{.underline}]{.mark},
safeguarding U.S. citizens, defending allies and partners, [[and
improving the **affordability, effectiveness, and speed of our
operations**]{.underline}.]{.mark} The women and men in the U.S. armed
forces remain our enduring source of strength; we will use AI-enabled
information, tools, and systems to empower, not replace, those who
serve.

### North Korea Add-On -- 2AC

#### AI technology can lay the groundwork for nuclear arms control with North Korea.

Jessica **Cox, 2021** (Director of Nuclear Policy at NATO, "The
Unavoidable Technology: How Artificial Intelligence Can Strengthen
Nuclear Stability," WASHINGTON QUARTERLY)

Similarly, [[the work of open source intelligence
experts]{.underline}]{.mark}, such as the Open Nuclear Network of One
Earth Future,38 [[could be buttressed **by applying AI tech¬nology**
**that could recognize and analyze missile activity in North
Korea**]{.underline}]{.mark}. Arms control with North Korea still seems
unlikely as the Kim regime has not expressed an interest in
relinquishing its nuclear weapons, but in the meantime, [[improved
info]{.mark}rmation [about North Korea's nuclear activities and plans
can improve situa¬tional awareness and understanding of their nuclear
program]{.mark}]{.underline} and processes, **[[potentially providing
the groundwork for denuclearization and cooperative arms
control]{.underline}]{.mark}** at a later time. Human involvement would
still be essential to provide important contextual information, but
[[these developments might facili¬tate arms control verification by
identifying treaty-prohibited items or activities in record
time]{.underline}]{.mark} and provide convincing intelligence to the
international community.

#### North Korean nuclearization leads to extinction

Peter **Hayes, &** Michael Hamel-**Green, 2009** (Honorary Professor,
Center for International Security Studies & professor in social sciences
in the College of Arts at Victoria University Melbourne) The Path Not
Taken, The Way Still Open: Denuclearizing The Korean Peninsula And
Northeast Asia, Dec. 14, 2009. Retrieved Apr. 24, 2016 from
http://apjjf.org/-Peter-Hayes/3267/article.html

The consequences of failing to address the proliferation threat posed by
the [[North Korea]{.underline}]{.mark} developments, and related
political and economic issues, are serious, not only for the Northeast
Asian region but for the whole international community. [At worst,
[there is the possibility of nuclear attack, whether by intention,
miscalculation, or merely accident, leading to the resumption of Korean
War hostilities]{.mark}]{.underline}. On the Korean Peninsula itself,
key population centres are well within short or medium range missiles.
The whole of Japan is likely to come within North Korean missile range.
Pyongyang has a population of over 2 million, Seoul (close to the North
Korean border) 11 million, and Tokyo over 20 million. Even a limited
nuclear exchange would result in a holocaust of unprecedented
proportions. But [[the catastrophe within the region would not be the
only outcome. New research indicates that even a limited nuclear war in
the region would rearrange our global climate far more quickly than
global warming]{.underline}]{.mark}. Westberg draws attention to [[new
studies]{.underline}]{.mark} modelling the effects of even a limited
nuclear exchange involving approximately 100 Hiroshima-sized 15 kt
bombs2 (by comparison it should be noted that the United States
currently deploys warheads in the range 100 to 477 kt, that is,
individual warheads equivalent in yield to a range of 6 to 32
Hiroshimas).The studies [[indicate that the soot from the fires produced
would lead to a decrease in global temperature]{.mark} by 1.25 degrees
Celsius for a period of 6-8 years]{.underline}.3 In Westberg's view:
That is not global winter, but the nuclear darkness will cause a deeper
drop in temperature than at any time during the last 1000 years. The
temperature over the continents would decrease substantially more than
the global average. A decrease in rainfall over the continents would
also follow...The period of nuclear darkness will cause much greater
decrease in grain production than 5% and it will continue for many
years\...[[hundreds of millions of people will die from
hunger]{.underline}]{.mark}...[To make matters]{.underline} even [worse,
[such amounts of smoke injected into the stratosphere would cause a huge
reduction in the Earth's protective ozone]{.mark}]{.underline}.4 These,
of course, are not the only consequences. Reactors might also be
targeted, causing further mayhem and downwind radiation effects,
superimposed on a smoking, radiating ruin left by nuclear next-use.
Millions of refugees would flee the affected regions. The direct
impacts, and the follow-on impacts on the global economy via ecological
and food insecurity, could make the present global financial crisis pale
by comparison. [[How the great powers]{.underline}]{.mark}, especially
the nuclear weapons states [[respond]{.mark}]{.underline} to such a
crisis, [[and in particular, whether nuclear weapons are used in
response to nuclear first-use, could make or break the global non
prolif]{.mark}eration]{.underline} and disarmament
[[regimes]{.underline}.]{.mark} There could be many unanticipated
impacts on regional and global security relationships5, with subsequent
nuclear breakout and geopolitical turbulence, including possible
loss-of-control over fissile material or warheads in the chaos of
nuclear war, and aftermath chain-reaction affects involving other
potential proliferant states. [The Korean nuclear proliferation issue is
not just a regional threat but a global one]{.underline} that warrants
priority consideration from the international community.

### North Korea Add-On -- Goes Nuclear

#### (\--) Risk of war with North Korea is the #1 foreign policy threat---miscalc is a particular scenario---prefer most recent evidence:

Scott A. **Snyder, 1/19**[/20]{.underline}**21** [(]{.underline}senior
fellow for Korea studies and director of the program on U.S.-Korea
policy at the Council on Foreign Relations (CFR), where he had served as
an adjunct fellow from 2008 to 2011, "Top Conflicts to Watch in 2021: A
North Korea Crisis,"
<https://www.cfr.org/blog/top-conflicts-watch-2021-north-korea-crisis>,
Retrieved 1/27/2021)

[As we turn the calendar on 2020 and embark on 2021, the incoming Joe
Biden administration faces no shortage of challenges. The priority areas
identified by his transition team include overcoming the pandemic,
reviving the economy, achieving racial justice, and addressing climate
change. Russia, China, and Iran have also been singled out as issues to
be addressed. However, [**the number one concern** identified in CFR's
annual Preventive Priorities Survey of **foreign policy experts** about
potential geopolitical risks to worry about in the coming
year]{.mark}---namely, **[a renewed crisis on the Korean
Peninsula]{.mark}**---has received scant attention in comparison. This
is surprising as the issue has hardly gone away---to the contrary, in
fact. President Obama warned President-elect Trump in November 2016 that
the most vexing international security threat he would face would
emanate from North Korea. [Two nuclear tests, myriad long-range missile
tests,]{.mark} and three Trump-Kim summits later, [the magnitude and
likelihood of North Korea posing a catastrophic threat to U.S. national
interests is greater than it was four years ago]{.mark}. Despite
President Trump's assertions that he averted a war with North Korea by
developing a close personal relationship with Kim Jong-un, Trump's
diplomacy appears to have only changed the tone of the relationship
while failing to address the underlying problems posed by North Korea's
ability to launch a nuclear strike on the U.S. mainland. [It is not
clear that Kim's self-restraint on long-range missile testing will
continue]{.mark}. At the Worker's Party of Korea (WPK) Eighth Party
Congress staged only days prior to the Biden administration's
inauguration, Kim characterized the United States as its "foremost
principal enemy," and criticized U.S. perceived "hostile policy" toward
North Korea despite North Korea's "good-will efforts." Military parades
staged in conjunction with the Eighth Party Congress and on the October
10, 2020, 75th anniversary of the WPK revealed that North Korea has
strengthened its conventional forces and has developed but not yet
tested several new types of missiles capable of delivering a nuclear
strike on the United States. While the Trump administration has left the
door open to diplomatic negotiations since a one-day meeting with North
Korean officials in Stockholm in October 2019, North Korea has refused
to come to the negotiating table. Meanwhile, Kim's 2018 summitry gambit
and accompanying economic hopes have turned to distress in the face of
ongoing sanctions, North Korea's COVID quarantine, and flooding from a
series of typhoons, putting even greater pressure on Kim to achieve an
economic breakthrough. North Korea's Eighth Party Congress addressed
these and other economic challenges while pledging to continue its
military development and promising to respond to "force with toughness"
and "good faith in kind." This was as close as Kim came during the
eight-day Party Congress to providing a signal of intent to open
negotiations with the Biden administration. In addition, [many analysts
expect North Korea to revert to]{.mark} its traditional playbook by
returning to [nuclear and missile tests as means by which to test new
leaders]{.mark} as Kim has previously done with Obama, Xi Jinping, Park
Geun-hye, and Trump. [North Korea's purpose in pursuing provocations
would be to push North Korea closer to the top of the Biden
administration's agenda]{.mark} by generating a crisis atmosphere and
shaping the space and prospects for diplomatic negotiations.
Anticipation of North Korean provocations is so high that analysts have
either rushed to recommend that Biden extend an early olive branch to
North Korea in an effort to forestall a crisis or speculated about how
to capitalize on a crisis to induce North Korea to return to
denuclearization negotiations. Regardless of whether Kim Jong-un is
motivated by domestic economic distress or the desire to redress
long-held international grievances, North Korea's insistence on
presenting itself as an entrenched nuclear weapons state remains at odds
with the longstanding U.S. policy and international security norms
upheld by the Nuclear Non-Proliferation Treaty. But [North Korea's
capabilities are]{.mark} also an undeniable reality and [an
international security threat that must be managed to avoid catastrophic
results. The Biden administration will need to devise a set of early
actions to]{.mark} reassure North Korea of its willingness to engage in
negotiations, [reduce the risk of North Korean miscalc]{.mark}ulation,
and forestall likely attention-grabbing provocations by North Korea,
[regardless of whether they emanate from manifestations of Kim's
military strength or his economic weakness]{.mark}.]{.underline}

#### (\--) Carefully considered diplomacy is necessary to solve the risk of a miscalculated nuclear conflict with North Korea---assumes Trump actions late in his administration:

Louis Rene **Beres, 10/21**/20**20** (Professor Emeritus of Political
Science and International Law at Purdue. He is the author of twelve
major books and several hundred journal articles in the field. Professor
Beres' writings appear in many leading newspapers and magazines,
including The Atlantic, The Hill, U.S. News & World Report, The National
Interest, The Jerusalem Post, The New York Times and Oxford University
Press. In Israel, where his latest writings were published by the BESA
Center for Strategic Studies, the Institute for Policy and Strategy and
the Institute for National Security Studies, he was Chair of Project
Daniel (PM Sharon, 2003). Dr. Beres' strategy-centered publications have
been published in such places as The Bulletin of the Atomic Scientists;
JURIST; Special Warfare (Pentagon); Infinity Journal (Israel); The
Strategy Bridge; The War Room (USA War College); Modern War Institute
(West Point); The Harvard National Security Journal (Harvard Law
School); Modern Diplomacy; Yale Global Online; The International Journal
of Intelligence and Counterintelligence, Parameters: Journal of the U.S.
Army War College, The Brown Journal of World Affairs, Israel Defense
(Tel Aviv); World Politics (Princeton); International Security (Harvard)
and the Israel Journal of Foreign Affairs. Professor Louis René Beres
was born in Zürich, Switzerland, at the end of World War II, ""Hic Sunt
Dracones": Still Expanding Risks of a US-North Korea Nuclear War,"
<https://www.jurist.org/commentary/2020/10/louis-rene-beres-us-north-korea-nuclear-war/>,
Retrieved 1/27/2021)

Once again, on October 9, 2020, with immodest displays of tangible
hardware, [[North Korea mocked]{.underline}]{.mark} Donald
[[Trump's]{.underline}]{.mark} lingering [[expectations of
"denuclearization."]{.mark}]{.underline} Here, in Pyongyang, President
Kim Jong Un smugly revealed a "monster" intercontinental ballistic
missile (ICBM). Further highlighted at Kim's extravagant military parade
were the Hwasong-15, which is the longest-range missile ever tested by
North Korea, and also what appeared to be a newly-refined
submarine-launched ballistic missile (SLBM). How did US President Trump
respond? The only apparent reaction from Washington was to call this
strategic exposure "disappointing." Nary a polite nod about the
corresponding legal consequences and implications was offered by the
White House. None of this should come as any surprise. Massive
state-of-the-art nuclear weapons remain North Korea's most conspicuous
expression of global power and influence. To be sure, Kim will never
voluntarily surrender such weapons. Realistically, all focused US
efforts to deal with this rapidly growing nuclear threat should center
on long-term mutual deterrence. Creating this plausibly stabilizing
condition by law and diplomacy will be indispensable. For the United
States, [[prudent decision-making in this unstable theatre of
**potential nuclear conflict** will be necessary]{.underline}]{.mark}.
Among other things, President Donald J. Trump should take scrupulous
care not to exaggerate or overstate America's military risk-taking
calculus. In part, at least, such aptly considered [[diplomatic caution
would stem from the absence of any historically comparable
crises]{.underline}]{.mark}. By this absence, prima facie, American
military planners and decision-makers remain starkly limited in their
capacity to learn from the past. Still, [[**preventing nuclear war with
North Korea** is not a seat-of-the-pants process for strategic
amateurs]{.underline}]{.mark} or political showmen. In the final
analysis, the primary battlefield of any war, including nuclear war,
must be intellectual. There is more. By definition, there are no "go to"
experts on the subject of a nuclear war, civilian or military. As there
has never been such a war, there could be no way for American planners
or decision-makers to ascertain the mathematical probability of a
US-North Korea nuclear conflict. It follows, inter alia, that there
exist ample grounds for US decisional modesty. For the United States, it
is high time to display profound humility on all strategic and law-based
dealings with Kim Jong Un. When a prospectively belligerent path has
never been walked upon before, it is incumbent on the calculating
"traveler" to advance slowly, purposefully and with recognizable
deliberateness. In essence, all strategic issues are many-sided matters
of science, law and logic, not just wishful thinking or faith. Though
Trump's original reference to the June 12, 2018 Singapore Summit was to
an occasion where the two leaders "fell in love," there remain few if
any residual benefits to this earlier "romance." This does not mean that
Trump's senior strategists and counselors should in any fashion steer
away consciously from clear-eyed assessments of nuclear costs and risks,
but only that such assessments be drawn from a constantly shifting and
hard to decipher geopolitics. In terms of international law, this
geopolitics remains much like its original form in the seventeenth
century; that is, anarchic, force-based and unmitigated by any
well-intentioned global authority. There is more. It goes without saying
that the "pandemic variable" could sometime prove decisive in strategic
terms. Unalterably, calculating plausible connections between this novel
biological variable and US national security would represent an
unprecedented task of Herculean proportion. President Trump will also
have to bear in mind that many continuously transforming and mutating
strategic developments throughout Asia will be impacted by "Cold War
II." This "War" references an ongoing and primary oppositional stance
with Russia, and -- more or less derivatively -- with China. How shall
the United States plan? Proceeding with assorted time-urgent
considerations of US -- North Korea policy, all significant US strategic
calculations will be fraught with intersecting, overlapping and daunting
uncertainties. Always, it will be necessary for President Trump and his
relevant counselors to remain ready to offer the best available
war-peace estimations. Among potential causal factors -- some of them
maximally interdependent or authentically "synergistic" -- [[the
calculable risks of a nuclear war between Washington and
Pyongyang]{.underline}]{.mark} (or between Pyongyang and South Korea)
[[will depend upon whether such a fearful conflict would be
**intentional, unintentional or accidental**]{.mark}**.**]{.underline}
Ipso facto, this three-fold distinction would also have pertinent
jurisprudential differences. Whatever the particular cause, useful
calculations will have to include presumed North Korean conflict
orientations to certain regional American allies, not just to the US
directly. Such inclusion, in turn, will have to factor in China. As
always, in these calculations, refined strategic theory will be a
necessary "net." Only those who "cast," can be expected to "catch." This
tripartite distinction on cause could prove important to any hoped for
success in US-North Korea nuclear war prediction and prevention. Any
accidental nuclear war between the US and North Korea would be
unintentional or inadvertent, but not all unintentional nuclear wars
would be the result of an accident. [[An unintentional nuclear war could
sometime be the result of decisional miscalc]{.underline}]{.mark}ulation
or irrationality, by either one or both of the two contending
parties/presidents. Such an understanding is entirely plausible, and
[[ought to underscore the need for decision-maker
humility]{.underline}]{.mark} rather than flagrantly chauvinistic
bravado. There is much more to know. Facing future North Korean
negotiations -- proceedings governed by authoritative international law
-- it will be necessary that competent US policy analysts systematically
examine dynamic configurations of foreseeable nuclear risk. When
expressed in the orthodox game-theoretic parlance of formal military
planning, these shifting configurations could present themselves singly
or one-at-a-time (the expectedly best case for Washington); but, they
might also arise more-or-less suddenly, unexpectedly, with an apparent
diffusiveness and in multiple or overlapping "cascades" of strategic
complexity. Whatever their nuances, these examinations will be
intellectual and legal tasks, not political ones. To understand any such
"cascades" will require carefully-honed, well-developed and formidable
analytic skills. Correspondingly, this will not be a graspable task for
the analytically faint-hearted. It will require generally rare
combinations of historical acquaintance, legal erudition and well-
demonstrated capacities for advanced dialectical thinking. In essence,
this points to a task that will require thinkers who are as comfortable
with elucidating holistic computation prescriptions of Plato and
Descartes as with more narrowly technical elements of modern strategic
planning. Certain understandings here will call for crucial
bifurcations. Currently, [[it is worrisome that neither Washington nor
Pyongyang is likely paying sufficient attention to the specific risks of
an unintentional nuclear war]{.underline}]{.mark}. Moreover, to this
point in their ongoing relations, each President would seem to assume
the other's decision-making rationality. If, after all, there were no
such mutual assumption, it would make no calculable sense for either
side to negotiate any further nuclear security accommodations with the
other. Goals here must be plain. Stable and viable deterrence, not
Pyongyang's "denuclearization," must become the overriding US strategic
goal vis-à-vis North Korea. This complex goal is always contingent upon
certain basic assumptions concerning enemy rationality. But are such
assumptions valid in the particular case of a potential war between two
nuclear powers? If not, if President Donald Trump should sometime begin
to fear overt enemy irrationality in Pyongyang, issuing any explicit
threats of US retaliation might only make matters less stable. This is
especially worrisome where the new threats were expressly
disproportionate. In the past, in his escalating bravado detached from
any secure intellectual foundations, Donald Trump has favored such
utterly vacant and law-violating threats as "complete annihilation" or
"total destruction." No such crudely lawless preference stands even a
scintilla of chance to meet legitimate American security goals. What
might sound reasonably "tough" to an American President comfortable only
with metaphors of the street may nonetheless only reduce US nuclear
deterrent persuasiveness. At some point, if made too contingent upon
seat-of-the-pants bellicosity, American national security could come to
depend on some presumptively viable combinations of ballistic missile
defense and defensive first strikes. Settling upon such untested and
legally-problematic combinations would lack decisional input from any
tangible/quantifiable historical evidence, and would be existentially
risky. In the conceivably worst case, the offensive military element
could entail a narrowly situational preemption -- a defensive first
strike. At that manifestly late stage, of course, all previous hopes for
bilateral reconciliation would already have become moot. At that
portentous point, there could remain no "ordinary" circumstances wherein
a preemptive strike against a nuclear North Korea would still be
rational. In Washington's nuclear relations with Pyongyang, none of
these decisions should ever be made casually or without fully
substantive intellectual foundations. More precisely, with the steadily
expanding development of "hypersonic" nuclear weapons, determining
optimal US policy combinations from one crisis to another could very
quickly become overwhelming. Though counterintuitive, the fact that the
United States is recognizably "more powerful" than North Korea could
prove to be largely irrelevant. Even worse, it could become the
underlying cause of some actual military nuclear engagement between the
two countries. Some years back, Donald Trump, speaking of Kim Jong Un,
bragged that both leaders may have a nuclear "button," but that "my
button is bigger than his." In such urgent matters of national strategy,
however, size would likely not matter. In matters of strategic nuclear
deterrence, even a seemingly "weaker" nuclear force could still inflict
wholly unacceptable harms. In these delicate matters, the weaker party
could remain fully capable of wreaking "assuredly destructive"
retaliations. In all such foreseeable circumstances, there would obtain
various overlapping issues of law and strategy. Under international law,
which remains an integral part of US law, the option of a selective or
comprehensive defensive first-strike might sometime be correctly
characterized as "anticipatory self-defense." This juridical correctness
would apply, however, only if the American side could argue persuasively
that the "danger posed" by North Korea was "imminent in point of time."
Discernible "imminence" is specifically required by the authoritative
standards of international law -- that is, by criteria established and
codified after an 1837 naval incident famously called "The Caroline."
Today, in the perplexing nuclear age, aptly precise characterizations of
"imminence" could also prove sorely abstract or densely problematic.
What then? For the time being, at least, it seems plausible that Kim
Jong Un would value his own personal life and that of his nation above
any other conceivable preference or combination of preferences. In any
corresponding scenario, Kim is assumed to be technically rational, and
thus remains subject to US nuclear deterrence. Nonetheless, it could
still become important for any negotiating American president to
distinguish accurately between authentic instances of enemy
irrationality and instances of feigned or pretended irrationality. Such
an expectation might not be easily satisfied in the midst of any
already-ongoing nuclear crisis; that is, in extremis atomicum. As for
the potential effects of disease pandemic upon accurate adversarial
assessments, these would inevitably be significant. They could also be
more-or-less indecipherable. There is more. [[Although neither side
would likely seek a shooting war]{.underline}]{.mark}, especially if
both adversaries were fully rational, [[either or both heads of state
could still commit **catastrophic errors** in making strategic
choices.]{.underline}]{.mark} Any such errors would likely represent an
unintended consequence of jointly competitive searches for "escalation
dominance." Arguably, these sorts of prospectively crucial errors are
more apt to occur in circumstances where one or both presidents had
chosen to reignite exclamations of gratuitous bravado or belligerent
rhetoric. [[An inadvertent nuclear war between Washington and Pyongyang
could take place not only as the result of]{.underline}]{.mark} certain
misunderstandings or [[miscalc]{.underline}]{.mark}ulations between
rational national leaders, [[but also as the unintended
consequence]{.underline}]{.mark} (singly or synergistic) [[of
mechanical]{.underline}]{.mark}, electrical, [[computer
malfunctions]{.underline}]{.mark}, or certain "hacking"-type
interventions. Going forward, these interventions could surely include
unprecedented intrusions of "cyber-mercenaries." What are the essential
"nuclear bargaining" dynamics that now need to be studied? In any crisis
between Washington and Pyongyang, each side will expectedly strive to
maximize two overriding goals at the same time. These objectives are (1)
to dominate the dynamic and largely unpredictable process of nuclear
crisis escalation; and (2) to achieve desired "escalation dominance"
without sacrificing vital national security obligations. In the final
analysis, this second objective means preventing one's own state and
society from suffering catastrophic or existential harms. What is the
"bottom line"? All underlying issues of strategic contention between
Washington and Pyongyang are enormously complicated and (as an
inevitable corollary) subject to irremediable failure. Faced with such
complexities -- both operational and legal -- each side must now proceed
warily, in suitably deliberate fashion, with a posture that is both
militarily purposeful and prudentially risk-averse. Reciprocally, any
aggressive over-confidence by President Trump and/or President Kim will
have to be consciously avoided. Recalling the terrible costs of
excessive leadership pride chronicled in Greek tragedy -- that is,
existential costs of "hubris" -- the American President must also
understand that there will be no rescues from any Deus ex machina. In
the end, these must all be matters of problematic human judgment.
Although everything on the bargaining table could appear simple, it
would be wise to keep in mind the classic "friction-centered" warning of
Carl von Clausewitz. "Everything is very simple in war," says the
Prussian military thinker in On War, "but even the simplest thing is
very difficult." Always, this difficulty must extend to corresponding
matters of law.

### Pandemics Add-On -- 2AC

#### AI solves pandemics.

Ania **Syrowatka,** et al, 6/10/20**21** (Division of General Internal
Medicine, Brigham and Women's Hospital, Boston, MA, USA, "Leveraging
artificial intelligence for pandemic preparedness and response: a
scoping review to identify key use cases," Retrieved 6/12/2022 from
https://www.nature.com/articles/s41746-021-00459-8)

Artificial intelligence ([[AI) represents a valuable tool that could be
widely used to inform]{.underline}]{.mark} clinical and public health
[[decision-making to **effectively manage the impacts of a
pandemic**]{.underline}.]{.mark} The objective of this scoping review
was to identify the key use cases for involving AI for pandemic
preparedness and response from the peer-reviewed, preprint, and grey
literature. The data synthesis had two parts: an in-depth review of
studies that leveraged machine learning (ML) techniques and a limited
review of studies that applied traditional modeling approaches. ML
applications from the in-depth review were categorized into use cases
related to public health and clinical practice, and narratively
synthesized. One hundred eighty-three articles met the inclusion
criteria for the in-depth review. Six key use cases were identified:
forecasting infectious disease dynamics and effects of interventions;
surveillance and outbreak detection; real-time monitoring of adherence
to public health recommendations; real-time detection of influenza-like
illness; triage and timely diagnosis of infections; and prognosis of
illness and response to treatment. Data sources and types of ML that
were useful varied by use case. The search identified 1167 articles that
reported on traditional modeling approaches, which highlighted
additional areas where ML could be leveraged for improving the accuracy
of estimations or projections. Important ML-based solutions have been
developed in response to pandemics, and particularly for COVID-19 but
few were optimized for practical application early in the pandemic.
These findings can support policymakers, clinicians, and other
stakeholders in [[prioritizing research and development to support
operationalization of AI for future pandemics.]{.underline}]{.mark}

#### New pandemics threaten human extinction:

Lakshmi **Supriya**, PhD., 4/19/20**21** (Lakshmi Supriya got her BSc in
Industrial Chemistry from IIT Kharagpur (India) and a Ph.D. in Polymer
Science and Engineering from Virginia Tech (USA)., "Humans versus
viruses - Can we avoid extinction in near future?",
<https://www.news-medical.net/news/20210419/Humans-versus-viruses-Can-we-avoid-extinction-in-near-future.aspx>,
Retrieved 8/2/2021)

Expert argues that human-caused changes to the environment can lead to
[[the emergence of pathogens]{.underline}]{.mark}, not only from outside
but also from our own microbiome, which [[can pave the way for
large-scale destruction of humans and **even our
extinction**]{.mark}**.**]{.underline} Whenever there is a change in any
system, it will cause other changes to reach a balance or equilibrium,
generally at a point different from the original balance. Although this
principle was originally posited by the French chemist Henry Le
Chatelier for chemical reactions, this theory can be applied to almost
anything else. In an essay published on the online server Preprints\*,
Eleftherios P. Diamandis of the University of Toronto and the Mount
Sinai Hospital, Toronto, argues that changes caused by humans, to the
climate, and everything around us will lead to changes that may have a
dramatic impact on human life. Because our ecosystems are so complex, we
don't know how our actions will affect us in the long run, so humans
generally disregard them. Changing our environment Everything around us
is changing, from living organisms to the climate, water, and soil. Some
estimates say about half the organisms that existed 50 years ago have
already become extinct, and about 80% of the species may become extinct
in the future. As the debate on global warming continues, according to
data, the last six years have been the warmest on record. Global warming
is melting ice, and sea levels have been increasing. The changing
climate is causing more and more wildfires, which are leading to other
related damage. At the same time, increased flooding is causing
large-scale devastation. One question that arises is how much
environmental damage have humans already done? A recent study compared
the natural biomass on Earth to the mass produced by humans and found
humans produce a mass equal to their weight every week. This human-made
mass is mainly for buildings, roads, and plastic products. In the early
1900s, human-made mass was about 3% of the global biomass. Today both
are about equal. Projections say by 2040, the human-made mass will be
triple that of Earth's biomass. But, slowing down human activity that
causes such production may be difficult, given it is considered part of
our growth as a civilization. Emerging pathogens Although we are made up
of human cells, we have almost ten times that of bacteria just in our
guts and more on our skin. These microbes not only affect locally but
also affect the entire body. There is a balance between the good and bad
bacteria, and any change in the environment may cause this balance to
shift, especially on the skin, the consequences of which are unknown.
Although most bacteria on and inside of us are harmless, gut bacteria
can also have viruses. If viruses don't kill the bacteria immediately,
they can incorporate into the bacterial genome and stay latent for a
long time until reactivation by environmental factors, when they can
become pathogenic. They can also escape from the gut and enter other
organs or the bloodstream. Bacteria can then use these viruses to kill
other bacteria or help them evolve to more virulent strains. [[An
example of the evolution of pathogens is the cause of the current
pandemic]{.underline}]{.mark}, the severe acute respiratory syndrome
[[coronavirus]{.underline}]{.mark} 2 (SARS-CoV-2). Several mutations are
now known that make the virus more infectious and resistant to immune
responses, and strengthening its to enter cells via surface receptors.
The brain There is evidence that the SARS-CoV-2 can also affect the
brain. The virus may enter the brain via the olfactory tract or through
the angiotensin-converting enzyme 2 (ACE2) pathway. Viruses can also
affect our senses, such as a loss of smell and taste, and there could be
other so far unkown neurological effects. The loss of smell seen in
COVID-19 could be a new viral syndrome specific to this disease. Many
books and movies have described pandemics caused by pathogens that wipe
out large populations and cause severe diseases. In the essay, the
author provides a hypothetical scenario where a gut bacteria suddenly
starts producing viral proteins. Some virions spread through the body
and get transmitted through the human population. After a few months,
the virus started causing blindness, and within a year, large
populations lost their vision. [[**Pandemics** can cause other diseases
that can threaten **humanity's entire existence**. The COVID-19 pandemic
brought this possibility to the forefront. If we continue disturbing the
equilibrium between us and the environment, we don't know what the
consequences may be and **the next pandemic could lead us to
extinction**]{.underline}]{.mark}.

# Offcase Answers

## AT: Rogue AI DA

### Rogue AI DA -- 2AC

#### Tech is inevitable---it's just a matter of whether the US or China gets the tech.

#### NATO coordination on joint operations with AI can promote coordination on the ethical guidelines for the development of AI.

Zoe Stanley-**Lockman, 2022** (Defense and Strategic Studies, Nanyang
Technological University, "NATO's Role in Responsible AI Governance in
Military Affairs," [https://www.oxfordhandbooks.com/view/
10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69](https://www.oxfordhandbooks.com/view/%2010.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69),
Retrieved 6/11/2022)

[[**NATO's influence** in the functioning of joint operations and
multinational military operations **situates the Alliance to
coordinate** between how Allies implement ethical principles in their
own national AI development]{.mark}.]{.underline} Specifically, [[**NATO
is well-situated** to advocate for transparency]{.underline}]{.mark},
accountability, [[and data governance, which]{.mark}]{.underline} are
also adoption factors that [[can translate into operational
benefits]{.underline}]{.mark}, among other values.69 For example,
[[these factors can promote coordination among Allies on ethical
guidelines]{.underline}]{.mark} on the development and use of AI, as
[[**this will be a necessary foundation** in any future joint operation
that uses this tech]{.underline}]{.mark}nology. "The transatlantic
partnership must focus on coordinating these core principles and
systematic governance to ensure AI systems development aligns with the
rule of law and democracy. In particular, this must ensure answering
questions about human dignity, human control, and accountability ...
[[**NATO remains the organization** that can bring these two (U.S. and
EU) together and **establishes the ethical bottom
line**]{.underline}]{.mark}."70 [[The issues of transparency and
accountability will define the scope of future
implementation.]{.underline}]{.mark}

#### NATO is vital to effectively managing AI technology---multilateral approaches and cohesion are necessary to solve.

Zoe Stanley-**Lockman, 2022** (Defense and Strategic Studies, Nanyang
Technological University, "NATO's Role in Responsible AI Governance in
Military Affairs," [https://www.oxfordhandbooks.com/view/
10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69](https://www.oxfordhandbooks.com/view/%2010.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69),
Retrieved 6/11/2022)

NATO structures around strategic and policy planning both set Allied
ambitions and priorities and have the competency to implement them
through its many consultative bodies, coordination formats, and albeit
to a lesser extent, technology foresight capacities. [[NATO has
facilitative power among Allies, both for defense planning and for the
conduct of operations]{.underline}]{.mark}. A cornerstone in modern
architecture of international security is coalition warfare---or, more
broadly, joint operations. [[**Working with military partners** has
become **a critical feature** of modern security policy,
where]{.underline}]{.mark} there is more power in enhancing numbers, but
also in [[having allies]{.underline}]{.mark} that [**[lend political and
practical legitimacy to deterrence and
operations]{.underline}**.]{.mark}49 [[**NATO is vital** to that effort
for many reasons, but also because **NATO's facilitative power is
significant to promote coordination and
cooperation**]{.mark}**.**]{.underline} Simply put, partners and
**[[allies are a necessary feature of modern military
behavior]{.underline}]{.mark}**, and strategic and policy planning are
necessary functions to encourage and underpin cohesion in alliance
settings. [[This is **important for AI governance** because the nature
of AI poses new strategic challenges and will **require multilateral
approaches** and some **degree of cohesion** to **effectively
incorporate**]{.underline}]{.mark} RRI [[**frameworks in policy
planning**. As such, **the necessity of working with security partners
extends to the AI-policy frontier**]{.underline}]{.mark}.

#### Technological limits prevent AI from being an existential threat to humanity.

Edward Moore **Geist,** 8/9/20**15** (MacArthur Nuclear Security Fellow
at Stanford University\'s Center for International Security and
Cooperation, "Is artificial intelligence really an existential threat to
humanity?"
<https://thebulletin.org/2015/08/is-artificial-intelligence-really-an-existential-threat-to-humanity/>,
Retrieved 6/15/2022)

Superintelligence: Paths, Dangers, Strategies is an astonishing book
with an alarming thesis: Intelligent machines are "quite possibly the
most important and most daunting challenge humanity has ever faced." In
it, Oxford University philosopher Nick Bostrom, who has built his
reputation on the study of "existential risk," argues forcefully that
artificial intelligence might be the most apocalyptic technology of all.
With intellectual powers beyond human comprehension, he prognosticates,
self-improving artificial intelligences could effortlessly enslave or
destroy Homo sapiens if they so wished. While he expresses skepticism
that such machines can be controlled, Bostrom claims that if we program
the right "human-friendly" values into them, they will continue to
uphold these virtues, no matter how powerful the machines become. These
views have found an eager audience. In August 2014, PayPal cofounder and
electric car magnate Elon Musk tweeted "Worth reading Superintelligence
by Bostrom. We need to be super careful with AI. Potentially more
dangerous than nukes." Bill Gates declared, "I agree with Elon Musk and
some others on this and don't understand why some people are not
concerned." More ominously, [[legendary
astrophysicist]{.underline}]{.mark} Stephen [[Hawking concurred: "I
think the development of full a]{.underline}]{.mark}rtificial
[[i]{.underline}]{.mark}ntelligence [[could spell the end of the human
race]{.underline}]{.mark}." Proving his concern went beyond mere
rhetoric, Musk donated \$10 million to the Future of Life Institute "to
support research aimed at keeping AI beneficial for humanity."
Superintelligence is propounding a solution that will not work to a
problem that probably does not exist, but Bostrom and Musk are right
that now is the time to take the ethical and policy implications of
artificial intelligence seriously. [[The extraordinary claim that
machines can become so intelligent as to gain demonic powers **requires
extraordinary evidence,** particularly since]{.underline}]{.mark}
artificial intelligence ([[AI) researchers have struggled to create
machines that show much evidence of intelligence at
all]{.underline}.]{.mark} While these investigators' ultimate goals have
varied since the emergence of the discipline in the mid-1950s, the
fundamental aim of AI has always been to create machines that
demonstrate intelligent behavior, whether to better understand human
cognition or to solve practical problems. [[Some AI researchers even
tried to create the self-improving reasoning machines Bostrom fears.
Through decades of bitter experience, however, they learned not only
that creating intelligence is more difficult than they initially
expected, but also that it grows increasingly harder the smarter one
tries to become]{.underline}]{.mark}. Bostrom's concept of
"superintelligence," which he defines as "any intellect that greatly
exceeds the cognitive performance of humans in virtually all domains of
interest," builds upon similar discredited assumptions about the nature
of thought that the pioneers of AI held decades ago. A summary of
Bostrom's arguments, contextualized in the history of artificial
intelligence, demonstrates how this is so. In the 1950s, the founders of
the field of artificial intelligence assumed that the discovery of a few
fundamental insights would make machines smarter than people within a
few decades. By the 1980s, however, they discovered fundamental
limitations that show that there will always be diminishing returns to
additional processing power and data. Although these **[[technical
hurdles]{.underline}]{.mark}** pose no barrier to the creation of
human-level AI, they [[will likely forestall the sudden emergence of an
unstoppable "superintelligence]{.underline}." [The risks of
self-improving intelligent machines are **grossly exaggerated** and
ought not serve as a distraction from the existential risks we already
face]{.underline}]{.mark}[,]{.underline} especially given that the
limited AI technology we already have is poised to make threats like
those posed by nuclear weapons even more pressing than they currently
are. Disturbingly, little or no technical progress beyond that
demonstrated by self-driving cars is necessary for artificial
intelligence to have potentially devastating, cascading economic,
strategic, and political effects. While policymakers ought not lose
sleep over the technically implausible menace of "superintelligence,"
they have every reason to be worried about emerging AI applications such
as the Defense Advanced Research Projects Agency's submarine-hunting
drones, which threaten to upend longstanding geostrategic assumptions in
the near future. Unfortunately, Superintelligence offers little insight
into how to confront these pressing challenges.

#### Case turns disad: Nuclear war would lead to the annihilation of all life on Earth.

António **Guterres, 1/2/**20**22** (Secretary-General of the United
Nations, "Threat of nuclear war: Not a thing of the past,"
<https://www.thedailystar.net/views/opinion/news/threat-nuclear-war-not-thing-the-past-2930251>,
Retrieved 6/15/2022)

We live in worrying times. The climate crisis, stark inequalities,
bloody conflicts and human rights abuses, and the personal and economic
devastation caused by the Covid-19 pandemic have put our world under
greater stress than it has faced in my lifetime. But [[the existential
threat that cast a shadow over the first half of my life no longer
receives the attention it should. Nuclear weapons have faded from
headlines]{.underline}]{.mark} and Hollywood scripts. [[But the danger
they pose remains as high as ever, and is growing by the year. Nuclear
annihilation is just one misunderstanding or miscalculation away---a
sword of Damocles that threatens]{.underline}]{.mark} not only suffering
and death on a horrific scale, but [[the end of all life on
earth]{.underline}]{.mark}.

### Rogue AI DA -- Link Turn -- 1AR

#### Greater transatlantic cooperation on AI is necessary to prevent the advancement of harmful AI.

Christie **Lawrence &** Sean **Cordey,** 20**20**, (Belfer Center for
Science and International Affairs, Harvard Kennedy School, "The Case for
Increased Transatlantic Cooperation on Artificial Intelligence,"
<https://www.belfercenter.org/publication/case-increased-transatlantic-cooperation-artificial-intelligence>,
Retrieved 6/12/2022)

Despite all of these changes, the importance of a strong relationship
between the United States and the European Union has been a constant.
The transatlantic disagreements that have characterized the past few
years---and have hampered a united front on emerging technologies like
5G and AI5---are not the first time US-EU relations have suffered, but
they should not further divide allies that share common values.6
[[Deepened US-EU cooperation across the entire AI
ecosystem]{.underline}]{.mark}7 [[is necessary to advance a more secure,
safe, and prosperous world, but to do this the current level of
AI-related coordination and partnership needs to be
increased]{.underline}]{.mark}. This report's purpose is twofold: first,
to inform policymakers and researchers about the current state of
transatlantic AI efforts; and second, to recommend specific areas where
transatlantic AI collaboration should be strengthened. Based on a
comprehensive study of over 260 documents and reports covering the
period from December 1997 to June 2020, we proposes more than 16
recommendations to increase US-EU AI collaboration across the entire AI
ecosystem, as well as 9 recommendations for AI cooperation in the
healthcare, environmental sciences, and defense sectors. [[Greater
transatlantic efforts are needed to prevent the advancement of an AI
vision that is adversarial and harmful to the wellbeing of the
U]{.underline}]{.mark}nited [[S]{.underline}]{.mark}tates, the European
Union, [[and allies]{.underline}]{.mark}.

#### NATO can lead the establishment of responsible technological development in AI to steward military development on a responsible trajectory.

Zoe Stanley-**Lockman, 2022** (Defense and Strategic Studies, Nanyang
Technological University, "NATO's Role in Responsible AI Governance in
Military Affairs," [https://www.oxfordhandbooks.com/view/
10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69](https://www.oxfordhandbooks.com/view/%2010.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69),
Retrieved 6/11/2022)

This chapter explores a role for the North Atlantic Treaty Organization
(NATO) in the emerging military artificial intelligence (AI) governance
architecture. As global powers compete for capabilities that AI can
offer, NATO has the challenging task of recalibrating strategic
relationships in the coming years. [[NATO has begun
to]{.mark}]{.underline} recognize technological change as a necessary
variable and, in turn, [[adapt its organizational composition and
strategy to increase the Alliance's capacity to meet emerging security
challenges]{.underline}.]{.mark} As NATO bodies and Allies prepare for
the impact of AI on future military operations, [[NATO has its own
responsibility to steward AI in ways that promote harmonization among
Allies]{.underline}]{.mark} and advance the NATO mission. Toward this
effort, the chapter highlights two governance mechanisms within NATO's
competency---strategic and policy planning, and standards and
certification---as practices that exemplify [[NATO's power to shape the
trajectory of tech]{.underline}]{.mark}nological
[[development]{.underline}.]{.mark} We operationalize these governance
tools by examining the three pillars that are particularly challenging
for AI governance: ethics and values, legal norms, and safety and
security. Within each pillar, we examine [[**NATO**'s facilitation of
strategic policy planning and standards and certification to **emerge as
a leader** in establishing responsible
tech]{.underline}]{.mark}nological [[development and, ultimately, a more
secure international security environment]{.underline}]{.mark}. This
chapter finds [[**there is space for NATO** to pursue its agenda to
maintain tech]{.underline}]{.mark}nological
[[superiority]{.underline}]{.mark} not just to protect and defend its
way of life, but [[**to build on AI governance pillars to steward
military innovation on a responsible trajectory**.]{.underline}]{.mark}

### Rogue AI DA -- No War -- 1AR

#### Claims that AI will cause World War III are overstated rhetoric.

Michael **Horowitz,** Dec. 20**19**, (Political Science Prof @
University of Pennsylvania, "A Stable Nuclear Future? The Impact of
Autonomous Systems and Artificial Intelligence," Retrieved Apr. 28, 2022
from <https://arxiv.org/abs/1912.05291>)

In early 2017, Klaus Schwab of the World Economic Forum argued that the
world is on the cusp of a Fourth Industrial Revolution, wherein several
technologies -- but most prominently AI -- could reshape global
affairs.5 Many defense experts around the world share Schwab's
recognition of the potentially transformative effects of AI.6 The most
prominent statements about the impact of AI on warfare, however, tend to
be extreme. Elon [[Musk]{.underline},]{.mark} for instance, [[has
vocally contended that AI run amok could risk World War
III]{.mark}.]{.underline}7 [[This overheated rhetoric masks the way that
advances in automation, autonomous systems, and AI may actually
influence warfare]{.underline}]{.mark}, especially in the vital areas of
nuclear deterrence and warfighting. The intersection of nuclear
stability and artificial intelligence thus raises critical issues for
the study of international politics.

### Rogue AI DA -- No Extinction -- 1AR

#### Doomsday AI scenarios won't happen---multiple reasons.

Michael **Shermer**, 3/1/20**17** (Presidential Fellow at Chapman
University, "Artificial Intelligence Is Not a Threat---Yet,"
<https://www.scientificamerican.com/article/artificial-intelligence-is-not-a-threat-mdash-yet/>,
Retrieved 6/15/2022)

[I\'m skeptical]{.underline}. First, all such [[doomsday scenarios
involve **a long sequence of if-then contingencies**, a failure of which
at any point would **negate the apocalypse**]{.underline}]{.mark}.
University of West England Bristol professor of electrical engineering
Alan Winfield put it this way in a 2014 article: "[[If we succeed in
building human equivalent AI and if that AI acquires a full
understanding of how it works,]{.underline}]{.mark} and if it then
succeeds in improving itself to produce super-intelligent AI, and if
that super-AI, accidentally or maliciously, starts to consume resources,
[[and if we fail to pull the plug, then, yes, we
may]{.underline}]{.mark} well [[have a problem. The risk, while not
impossible**, is improbable**]{.underline}]{.mark}." Second, [[the
development of AI has been **much slower than predicted**, allowing time
to **build in checks at each stage**]{.underline}]{.mark}. As Google
executive chairman Eric Schmidt said in response to Musk and Hawking:
"Don\'t you think humans would notice this happening? And don\'t you
think humans would then go about turning these computers off?" Google\'s
own DeepMind has developed the concept of an AI off switch, playfully
described as a "big red button" to be pushed in the event of an
attempted AI takeover. As Baidu vice president Andrew Ng put it (in a
jab at Musk), it would be "like worrying about overpopulation on Mars
when we have not even set foot on the planet yet." Third, [[AI doomsday
scenarios are often predicated **on a false analogy** between natural
intelligence and a]{.mark}rtificial [i]{.mark}ntelligence]{.underline}.
As Harvard University experimental psychologist Steven Pinker elucidated
in his answer to the 2015 Edge.org Annual Question "What Do You Think
about Machines That Think?": "[[AI dystopias project a parochial
alpha-male psychology onto the concept of intelligence. They assume that
superhumanly intelligent robots would develop goals like]{.mark}
deposing their masters or [taking over the world." It is equally
possible]{.mark}]{.underline}, Pinker suggests, [[that
"a]{.underline}]{.mark}rtificial [[i]{.underline}]{.mark}ntelligence
[[will naturally develop along female lines: fully capable of solving
problems, but with **no desire to annihilate innocents**]{.mark} or
dominate the civilization."]{.underline} Fourth[, [the implication that
computers will "want" to do something]{.mark}]{.underline} (like convert
the world into paperclips) [[means AI has emotions,
but]{.underline}]{.mark} as science writer Michael Chorost notes, "the
minute an A.I. wants anything, [[it will live in a universe with rewards
and punishments---including punishments]{.mark} from us [for behaving
badly]{.mark}]{.underline}[."]{.mark} Given the zero percent historical
success rate of apocalyptic predictions, coupled with the incrementally
gradual development of AI over the decades, [[we have **plenty of time
to build in fail-safe systems** to prevent any such AI
apocalypse.]{.underline}]{.mark}

#### Superintelligence is a practical impossibility.

Edward Moore **Geist,** 8/9/20**15** (MacArthur Nuclear Security Fellow
at Stanford University\'s Center for International Security and
Cooperation, "Is artificial intelligence really an existential threat to
humanity?"
<https://thebulletin.org/2015/08/is-artificial-intelligence-really-an-existential-threat-to-humanity/>,
Retrieved 6/15/2022)

[[Convinced that sufficient "intelligence" can overcome almost any
obstacle, Bostrom acknowledges few limits on what artificial
intelligences might accomplish. Engineering realities rarely enter into
Bostrom's analysis, and those that do contradict the thrust of his
argument]{.underline}]{.mark}. He admits that the theoretically optimal
intelligence, a "perfect Bayesian agent that makes probabilistically
optimal use of available information," will forever remain "unattainable
because it is too computationally demanding to be implemented in any
physical computer." Yet Bostrom's postulated "superintelligences" seem
uncomfortably close to this ideal. The author offers few hints of how
machine superintelligences would circumvent the computational barriers
that render the perfect Bayesian agent impossible, other than promises
that the advantages of artificial components relative to human brains
will somehow save the day. But [[over the course of 60 years of attempts
to create thinking machines, AI researchers have come to the realization
that there is far more to intelligence than simply deploying a faster
mechanical alternative to neurons]{.underline}]{.mark}. In fact, [[the
history of a]{.underline}]{.mark}rtificial
[[i]{.underline}]{.mark}ntelligence [[suggests that Bostrom's
"superintelligence" is a practical impossibility.]{.underline}]{.mark}

## A2: Other DAs

### Readiness DA/Ethics Bad DA -- 2AC

#### Incorporating ethics into AI will bolster US capabilities to create effective AI.

Benjamin **Boudreaux,** 1/11/20**19** (professor at the Pardee RAND
Graduate School, "Does the U.S. Face an AI Ethics Gap?"
[https://www.realcleardefense.com/articles/2019/01/11/
does_the_us_face_an_ai_ethics_gap_114095.html](https://www.realcleardefense.com/articles/2019/01/11/%20does_the_us_face_an_ai_ethics_gap_114095.html),
Retrieved 6/12/2022)

Even with differences in how [[ethical risks]{.underline}]{.mark} are
interpreted between the U.S. and its adversaries, [[this is not a gap
that will debilitate the U.S. but **could instead be a source of U.S.
strength**. Ethical conduct by the DoD is essential to **bolster
domestic popular support** and the legitimacy of military
action]{.mark}.]{.underline} This is especially important in the context
of open source access to details about military operations that
previously would have been opaque to most Americans. Further, [[an
emphasis on ethical action could also help the military **build
partnerships with the private sector** to **leverage the most advanced
tech**]{.underline}]{.mark}nologies, [[attract AI talent, and promote
multinational alliances with like-minded countries in Europe and
elsewhere]{.mark}.]{.underline} So [[ethical considerations could become
a fundamental component of how the U.S. **builds the partnerships** and
capabilities essential for **both its hard and soft
power**]{.underline}.]{.mark} But in addition to these pragmatic reasons
to care about ethics, the U.S. should also recognize that the ethical
risks raised about AI reflect real humanitarian values that matter
deeply. Instead of worrying about an ethics gap, [U.S.
policymakers]{.underline} and the military community [could proudly
demonstrate a commitment to leading in AI ethics, and]{.underline} build
standards of responsible AI behavior reflecting American values that can
[rally the international community]{.underline}. Indeed, U.S. leadership
on AI ethics could be essential to ensuring that risks are mitigated and
the AI arms race does not become a race to the bottom.

#### Infusing ethical principles into AI do not detract from military readiness.

Zoe Stanley-**Lockman, 2022** (Defense and Strategic Studies, Nanyang
Technological University, "NATO's Role in Responsible AI Governance in
Military Affairs," [https://www.oxfordhandbooks.com/view/
10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69](https://www.oxfordhandbooks.com/view/%2010.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69),
Retrieved 6/11/2022)

Additionally, [[infusing AI development with]{.underline}]{.mark}
certain [[ethical principles]{.underline}]{.mark} and values [[can have
operational advantages]{.underline}]{.mark} and benefits, [[and NATO
can, in particular, promote the ethical principles as operational
standards for the Allies. A common critique within the ethics debate is
that approaching new tech]{.underline}nology [with an
ethical]{.underline}]{.mark} or democratic values-[[driven perspective
translates into comparative military disadvantage]{.mark}.]{.underline}
Essentially, if your adversary develops technology without the
constraints of ethical principles then there will be diminished
effectiveness on the battlefield.56 [[We find this critique unfounded
because it assumes there is a false trade-off between ethics and
effectiveness; instead, we argue ethical foundations are built into the
architecture of modern warfare]{.underline}.]{.mark}57 As such, [[ethics
is]{.underline}]{.mark} a background condition for battlefield
effectiveness, which is [[already infused in military
decision-making]{.underline}]{.mark} and helping to guide the boundaries
of international humanitarian law. As such, [[ethical guidelines do not
have to detract from a military's capacity]{.underline}]{.mark} or
competency [[to devise]{.underline}]{.mark} means and [[methods of
warfare that will serve their]{.underline}]{.mark} national or coalition
[[interest]{.underline}]{.mark}.58 If anything, a first-mover advantage
can incentivize an ethical and values-driven AI to establish the
threshold of technological standards globally.59

#### Developing safe and secure AI is necessary for NATO to maintain AI technological superiority.

Zoe Stanley-**Lockman, 2022** (Defense and Strategic Studies, Nanyang
Technological University, "NATO's Role in Responsible AI Governance in
Military Affairs," [https://www.oxfordhandbooks.com/view/
10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69](https://www.oxfordhandbooks.com/view/%2010.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69),
Retrieved 6/11/2022)

In any discussion of AI as an emerging military technology, it is
necessary to strike a balance between acknowledging the transformative
potential of AI in the security environment, while simultaneously
recognizing the "hype" that may, thus far, be unfounded. But some
conclusions are clear. The risks and opportunities of [[military AI can
pose significant challenges for future military operations, and
this]{.underline}]{.mark} necessarily [[means there are many
stakeholders with a vested interest in
**developing**]{.mark}**,**]{.underline} promoting, and implementing
**[[responsible military AI.]{.underline}]{.mark}** As multinational
coalitions and military operations are a foundational security policy
for much of the world, this means [[NATO is]{.underline}]{.mark} also
[[a stakeholder with **a vital interest** in promoting safe and secure
technology among its partners]{.underline},]{.mark} both traditional and
non-traditional. As the international security environment continues to
shift, [[there is space for NATO to pursue its agenda to **maintain
technological superiority**]{.underline}]{.mark} not just to protect and
defend its way of life, but also [to [**build on its pillars of AI
governance to steward military innovation** on a responsible
trajectory]{.mark}]{.underline}[.]{.mark}

#### AI is key to US readiness.

#### DEPARTMENT **O**F **D**EFENSE, 2/12/20**19** ("SUMMARY OF THE 2018 DEPARTMENT OF DEFENSE ARTIFICIAL INTELLIGENCE STRATEGY," Retrieved 6/12/2022 from <https://media.defense.gov/2019/Feb/12/2002088963/-1/-1/1/SUMMARY-OF-DOD-AI-STRATEGY.PDF>.)

The Strategy directs that we will use AI in a human-centered manner to:
Support and protect U.S. servicemembers and civilians around the world.
We will incorporate AI into decision-making and operations to reduce
risk to fielded forces and generate military advantage. [[AI can help us
better maintain our equipment, reduce operational costs, and improve
readiness]{.underline}]{.mark}. Incorporating AI also has the potential
to enhance our implementation of the Law of War. [[By improving the
accuracy of military assessments and enhancing mission precision, AI can
reduce the risk of civilian casualties and other collateral
damage]{.underline}]{.mark}.

### Politics -- Plan Popular -- 2AC

#### There is growing political support for transatlantic cooperation on AI with NATO.

Christie **Lawrence &** Sean **Cordey,** 20**20**, (Belfer Center for
Science and International Affairs, Harvard Kennedy School, "The Case for
Increased Transatlantic Cooperation on Artificial Intelligence,"
<https://www.belfercenter.org/publication/case-increased-transatlantic-cooperation-artificial-intelligence>,
Retrieved 6/12/2022)

Transatlantic Cooperation: Despite over 40 years of scientific
relationships and projects between the United States and the European
Union, AI-specific collaboration has been fraught with varying degrees
of political and academic skepticism on both side of the Atlantic,
notably within the European Commission and the governments of some
Member States (e.g., France and Germany).31 Such a dynamic is
aggravated, in part, by the ever-deteriorating transatlantic
relationship spurred by policy and trade disagreements, public spats,
and increasing American isolationism. Despite such explicit omissions
and stand-offs at the highest levels, transatlantic collaboration for AI
does happen, most notably in various multilateral forums working on
standards (e.g., ISO, IEC, IEEE, G7, G20) or on ethics and norms (e.g.,
OECD, GPAI32).33 In recent months, however, [[interests and **political
support** for greater transatlantic]{.mark} [coordination on AI **seems
to be increasing**. This trend was notably demonstrated by a visit from
Lt. Gen]{.mark}.]{.underline} Jack
[[Shanahan]{.underline}]{.mark}---then Director of the US Department of
Defense's Joint Artificial Intelligence Center (JAIC)---to Brussels in
January 2020 and a visit by the European Parliament's delegation to
Washington D.C in February 2020. [[Both visits included discussions on
AI with a variety of key stakeholders, **such as NATO,** representatives
from the US Congress, State Department]{.underline}]{.mark}, Federal
Transit Administration (FTA), Federal Bureau of Investigation (FBI), and
Privacy and Civil Liberties Oversight Board (PCLOB).34

## Counterplan Answers

### A2: Domestic Counterplan

#### Domestic counterplan can't solve for AI---international cooperation is necessary:

DEPARTMENT **O**F **D**EFENSE, 2/12/20**19** ("SUMMARY OF THE 2018
DEPARTMENT OF DEFENSE ARTIFICIAL INTELLIGENCE STRATEGY," Retrieved
6/12/2022 from
<https://media.defense.gov/2019/Feb/12/2002088963/-1/-1/1/SUMMARY-OF-DOD-AI-STRATEGY.PDF>.)

[[**We cannot succeed alone;** this undertaking
requires]{.underline}]{.mark} the skill and commitment of those in
government, close collaboration with academia and non-traditional
centers of innovation in the commercial sector, and [[strong cohesion
among international allies]{.underline}]{.mark} and partners. [[**We
must learn from others** to help us achieve **the fullest understanding
of the potential of AI**, and we must lead in responsibly developing and
using these powerful tech]{.underline}]{.mark}nologies, in accordance
with the law and our values.

### A2: Non-NATO Counterplan

#### NATO is uniquely situated to create AI norms and promote standards that shape AI development in the future.

Zoe Stanley-**Lockman, 2022** (Defense and Strategic Studies, Nanyang
Technological University, "NATO's Role in Responsible AI Governance in
Military Affairs," [https://www.oxfordhandbooks.com/view/
10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69](https://www.oxfordhandbooks.com/view/%2010.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69),
Retrieved 6/11/2022)

NATO's increasing interest in EDTs introduces the need to consider how
governance priorities can help reinforce the Alliance's influence. The
STS and military innovation literature provide the theoretical
foundations for NATO's stewardship of AI as they place attention on "the
role that institutions play in shaping technological trajectories."45
[[**As AI development continues, the actions that NATO** and its members
**take** will have important implications for their capacity
to]{.underline}]{.mark} adopt, respond to, and [[shape their future
operating environment]{.mark}.]{.underline} Particularly for
democracies, this confers to military stakeholders a dual responsibility
to prevent and manage risks, as well as to proactively shape their
approach to technological development anchored in democratic values and
security. [[**As a multinational alliance** with an incentive to drive
cooperation and alignment, **NATO is situated to define and
operationalize norms**, as well as **promote standards** that help shape
the contours of future military effectiveness and
tech]{.underline}]{.mark}nological [[competition]{.underline}.]{.mark}
In a RRI framework, not only is this an institutional role, but it also
becomes an institutional responsibility. To apply this responsibility to
NATO's stewardship of AI, the institutional interplay between
technology, structure, and concepts is a form of socio-technical system
with important implications for AI governance because they link the ways
that an institution uses its power to adopt and shape AI trajectory to
its respective ends. Already, several mechanisms are built into military
bureaucracies to ensure that technology is adopted in alignment with
responsible engineering practices and responsible state behavior.46
[[The Alliance is organized to harmonize between Allies so that their
contributions enhance military effectiveness and political cohesion
between like-minded democracies. We argue that these
effectiveness-centric mechanisms likewise **empower NATO to exert its
influence in tech**]{.underline}]{.mark}nology
[**[governance]{.underline}**.]{.mark} More specifically, [[this entails
the Alliance helping steward tech]{.underline}]{.mark}nological
[[development for a more predictable strategic environment and enhanced
democratic clout around the exploitation of
tech]{.underline}]{.mark}nology reinforcing rule of law. For NATO, we
focus on strategic and policy planning, as well as standards and
certification because they reflect the Alliance's particular strengths
and interests in S&T. These practices are relevant to governance insofar
as they exemplify an institution's power to shape the trajectory of
technological development---but this selection is by no means
exhaustive.47

#### NATO is key to transatlantic alignment on AI issues:

**C**ENTER FOR **E**UROPEAN **P**OLICY **A**NALYSIS, 2/17/20**21**
("NATO Leadership on Ethical AI is Key to Future Interoperability,"
<https://cepa.org/nato-leadership-on-ethical-ai-is-key-to-future-interoperability/>.,
Retrieved 6/15/2022)

[[The transatlantic partnership must focus on coordinating these core
principles]{.underline}]{.mark} and systematic governance [[to ensure AI
systems development aligns with the rule of law]{.underline}]{.mark} and
democracy. In particular, this must ensure answering questions about
human dignity, human control, and accountability. [[**NATO is the
ideal**]{.underline}]{.mark} defense and security [[**forum for this
alignment**. Given the US lead on adopting ethical principles for the
entire DoD and the EU's drive to assert checks and balances for
private-sector tech companies, NATO remains the organization that can
**bring these two together and establishes the ethical bottom
line**]{.underline}]{.mark}. These will then ensure the diverging legal
and ethical stances towards Big Tech do not lead to an interoperability
barrier in the future. If developments surrounding the General Data
Protection Regulation (GDPR) and the challenges it brought for
U.S.-based, data-driven companies are any indication, [[a strong
transatlantic led initiative is needed in order to ensure the same
challenges do not hinder NATO.]{.underline}]{.mark}

#### NATO standards on AI will help develop world standards on AI technology.

Amanda **Miller,** 12/13/20**21** (staff writer, AIR FORCE MAGAZINE,
"NATO's Plan to Grow Trust in Military AI,"
<https://www.airforcemag.com/natos-plan-to-grow-trust-in-military-ai/>,
Retrieved 6/15/2022)

Western militaries---already "late to the party" in the creation of
artificial intelligence---risk unforeseen consequences by adopting AI
made for the commercial sector, said NATO's David van Weel. That's why
the alliance is publicizing a new plan by which it hopes its governments
will get involved in AI development from the start, both for security
reasons and to "bridge a gap of distrust" in the technology. Though he
acknowledged that sharing the plan is a bit out of character for NATO,
all 30 nations, including the U.S., have signed on. "We are not known,
at NATO, for publishing a lot," said van Weel, assistant secretary
general for emerging security challenges. "We try to keep secrets a
lot." Van Weel introduced [[NATO's AI strategy]{.underline}]{.mark},
published in October, during an American Enterprise Institute webinar
Dec. 7. The webinar "Artificial Intelligence: Can We Go From Chaos to
Cooperation?" accompanied the release of AEI's paper, "Artificial
Intelligence: The Risks Posed by the Current Lack of Standards." As a
"pervasive technology," AI will "have an impact on everything we do,"
said van Weel. Setting aside "the killer robot discussion," van Weel
dismissed the notion of excluding AI from all military uses: "The idea
that AI would not be used for defense purposes is like saying that the
steam engine, when it was invented, could only be used for commercial
purposes, or electricity would not be supplied to the military." But
[[being behind the private sector in AI development has left governments
"in a situation where regulation comes after the broad use and misuse of
tech]{.mark}nology]{.underline}," van Weel said. "[[So **we need to be
early to the party** and make sure that we understand new
tech]{.underline}]{.mark}nologies, [not to militarize them---no, but [to
understand the security and defense implications]{.mark}]{.underline}."
Van Weel said military uses of AI should be regulated, but "you don't
want to over-regulate if you don't know that you can defend yourself
within the regulations that you're proposing." He provided the example
of drone swarms "that collectively, powered by AI, are able to follow an
intrinsic pattern---for example, our water supply or one of our cities.
So how do we defend against them? Well, we can't, frankly, because you
need AI in that case in order to be able to counter AI." But even among
peers, he describes skepticism. "I've been on panels quite a lot where
people say, 'Well, please, I don't trust the defense use of artificial
intelligence,' and that's something we need to address," van Weel said.
"We are a trusted user. We---NATO, all the 30 allies---we all subscribe
to the democratic values. We all subscribe to the values our societies
are built upon, and we're there to protect them." NATO's strategy
proposes six principles of responsible use of AI similar to the Defense
Department's Ethical Principles for Artificial Intelligence adopted in
2020---but with a plan to verify that the principles are followed.
According to NATO's list of attributes, military AI should be lawful;
responsible and accountable; explainable and traceable; reliable;
governable; and having bias mitigation. To engender confidence in the
principles, NATO has also proposed a new initiative. "Principles are
nice, but they need to be verifiable as well, and they need to be baked
in from the moment of the first conception of an idea up until the
delivery," van Weel said. To that end, to verify new AI, NATO wants to
create test centers, co-located with universities throughout the
alliance. This includes "existing test centers with knowledge, where
allies that are thinking about co-developing AI for use in the defense
sector can come in and verify, with protocols, with certain standards
that we're setting, that this AI is actually verified," van Weel said.
"[[It's not a world standard yet, but **if the 30 nations**, Western
democracies, **start out by shaping industry to adhere by these
standards,** then]{.underline}]{.mark} I feel that [[we are making an
impact, at least in the development of AI and hopefully also **in the
larger world setting standards."**]{.mark}]{.underline}

#### NATO is key to multinational alignment on AI policy---three reasons:

Zoe Stanley-**Lockman, 2022** (Defense and Strategic Studies, Nanyang
Technological University, "NATO's Role in Responsible AI Governance in
Military Affairs," [https://www.oxfordhandbooks.com/view/
10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69](https://www.oxfordhandbooks.com/view/%2010.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69),
Retrieved 6/11/2022)

To begin to fill this gap, the analysis in [[this chapter centers on two
AI governance mechanisms that NATO has at its
disposal,]{.underline}]{.mark} and subsequently explores the Alliance's
capacity to use these mechanisms to exert its influence in key pillars
of AI governance. Of the many possible AI governance mechanisms for
NATO, this chapter offers a deeper assessment of two: (1) [[strategic
and policy planning and]{.underline}]{.mark} (2) [[standards and
certification.]{.underline}]{.mark} We fashion these mechanisms as
primary components that connect NATO technology governance measures and
responsible AI use.12 To illustrate NATO's capacity to govern AI, we
then examine three pillars, or foundational issue areas, which we
believe represent critical elements of technology governance. We argue
that, [[within each pillar,]{.underline} [**NATO is uniquely situated to
facilitate cooperation**]{.underline} ]{.mark}via its governance
mechanisms, [[with a view to shaping the future of AI for the Alliance
and maintaining a competitive edge. Each
pillar]{.underline}]{.mark}---(1) [[ethics and
values]{.underline}]{.mark}, (2) [[legal norms, and]{.underline}]{.mark}
(3) [[security and safety]{.underline}]{.mark}---is an area where
researchers and analysts have acknowledged significant governance
challenges, both at a national level and for international organizations
like NATO. [[Each pillar]{.underline},]{.mark} discussed in depth below,
[**[illustrates NATO's potential]{.mark}** as a governance stakeholder
[that **can encourage multinational alignment** on policy]{.mark} and
standards [for safer and better outcomes in future
operations]{.mark}]{.underline}.

#### NATO has a unique role to play as an AI leader.

Zoe Stanley-**Lockman, 2022** (Defense and Strategic Studies, Nanyang
Technological University, "NATO's Role in Responsible AI Governance in
Military Affairs," [https://www.oxfordhandbooks.com/view/
10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69](https://www.oxfordhandbooks.com/view/%2010.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69),
Retrieved 6/11/2022)

At the core, this chapter argues that [[NATO is well positioned to
steward the development of military AI and institute governance
mechanisms towards coalition inclusion of responsible AI while
simultaneously maintaining incentives for comparative
advantage]{.mark}.]{.underline} Using the three pillars---ethics and
values, legal norms, and safety and security---as issue areas which
present AI governance challenges, we show that [[NATO has space to
emerge as a leader in AI governance and contribute to responsible
adoption of EDTs in the international security environment. This builds
on foundations that derive NATO's responsibilities to govern AI
according to its values, legal obligations, and institutional
interests]{.underline}.]{.mark} These foundations from both STS and
military innovation studies offer ways that the Alliance can activate
its existing governance mechanisms to exert influence in new ways. Not
only is this influence important for the Alliance to bolster its
institutional relevance in an evolving international security
architecture, but it also dovetails with its capacity to shore up
military effectiveness and interoperability as Allies modernize their
arsenals and associated concepts into the frontier of AI.

### A2: Private Sector Counterplan

#### Private sector AI can't lead to AI leadership---the government is critical.

Michael C. **Horowitz, 2018** (Professor at the University of
Pennsylvania, "Artificial Intelligence, International Competition, and
the Balance of Power," Retrieved 6/11/2022 from
<https://tnsr.org/2018/05/artificial-intelligence-international-competition-and-the-balance-of-power/>)

Some might argue that it is necessary for the United States to develop
and announce a formal AI strategy similar to China's.122 [[While there
are plenty of private-sector incentives for the development of AI
tech]{.underline}]{.mark}nology, [[**only the government** can
coordinate AI investments and ensure the development of particular
implementations that it considers critical for AI
leadership]{.underline}]{.mark}.123
