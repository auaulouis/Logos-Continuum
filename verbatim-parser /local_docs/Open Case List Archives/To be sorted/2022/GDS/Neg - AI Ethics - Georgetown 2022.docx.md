**NEG**

**Case**

**[\*JOINT OPERATIONS ADV\*]{.underline}**

**[Say No\-\--1NC]{.underline}**

**NATO allies say no\-\--divergent demands and public opposition.**

**HeikkilÄ 22**, 7-4-2022, \"NATO wants to set AI standards. If only its
members agreed on the basics.,\" POLITICO,
https://www.politico.eu/article/nato-ai-artificial-intelligence-standards-priorities/

[On paper, NATO is the ideal organization to go about setting standards
for military applications of artificial intelligence. **But the widely
divergent priorities** and budgets of its 30 members **could get in the
way.**]{.underline}

[The Western military alliance
has [identified](https://www.nato.int/nato_static_fl2014/assets/pdf/2020/12/pdf/201201-Reflection-Group-Final-Report-Uni.pdf) artificial
intelligence as a key technology needed to maintain an edge over
adversaries, and it wants to lead the way in establishing common ground
rules for its use. ]{.underline}

"We need each other more than ever. No country alone or no continent
alone can compete in this era of great power competition," NATO Deputy
Secretary-General Mircea Geoană, the alliance's second in command, said
in an interview with POLITICO.

[The standard-setting effort comes as China is pressing ahead with AI
applications in the military largely free of democratic
oversight]{.underline}.

David van Weel, NATO's assistant secretary general for emerging security
challenges, said Beijing\'s lack of concern with the tech\'s ethical
implications has sped along the integration of AI into the military
apparatus.

\"I\'m \... not sure that they\'re having the same debates on principles
of responsible use or they\'re definitely not applying our democratic
values to these technologies," he said.

[Meanwhile, the EU --- which has pledged to roll out the world\'s first
binding rules on AI in coming weeks --- is seeking closer collaboration
with Washington to oversee emerging technologies, including artificial
intelligence. But those **efforts have been slow in getting off the
ground**.]{.underline}

For Geoană, that collaboration will happen at NATO, which is working
closely with the European Union as it prepares AI regulation focusing on
"high risk" applications.

The pitch

NATO does not regulate, but "once NATO sets a standard, it becomes in
terms of defensive security the gold standard in that respective field,"
Geoană said.

The alliance\'s own AI strategy, to be released before the summer, will
identify ways to operate AI systems responsibly, identify military
applications for the technology, and provide a "platform for allies to
test their AI to see whether it\'s up to NATO standards," van Weel
said. 

The strategy will also set ethical guidelines around how to govern AI
systems, for example by ensuring systems can be shut down by a human at
all times, and to maintain accountability by ensuring a human is
responsible for the actions of AI systems.

"If an adversary would use autonomous AI powered systems in a way that
is not compatible with our values and morals, it would still have
defense implications because we would need to defend and deter against
those systems," van Weel said. 

"We need to be aware of that and we need to flag legislators when we
feel that our restrictions are coming into the realm of \[being
detrimental to\] our defense and deterrence," he continued.

Mission impossible?

[The problem is that NATO\'s members are at **very different stages**
when it comes to thinking about AI in the military context.]{.underline}

[The U.S., the world\'s biggest military spender, has prioritized the
use of AI in the defense realm. But in Europe, most countries --- France
and the Netherlands excepting --- barely mention the technology's
defense and military implications in their national AI
strategies. ]{.underline}

["It's absolutely no surprise that the U.S. had a military AI strategy
before it has a national AI strategy,\" but the Europeans \"did it
exactly the other way around,\" said Ulrike Franke, a senior policy
fellow at the European Council on Foreign Relations, said:]{.underline}

[That echoes familiar transatlantic differences --- and previous U.S.
President Donald Trump\'s complaints --- over defense spending, but also
highlights the different approaches to AI regulation more
broadly.]{.underline}

The EU\'s AI strategy takes a cautious line, touting itself as
\"human-centric,\" focused on taming corporate excesses and keeping
citizens\' data safe. The U.S., which tends to be light on regulation
and keen on defense, sees things differently.

[There are also **divergences** over **what technologies the alliance
ought to develop**, including lethal autonomous weapons systems ---
often dubbed "killer robots" --- programmed to identify and destroy
targets without human control. ]{.underline}

[Powerful NATO members including France, the U.K., and the U.S. have
developed these technologies and oppose a treaty on these weapons, while
others like Belgium and Germany have [expressed serious
concerns](https://www.stopkillerrobots.org/action-and-achievements/) about
the technology.]{.underline}

[These weapons systems have also faced **fierce public opposition** from
civil society and human rights groups, including from United Nations
Secretary-General António Guterres, who in
2018 [called](https://www.un.org/sg/en/content/sg/speeches/2018-11-05/remarks-web-summit) for
a ban. ]{.underline}

[Geoană said the alliance has "retained autonomous weapon systems as
part of the interests of NATO." The group hopes that its upcoming
recommendations will allow the ethical use of the technology without
"stifling innovation." ]{.underline}

**NATO says no\-\--[political frition]{.underline} prevents unity on AI
standards.**

Zoe **Stanley-Lockman &** Lena **Trabucco 22**, Stanley-Lockman is an
Associate Research Fellow in the Military Transformations Programme at
the Institute of Defence and Strategic Studies at the S. Rajaratnam
School of International Studies in Singapore; Lena Trabucco is a dual
degree candidate pursuing a PhD in political science at Northwestern
University and a PhD in Law at iCourts Center of Excellence in
International Courts at the University of Copenhagen, "NATO's Role in
Responsible AI Governance in Military Affairs," The Oxford Handbook of
AI Governance, edited by Justin Bullock et al., Oxford University Press,
03/18/2022, DOI.org (Crossref),
doi:10.1093/oxfordhb/9780197579329.013.69

On that note [**NATO**, or]{.underline} **[any]{.underline}** other
**[i]{.underline}**nternational **[o]{.underline}**rganization,
[is]{.underline} **[not exempt]{.underline}** [from]{.underline} these
[**political hurdles**. As EDTs increasingly become a focal
point]{.underline} in the geopolitical space, [any approach of AI
governance in the international security environment will have global
**political undertones**. This will]{.underline} undoubtedly [be
a]{.underline} **[significant hurdle]{.underline}** [for NATO as it
balances responsible AI development and Allied]{.underline} coordination
and **[coop]{.underline}**eration in a changing geopolitical landscape.
And [certainly]{.underline}, the **[political]{.underline}** [realities
may]{.underline} well [represent the]{.underline} **[greatest
challenge]{.underline}** [and]{.underline}
**[disincentivize]{.underline}** [NATO to emerge as a]{.underline}
**[leader]{.underline}** in responsible military AI. Nevertheless, the
three pillars indicate that NATO is an institution with considerable
opportunity to shape responsible AI governance. More specifically, this
entails urging and facilitating Allied standards and policies to
establish foundations for emerging military technology built on informed
and ethical principles and enhance the international security
environment.

**[Interop Fails\-\--1NC]{.underline}**

**Interoperability challenges are [structural]{.underline}\-\--they
[can't be fixed]{.underline} through consultation or dialogue.**

Edward Hunter **Christie 22**, Senior Research Fellow at the Finnish
Institute of International Affairs, "Defence Cooperation in Artificial
Intelligence: Bridging the Transatlantic Gap for a Stronger Europe,"
European View, vol. 21, no. 1, SAGE Publications Ltd, 04/01/2022, pp.
13--21

Interoperability challenges

Interoperability can be defined as 'the ability of systems, units or
forces to provide services to, and accept services from other systems,
units or forces and the use the services so exchanged to enable them to
operate effectively together' (Dufour 2018, 1).

[The]{.underline} first [general challenge to interoperability is the
**overall gap**]{.underline} [between the US and Europe in terms
of]{.underline} [**total defence investment**, as well as
in]{.underline} terms of **[civilian technological
attainment]{.underline}** [with]{.underline} respect to
**[AI]{.underline}** and related technologies. [There is]{.underline}
**[no]{.underline}** single [**solution to this problem**, which is
much]{.underline} **[broader]{.underline}** [in scope than]{.underline}
[**traditional military--technical standards**, such as those pursued
in]{.underline} the **[NATO]{.underline}** context [through]{.underline}
[**existing mechanisms**. For this **broad**]{.underline}
[challenge]{.underline}, **[overall]{.underline}** [policy decisions
relating to]{.underline} national **[investment]{.underline}** choices
[and]{.underline} **[tech]{.underline}**nology **[policy]{.underline}**
coordination [between the two sides]{.underline} of the Atlantic [are
of]{.underline} **[particular importance]{.underline}**. Further
discussion of this follows in the sections on investment challenges and
international security challenges.

[A]{.underline} **[second]{.underline}** [challenge]{.underline} to
interoperability [is that]{.underline}, as far as digital technologies
are concerned, [the]{.underline} **[civilian]{.underline}**
[sector]{.underline} of the economy, [on both sides]{.underline} of the
Atlantic, [is]{.underline} **[more advanced]{.underline}**, more
**[dynamic]{.underline}** [and]{.underline} also **[not]{.underline}**
especially **[oriented]{.underline}** [towards]{.underline} meeting
**[military needs]{.underline}**. For decades, the military sector has
represented only a very small share of the total sales volume of the
computing and semiconductor industries. The same pattern is repeating
itself currently with AI. This stands [in]{.underline} **[great
contrast]{.underline}** [to]{.underline} **[narrower]{.underline}**
[dual-use technologies, for example aerospace, where the military sector
remains inherently]{.underline} **[important]{.underline}**. With
digital technologies, defence institutions are under much more pressure
to either adapt to civilian industry products and standards or to pay a
significant premium to suppliers to secure military-grade equipment and
software.

[A third challenge]{.underline} to interoperability [lies in how AI is
implemented in **practice**]{.underline}. To set up a bespoke
machine-learning algorithm in a given data environment, best practice in
the software industry is to pursue some variant of **['agile'
development]{.underline}**. This involves a very different
product-development cycle, essentially proceeding [with
multiple]{.underline} **[rapid iterations]{.underline}** [of
an]{.underline} **[imperfect product]{.underline}** that is released in
preliminary versions and later revised---like software products released
in various 'beta versions'---with upgrades developed over time. This
**[contrasts greatly]{.underline}** [with the traditional production of
major military platforms, which puts a]{.underline}
**[premium]{.underline}** [on]{.underline} strict **[quality
control]{.underline}** [and]{.underline} **[compliance]{.underline}**
with requirements [at]{.underline} **[every development
step]{.underline}**---an approach referred to in the software industry
as 'waterfall' development (Christie 2021b, 87). **[Agile]{.underline}**
product [development may pose **challenges**]{.underline}
[to]{.underline} [**interoperability**. Unless very tight standards are
applied, there is a considerable risk of]{.underline}
**[divergences]{.underline}** in how different national institutions go
about solving a particular AI or data analytics problem.

With large traditional military platforms there are long time frames
during which states can take coordination steps, either by purchasing
the same platforms, or by building consensus in terms of requirements
and standards. However, [when a]{.underline} comparatively **[small
team]{.underline}** [works **dynamically**]{.underline} [to generate
an]{.underline} **[algorithmic solution]{.underline}** [to
a]{.underline} **[particular problem]{.underline}** [in]{.underline} a
matter of **[weeks]{.underline}** or months, [traditional coordination
through existing consultation mechanisms may pose]{.underline} **[risks
to the speed advantage inherent to agile development]{.underline}**.
Conversely, once a solution has been developed, its adoption in somewhat
different environments may be challenging for a range of technical
reasons. None of these issues is insurmountable, but they do pose, in a
new light, classical trade-offs between the benefits of inventiveness
and dynamism, on the one hand, and those of imposing constraints through
standards and other harmonising measures to ensure that new products can
be broadly used and shared on the other. In the case of AI, a typical
observation is that there are many excellent prototypes and pilot
projects in numerous defence institutions, but [there are]{.underline}
also **[serious]{.underline}** outstanding **[challenges]{.underline}**
[in terms of **scaling up** to]{.underline}
**[enterprise]{.underline}**-wide [solutions, **let alone Alliance-wide
solutions**]{.underline}.

**[Alt Causes\-\--1NC]{.underline}**

**[Tons]{.underline} of issues are fracturing NATO. It's a
[structural]{.underline} problem of [interest divergence]{.underline},
not something that can be solved through limited dialogue.**

Eugene **Rumer &** Richard **Sokolsky 4/11**, Rumer, a former national
intelligence officer for Russia and Eurasia at the U.S. National
Intelligence Council, is a senior fellow and the director of Carnegie's
Russia and Eurasia Program; Sokolsky is a nonresident senior fellow in
Carnegie's Russia and Eurasia Program, "Putin's War Against Ukraine and
the Balance of Power in Europe," Carnegie Endowment for International
Peace, 4-11-2022,
https://carnegieendowment.org/2022/04/11/putin-s-war-against-ukraine-and-balance-of-power-in-europe-pub-86832

[Notwithstanding the allies']{.underline} **[early]{.underline}** [show
of unity]{.underline} in the wake of the Russian attack on Ukraine, some
of [their]{.underline} **[differences]{.underline}** [and]{.underline}
**[challenges]{.underline}** [to a]{.underline} **[more robust NATO
posture]{.underline}** [have]{.underline} **[not
disappeared]{.underline}** entirely. [These include the
varying]{.underline} **[interests]{.underline}** [and]{.underline}
**[priorities]{.underline}** [of]{.underline} the EU's and NATO's
[**diverse members**, as well as likely disagreements over **which
threats and challenges**]{.underline} [should be]{.underline}
**[privileged]{.underline}** [in]{.underline} **[resource
allocation]{.underline}** decisions ([among issues ranging from the
Russian threat, China, climate change, pandemics, immigration, borders,
refugees, or diversification of energy supplies]{.underline}). [It would
be prudent]{.underline} [to]{.underline} **[not take for
granted]{.underline}** [that Europe will forge]{.underline} the
**[political unity]{.underline}** [and]{.underline}
**[raise]{.underline}** [the]{.underline} **[billions]{.underline}** of
euros [it will require to create a]{.underline} **[first-class
military]{.underline}** that might substitute for or provide a
substantial addition to NATO's military kit.

Moreover, [the unanimity with which Europe came together to impose
sanctions on Russia and help Ukraine is likely due to the fact that
Ukraine is **not a NATO member**]{.underline}, and demonstrations of
solidarity with it do not involve defense commitments through NATO's
Article 5. [In the event of a Russian attack against a]{.underline}
**[NATO member]{.underline}** country, [the specter of]{.underline} an
**[all-out war]{.underline}** with Russia [may lead some]{.underline}
allies [to demonstrate]{.underline} **[less resolve]{.underline}**
[and]{.underline} **[more caution and hesitation]{.underline}**.

One headline is likely to become a trend line: [Putin has]{.underline}
**[confirmed]{.underline}** [that]{.underline} **[nuclear weapons are
useful]{.underline}** for a wide range of deterrence and coercive
purposes to go along with what will still be formidable conventional
capabilities in a short-war scenario, such as a quick land grab in the
Baltic region. Several implications flow from this development.

First, [notwithstanding]{.underline} **[rhetoric]{.underline}** about
defending every inch of NATO territory and the alliance's impressive
show of resolve, [NATO may be **unable**]{.underline} [or]{.underline}
**[unwilling]{.underline}** [to conduct an Article 5 intervention
against a Russian attack. The alliance may choose]{.underline}
**[instead]{.underline}** [to form a]{.underline} **[coalition of
willing NATO countries]{.underline}** [to defend]{.underline} vulnerable
countries on [its eastern flank]{.underline}.

**[AT: Russia War Impact\-\--1NC]{.underline}**

**Larger Russia war is [impossible]{.underline}\-\--they don't have
[capabilities]{.underline} AND [deterrence]{.underline} prevents going
[nuclear]{.underline}.**

Limor **Simhony 22**, policy advisor and researcher based in London,
"NATO Intervention in Ukraine Won't Spark World War III," Foreign
Policy, 4/1/2022,
https://foreignpolicy.com/2022/04/01/nato-intervention-in-ukraine-wont-spark-world-war-iii/

[The]{.underline} main [concern is any]{.underline} such [escalation
could lead to]{.underline} **[World War III]{.underline}**. [There
are]{.underline} two [reasons that this is]{.underline}
**[unlikely]{.underline}**. The [first]{.underline} is that
[Russia's]{.underline} **[military capabilities]{.underline}**
[are]{.underline} **[poor]{.underline}** relative to those of Western
armies. [Their forces are]{.underline} **[not]{.underline}**
sufficiently [**trained**; their equipment and weapons are]{.underline}
**[dated]{.underline}** [and]{.underline} [**inferior**; they
experience]{.underline} **[major logistical, operational, and tactical
difficulties]{.underline}**; and [their soldiers have]{.underline}
**[low morale]{.underline}**.

[Damaging]{.underline} economic **[sanctions]{.underline}** also
[mean]{.underline} that [Russia may not be able to]{.underline}
**[fund]{.underline}** [a wider war. The expectation that Moscow will be
**able** to]{.underline} **[escalate]{.underline}** the war into other
theaters in an effective way, especially by conventional means,
[is]{.underline} [**unrealistic**. It is possible that]{.underline} if
the Russian military continues to struggle, Russian President Vladimir
[Putin will deploy]{.underline} chemical or even
**[nuclear]{.underline}** [weapons]{.underline} to increase gains and
deter the West from interfering---[but that is]{.underline}
**[unlikely]{.underline}**.

The [second]{.underline} is that [Russia has become **isolated**. To
fight a]{.underline} [**world war**, Russia needs]{.underline} powerful
[**allies**, which it]{.underline} **[does not have]{.underline}**. Its
strongest ally, **[China]{.underline}**, [has]{.underline} largely
[remained on the]{.underline} **[sidelines]{.underline}** since the war
started. It abstained from voting against the U.N. resolution demanding
that Russia ends its offensive, and it is worried about secondary
sanctions if it aids Russia. The only countries besides Russia that
voted to reject the resolution were Belarus, North Korea, Eritrea, and
Syria---hardly a winning alliance. Both [world wars saw blocks of
powerful allies fight one another. Currently, such a bloc
does]{.underline} **[not exist]{.underline}** [on]{.underline}
**[Russia's]{.underline}** [side]{.underline}.

[These factors mean]{.underline} that [there is]{.underline}
**[not]{.underline}** a **[high risk of substantial escalation into
total global war]{.underline}**. This should be enough to convince
Western nations to change their engagement policy and help Ukraine win
the war by repulsing an opponent that is considerably inferior
militarily to their own forces. It is unlikely to happen for two main
reasons: fear of Russian nukes and the West's aversion to casualties.

[The most widely discussed reason is the concern that Russia will
use]{.underline} **[nuclear weapons]{.underline}** if NATO intervenes
militarily. Putin has reasserted Russia's right to use nuclear weapons
in Ukraine, making this a legitimate concern. [However, it is **more
likely**]{.underline} [that]{.underline} nuclear
**[deterrence]{.underline}**---albeit different to Cold War
deterrence---[will]{.underline} [**hold**. Russia's deployment of
nuclear weapons, either against Ukraine or against]{.underline} a
[NATO]{.underline} member state, [could incur]{.underline}
**[devastating consequences]{.underline}** for Russia.

As then-U.S. Defense Secretary James Mattis said in 2018, dismissing the
notion that tactical nuclear weapons are somehow a lesser threat,
"**[Any]{.underline}** [nuclear weapon used]{.underline} ... [is
a]{.underline} **[strategic game-changer]{.underline}**." Therefore, [if
NATO retaliates with a]{.underline} **[powerful response]{.underline}**,
either nuclear or conventional, [it may target
**strategic**]{.underline} Russian **[military positions]{.underline}**
[and]{.underline} perhaps [even sites of]{.underline} [**political
power**, aiming at]{.underline} **[wiping out]{.underline}** Russian
**[military capabilities]{.underline}** [and targeting]{.underline}
those in positions of authority---a move that could threaten Putin's
**[leadership]{.underline}**. A NATO **[retaliation]{.underline}**
[should therefore be considered a]{.underline} **[major
threat]{.underline}** [to Putin]{.underline}, especially because rivals
include numerous nations with considerable nuclear capabilities, such as
the United States, United Kingdom, and France.

[In addition, at the heart of this conflict]{.underline}
[stands]{.underline} [**national identity**. Putin has]{.underline}
**[little motivation]{.underline}** [to devastate a]{.underline}
**[county]{.underline}** that [he]{.underline} **[wishes to
annex]{.underline}** [and has]{.underline} **[not knowingly made any
preparations for using nuclear weapons]{.underline}**. Fear of the bomb
accounts for one reason behind the West's decision to leave Ukraine to
fight on its own.

Another consideration is fundamental to the West: casualty sensitivity.

Sensitivity to casualties---specifically deaths among troops---has
become a major element affecting liberal democracies' war preparedness,
use of force, and decision-making regarding participation in wars.

The trauma of Britain's so-called lost generation followed the loss of
750,000 troops in World War I. It overwhelmed the public and affected
interwar foreign policy and military preparedness in a misguided attempt
to avoid another war. The same happened in other liberal democracies
scarred by the war, such as France, whereas countries with shallower
liberal and democratic traditions---such as Germany, which suffered
heavier losses than France and Britain---consequently gravitated toward
fascism and reverted to militarism.

Conflict behavior and public attitudes toward wars have undergone deep
changes during the 20th and 21st centuries as a result of extensive
liberalization and democratization processes. Liberal concepts of
individualism, personal freedoms, a reduction in internal violence, and
a comfortable lifestyle that includes longer life expectancy brought
about changes in attitudes about war---primarily, that it is an
undesirable way to resolve conflicts. Rejecting the violence and
suffering that comes with it has made it difficult for leaders of
liberal democracies to justify to the public participation in wars,
especially wars of choice, in which the nation is not under direct
threat.

The United States' interventions in Vietnam, Lebanon, Somalia, and Iraq,
for example, were shaped by the casualties incurred. The 1983 bombing of
the Marine Corps barracks in Lebanon that killed 241 U.S. service
members and the 1993 Battle of Mogadishu, where 18 U.S. soldiers died,
provoked powerful reactions against the missions, bringing them to an
abrupt end despite them initially enjoying wide public support.

A similar reaction came after the Tet Offensive in Vietnam in January
1968, which resulted in 1,500 American fatalities. It was a watershed
moment that changed the debate about the war and led to the shelving of
plans for escalation. Support for the second war in Iraq also fell
dramatically as deaths mounted, causing the American public to question
the necessity of the war or its conduct and chances of success.

Israel's use of force against Hezbollah in Lebanon has been heavily
influenced by casualty aversion. This included an overreliance on air
power in an attempt to limit fatalities among ground forces during the
2006 Lebanon War at the price of undermining military effectiveness.
Then-Israeli Chief of Staff Lt. Gen. Dan Halutz famously commented: "We
didn't send ground troops into Lebanon because the public couldn't
stomach any more deaths."

Israel's withdrawal from southern Lebanon, where forces had been
deployed between 1985 and 2000, was also heavily influenced by the
public's dissatisfaction with the casualties incurred, particularly
after several costly incidents during the 1990s undermined support for a
continued military presence and enhanced criticism of the government.

Nondemocracies and guerrilla and terrorist organizations do not exhibit
such an aversion to casualties. During the Iran-Iraq War, both sides
callously scarified children by using them as human minesweepers and
shields. Similarly, both the Viet Cong in Vietnam and Hezbollah in
Lebanon showed considerable willingness to sacrifice lives despite
suffering more losses than their liberal enemies. Then-Egyptian
President Anwar Sadat famously said, "Egypt would sacrifice a million
Egyptian soldiers" during the October 1973 war against Israel despite
not facing an existential threat or serious strategic concerns.

There has been little evidence to suggest there is heightened
sensitivity to losses among troops in Russia, a nation with a history of
mass deaths in both the world wars, its own civil war, and from the
brutal suppression and killing of its own people. The continued use of
force in Ukraine, which has resulted in as many as 15,000 Russian
military deaths so far according to the Washington Post, indicates that
casualties are of no concern to Russia's top brass. This stands in
contrast to Ukraine, which accepts its causalities because it is
fighting an existential war for independence and national survival.

Casualty sensitivity has been one of the factors shaping democracies'
behavior, with Western politicians preferring to avoid direct engagement
in wars or to limit the use of ground forces, even at the price of
compromising objectives and deterrence. It is one of the reasons that a
policy of nonengagement was adopted, without question or hesitation,
regarding Ukraine, long before Putin raised the alert status of Russia's
nuclear arsenal.

Fear of casualties among soldiers meant that a policy of nonengagement
has existed prior to Russia's invasion---and therefore separately to a
concern about escalating into a broader war. This has been understood by
Putin, who bet---correctly---that Western nations will not take an
active role in the war by using direct force against Russian troops, not
only out of fear of escalation but as a result of a preexisting doctrine
that seeks to minimize casualties. Had the West exhibited less casualty
aversion, this could have acted as a greater deterrent against Russian
aggression.

For the war in Ukraine, unlike the risk of escalation and use of nuclear
weapons, the risk of incurring casualties is high. Considering how
formative aversion to casualties has been, committing troops to fight
Russia will require liberal democracies to undergo a major paradigm
shift.

But there are ways to mitigate the effect of casualty sensitivity on
public opinion. Adjusting the public's expectations regarding the length
of the war and the casualties that will result as well as displaying
internal political unity could help. Employing force that relies
primarily on air power, which limits casualties, can be used; during
Israel's 2006 war in Lebanon and other wars, this has proved to have
only limited effectiveness. However, if done in collaboration with
Ukrainian ground forces, this could have better chances of success.

This war brought a shift in attitudes toward wars in Europe. The
Germans, famously pacifist since 1945, have undergone the largest shift
and now support military aid to Ukraine and a considerable increase in
funds to rebuild Germany's military power. But a bigger shift is needed
considering Russia's aggression.

Russia is no stranger to targeting civilians, as it has done in the
carpet-bombing of Grozny in Chechnya, in 1994 to 1995 and 1999 to 2000.
It is doing this again now. It is time for the West to stop being afraid
of limited threats that are not likely to materialize and to use its
military superiority to help Ukraine defend its independence.

[Intervention will]{.underline} [**not turn this local conflict into
World War III**. It runs the risk of causing a tactical nuclear attack
on Ukraine, but this risk is]{.underline} **[limited]{.underline}**
[given what]{.underline} any **[retaliation]{.underline}** [could mean
for]{.underline} **[Russia]{.underline}**. The West must therefore
decide how long it will refrain from engagement and allow Russia to sow
devastation in pursuing expansionist ambitions for fear of casualties or
the bomb.

**[AT: Russia War Impact\-\--AT: Invasion]{.underline}**

**Zero chance Russia attacks NATO after Ukraine**

Paul **Miller 22**, professor of the practice of international affairs
at Georgetown University, "Ukraine Is Not World War III," The Dispatch,
3/8/2022, https://thedispatch.com/p/ukraine-is-not-world-war-iii?s=r

[War **gets the blood up**]{.underline}. Gary
**[[Kasparov]{.underline}]{.mark}**---former world chess champion turned
dissident against Putin's Russia---**[[claimed]{.underline}]{.mark}** on
March 3 [that "[this is **already World War III**]{.mark}]{.underline}."

"Putin started it long ago & Ukraine is only the current front,"
Kasparov [[argued]{.underline}]{.mark}. [[He will]{.underline}
**[escalate anyway]{.underline}**]{.mark}, and it\'s even more likely if
he succeeds in destroying Ukraine because you have again convinced him
you won\'t stop him even though you could."

Kasparov has warned about Putin's aggression for years, and his book
Winter Is Coming largely predicted what we're witnessing today. But
sayijeng we are already fighting World War III is the classic
never-appease-aggressors logic by which any authoritarian is likened to
Hitler in 1939: if we don't stop him now, he will only be emboldened to
invade the next country, and the next, until he is knocking on our front
door with an armored division or two. Better to accept reality and start
World War III now than wait for Putin to initiate it and force us to
fight it on his terms.

[[The]{.underline} **[logic]{.underline}**]{.mark} **[is
familiar]{.underline}** and the danger is plain, [which [is
why]{.mark}]{.underline} [**[some]{.underline}**]{.mark} people
[[seem]{.underline}]{.mark} more [**[willing]{.underline}** [to
risk]{.underline} **[general war]{.underline}**]{.mark} **[against
Russia]{.underline}** [in an]{.underline} [**all-out effort to stop
Putin [now, before he invades the next country]{.mark}**.
Kasparov's]{.underline} **[argument]{.underline}** has been echoed by
other commentators who warn Putin will not stop at Ukraine, or who
insist the U.S. and NATO must militarily intervene in the war in
Ukraine. The head of the European Council on Foreign Relations openly
called for regime change in Russia. Ukrainian President Volodymyr
Zelensky called on NATO to impose a no-fly zone over Ukraine, an idea
former National Security Adviser John Bolton partially endorsed. A
no-fly zone, of course, would involve NATO aircraft shooting down
Russian warplanes over Ukrainian skies. [To [put]{.mark} it]{.underline}
**[[plainly]{.underline}]{.mark}**: A no-fly zone [is
[a]{.mark}]{.underline} **[[declaration of war]{.mark} against
Russia]{.underline}** [[and]{.mark} the]{.underline} **[first step on a
path]{.underline}** [that]{.underline} would [lead to]{.underline}
**[general war]{.underline}**.

The war in [Ukraine is]{.underline} [not]{.underline}
**[yet]{.underline}** [World War III. To act as if it]{.underline}
**[were]{.underline}** [by]{.underline} **[proactively
escalating]{.underline}** [or]{.underline} **[expanding the
war]{.underline}** [is both]{.underline} **[strategically
unnecessary]{.underline}** [and]{.underline} [**immoral**. It
[would]{.mark} be to]{.underline} **[[trigger the very war
we]{.underline}]{.mark}** should [**[most want to avoid]{.mark}**. The
war in Ukraine is]{.underline} an **[extremely dangerous]{.underline}**
development for world order, [the only thing]{.underline}
**[more]{.underline}** [dangerous than which would be to]{.underline}
**[overreact]{.underline}** and recklessly expand the war.

Prelude to a conflict.

[Treating the war as if it were]{.underline} **[already]{.underline}**
[World War III]{.underline}, and Russia's invasion of Ukraine a prelude
to general European conflict, [is]{.underline}
**[unnecessary]{.underline}** [because [Russia]{.mark}]{.underline}
[**[cannot]{.underline}** [and]{.underline} **[will not expand the war
beyond Ukraine]{.underline}**]{.mark}[. The]{.underline}
**[historical]{.underline}** [analogy---[Putin as]{.mark}]{.underline}
[**[Hitler]{.underline}**]{.mark} [hellbent on **continental
conquest**---[is]{.mark}]{.underline} [[**flawed**]{.mark}. While Putin
may have]{.underline} [**boundless ambition**, [his]{.mark}]{.underline}
actual [**[capabilities]{.underline}** [are]{.underline}]{.mark}
**[severely [bounded]{.mark}]{.underline}** by reality.

[[The **German**]{.underline} [military]{.underline}]{.mark}
[in]{.underline} **[1940]{.underline}**, as its blitzkrieg swept across
Europe, [[numbered]{.underline}]{.mark} some **[6 million]{.underline}**
soldiers in all branches. [Over the course of the war, some]{.underline}
**[[18 million]{.mark} Germans served]{.underline}** in uniform,
[approaching]{.underline} [**one-third of its total population**.
Germany was the]{.underline} economic **[powerhouse of
Europe]{.underline}** in 1940 and could outproduce any European
competitor in military equipment and supplies.

[At the start of the war, the Germans]{.underline} arguably [[had
the]{.underline} **[best tank]{.underline}**]{.mark} (the Panzer)
[[and]{.mark} the]{.underline} **[best [fighter]{.mark}]{.underline}**
plane (the Messerschmitt). [The German scientific and industrial base
was among the best in Europe and had a head start in its focus on
military technology. German military scientists invented the jet,
rocket, cruise missile, and helicopter before any of the Allies. And the
German military was infamous---again, at the beginning of the war---for
its extraordinary training, discipline, and cohesion.]{.underline}

**[[None]{.mark} of that is [true of Russia]{.mark} or the Russian
military]{.underline}** today. [The Russian military [has]{.mark}
about]{.underline} **[[1 million]{.underline}]{.mark}** active-duty
[soldiers]{.underline}, a fraction of what Germany had at the beginning
of its conquests. Russia **[could]{.underline}** [call up]{.underline}
vast [**reserves**, but it would take]{.underline}
**[years]{.underline}** [to turn them into a]{.underline}
**[trained]{.underline}** [and]{.underline} [**capable fighting force**.
Russian]{.underline} **[[tanks]{.underline}]{.mark}** [[and]{.underline}
**[jets]{.underline}** [are]{.underline}]{.mark} better than Germany's
of 1940---but **[[not better]{.mark} than NATO's]{.underline}** in 2022.
[Over the past week, the Russian military [has
proven]{.mark}]{.underline} [**[inadequate in basic
tasks]{.underline}**]{.mark} like vehicle maintenance, let alone
operational planning, combined arms operations, air assault, and air
defense.

[The 21s century **Russia**n military overwhelmed **smaller** opponents
in **Chechnya**]{.underline} [and]{.underline} **[Syria]{.underline}**
[through]{.underline} **[sheer]{.underline}** force of
**[numbers]{.underline}** [and]{.underline} **[utter disregard for the
laws]{.underline}** of armed conflict. [But]{.underline} it has
**[clearly struggled]{.underline}** [when faced with a]{.underline}
moderately **[larger]{.underline}** [and]{.underline} **[more
challenging opponent]{.underline}** in Ukraine. [The Russian army
is]{.underline} **[hardly ready to invade the next
country]{.underline}** over, or the one after that.
**[[No]{.underline}]{.mark}** Russian [**[blitzkrieg is in the
offing]{.underline}**. [It is]{.underline} **[materially
incapable]{.underline}**]{.mark} [of doing so. **[Hitler]{.mark}**
[spent]{.mark} the **better part of [a decade]{.mark}**]{.underline}
[[rearming]{.mark} and preparing]{.underline} for his war
([[and]{.underline} **[still lost]{.underline}**]{.mark}).

And [[Russia is]{.underline} **[utterly incapable
of]{.underline}**]{.mark} waging a [pro**[long]{.mark}**ed
**[war]{.mark}**. Even]{.underline} **[before]{.underline}** global
economic **[sanctions]{.underline}** [cratered the Russian economy last
week, it was **smaller than Italy's**. The GDP of the]{.underline}
**[U]{.underline}**nited **[S]{.underline}**tates [and]{.underline}
**[E]{.underline}**uropean **[U]{.underline}**nion [combined account for
about]{.underline} **[42 percent]{.underline}** [of the world's
wealth;]{.underline} **[Russia]{.underline}** [about]{.underline} **[3
percent]{.underline}** ([and]{.underline} **[shrinking]{.underline}**).
[Russia does have an advanced scientific and knowledge base, but because
of its economic woes struggles to translate its knowledge into
superior]{.underline} **[weaponry]{.underline}** that it can produce at
scale. If the Russians tried today, [[the]{.underline} **[Polish
army]{.underline}**]{.mark} **[backed by the American Air Force [would
win]{.mark} a [decisive]{.mark} and [rapid
victory]{.mark}]{.underline}**.

**[AT: Russia War Impact\-\--AT:
Invasion\-\--Defense\-\--Ext]{.underline}**

**[Zero chance]{.underline} of an attack on NATO. Ukraine's
[different]{.underline} because it's not covered by a [defense
commitment]{.underline}. NATO's a [clear redline]{.underline} Putin's
[deliberatly avoiding]{.underline}. Even if he [wants]{.underline} to
take over Europe, he [can't]{.underline} because of [clear
economic]{.underline}, [manpower]{.underline}, and
[technical]{.underline} constraints. That's Miller.**

**He's worried about NATO's [nukes]{.underline}\-\--he [won't risk
it]{.underline}**

Nina **Tannenwald 3/10**, teaches international relations in the
Political Science Department at Brown University, "'Limited' Tactical
Nuclear Weapons Would Be Catastrophic," Scientific American, 3/10/2022,
https://www.scientificamerican.com/article/limited-tactical-nuclear-weapons-would-be-catastrophic/

Since Russia invaded Ukraine on February 24, Russian President Vladimir
Putin has given orders to increase the alert level of Russia's nuclear
forces and has made veiled nuclear threats. The blatant aggression
against Ukraine has shocked Europe and the world. The war is a tragedy
for **[Ukraine]{.underline}**. It also [exposes the]{.underline}
**[limits]{.underline}** [of the West's]{.underline}
**[reliance]{.underline}** [on]{.underline} **[nuclear
deterrence]{.underline}**.

Deterrence refers to the idea that possessing nuclear weapons protects a
nation from attack, through the threat of overwhelming retaliation. This
concept is widely credited for helping prevent war between the United
States and the Soviet Union during the Cold War. However, Russia's
invasion of Ukraine casts a harsh light on its downsides. Most obvious
is that [[Putin is using]{.underline}]{.mark} nuclear
[**[deterrence]{.mark}** **not**]{.underline} [to]{.underline}
**[protect Russia]{.underline}** [but rather [to]{.mark} **have his way
in Ukraine**. Russia's nuclear weapons]{.underline} **[[deter the
West]{.underline}]{.mark}** [from]{.underline} **[[intervening with
conventional]{.mark} military [forces]{.mark}]{.underline}** to defend
Ukraine. Despite scattered calls in the U.S. for the creation of a
"no-fly zone" over some or all of Ukraine, the
[[Biden]{.underline}]{.mark} administration [has]{.underline} **[wisely
[resisted]{.mark}]{.underline}**. In practice this would mean shooting
down Russian planes. [It could lead to]{.underline} [**World War III**.
On the other side of the ledger, [**NATO's** nuclear weapons]{.mark}
presumably [**deter Russia** from expanding the war to **NATO
countries**]{.mark}, such as Poland, Romania or the Baltic states.
[Thus, the]{.mark}]{.underline} nuclear **[[balance of
terror]{.underline}]{.mark}** [likely]{.underline} [**[deters a wider
European war]{.underline}** [but leaves]{.underline}
**[Ukraine]{.underline}** [to]{.underline}]{.mark} [struggle on with
only]{.underline} **[limited support]{.underline}** [and perhaps
eventually to [be]{.mark}]{.underline}
[**[swallowed]{.underline}**]{.mark}. On balance, NATO states do not
seem very reassured by their vaunted nuclear deterrence. They continue
to worry about the (remote) possibility of a Russian conventional attack
beyond Ukraine.

**Residual tensions can be [managed]{.underline} to avoid
miscalculation\-\--[even if]{.underline} Russia [wins]{.underline}**

Liana **Fix &** Michael **Kimmage 2/18**, Liana Fix is a Resident Fellow
at the German Marshall Fund, in Washington, D.C.; Michael Kimmage is
Professor of History at the Catholic University of America and a
Visiting Fellow at the German Marshall Fund, served on the Policy
Planning Staff at the U.S. Department of State, where he held the
Russia/Ukraine portfolio, "What If Russia Wins?," Foreign Affairs,
2/18/2022,
https://www.foreignaffairs.com/articles/ukraine/2022-02-18/what-if-russia-wins

IMPERILING EUROPE\'S EAST

[[In]{.mark} the event of a]{.underline} **[[Russian
victory]{.underline}]{.mark}** [in Ukraine]{.underline}, Germany's
position in Europe will be severely challenged. Germany is a marginal
military power that has based its postwar political identity on the
rejection of war. The ring of friends it has surrounded itself with,
especially in the east with Poland and the Baltic states, risks being
destabilized by Russia. France and the United Kingdom will assume
leading roles in European affairs by virtue of their comparatively
strong militaries and long tradition of military interventions. The key
factor in Europe, however, will remain the United States. NATO will
depend on U.S. support as will the anxious and imperiled countries of
Europe's east, the frontline nations arrayed along a now very large,
expanded, and uncertain line of contact with Russia, including Belarus
and the Russian-controlled parts of Ukraine.

Eastern member states, including Estonia, Latvia, Lithuania, Poland, and
Romania, will likely have substantial numbers of NATO troops permanently
stationed on their soil. A request from Finland and Sweden to gain an
Article 5 commitment and to join NATO would be impossible to reject. In
Ukraine, EU and NATO countries will never recognize a new Russian-backed
regime created by Moscow. But they will face the same challenge they do
with Belarus: wielding sanctions without punishing the population and
supporting those in need without having access to them. Some NATO
members will bolster a Ukrainian insurgency, to which Russia will
respond by threatening NATO members.

Ukraine's predicament will be very great. Refugees will flee in multiple
directions, quite possibly in the millions. And those parts of the
Ukrainian military that are not directly defeated will continue
fighting, echoing the partisan warfare that tore apart this whole region
of Europe during and after World War II.

[The permanent state of **escalation** [between Russia and **Europe**
may **stay cold**]{.mark} from a **military perspective**. It is likely,
though, to be **economically hot**]{.underline}. The sanctions put on
Russia in 2014, which were connected to formal diplomacy (often referred
to as the "Minsk" process, after the city in which the negotiations were
held), were not draconian. They were reversible as well as conditional.
Following a Russian invasion of Ukraine, new sanctions on banking and on
technology transfer would be significant and permanent. They would come
in the wake of failed diplomacy and would start at "the top of the
ladder," according to the U.S. administration. In response, Russia will
retaliate, quite possibly in the cyber-domain as well as in the energy
sector. Moscow will limit access to critical goods such as titanium, of
which Russia has been the world's second-largest exporter. [This [war of
**attrition**]{.mark} will **test both**]{.underline} sides. Russia will
be ruthless in trying to get one or several European states to back away
from economic conflict by linking a relaxation in tension to these
countries' self-interest, thus undermining consensus in the EU and NATO.

Europe's strong suit is its economic leverage. Russia's asset will be
any source of domestic division or disruption in Europe or in Europe's
transatlantic partners. Here Russia will be proactive and opportunistic.
If a pro-Russian movement or candidate shows up, that candidate can be
encouraged directly or indirectly. If an economic or political sore
point diminishes the foreign policy efficacy of the United States and
its allies, it will be a weapon for Russian propaganda efforts and for
Russian espionage.

Much of this is already happening. But a war in Ukraine will up the
ante. Russia will use more resources and be unchained in its choice of
instruments. The massive refugee flows arriving in Europe will
exacerbate the EU's unresolved refugee policy and provide fertile ground
for populists. The holy grail of these informational, political, and
cyberbattles will be the 2024 presidential election in the United
States. Europe's future will depend on this election. The election of
Donald Trump or of a Trumpian candidate might destroy the transatlantic
relationship at Europe's hour of maximum peril, putting into question
NATO's position and its security guarantees for Europe.

TURNING NATO INWARD

For the United States, a Russian victory would have profound effects on
its grand strategy in Europe, Asia, and the Middle East. First, Russian
success in Ukraine would require Washington to pivot to Europe. No
ambiguity about NATO's Article 5 (of the kind experienced under Trump)
will be permissible. Only a strong U.S. commitment to European security
will prevent Russia from dividing European countries from one another.
This will be difficult in light of competing priorities, especially
those that confront the United States in a deteriorating relationship
with China. But the interests at stake are fundamental. The United
States has very large commercial equities in Europe. The European Union
and the United States are each other's largest trade and investment
partners, with trade in goods and services totaling \$1.1 trillion in
2019. A well-functioning, peaceful Europe augments American foreign
policy---on climate change, on nonproliferation, on global public
health, and on the management of tensions with China or Russia. If
Europe is destabilized, then the United States will be much more alone
in the world.

NATO is the logical means by which the United States can provide
security reassurance to Europe and deter Russia. A war in Ukraine would
revive NATO not as a democracy-building enterprise or as a tool for
out-of-area expeditions like the war in Afghanistan but as the
unsurpassed defensive military alliance that it was designed to be.
Although Europeans will be demanding a greater military commitment to
Europe from the United States, a broader Russian invasion of Ukraine
should drive every NATO member to increase its defense spending. For
Europeans, this would be the final call to improve Europe's defensive
capabilities---in tandem with the United States---in order to help the
United States manage the Russian-Chinese dilemma.

The nuclear superpowers would have to keep their outrage in check.

For a Moscow now in permanent confrontation with the West, Beijing could
serve as an economic backstop and a partner in opposing U.S. hegemony.
In the worst case for U.S. grand strategy, China might be emboldened by
Russia's assertiveness and threaten confrontation over Taiwan. But there
is no guarantee that an escalation in Ukraine will benefit the
Sino-Russian relationship. China's ambition to become the central node
of the Eurasian economy will be damaged by war in Europe, because of the
brutal uncertainties war brings. Chinese irritation with a Russia on the
march will not enable a rapprochement between Washington and Beijing,
but it may initiate new conversations.

The shock of a big military move by Russia will likewise raise questions
in Ankara. President Recep Tayyip Erdogan's Turkey has been enjoying the
venerable Cold War game of playing off the superpowers. Yet Turkey has a
substantial relationship with Ukraine. As a NATO member, it will not
benefit from the militarization of the Black Sea and the eastern
Mediterranean. Russian actions that destabilize the wider region could
push Turkey back toward the United States, which could in turn drive a
wedge between Ankara and Moscow. This would be good for NATO, and it
would also open up greater possibilities for a U.S.-Turkish partnership
in the Middle East. Rather than a nuisance, Turkey could turn into the
ally it is supposed to be.

A bitter consequence of a wider war in Ukraine is that
[**[Russia]{.underline}** [and the]{.underline}
**[U]{.underline}**]{.mark}nited **[[S]{.underline}]{.mark}**tates would
now encounter each other as enemies in Europe. Yet they [[will be
**enemies** who]{.underline} **[cannot afford to take hostilities beyond
a]{.underline}**]{.mark} [**certain [threshold]{.mark}**[.
However]{.mark} far **[apart their]{.mark}** world[**views**,
however]{.mark}]{.underline} [**ideologically [opposed]{.mark}**[, the
world's]{.mark} two most significant [nuclear powers will]{.mark} have
to **[keep their outrage in check]{.mark}**. This will amount to
[a]{.mark}]{.underline} fantastically tricky [**[juggling act]{.mark}**:
a state [of **economic warfare** and **geopolitical
struggle**]{.mark}]{.underline} across the European continent, yet a
state of affairs [that [does]{.mark}]{.underline} [**[not allow
escalation]{.mark} to tip [into]{.mark} outright [war]{.mark}**. At the
same time, U.S.-Russian confrontation can in the worst case extend to
**proxy wars**]{.underline} in the Middle East or Africa if the United
States decides to reestablish its presence after the catastrophic
Afghanistan withdrawal.

[[Maintaining]{.underline} **[communication]{.underline}**]{.mark},
especially on strategic stability and cybersecurity, [[will
be]{.underline} **[crucial]{.underline}**]{.mark}[. It is notable that
U.S.-Russian cooperation on]{.underline} **[malicious
cyber-activities]{.underline}** **[continues]{.underline}**
[even]{.underline} [**during the current tensions**. The necessity of
maintaining rigorous arms control agreements will be even greater after
a Ukraine war and the sanctions regime that follows it]{.underline}.

**Putin's aims are [limited]{.underline}**

Mitch **Clarke 3/16**, director of news and content for Jacobs Media,
citing Craig Greathouse, associate department head in political science
and international affiars at UNG, "UNG prof: Conflict unlikely to expand
beyond Ukraine," AccessWDUN, 3/16/2022,
https://accesswdun.com/article/2022/2/1080789/ung-prof-conflict-unlikely-to-expand-beyond-ukraine

Experts are divided over what Russian President Vladimir [[Putin\'s end
game]{.underline}]{.mark} in Ukraine is, but [an international
affairs]{.underline} **[expert]{.underline}** [at]{.underline}
**[UNG]{.underline}** **[[doesn\'t]{.mark} think]{.underline}** [he\'ll
try to [invade]{.mark}]{.underline} [**[any]{.underline}**]{.mark} of
the **[[former Soviet bloc countries]{.underline}]{.mark}**.

Craig Greathouse, the associate department head in political science and
international affairs, believes [Putin [would]{.mark}]{.underline}
[**[like]{.underline}** [to reconstitute]{.underline}]{.mark}
[the]{.underline} old [Soviet Union. [But that might
be]{.mark}]{.underline} **[[out of]{.mark} his
[reach]{.mark}]{.underline}**, Greathouse said.

Former Soviet bloc [[countries]{.underline}]{.mark} like Estonia,
Latvia, Lithuania [[are]{.mark} now]{.underline} [**[members of
NATO]{.mark}**, and]{.underline} the provisions of the NATO treaty\'s
**[Article 5]{.underline}** might [cause]{.underline}
**[concern]{.underline}** for Russia.

\"[If he moves to]{.underline} **[[attack]{.underline}]{.mark}** these
countries, [it]{.underline} **[[activates Article
5]{.underline}]{.mark}** of the NATO Treaty,\" Greathouse said. \"And
Article 5 is very specific. It says, \'If any member of NATO is
attacked, all the other members of NATO will come to their defense.\'
And that includes the United States.\"

[**[Ukraine]{.mark}**, on the other hand, [is]{.mark}]{.underline}
[**[not]{.underline}**]{.mark} [a NATO member]{.underline} and has
perhaps the closest historical ties to Russia.

\"Before the Soviet Union broke apart, Ukraine was a significant element
of the Soviet Union,\" Greathouse said. \"In the past, it\'s been
described as the Soviet Union\'s breadbasket. There was also a lot of
industry, especially in the eastern part of the country. Also it holds
close ties to the Crimea region, which holds one of the few ports that
Russia can use to get into the Mediterranean.\"

Greathouse said [it\'s too early to know what Putin\'s ultimate goal is.
[Putin]{.mark}, in fact, [may only be trying to claim
a]{.mark}]{.underline} **[[portion]{.mark} of Ukraine]{.underline}**.

\"That\'s going to be an interesting question, because
[[it\'s]{.underline} **[not]{.underline}**]{.mark} quite
[**[clear]{.underline}** [how **far**]{.underline} [he\'s **going to
go**]{.underline}]{.mark} [with]{.underline} **[Ukraine
yet]{.underline}**,\" he said. \"[Is he just going to take]{.underline}
**[parts]{.underline}** of it**[?]{.underline}** [Or]{.underline} is he
going to try and take [the]{.underline} **[whole country?]{.underline}**
If the reports are correct, with 190,000 Russian soldiers, I don\'t know
if he can basically control the entire Ukraine.\"

[[Greathouse]{.underline} **[doesn\'t believe the conflict will spread
beyond Ukraine]{.underline}**]{.mark} **[in a physical
war]{.underline}**. But an increase in cyberattacks is likely.

**[AT: Russia War Impact\-\--AT: Ukraine\-\--Not
Nuclear\-\--Ext]{.underline}**

**Won't go nuclear or draw in NATO**

Tom **Rogan 2/28**, foreign policy/national security writer for the
Washington Examiner, Bachelor of Arts in War Studies from King\'s
College London, a Master of Science in Middle East politics from SOAS,
and a Graduate Diploma in Law from the University of Law, London, "Why
Russia is highly unlikely to use nuclear weapons," Washington Examiner,
2/28/22,
https://www.washingtonexaminer.com/restoring-america/courage-strength-optimism/why-russia-is-highly-unlikely-to-use-nuclear-weapons

[As Russia struggles to **conquer Ukraine**]{.underline}, Vladimir
[Putin has moved his **strategic nuclear forces** to a **heightened
alert posture**]{.underline}.

Satellite imagery also indicates that the Russian Northern Fleet has
moved more ballistic missile submarines into Arctic and Barents sea
patrol sectors. While U.S. nuclear forces remain at standard readiness
levels, the U.S. military has a greater baseline readiness and redundant
nuclear strike capability than does Russia.

I suspect [the]{.underline} ultimate [**[intent]{.underline}** [of
Putin\'s]{.underline}]{.mark} [public nuclear [threat is]{.mark}
to]{.underline} **[[dangle]{.underline}]{.mark}** [the **[risk of
escalation]{.mark}**]{.underline} [so as [to]{.mark}]{.underline}
**[[deter]{.mark} Western unity]{.underline}** [on]{.underline} further
**[[sanctions]{.underline}]{.mark}**. This would not be the first time
--- in October 2020, Russian state media threatened to turn Germany into
a \"radioactive desert\" following that nation\'s hosting of NATO
nuclear exercises. The pressure worked. Nudged by left-wing elements in
his Social Democratic Party, Chancellor Olaf Scholz cooled Germany\'s
nuclear commitments under NATO.

In Ukraine\'s case, [Putin\'s nuclear threats likely come in his
anticipation of massive Russian **conventional attacks
upon**]{.underline} Ukrainian **[civilian population
centers]{.underline}** such as Kyiv. Russian forces are struggling to
break through determined Ukrainian resistance. Putin\'s form in Chechnya
and Syria suggests he will attempt to smash Ukraine\'s civilian morale
and thus its government\'s will to resist. But Putin also needs the West
to hesitate before further punishing him for the terror yet to come.

[**Regardless**, the [risk of]{.mark} a]{.underline} Russian **[nuclear
[strike]{.mark}]{.underline}** [[remains]{.underline} **[very
low]{.underline}**]{.mark} for two further reasons.

First off, [a nuclear strike would]{.underline} [**[not]{.mark} be [in
Russia\'s]{.mark} or Putin\'s [interest]{.mark}**. The Kremlin appears
to have been shocked by the significant]{.underline} Western
**[sanctions]{.underline}** **[already]{.underline}**
[imposed]{.underline} upon its economy and against Putin\'s person. Yet
[were Russia to **detonate a nuclear warhead**]{.underline} over
Ukrainian forces or Kyiv, [[it would]{.mark} likely
[precipitate]{.mark}]{.underline} [[**total economic
isolation**]{.mark}. This would have]{.underline} a **[profound
impact]{.underline}** [on Russian **society**]{.underline}, likely
[precipitating]{.underline} **[mass protests]{.underline}** against
Putin\'s rule [and]{.underline} perhaps [[encouraging
a]{.underline}]{.mark} [**palace [coup]{.mark}**. Even]{.underline}
**[erstwhile]{.underline}** Russian [partners such as]{.underline}
[**[China]{.underline}** [would]{.underline}]{.mark} likely [be pushed
into]{.underline} **[[support]{.mark}ing
[sanctions]{.mark}]{.underline}** in such a scenario, fearing the
catastrophic public relations damage of failing to do so. (China has a
vested interest in strengthening its relations with the European Union.)
[[Putin]{.mark} may be many things, but]{.underline} **[he [is not
stupid]{.mark}]{.underline}**. And [despite]{.underline} the
**[speculation]{.underline}**, I understand that [there is]{.underline}
**[no]{.underline}** high-quality [**evidence** to suggest]{.underline}
that Putin is mentally ill or has otherwise lost his mind.

Second, [it is [far from certain]{.mark} that [Russian]{.mark}
**military [forces]{.mark}** [would]{.mark} actually [**carry out**
a]{.mark} nuclear attack [order]{.mark}]{.underline}. Like the U.S.,
Russian nuclear command and control has traditionally relied upon two-
to three-person release protocols to ensure a legitimate nuclear order.

The exact [Russian nuclear release protocols]{.underline} are highly
classified and unknown but [would]{.underline} likely [involve
both]{.underline} Defense Minister Sergei **[Shoigu]{.underline}**
[and]{.underline} Chief of the General Staff Valery **[Gerasimov\'s
authentication]{.underline}** [of Putin\'s order.]{.underline} While
Putin\'s more recent centralization of power may have altered these
protocols, [the general staff would]{.underline} still [need
to]{.underline} **[distribute attack orders]{.underline}** [to nuclear
forces]{.underline}. Those forces would then need to carry out the
order. That matters because [these personnel know that any nuclear
strike would entail]{.underline}, as a minimum, **[catastrophic
sanctions]{.underline}** [and the degradation of Russian military
history and honor. In the worst-case scenario, a nuclear strike would
risk an]{.underline} **[escalation spiral]{.underline}** that ends with
nuclear war against NATO.

[**[Gerasimov isn\'t crazy]{.underline}**. **[Nor]{.underline}**]{.mark}
**[are]{.underline}** most of **[the [security elite]{.mark} around
Putin.]{.underline}** They know that once one nuclear weapon is used,
U.S., British, and French nuclear forces would immediately move to very
high alert status. Russian forces would then do the same. The Russians
know that this dynamic would greatly exacerbate the risk of
miscalculation.

Consider, for example, that Russian ballistic missile submarines are
almost constantly shadowed by U.S. and British attack submarines while
on patrol. After a Russian nuclear strike on Ukraine, one miscalculation
might lead to one undersea battle. Fearing an imminent attack at scale,
this might then lead to one nation\'s preemptive strike against the
other nation\'s nuclear assets. This is just a hypothetical scenario,
but it illustrates how even the hint of nuclear warfare could lead to a
worldwide shooting war. The Russians know this.

The bottom line: [Putin and his ultra-hawk spymaster Nikolai Patrushev
might support a nuclear strike, but it\'s **highly unlikely they will
order one**]{.underline}. It\'s even less likely that others in Putin\'s
inner circle would support it. [They would more likely
strike]{.underline} **[him]{.underline}** out [before agreeing to fire
off nukes.]{.underline}

**There are [intermediate steps]{.underline} in the escalatory
ladder\-\--ongoing conflict doesn't necessarily mean nuclear war**

Ryan **Faith 3/11**, former defense and national security editor at VICE
News and congressional staffer, writes about defense and space policy,
"Ukraine Isn't World War III. It's Not Even Close.," Daily Beast,
3/11/2022,
https://www.thedailybeast.com/ukraine-isnt-world-war-iii-its-not-even-close

[[However]{.underline} **[unnerving]{.underline}**]{.mark} [Russia's
invasion of [Ukraine is]{.mark}, the fight is [a]{.mark}]{.underline}
**[[long, long way from]{.mark} the titanic, globe-spanning conflict
that would constitute a "[world war]{.mark}."]{.underline}**

[For]{.underline} **[Ukraine]{.underline}**, [this is]{.underline} an
**[existential]{.underline}** conflict for national survival. [For
the]{.underline} **[rest]{.underline}** of the world, [[this]{.mark}
conflict [may]{.mark}]{.underline} [[**seem terrifying**, but that's
what]{.underline} **[all wars look like]{.underline}**]{.mark} to anyone
paying attention up close---especially one involving a nuclear-armed
combatant. The world hasn't seen a high-intensity conflict between two
relatively modern militaries in Europe since World War II. Of course
this is a shock to the system.

If the U.S. and NATO want to constrain Russia's actions in Ukraine,
[there are **many** options **short of full conflict.**]{.underline}

For instance, during the Korean War, the Soviet Union sent both fighter
aircraft and pilots to fly them against U.S. aircraft. This playbook
could be repeated with NATO countries contributing equipment and troops.
More recently, Russia deployed military "contractors" throughout the
eight years of destabilization in Ukraine to provide Moscow with
plausible deniability. The U.S. and NATO could likewise deploy
contractors, even if they are used in limited non-combat roles such as
supply and building fortifications. Plans for Pentagon cyberattacks have
been on the books for a while. The point is, there are options for the
U.S. and NATO to exert military pressure on Russia without escalating to
an all-out war.

The problem now is that preemptively panicking over potential escalation
effectively grants Vladimir Putin control over the size and scale of the
conflict.

Crucially, [[just because a conflict]{.underline}
**[could]{.underline}** [grow]{.underline}]{.mark} [into a larger-scale,
multi-nation fight [doesn't mean it]{.mark}]{.underline} **[necessarily
[will]{.mark}]{.underline}**. The [[management of]{.mark} a
[conflict\'s]{.mark}]{.underline} [**[size]{.underline}**
[and]{.underline} **[scope]{.underline}** [are
things]{.underline}]{.mark} that [[participants]{.underline}]{.mark} try
to [**closely [monitor and manage]{.mark}**[. Jumping to]{.mark} the
conclusion that]{.underline} **[literally every move by
NATO]{.underline}** [will lead to]{.underline} an **[[apocalyptic
war]{.mark} for the ages]{.underline}** [[is]{.underline}]{.mark}
[**grossly premature**. It's [like]{.mark}]{.underline}
[**[forwarding]{.mark} matches [from]{.mark} a [dating]{.mark} app [to a
wedding]{.mark} planner**. [There are]{.mark}]{.underline} some
**[important [intermediate steps]{.mark}]{.underline}** you can't skip.

**[\*NORMS ADV\*]{.underline}**

**[Squo Solves\-\--1NC]{.underline}**

**The US is already innovating, AND [existing]{.underline} NATO
structures can help set norms**

Edward Hunter **Christie 22**, Senior Research Fellow at the Finnish
Institute of International Affairs, "Defence Cooperation in Artificial
Intelligence: Bridging the Transatlantic Gap for a Stronger Europe,"
European View, vol. 21, no. 1, SAGE Publications Ltd, 04/01/2022, pp.
13--21

Investment challenges

As noted in the introduction, [there is a significant **gap** between
overall **US** and **European** **defence** spending levels. This
general pattern]{.underline} **[also]{.underline}** [holds for
defence]{.underline} **[r]{.underline}**esearch [and]{.underline}
**[d]{.underline}**evelopment spending. In 2020, EU spending in this
area amounted to €8 billion (EDA 2021). For the US, with caveats as to
comparability, expenditure for 'research, development, test and
evaluation' totalled approximately €90 billion3 in the 2021 fiscal year
(from October 2020 to September 2021), or about 10 times more.

Investment [challenges go]{.underline} **[beyond]{.underline}** issues
of [**scale**. The US]{.underline} also [has]{.underline} **[greater
experience]{.underline}** [in]{.underline} the **[setting
up]{.underline}** [and]{.underline} **[operation]{.underline}**
[of]{.underline} **[structures]{.underline}** [to]{.underline}
**[promote]{.underline}** both [**military and dual-use innovation**.
While the best-known institution is the]{.underline}
**[D]{.underline}**efense **[A]{.underline}**dvanced
**[R]{.underline}**esearch **[P]{.underline}**rojects
**[A]{.underline}**gency, **[other]{.underline}** [US government
structures are also relevant in discussions on fostering innovation in
**AI**]{.underline} [for]{.underline} [**military applications**. A
much-discussed example is **In-Q-Tel**]{.underline}, which was
originally set up as the state venture-capital arm of the Central
Intelligence Agency. To illustrate the influence of the In-Q-Tel
example, one may note that both its current Chief Executive Officer,
Chris Darby, and one of its former Chief Executive Officers, Gilman
Louie, served among the 15 commissioners of the National Security
Commission on Artificial Intelligence.4 This was a temporarily created
expert commission mandated by the US Congress to provide policy
recommendations for a whole-of-government and whole-of-society approach
for US AI policy.5

With In-Q-Tel, the idea is to learn from private-sector practices in the
area of venture-capital investment and repurpose them for state needs
and more patient time horizons. A supported company should pursue
product development strategies aimed at serving both civilian markets
and government needs. In this way, rather than effectively taking over a
commercial company and limiting its growth potential to future
government contracts alone, the government body encourages an
intermediate trajectory made up of mixed revenue streams, in the hope
that this will generate greater returns to scale and higher efficiency
thanks to the disciplining effect of private-sector competition.
Conversely, the advantage of this approach as compared to not
intervening at all is that the commercial company will integrate current
and likely future government needs into its product and
business-development strategy, rather than ignoring them and finding
itself, at a later date, unable to supply the government sector
according to the latter's requirements.

A related issue which falls between what can be achieved with new
investment instruments and new protections that can be assured through
the screening of foreign direct investment is the provision of
investment from trusted private investors to the technology sector.
[Certain technology companies that are not part of the traditional
defence industry may be developing dual-use products]{.underline} that
are [of potential interest to the defence sector while having limited
awareness of national security concerns. This may make them vulnerable
targets for both licit and illicit attempts to **acquire their
technologies**]{.underline} [on the part of **foreign state
actors**]{.underline}. [At the same time, their business development
needs may lead them to seek **investment** from]{.underline} **[any
potential source]{.underline}**, thus [exposing them to potential
**risks**]{.underline}. To respond to this challenge, the US Department
of Defense has launched a scheme called the Trusted Capital Marketplace
(US Department of Defense 2021a).

[Building on these considerations]{.underline}, the
**[NATO]{.underline}** Innovation Unit [has developed two new
instruments for Allied use]{.underline} which were announced to the
public in October 2021 (NATO 2021a; 2021b). [Both]{.underline}
instruments [aim to foster]{.underline} **[tech]{.underline}**nological
**[innovation]{.underline}** [with a deliberate focus on dual-use
applications and on enterprises with mixed (potential) revenue streams.
The first instrument is the Defence Innovation Accelerator for the North
Atlantic (DIANA), which is a NATO instrument, that is, it involves the
participation of all 30 NATO Allies. The second instrument is the NATO
Innovation Fund, which in NATO terminology is a 'multinational'
instrument]{.underline}, namely one [that Allies freely opt
into]{.underline}.

[DIANA will aim to accelerate the]{.underline}
**[adoption]{.underline}** [of dual-use technological solutions through
several interlocking components.]{.underline}6 First, [it will develop a
network of national organisations, in particular test centres and
innovation accelerators]{.underline}. Second, [it will competitively
select private-sector innovators and allow them to use national
organisations in the network to interface with military end users and
military capability-development specialists]{.underline}. Third, [it is
envisaged that DIANA will provide mentorship and education services for
private innovators to familiarise them with the opportunities and
responsibilities inherent to the defence and security
sector]{.underline}. Fourth, [DIANA will develop a database of trusted
financial investors from Allied nations and support matchmaking between
investors and innovators]{.underline}. Fifth and finally, [DIANA will
also provide expert advice on defence and security innovation to all
relevant stakeholders, including private-sector and academic
entities.]{.underline}

[Regarding the NATO Innovation Fund, 17 Allies had **opted into the
Fund**]{.underline} [as of the date of its announcement]{.underline} in
October 2021. [The participating Allies will inject up to €1 billion
into Allied innovation ecosystems over the next 15 years]{.underline}.
[The Fund aims to attract **additional private
investments**]{.underline} [due to the de-risking effect, both financial
and technological, thanks to state co-funding and diligence and
screening efforts. The funds are intended to be used for **long-term
support of 'deep tech' innovative companies**]{.underline}, that is, for
advanced research into AI, quantum and related technologies that may
have both military and civilian applications. [Due diligence and
security screening practices will aim to ensure that both private
investors and fund recipients are **trusted** entities.]{.underline}

**[Interop Fails\-\--1NC]{.underline}**

**Interoperability challenges are [structural]{.underline}\-\--they
[can't be fixed]{.underline} through consultation or dialogue.**

Edward Hunter **Christie 22**, Senior Research Fellow at the Finnish
Institute of International Affairs, "Defence Cooperation in Artificial
Intelligence: Bridging the Transatlantic Gap for a Stronger Europe,"
European View, vol. 21, no. 1, SAGE Publications Ltd, 04/01/2022, pp.
13--21

Interoperability challenges

Interoperability can be defined as 'the ability of systems, units or
forces to provide services to, and accept services from other systems,
units or forces and the use the services so exchanged to enable them to
operate effectively together' (Dufour 2018, 1).

[The]{.underline} first [general challenge to interoperability is the
**overall gap**]{.underline} [between the US and Europe in terms
of]{.underline} [**total defence investment**, as well as
in]{.underline} terms of **[civilian technological
attainment]{.underline}** [with]{.underline} respect to
**[AI]{.underline}** and related technologies. [There is]{.underline}
**[no]{.underline}** single [**solution to this problem**, which is
much]{.underline} **[broader]{.underline}** [in scope than]{.underline}
[**traditional military--technical standards**, such as those pursued
in]{.underline} the **[NATO]{.underline}** context [through]{.underline}
[**existing mechanisms**. For this **broad**]{.underline}
[challenge]{.underline}, **[overall]{.underline}** [policy decisions
relating to]{.underline} national **[investment]{.underline}** choices
[and]{.underline} **[tech]{.underline}**nology **[policy]{.underline}**
coordination [between the two sides]{.underline} of the Atlantic [are
of]{.underline} **[particular importance]{.underline}**. Further
discussion of this follows in the sections on investment challenges and
international security challenges.

[A]{.underline} **[second]{.underline}** [challenge]{.underline} to
interoperability [is that]{.underline}, as far as digital technologies
are concerned, [the]{.underline} **[civilian]{.underline}**
[sector]{.underline} of the economy, [on both sides]{.underline} of the
Atlantic, [is]{.underline} **[more advanced]{.underline}**, more
**[dynamic]{.underline}** [and]{.underline} also **[not]{.underline}**
especially **[oriented]{.underline}** [towards]{.underline} meeting
**[military needs]{.underline}**. For decades, the military sector has
represented only a very small share of the total sales volume of the
computing and semiconductor industries. The same pattern is repeating
itself currently with AI. This stands [in]{.underline} **[great
contrast]{.underline}** [to]{.underline} **[narrower]{.underline}**
[dual-use technologies, for example aerospace, where the military sector
remains inherently]{.underline} **[important]{.underline}**. With
digital technologies, defence institutions are under much more pressure
to either adapt to civilian industry products and standards or to pay a
significant premium to suppliers to secure military-grade equipment and
software.

[A third challenge]{.underline} to interoperability [lies in how AI is
implemented in **practice**]{.underline}. To set up a bespoke
machine-learning algorithm in a given data environment, best practice in
the software industry is to pursue some variant of **['agile'
development]{.underline}**. This involves a very different
product-development cycle, essentially proceeding [with
multiple]{.underline} **[rapid iterations]{.underline}** [of
an]{.underline} **[imperfect product]{.underline}** that is released in
preliminary versions and later revised---like software products released
in various 'beta versions'---with upgrades developed over time. This
**[contrasts greatly]{.underline}** [with the traditional production of
major military platforms, which puts a]{.underline}
**[premium]{.underline}** [on]{.underline} strict **[quality
control]{.underline}** [and]{.underline} **[compliance]{.underline}**
with requirements [at]{.underline} **[every development
step]{.underline}**---an approach referred to in the software industry
as 'waterfall' development (Christie 2021b, 87). **[Agile]{.underline}**
product [development may pose **challenges**]{.underline}
[to]{.underline} [**interoperability**. Unless very tight standards are
applied, there is a considerable risk of]{.underline}
**[divergences]{.underline}** in how different national institutions go
about solving a particular AI or data analytics problem.

With large traditional military platforms there are long time frames
during which states can take coordination steps, either by purchasing
the same platforms, or by building consensus in terms of requirements
and standards. However, [when a]{.underline} comparatively **[small
team]{.underline}** [works **dynamically**]{.underline} [to generate
an]{.underline} **[algorithmic solution]{.underline}** [to
a]{.underline} **[particular problem]{.underline}** [in]{.underline} a
matter of **[weeks]{.underline}** or months, [traditional coordination
through existing consultation mechanisms may pose]{.underline} **[risks
to the speed advantage inherent to agile development]{.underline}**.
Conversely, once a solution has been developed, its adoption in somewhat
different environments may be challenging for a range of technical
reasons. None of these issues is insurmountable, but they do pose, in a
new light, classical trade-offs between the benefits of inventiveness
and dynamism, on the one hand, and those of imposing constraints through
standards and other harmonising measures to ensure that new products can
be broadly used and shared on the other. In the case of AI, a typical
observation is that there are many excellent prototypes and pilot
projects in numerous defence institutions, but [there are]{.underline}
also **[serious]{.underline}** outstanding **[challenges]{.underline}**
[in terms of **scaling up** to]{.underline}
**[enterprise]{.underline}**-wide [solutions, **let alone Alliance-wide
solutions**]{.underline}.

**[Governance Fails\-\--1NC]{.underline}**

**Other states will [inevitably]{.underline} deploy militarized AI and
future tech\-\--attempts at [norm-setting]{.underline} just signal
[weakness]{.underline} and [cede the race]{.underline} to adversaries.**

Matt **Bartlett 19**, Lecturer in the Faculty of Law at the University
of Auckland, focuses on the gauntlet of legal and policy issues raised
by technology, particularly emerging technologies like AI, blockchain
and cryptocurrency, "The AI Arms Race In 2019",
<https://towardsdatascience.com/the-ai-arms-race-in-2019-fdca07a086a7>

This piece will show just how ineffective such activism has been,
however well-intentioned. [[The **arms race** in **AI** is]{.mark}
**already [underway]{.mark}**]{.underline} --- [[and has been for
**years**]{.underline}]{.mark}. It is now 2019, and [[we]{.underline}
**[cannot]{.underline}**]{.mark} **[waste time [pretend]{.mark}ing
[Pandora's Box hasn't]{.mark} already [been
opened]{.mark}]{.underline}**. [This is the time to take stock
of]{.underline} the latent evidence of [weaponised AI, and consider the
geopolitical incentives]{.underline} that produced this quagmire.

Ready, Set, Gone

[A tour of]{.underline} the [countries driving the AI arms race may as
well start in **Moscow**]{.underline}. [[Putin's
government]{.underline}]{.mark}, hardly one to [fall in line with
existing global
norms](https://www.vox.com/2014/9/3/18088560/ukraine-everything-you-need-to-know),
[[is]{.underline} **[categorically opposed]{.underline}**
[to]{.underline}]{.mark} [the [creation of a]{.mark} **new
[norm]{.mark}**]{.underline} [([against autonomous
weapons]{.underline}]{.mark}). [Moscow has even]{.underline} ---
successfully --- [[lobbied to reduce the number of
days](https://futureoflife.org/2018/11/26/handful-of-countries-including-the-us-and-russia-hamper-discussions-to-ban-killer-robots-at-un/)
states meet just to discuss the issue.]{.underline} [Russia]{.underline}
itself has
[[claimed](https://eandt.theiet.org/content/articles/2017/12/russia-rejects-potential-un-killer-robots-ban-official-statement-says/)
that a limit on autonomous weapon development is
**inappropriate**]{.underline} given "few such weapons have ever been
developed".

Selflessly, Russia is working hard on making a lie of such a claim.
Leaked budgets for AI-specific research and development for 2019--2021
show state investment
([previously](https://www.defenseone.com/technology/2019/01/russia-expect-national-ai-roadmap-midyear/154015/)
\$490m USD) almost
[doubling](https://www.defenseone.com/technology/2019/01/russia-expect-national-ai-roadmap-midyear/154015/)
over the next three years. Russian intent in this area is no secret.
Just ask [General [Gerasimov]{.mark}]{.underline}, a general and [Chief
of the General Staff of the Russian Forces]{.underline}: [[he [is on
record]{.mark}](http://www.militarynews.ru/story.asp?rid=1&nid=476975)
with the state news agency as [saying]{.mark} "robots will be one of the
main features of future wars... [\[Russia\] is seeking to **completely
automate** the battlefield]{.mark}."]{.underline}

For a taste of what to expect in future wars, consider this announcement
from the crown jewel of Russian arms manufacturers: Kalashnikov (maker
of the ubiquitous AK-47). The [arms giant is developing and
launching](https://news.vice.com/en_us/article/vbzq8y/russian-weapons-maker-kalashnikov-developing-killer-ai-robots)
an entire range of autonomous weapons, each with a 'neural network'
enabling the machines to pick out targets and decide autonomously
whether to engage. Another Russian weapons manufacturer, Degtyarev, [has
developed](https://www.forbes.com/sites/noelsharkey/2018/11/28/killer-robots-from-russia-without-love/)
an autonomous 'suicide machine' called the Nerekhta. This drone is built
to stealthily traverse close to a target, and then explode with the
force to destroy fortifications or enemy tanks.

It's important to emphasise here that the selected examples are just the
tip of the Russian iceberg: we have not touched the [autonomous nuclear
submarines](https://en.wikipedia.org/wiki/Status-6_Oceanic_Multipurpose_System),
the '[smart swarm' robot
missiles](https://www.newsweek.com/drones-swarm-autonomous-russia-robots-609399)
or the [Armata T-14 'super
tank'.](https://www.forbes.com/sites/noelsharkey/2018/11/28/killer-robots-from-russia-without-love/)
[The picture is pretty clear]{.underline}: [[Russia]{.mark} has a
**large** and **ambitious** autonomous weapons program in place, and
[sees this program as **central** to its **national security
interests**]{.mark}]{.underline}. [It follows that nobody should be
surprised to see Putin --- already --- on the offensive against the mere
spectre of a global AI arms ban.]{.underline}

More [surprising]{.underline}, [perhaps, is just how aligned the
**Russian** position on autonomous weapons is with that of the **United
States** and]{.underline} **[China]{.underline}**. Indeed, for a pair of
geopolitical powers that struggle mightily to [come to
consensus](https://en.wikipedia.org/wiki/List_of_vetoed_United_Nations_Security_Council_resolutions)
around contentious geopolitical issues, the United States and Russia
have displayed [remarkable cohesion in
opposing](https://www.independent.co.uk/life-style/gadgets-and-tech/news/killer-robots-un-meeting-autonomous-weapons-systems-campaigners-dismayed-a8519511.html)
any prohibitions on autonomous weapons.

Why might this be? No need to reach for the [particular idiosyncrasies
of the Commander in
Chief](https://www.npr.org/2018/07/17/629601233/trumps-helsinki-bow-to-putin-leaves-world-wondering-whats-up);
try a simple number (albeit one with a lot of zeros). The Pentagon [has
committed](https://www.theverge.com/2018/4/12/17229150/pentagon-project-maven-ai-google-war-military)
to a \$9 billion spend on American military AI, explicitly citing the
need to keep up with Russian and Chinese military technology. While the
American budget for AI represents just a fraction of overall defence
spending, much like in Russia, the figure has doubled in recent years.

Unique among the global powers, the US [has already
started](https://www.bloomberg.com/news/articles/2018-05-18/the-u-s-army-is-turning-to-robot-soldiers)
deploying autonomous vehicles in turbulent combat areas, in large
numbers and with significant roles. Autonomous naval vehicles have begun
to patrol the South China Sea --- with larger, more powerful machines
[on their
way](https://www.army-technology.com/features/mq4c-triton-drones/). Most
striking of all, American aerial drones have [rained
death](https://www.thebureauinvestigates.com/projects/drone-war) all
over Afghanistan and Pakistan under the Obama administration. It is
absolutely clear why the United States have opposed all moves towards a
prohibition of autonomous weapons: America wants to win the arms race,
not stop it.

For its part, China has actually indicated [its
support](https://www.lawfareblog.com/chinas-strategic-ambiguity-and-shifting-approach-lethal-autonomous-weapons-systems)
in April last year for a ban on battlefield use of autonomous weapons.
However, discerning readers ought to take the Chinese statement with
several grains of salt: the very same day, [the]{.underline} **[Chinese
air force]{.underline}** [[released
plans](https://mp.weixin.qq.com/s/xfw3hZkCiPJa-gX3GExEcQ) for an
'intelligent-swarm' design for a new autonomous drone]{.underline}. In a
similar vein, even [[in the last year]{.underline} [the **Chinese**
autonomous weapons program]{.underline}]{.mark} [has [**churned out**
success stories]{.mark}]{.underline}. [Some critics
feel](https://thediplomat.com/2018/08/the-trouble-with-chinas-edge-in-the-ai-arms-race/)
that China is taking an unassailable edge in the arms race; somewhat at
odds with Beijing's support for an AI weapons ban.

Elsa Kania for Lawfare
[posited](https://www.lawfareblog.com/chinas-strategic-ambiguity-and-shifting-approach-lethal-autonomous-weapons-systems)
that [the Chinese are pursuing a policy of 'strategic ambiguity' with
military AI]{.underline}: [displaying]{.underline} **[rhetorical
commitment]{.underline}** [to concerned human]{.underline} [rights
groups **without sacrificing any real flexibility**]{.underline}
[to]{.underline} **[develop cutting-edge lethal autonomous
weapons]{.underline}**. After all, [[becoming the global leader in
AI]{.underline}]{.mark} (including arms development) [[is [**literally**
the **official Chinese
plan**](https://www.nytimes.com/2017/07/20/business/china-artificial-intelligence.html)]{.underline}]{.mark};
[and Beijing [tends
not](https://www.hrw.org/world-report/2019/country-chapters/china-and-tibet)
to be too bothered with human rights groups]{.underline} when a
strategic interest is at stake.

In other words, the three biggest military powers in the world have
already:

Identified autonomous weapons as crucial to their military strategy;

Scaled up their resourcing and development of these weapons; and

Characterised the need for more advanced weapons in the context of other
powers' technological development.

We have to call this what it is: a serious [arms
race](http://www.oxfordbibliographies.com/view/document/obo-9780199743292/obo-9780199743292-0002.xml).

A Reckoning for Elon and Friends

In my view, [continued activism to block the development of lethal
autonomous weapons is untenable in light of the evidence
available]{.underline}. Elon Musk and the Future of Life's
well-intentioned
[[efforts](https://futureoflife.org/lethal-autonomous-weapons-pledge/)
to **forestall** an arms race in military AI have
**failed**]{.underline}. [At this stage, [**Russia**, **China**]{.mark}
[and]{.mark}]{.underline} the United States (not to mention [[**[plenty
of smaller
states]{.underline}**](https://www.timesofisrael.com/unmanned-subs-and-sniper-drones-israel-unveils-its-weapons-of-the-future/))
[are]{.underline} **[significantly invested]{.underline}**]{.mark}
[[in]{.mark} lethal [autonomous weapons,]{.mark}]{.underline} [[and view
them as **fundamental** to the **future of**]{.mark} **armed
[conflict]{.mark}**]{.underline}. [We can expect resourcing for military
AI to continue to escalate]{.underline}, and for states to begin to
deploy sophisticated drones in greater numbers.

It is important to note that [[this behaviour]{.underline}]{.mark} from
large states [[is **right in line**]{.underline}
[with]{.underline}]{.mark} **[their [rational
incentives]{.mark}]{.underline}** (rather than, for instance,
[conforming to a bad science fiction
plot](https://en.wikipedia.org/wiki/RoboCop#Plot)). [[It is **not
in**]{.mark} **any of the great [powers' interests]{.mark}** [to
**unilaterally**]{.mark} **support an AI weapons ban**]{.underline}
[and]{.underline} **[[de-escalate]{.mark} weapons
development]{.underline}**. [[If one were to do so,]{.underline}
[the]{.underline} [possibility that **another power
might**]{.underline}]{.mark} [**[take the opportunity]{.underline}** [to
develop an]{.underline}]{.mark} [**unassailable [edge]{.mark}** in
weaponised AI [is]{.mark} **nigh on [inevitable]{.mark}**]{.underline}.
[Battles]{.underline} between autonomous drones [[are likely to be
decided](https://www.researchgate.net/publication/256017649_The_Seabots_are_Coming_Here_Should_They_Be_Treated_as_'Vessels')
by which side has the more **powerful** software and
autonomy]{.underline}. Machines that are able to 'think', react,
manoeuvre and engage on their own accord will prevail over slower
machines, let alone sluggish humans.

**Emerging tech regulation fails and AFF can't solve.**

Greg E. **Marchant 20**, Regents Professor and Lincoln Professor of
Emerging Technologies, Law & Ethics, and Faculty Director, Center for
Law, Science & Innovation, Sandra Day O'Connor College of Law, Arizona
State University, "Governing Emerging Technologies," Vanderbilt Law
Review, Vol. 73(6), 2020, p. 1863-1865

I. [THE WICKED PROBLEM OF EMERGING TECHNOLOGY GOVERNANCE]{.underline}

[**[Emerging tech]{.mark}nologies**---such as synthetic biology, gene
editing, nanotechnology, artificial intelligence, internet of things, 3D
printing, drones, applied neurotechnologies, and blockchain and
cryptocurrencies---**[present]{.mark} a common set of [governance
challenges]{.mark}**]{.underline}.5 Perhaps [[most significant
is]{.mark} the "[pacing]{.mark} problem]{.underline}," where
[[the]{.mark} [pace of]{.mark} technology [development]{.mark} **[far
outstrips]{.mark}** the [capability of **regulatory systems**]{.mark}
[to keep up]{.mark}]{.underline}.6 Powered by growing market demand and
intense business competition, new technologies are being developed,
deployed, and commercialized faster than ever before.7 At the same time,
[traditional [governmental processes]{.mark} of legislation, regulation,
and judicial review [have been **slowed**]{.mark} [by]{.mark} increasing
**[bureaucratic requirements]{.mark}** [and]{.mark} the increasing
**[politicization]{.mark}** of **technological disputes**]{.underline}.8
[The [result]{.mark} of accelerating technology and decelerating
regulatory oversight [is a]{.mark} growing **[governance gap]{.mark}**.
Any new statutes or regulations affecting these new technologies are
likely to be outdated before the ink dries]{.underline}. As technology
governance expert David Rajeski has noted, "\[i\]f you think that any
existing regulatory framework can keep pace with this rate of change,
think again."9 Facing such a bleak prospect, [regulators often sensibly
defer regulation, waiting for a more stable technology plateau that may
or may not ever come]{.underline}.

[A second regulatory challenge of [many]{.mark} emerging technologies is
that **they [present]{.mark} [risks]{.mark} and concerns [outside the
scope of existing regulatory]{.mark} agency
[jurisdictions]{.mark}**]{.underline}.10 [Regulatory agencies, such as
the U.S. Food and Drug Administration, are restricted to regulating the
safety and efficacy of products]{.underline}. But [many applications of
emerging technologies raise broader ethical and social concerns relating
to human enhancement]{.underline}, "playing God," autonomy, dignity,
fairness, equitable access, privacy, and longer-term impacts on
society.11 [These issues are largely outside the safety and efficacy
scope of current agency jurisdictions and [thus]{.mark} often
[escape]{.mark} any regulatory [oversight]{.mark}]{.underline}.

Yet **[[another challenge]{.mark} to the regulation of emerging
technologies [is]{.mark} their [breadth of
application.]{.mark}]{.underline}** [Technologies such **as artificial
intelligence, nanotechnology, and blockchain [span the entire
industry]{.mark} [spectrum]{.mark}, as well as many nonindustrial
activities and sectors**. They are sometimes referred to as "enabling"
or "platform" technologies that, like computers or]{.underline} the
internet, [have the potential to affect virtually every industry
sector]{.underline}.12 There are thousands, if not tens or hundreds of
thousands, of ways these core technologies are used, each with their own
context of risks and benefits. [These broad applications not only
involve many different types of industries and businesses, but also
affect many other types of stakeholders and nongovernmental
organizations with particular interests]{.underline} in specific
applications. [The broad applications of these technologies also [span
many different]{.mark} regulatory [agencies]{.mark}]{.underline}, each
with their own organic statutes with different requirements, criteria,
and goals. [The end result of this multitude of applications, regulated
parties, stakeholders, and regulators is tremendous regulatory diversity
and complexity]{.underline}. Further complicating the regulatory
challenge, [emerging technologies are inherently international in
application, creating the need for some type of international
coordination.]{.underline}13

Finally, **[the [unprecedented uncertainty]{.mark} about emerging
technologies also [impedes]{.mark} effective
[regulation]{.mark}.]{.underline}**14 Beca[use the technologies are so
new and moving forward so quickly, there is enormous uncertainty about
the trajectories, benefits, and risks of these
technologies]{.underline}.15 Given these uncertainties, [it is possible
to paint unrealistically optimistic or pessimistic visions of the
technology]{.underline} at issue, thus [fostering public controversy,
conflict, and unease.16]{.underline}

In summary, **[the governance of emerging technologies is characterized
by complexity, diversity, and uncertainty]{.underline}**. **[These same
characteristics]{.underline}**---complexity, diversity, and
uncertainty---**[are the defining characteristics of a wicked problem.17
As a wicked problem, the [governance]{.mark} of emerging technologies
[is unlikely to be solved by a single]{.mark} or simple
[solution]{.mark}.]{.underline}** **[[Traditional]{.mark} government
[regulation]{.mark} [will not be sufficient]{.mark}, or many times even
appropriate, for emerging technologies]{.underline}**.[18 Rather than
traditional regulation---consisting of enforceable rules unilaterally
imposed by a regulatory agency---emerging technologies will require a
"governance" approach that expands the categories of responsible parties
beyond government to include the private sector, nongovernmental
organizations, and think tanks and also **expands the relevant oversight
mechanism beyond enforceable government regulations**]{.underline}.19
Four alternative governance approaches for emerging technologies are
discussed and evaluated in the next Part.

**[Governance Fails\-\--2NC]{.underline}**

**Future tech and militarized AI deployment is [inevitable]{.underline}.
Russia and China both view AI weapons as [absolutely
critical]{.underline} to their defense strategy and national security in
the coming years. They've both [already]{.underline} shot down efforts
at developing international norms. There is [zero rational
incentive]{.underline} for either of them to stop developing the
weapons. That's Bartlett.**

**[Zero shot]{.underline} at successful future technology arms
control.**

\-\--LAWS = lethal autonomous weapons systems

Kyle **Hiebert 22**, Senior Program & Policy Analyst @ Enterprise
Machine Intelligence and Learning Initiative, deputy editor of the
Africa Conflict Monitor, "[[Are Lethal Autonomous Weapons
**Inevitable?**]{.underline}]{.mark} **[[It Appears
So]{.underline}]{.mark}**",
https://www.cigionline.org/articles/are-lethal-autonomous-weapons-inevitable-it-appears-so/

The Evolution of Automated Weapons

[In December 2021]{.underline}, [[the Sixth Rev]{.mark}iew
[Con]{.mark}ference of the UN Convention on Certain Conventional
Weapons]{.underline} (CCW), a 125-member intergovernmental forum that
discusses nascent trends in armed conflict and munitions, [[was [unable
to progress talks on new legal
mechanisms](https://www.aljazeera.com/news/2021/12/18/un-talks-fail-to-open-negotiations-on-killer-robots)]{.mark}
to rein in the development and use of [LAWS]{.mark}]{.underline}. [[The
failure continues]{.underline} **[eight years]{.underline}**
[of]{.underline} **[unsuccessful]{.underline}**]{.mark}
**[[efforts]{.underline}]{.mark}** [[toward]{.mark} either
[regulation]{.mark} or an outright ban]{.underline}. "At the present
rate of progress, [the pace of technological development risks
overtaking our deliberations," warned Switzerland's
representative]{.underline} as the latest conference wrapped up in
Geneva. **[No date is set for the forum's next meeting.]{.underline}**

Semi-autonomous weapons like self-guided bombs, military drones or
Israel's famed Iron Dome missile defence system have existed for
decades. In each case, a human operator determines the target, but a
machine completes the attack. On the other hand, LAWS --- derided by
critics as "slaughterbots" --- empower AI to identify, select and kill
targets absent human oversight and control. The Future of Life
Institute, a think tank based in Cambridge, Massachusetts, that is
focused on threats to humanity posed by AI and which organized the 2017
open letter to the United Nations, makes the distinction by saying, "In
the case of autonomous weapons the decision over who lives and who dies
is made solely by algorithms."

Myriad concepts of LAWS for air, ground, sea and space use have long
been speculated about. The difference now is that some models are ready
to be field tested. At the US Army's latest annual convention in
Washington, DC, in October 2021, attendees were treated to prototypes of
robotic combat dogs that could be built with rifles attached. Australian
robotics maker GaardTech announced in November an agreement with the
Australian army to demonstrate the Jaeger-C uncrewed vehicle some time
this year. Described as a "mobile robotic mine" or "beetle tank," the
bulletproof autonomous four-wheeled combat unit can be outfitted with an
armour-piercing large-calibre machine gun and sniper rifle and carry up
to 100 pounds of explosives for use in suicide attacks.

In The Kill Chain: Defending America in the Future of High-Tech Warfare,
Christian Bose, who served as top adviser to US Senator John McCain and
staff director of the Senate Armed Services Committee, tells of how
China intends to develop fully autonomous swarms of intelligent combat
drones. Recent actions bear this out. In addition to China's rapid
expansion of its own domestic drone industry, last September two
state-owned Chinese companies were linked to a Hong Kong firm that
acquired a 75 percent stake in an Italian company that manufactures
military-grade drones for the North Atlantic Treaty Organization. The
Hong Kong firm reportedly paid 90 times the valuation of the Italian
company to execute the takeover.

Meanwhile, a report prepared for the Pentagon's Joint Artificial
Intelligence Center in 2021 by CNA, a non-profit research and analysis
institute located in Arlington, Virginia, describes how Chinese
technology is enabling Russia's military to integrate autonomous AI into
dozens of its platforms. According to the report, this technology
includes anthropomorphic robots capable of carrying multiple weapons
and, possibly, of driving vehicles. Russian media quoted defence
minister Sergei Shoigu confirming last May that Russia has commenced
with the manufacturing of killer robots, saying, "What has emerged are
not simply experimental, but robots that can be really shown in
science-fiction films as they are capable of fighting on their own."

Yet the world's first true test case of a fully autonomous killer robot
may have already taken place, in Libya in March 2020. According to a
report submitted by a panel of experts to the UN Security Council in
March 2021, drones produced by Turkish state-owned defence conglomerate
STM were allegedly sent to track down a convoy of retreating forces
loyal to renegade military general Khalifa Haftar after they abandoned a
months-long siege of the capital, Tripoli.

Turkey's intervention into Libya to prop up the Tripoli-based Government
of National Accord, the war-torn country's UN-recognized government
faction, has opened up Libya's vast deserts to be used as a giant test
theatre for Turkey's booming military drone industry. Turkish drones
have recently altered the trajectory of civil wars in favour of Turkey's
government clients in both Libya and Ethiopia, and delivered a decisive
victory for Azerbaijan during a violent flare-up with Armenia in late
2020 over the disputed territory of Nagorno-Karabakh. Over the past two
years Ukraine has purchased dozens of Turkish drones in response to
Russia's military buildup on Ukraine's eastern border.

The experts' report claims Haftar's forces "were hunted down and
remotely engaged" by a Turkish Kargu-2 drone and other "loitering
munitions" --- those with the ability to hover over targets for hours
--- that "were programmed to attack targets without requiring data
connectivity between the operator and the munition." In other words, the
machines were apparently capable of identifying, selecting and killing
targets without communication from a human handler.

In many ways, the evolution of military drones is a canary in the coal
mine, bridging eras between semi-autonomous and autonomous weapons and
perhaps foreshadowing the way in which fully independent killer robots
might proliferate in the future. In the 2000s, military drones were a
very expensive and hard-to-operate weapons system possessed almost
exclusively by the United States. Less than two decades later, they have
become a low-cost, widely available technology being manufactured and
exported worldwide --- not only by China, Turkey and the United States,
but by Iran, the United Arab Emirates and others, each motivated by not
only geopolitical interests but the lucrative commercial stakes
involved.

By some estimates, more than 100 countries now have active military
drone programs --- all springing up without any sort of international
regulatory structure in place.

Autonomous weapons systems may be able to assess a target's legitimacy
and make decisions faster, and with more accuracy and objectivity than
fallible human actors could.

More Just War --- or Just More War?

Rapid advances in autonomous weapons technologies and an increasingly
tense global order have brought added urgency to the debate over the
merits and risks of their use.

Proponents include Robert Work, a former US deputy secretary of defence
under the Obama and Trump administrations, who has argued the United
States has a "moral imperative" to pursue autonomous weapons. The chief
benefit of LAWS, Work and others say, is that their adoption would make
warfare more humane by reducing civilian casualties and accidents
through decreasing "target misidentification" that results in what the
US Department of Defense labels "unintended engagements."

Put plainly: Autonomous weapons systems may be able to assess a target's
legitimacy and make decisions faster, and with more accuracy and
objectivity than fallible human actors could, either on a chaotic
battlefield or through the pixelated screen of a remote-control centre
thousands of miles away. The outcome would be a more efficient use of
lethal force that limits collateral damage and saves innocent lives
through a reduction in human error and increased precision of munitions
use.

Machines also cannot feel stress, fatigue, vindictiveness or hate. If
widely adopted, killer robots could, in theory, lessen the opportunistic
sexual violence, looting and vengeful razing of property and farmland
that often occurs in war --- especially in ethnically driven conflicts.
These atrocities tend to create deep-seated traumas and smouldering
intergenerational resentments that linger well after the shooting stops,
destabilizing societies over the long term and inviting more conflict in
the future.

But critics and prohibition advocates feel differently. They say the
final decision over the use of lethal force should always remain in the
hands of a human actor who can then be held accountable for that
decision. Led by the Campaign to Stop Killer Robots, which launched in
2013 and is now comprised of more than 180 member organizations across
66 countries and is endorsed by over two dozen Nobel Peace laureates,
the movement is calling for a pre-emptive, permanent international
treaty banning the development, production and use of fully autonomous
weaponry.

Dozens of countries support a pre-emptive ban as well. This briefly
included Canada, when the mandate letter issued by Prime Minister Justin
Trudeau in 2019 to then foreign affairs minister François-Philippe
Champagne requested he assist international efforts to achieve
prohibition. That directive has since disappeared from the mandates
given to Champagne's successors, Marc Garneau and now Mélanie Joly.

For those calling for a ban, the risks of LAWS outweigh their supposed
benefits by ultimately incentivizing war through eliminating some of its
human cost. The unavoidable casualties that result from armed conflict,
and the political blowback that can produce, has always moderated the
willingness of governments to participate in wars. If this deterrent is
minimalized by non-human combatants over time, it may render military
action more appealing for leaders --- especially for unpopular ones,
given the useful distraction that foreign adventurism can sometimes
inject into domestic politics.

Other risks are that autonomous weapons technology could fall into the
hands of insurgent groups and terrorists. At the peak of its so-called
caliphate in Iraq and Syria, the Islamic State was launching drone
strikes daily. Despotic regimes may impulsively unleash autonomous
weapons on their own populations to quell a civilian uprising. Killer
robots' neural networks could also be susceptible to being hacked by an
adversary and turned against their owners.

Yet, just as the debate intensifies, a realistic assessment of the state
of the killer robots being developed confirms what the Swiss ambassador
to the CCW feared --- technological progress is far outpacing
deliberations over containment. But even if it weren't, amid a
splintering international order, plenty of nation-states are readily
violating humanitarian laws and treaties anyway, while others are
seeking new ways to gain a strategic edge in an increasingly hostile,
multipolar geopolitical environment.

**[[National Interests Undermine Collective
Action]{.underline}]{.mark}**

While Turkey may have been the first to allegedly deploy live [[killer
robots]{.underline}]{.mark}, their wide-ranging [[use is likely to be
driven by **Beijing**]{.underline}, **[Moscow]{.underline}** [and
Washington]{.underline}]{.mark}. [**Chinese** President]{.underline}
[[Xi]{.underline}]{.mark} Jinping [[and]{.mark} Russian
President]{.underline} Vladimir [[Putin]{.underline} [both **openly
loathe the Western**]{.underline}]{.mark}**[-oriented human rights
[doctrines]{.mark}]{.underline}** [[that underpin calls to ban]{.mark}
killer [robots]{.mark}]{.underline}. And despite America's domestic
division and dysfunction, its political class still has a bipartisan
desire for the United States to remain the world's global military
hegemon.

With a GDP just slightly larger than that of the state of Florida,
[[Russia's inability to compete in]{.mark} a **great power
competition**]{.underline} [economically [renders it reliant on]{.mark}
exploiting **[asymmetric]{.mark} power
[imbalances]{.mark}**]{.underline} [wherever possible, [including
through]{.mark} furthering its [**[AI]{.mark} capability** for military
and espionage
purposes](https://www.aljazeera.com/news/2021/11/30/uk-spy-chief-warns-china-russia-racing-to-master-ai)]{.underline}.
Autonomous weapons could be well-suited to secure the resource-rich but
inhospitable terrain of the Arctic, a region where the Kremlin is
actively trying to assert Russia's primacy. The country is also the
[world's second-largest arms
exporter](https://crsreports.congress.gov/product/pdf/R/R46937) behind
the United States, accounting for one-fifth of global arms sales since
2016 --- a key source of government revenue and foreign influence. Its
recent [anti-satellite weapons
test](https://www.bbc.com/news/science-environment-59299101) underscores
the Kremlin's willingness to explore controversial weapons technologies
too, even in the face of international condemnation.

President **[[Xi]{.underline}]{.mark}** Jinping, meanwhile, [has
**[pinned [China's ambitions of remaking the global
order](https://www.theatlantic.com/international/archive/2021/12/china-wants-rule-world-controlling-rules/620890/)]{.mark}**]{.underline}
[in favour of autocracies [on]{.mark} the domination of **[key emerging
technologies]{.mark}.**]{.underline} On track by some estimates to
becoming the [world's biggest economy by
2028](https://www.cnbc.com/2021/02/01/new-chart-shows-china-gdp-could-overtake-us-sooner-as-covid-took-its-toll.html),
[China is [pouring **spectacular amounts**]{.mark} of money and
resources [into]{.mark}]{.underline} everything from
**[[AI]{.underline}]{.mark}**, **[nanotechnology]{.underline}**
[and]{.underline} **[quantum computing]{.underline}** to genetics and
synthetic biology, and has a [stranglehold on the market for rare earth
metals](https://www.scmp.com/news/china/diplomacy/article/3130990/chinas-dominance-rare-earths-supply-growing-concern-west).
After tendering his resignation in September out of frustration, the
Pentagon's ex-software chief, Nicolas Chaillan, declared in an
[interview](https://www.ft.com/content/f939db9a-40af-4bd1-b67d-10492535f8e0)
with the Financial Times a month later that the United States will have
"no competing fighting chance against China in 15 to 20 years."

China is also notably keen on state-sponsored intellectual property
theft to accelerate its innovation cycles. The more that others
demonstrably advance on killer robots, the more that China will attempt
to steal that technology --- and inevitably succeed to a degree. This
could create a self-reinforcing feedback loop that hastens the killer
robot arms race among military powers.

This race of course includes the United States. The New York Times
[reported](https://www.nytimes.com/2005/02/16/technology/new-model-army-soldierrolls-closer-to-battle.html)
back in 2005 that the Pentagon was mulling ways to integrate killer
robots into the US military. And much to the dismay of progressives,
even Democrat-led administrations exhibit no signs whatsoever of winding
down military spending any time soon --- the Biden administration
released a decidedly [hawkish Global Posture
Review](https://theintercept.com/2021/12/02/biden-military-deployment-global-footprint/)
at the end of November just as a massive [US\$770 billion defence
bill](https://www.reuters.com/world/us/majority-us-senate-backs-770-billion-defense-bill-2021-12-15/)
sailed through Congress. The US military has already [begun training
drills to fight enemy
robots](https://www.forbes.com/sites/davidhambling/2021/10/22/us-army-carries-out-first-exercise-fighting-enemy-robots/?sh=21c0313556c0),
while deploying autonomous weapons systems could uphold its capacities
for foreign intervention and power projection overseas, now that
[nation-building projects have fallen out of
fashion](https://www.bbc.com/news/world-asia-57489095).

Most important of all, mass production of killer robots could offset
America's flagging enlistment numbers. The US military requires 150,000
new recruits every year to maintain its desired strength and capability.
And yet Pentagon data from 2017 revealed that more than 24 million of
the then 34 million Americans between the ages of 17 and 24 --- over 70
percent --- would have been [disqualified from serving in the
military](https://www.heritage.org/defense/report/the-looming-national-security-crisis-young-americans-unable-serve-the-military)
if they applied, due to obesity, mental health issues, inadequate
education or a criminal record. Michèle Flournoy, a career defence
official who served in senior roles in both the Clinton and the Obama
administrations, [told](https://www.bbc.com/news/world-59755100) the BBC
in December that "one of the ways to gain some quantitative mass back
and to complicate adversaries' defence planning or attack planning is to
pair human beings and machines."

Other, [**[smaller players]{.underline}** [are nurturing an
affinity]{.underline}]{.mark} [for LAWS [too]{.mark}]{.underline}.
**[[Israel]{.underline}]{.mark}** [assassinated Iran's top nuclear
scientist]{.underline}, Mohsen Fakhrizadeh, outside of Tehran in
November 2020 [using a remote-controlled, [AI-assisted machine
gun](https://www.nytimes.com/2021/09/18/world/middleeast/iran-nuclear-fakhrizadeh-assassination-israel.html)]{.underline}
mounted inside a parked car, [and is [devising more remote ways to
strike back against
Hamas](https://www.businesslive.co.za/bd/opinion/2021-05-20-remote-warfare-will-not-end-age-old-israel-palestine-conflict/)]{.underline}
in the Gaza Strip. [Since 2015, **[South Korea]{.mark}**]{.underline}
[has placed nearly fully [autonomous sentry
guns](https://www.bbc.com/future/article/20150715-killer-robots-the-soldiers-that-never-sleep)
on the edge of its demilitarized zone with North Korea]{.underline},
[selling the domestically built robot turrets to customers throughout
the Middle East]{.underline}. Speaking at a defence expo in 2018, Prime
Minister Narendra [Modi of]{.underline} **[[India]{.underline}]{.mark}**
--- the world's second-largest arms buyer ---
[[told](https://timesofindia.indiatimes.com/india/india-moves-to-develop-ai-based-military-systems/articleshow/64250232.cms)
the audience: "New and emerging technologies like AI and Robotics will
perhaps be the most **important determinants** of **defensive and
offensive capabilities** for **any** defence force in the
future."]{.underline}

**Pandora's box is [already open]{.underline}.**

Elsa B. **Kania 18**, Senior Fellow with the Technology and National
Security Program at the Center for a New American Security, "The Pursuit
of AI Is More Than an Arms Race",
https://www.defenseone.com/ideas/2018/04/pursuit-ai-more-arms-race/147579/

In many respects, [[this]{.mark} particular [Pandora's box is **already
open**]{.mark}]{.underline}[,]{.mark} [so [calls
for]{.mark}]{.underline} absolute [[bans may prove **too little, too
late**]{.underline}]{.mark}. Increasingly, [states and]{.underline} even
[non-state actors are using]{.underline} commercial, off-the-shelf
[technologies to enable **new military capabilities**]{.underline}; ISIS
[uses](https://www.defensenews.com/digital-show-dailies/modern-day-marine/2017/09/21/in-drones-isis-has-its-own-tactical-air-force/)
cheap commercial drones to gather intelligence and provide close air
support. [The [**rapid advances** in **AI**]{.mark}
**[tech]{.mark}nologies** [continue]{.mark}, and [[new
products]{.mark}](https://spectrum.ieee.org/automaton/robotics/drones/skydio-r1-drone)
and available
[algorithms](https://www.digitaltrends.com/cool-tech/dronet-autonomous-naviagation/)
can [enable]{.mark} the **autonomy** and thus [**scalability** of these
capabilities.]{.mark}]{.underline}

[[It seems **unlikely** that **any major military would**]{.mark} **be
willing to [tie its hands]{.mark}**]{.underline} [[or]{.underline}
**[constrain its pursuit of technologies]{.underline}**]{.mark}
[and]{.underline} **[capabilities]{.underline}** [[that are so
**strategic**]{.underline} [and]{.underline} **[evolving so
rapidly]{.underline}**]{.mark}. [[Beyond]{.mark} the [lack of
trust]{.mark}, attempts to enable **[verification]{.mark}** of
compliance with any future agreements [would]{.mark} also [be
**challenging at best.**]{.mark}]{.underline}

**[AT: AI Impact\-\--1NC]{.underline}**

**We'll adapt to AI.**

Amy **Zhang 21**, PhD candidate at Cornell studying Operations Research
and Research Assistant at Cornell Tech, "DLI Debate: Does AI Pose an
Existential Threat to Humanity?," Cornell Tech, 5/16/21,
https://www.dli.tech.cornell.edu/post/dli-debate-does-ai-pose-an-existential-threat-to-humanity

First of all, [[AI]{.mark} as a tool [is **not
smart**]{.mark}]{.underline}. It needs you to tell it exactly 1. what is
the specific goal to achieve, 2. a success metric that is meticulously
defined, and 3. information to use as a basis that you prepare and feed
in. Then to what extent can you say that AI does bad things? For
example, if a company is allowed to set maximizing the time spent in an
app as its ultimate goal, is it the algorithm's fault for achieving it?
Or if we task a model to mimic our speech by showing it all of Twitter
to use as example, and it produces language that mirrors some of the
toxicity, can we call the model racist? [What [it]{.mark} really [comes
down to]{.mark} is in **[how]{.mark}** these [**systems** are
**designed**]{.mark}, and whether it is done with the level of
**awareness** and]{.underline} **[sensitivity]{.underline}** [required
in really **thinking through** these **human aspects.**]{.underline}

Indeed[, an important part of this [relies on]{.mark} **checks** and
**balances** put in by the **[government]{.mark}**]{.underline} [and
other **rule-setting agencies.** [And]{.mark} it is **true** that [it
can be **frustrating** to feel like they\'re]{.mark}]{.underline}
**[[not measuring up]{.mark},]{.underline}** [which then could lead to a
**pessimistic outlook**]{.underline} that they never will and this will
never work. [[But]{.mark} there are two important points to consider
here. Number one, [there will be a **lag** in **legislative actions**
with **any**]{.mark} **technological advances**]{.underline} almost [by
definition. A [nascent tech]{.mark}nology first needs **time** to
**emerge**, to **grow**]{.underline}, [and to become **widespread
enough** that it **matters**]{.underline} [to the **general public**.
**Then**]{.underline}, only once it gets past the point where people are
just immersed in the excitement and the benefits - because it does
provide real benefits - [do **problems** become **apparent** and gain
**attraction**.]{.underline} [That's when the **agencies** can go in and
try to **understand them**, which in itself is not easy.]{.underline}
Then a second point to consider is that this is creating a new context,
and any change in contexts is very difficult to grapple with for the
legislative. Keep in mind that even the processes that seem very
established today, have gotten here only after being studied and refined
over a long period of time. One should expect this case to be no
different. [So yes, it will take time, but [that **does not mean** that
we will **never get there.**]{.mark}]{.underline}

In addition, [it is very important to bear in mind that [**society**
itself is **adaptive**]{.mark}.]{.underline} **[Humans are
adaptive]{.underline}**[. [This is **not the first
time**]{.underline}]{.mark} [that **[tech]{.mark}nological
[breakthroughs]{.mark}** have [become a **disruptive force**]{.mark} in
human society.]{.underline} Yes, it\'s true that [such disruptions
**bring out** previously dormant **conflicts**]{.underline}, [in a way
that [can **feel like** a]{.mark}]{.underline}
[**[crisis]{.underline}**. [But]{.underline}]{.mark} [it is also a
**chance** for us to **re-examine** and to **make
changes**]{.underline}. We have done this in history, and we have seen
through history that it\'s by facing up to these challenges that
societies progress[. [We have seen]{.mark} this through [many
revolutions]{.mark}, and **this will be another one**]{.underline}. One
is right to argue that it will be all on a much larger scale, but that
exponential rate of change is part of the nature of progress, and part
of what societies have potential to adapt to. So if anything, the
concern with AI is that it\'s still unable to change itself. This means
that unless we do something about it, past mistakes could be frozen in
place and propagated, and that could be the actual risk to our progress
as societies. That\'s why, again, the burden of responsibility is on us
humans.

**[AT: AI Impact\-\--2NC]{.underline}**

**AI will never develop consciousness.**

Meg **Young 21**, Postdoctoral Fellow at Cornell Tech\'s Digital Life
Initiative, "DLI Debate: Does AI Pose an Existential Threat to
Humanity?," Cornell Tech, 5/16/21,
https://www.dli.tech.cornell.edu/post/dli-debate-does-ai-pose-an-existential-threat-to-humanity

Returning to what Salome has asserted, [let\'s]{.underline}
**[pause]{.underline}** for a moment [to **take in**
[the]{.mark}]{.underline} [**[argument]{.underline}** [that AI
poses]{.underline}]{.mark} [[an **existential
risk**]{.underline}]{.mark} to humanity. [An **existential threat** is
one that will **destroy life on earth**]{.underline}\-\--to **[literally
wipe it out]{.underline}**. [This argument [warns]{.mark} that [AI will
become **super intelligent**]{.mark}]{.underline},
**[overpower]{.underline}** [its **human creators** to]{.underline}
[pursue its own]{.underline} **[unimaginable ends]{.underline}**, and to
menace life as it takes over the planet. [[But]{.mark} what would need
to be true for that to be possible? AI would need to be **intelligent**
in a **meaningful sense**]{.underline}. Meaning it can reason, form its
own goals, and pursue those goals across contexts. In other words, it
would need to be able to think for itself. The philosopher John Searle
refers to this idea that AI will ever be able to do that as quote, "an
enormous philosophical confusion about the correct interpretation of AI
technology." He points out that [**[consciousness]{.underline}** [is
**essential** to **intelligence**]{.underline}]{.mark}.
[And]{.underline} that [without it, **even** an **advanced system** like
IBM Deep Blue is **not playing chess** in the **same way** a **chess
master**]{.underline} like Garry Kasparov [is]{.underline}. Instead**[,
it is just performing a computation.]{.underline}** [We know that [AI is
**not conscious** and **not at risk of becoming
so**]{.mark}]{.underline}[,]{.mark} [because consciousness is an
**enduring mystery**]{.underline} in philosophy, neuroscience, and
psychology. **[[Basic science]{.underline}]{.mark}** [[is **not able**
to **characterize consciousness**]{.mark}]{.underline} and where it
comes from in vivo, [so [why do we think]{.mark} that [**computer
scientists** will be **able** to **recreate it**]{.mark} **in
silico[?]{.mark}**]{.underline}

**[[Proponents]{.underline}]{.mark}** [of **super-intelligent AI** argue
that the technology is **already** on **course** to **emulate human
intelligence**]{.underline}. [They say]{.underline} that because
computational power is becoming cheaper and faster,
**[eventually]{.underline}** [machine learning systems like neural nets
will function **akin** to a **human brain**]{.underline} [and exceed it
in **unpredictable ways**]{.underline}. [But this argument
**[mis-apprehend]{.mark}s** **[what intelligence
is]{.mark}**]{.underline}[.]{.mark} [[It is]{.mark} much [**more** than
the **ability to solve problems**]{.mark}]{.underline}[.]{.mark} A
driverless car, while much more computationally intensive, is no closer
to being sentient than a calculator is; both are machines purpose-built
to solve problems, and both are equally unlikely to plot to kill
humankind. Instead, increases in computational power are merely bringing
us a better and more convincing illusion that AI is super intelligent.
To people decades ago, Siri and Alexa would have seemed akin to Rosie,
the humanoid robot on The Jetsons. But knowing Siri and Alexa as we do
today, we know they cannot be called "intelligent" in a meaningful sense
at all. So yes, we are on course to get better simulations of
intelligence, but [they\'ll have **none** of the **underlying
capability**]{.underline} [necessary for **consciousness
itself**]{.underline}\--[and as such, they **pose no risk** of
**overthrowing humanity.**]{.underline}

**No runaway AI**

Edward Moore **Geist 15**, MacArthur Nuclear Security Fellow at Stanford
University\'s Center for International Security and Cooperation, Former
Stanton Nuclear Security Fellow at the RAND Corporation, Doctorate in
History from the University of North Carolina, "Is Artificial
Intelligence Really An Existential Threat to Humanity?", Bulletin of the
Atomic Scientists, 8-9,
https://thebulletin.org/2015/08/is-artificial-intelligence-really-an-existential-threat-to-humanity/

Superintelligence: Paths, Dangers, Strategies is an astonishing book
with an alarming thesis: Intelligent machines are "quite possibly the
most important and most daunting challenge humanity has ever faced." In
it, Oxford University philosopher Nick [[Bostrom]{.underline}]{.mark},
who has built his reputation on the study of "existential risk,"
[[argues]{.underline}]{.mark} forcefully [that **[a]{.mark}**rtificial
**[i]{.mark}**ntelligence [might be]{.mark}]{.underline} the most
[[apocalyptic]{.mark} technology]{.underline} of all. With intellectual
powers beyond human comprehension, he prognosticates, self-improving
artificial intelligences could effortlessly enslave or destroy Homo
sapiens if they so wished. While he expresses skepticism that such
machines can be controlled, Bostrom claims that if we program the right
"human-friendly" values into them, they will continue to uphold these
virtues, no matter how powerful the machines become.

[These views have found an eager audience]{.underline}. In August 2014,
PayPal cofounder and electric car magnate Elon Musk tweeted "Worth
reading Superintelligence by Bostrom. We need to be super careful with
AI. Potentially more dangerous than nukes." Bill Gates declared, "I
agree with Elon Musk and some others on this and don't understand why
some people are not concerned." More ominously, legendary astrophysicist
Stephen [Hawking concurred]{.underline}: "I think [the development
of]{.underline} full [artificial intelligence could spell the end of the
human race]{.underline}." Proving his concern went beyond mere rhetoric,
Musk donated \$10 million to the Future of Life Institute "to support
research aimed at keeping AI beneficial for humanity."

Superintelligence is propounding a solution that will not work to a
problem that probably does not exist, but Bostrom and Musk are right
that now is the time to take the ethical and policy implications of
artificial intelligence seriously. [The [extraordinary claim]{.mark}
that machines can become so intelligent as to gain demonic powers
**[requires extraordinary evidence]{.mark}**, particularly
[since]{.mark} artificial intelligence (AI) [researchers]{.mark} have
[**struggled** to create]{.mark} machines that show [much]{.mark}
evidence of [intelligence at all]{.mark}]{.underline}. While these
investigators' ultimate goals have varied since the emergence of the
discipline in the mid-1950s, the fundamental aim of AI has always been
to create machines that demonstrate intelligent behavior, whether to
better understand human cognition or to solve practical problems. Some
AI researchers even tried to create the self-improving reasoning
machines Bostrom fears. [Through decades of bitter
experience]{.underline}, however, [[they learned]{.mark} not only that
creating [intelligence is **more difficult** than]{.mark} they initially
[expected]{.mark}, but also that [it grows **increasingly
harder**]{.mark} the smarter one tries to become. [Bostrom]{.mark}'s
concept of "superintelligence,"]{.underline} which he defines as "any
intellect that greatly exceeds the cognitive performance of humans in
virtually all domains of interest," [[builds upon]{.underline}]{.mark}
similar [**[discredited assumptions]{.mark}** about the nature of
thought]{.underline} that the pioneers of AI held decades ago. A summary
of Bostrom's arguments, contextualized in the history of artificial
intelligence, demonstrates how this is so.

In the 1950s, the founders of the field of artificial intelligence
assumed that the discovery of a few fundamental insights would make
machines smarter than people within a few decades. By the 1980s,
however, they discovered **[[fundamental
limitations]{.underline}]{.mark}** that [[show]{.mark} that there will
**[always]{.mark}** be [**diminishing returns** to additional]{.mark}
processing [power and data]{.mark}]{.underline}. Although these
**[[technical hurdles]{.underline}]{.mark}** pose no barrier to the
creation of human-level AI, they [will likely **[forestall]{.mark}**
the]{.underline} sudden [emergence of [an unstoppable
"superintelligence."]{.mark}]{.underline}

[The [risks of self-improving]{.mark} intelligent [machines are
**grossly exaggerated**]{.mark} and ought not serve as a **distraction**
from the existential risks we already face]{.underline}, especially
given that the limited AI technology we already have is poised to make
threats like those posed by nuclear weapons even more pressing than they
currently are. Disturbingly, little or no technical progress beyond that
demonstrated by self-driving cars is necessary for artificial
intelligence to have potentially devastating, cascading economic,
strategic, and political effects. While policymakers ought not lose
sleep over the technically implausible menace of "superintelligence,"
they have every reason to be worried about emerging AI applications such
as the Defense Advanced Research Projects Agency's submarine-hunting
drones, which threaten to upend longstanding geostrategic assumptions in
the near future. Unfortunately, Superintelligence offers little insight
into how to confront these pressing challenges.

**It\'s [super far off]{.underline} and won't be threatening**

Dr. Oren **Etzioni 16**, Professor of Computer Science at the University
of Washington, CEO of the Allen Institute for Artificial Intelligence,
Ph.D. from Carnegie Mellon University and BA from Harvard University,
"No, the Experts Don't Think Superintelligent AI is a Threat to
Humanity", MIT Technology Review, 9-20,
https://www.technologyreview.com/s/602410/no-the-experts-dont-think-superintelligent-ai-is-a-threat-to-humanity/

[[If you **believe everything you read**, you are]{.mark} probably quite
[worried about]{.mark}]{.underline} the prospect of [a superintelligent,
[killer AI]{.mark}]{.underline}. The Guardian, a British newspaper,
warned recently that "we're like children playing with a bomb," and a
recent Newsweek headline reads, "Artificial Intelligence Is Coming, and
It Could Wipe Us Out."

Numerous such [headlines]{.underline}, fueled by comments from the likes
of Elon Musk and Stephen Hawking, [are strongly influenced
by]{.underline} the work of one man: professor Nick
[Bostrom]{.underline}, author of the philosophical treatise
Superintelligence: Paths, Dangers, and Strategies.

[Bostrom is a]{.underline}n Oxford [philosopher, but **quantitative
assessment of risks** is the province of actuarial science]{.underline}.
He may be dubbed the world's first prominent "actuarial philosopher,"
though the term seems an oxymoron given that philosophy is an arena for
conceptual arguments, and risk assessment is a data-driven statistical
exercise.

So what do the data say? Bostrom aggregates the results of four
different surveys of groups such as participants in a conference called
"Philosophy and Theory of AI," held in 2011 in Thessaloniki, Greece, and
members of the Greek Association for Artificial Intelligence (he does
not provide response rates or the phrasing of questions, and he does not
account for the reliance on data collected in Greece).

His findings are presented as probabilities that human-level AI will be
attained by a certain time:

> By 2022: 10 percent.
>
> By 2040: 50 percent.
>
> By 2075: 90 percent.

This aggregate of four surveys is the main source of data on the advent
of human-level intelligence in over 300 pages of philosophical
arguments, fables, and metaphors.

To get a more accurate assessment of the opinion of leading researchers
in the field, I turned to [the Fellows of the **A**merican
**A**ssociation for **A**rtificial **I**ntelligence]{.underline}, [a
group of researchers who are recognized as having made significant,
sustained contributions to the field]{.underline}.

In early March 2016, AAAI [sent out [a]{.mark}n anonymous
[survey]{.mark}]{.underline} on my behalf, posing the following question
[[to 193 fellows]{.underline}]{.mark}:

"In his book, Nick Bostrom has defined Superintelligence as 'an
intellect that is much smarter than the best human brains in practically
every field, including scientific creativity, general wisdom and social
skills.' **[[When]{.mark} do you think [we will achieve
Superintelligence?]{.mark}]{.underline}**"

Over the next week or so, 80 fellows responded (a 41 percent response
rate), and their responses are summarized below:

![https://cdn.technologyreview.com/i/images/ykuvebi16-1.jpg?sw=600&cx=0&cy=0&cw=1024&ch=689](media/image1.jpeg){width="2.8640004374453194in"
height="1.9252504374453194in"}

In essence, [[according to 92]{.mark}.5 [percent]{.mark} of the
respondents, **superintelligence is [beyond the foreseeable
horizon]{.mark}**]{.underline}. This interpretation is also supported by
written comments shared by the fellows.

Even though the survey was anonymous, 44 fellows chose to identify
themselves, including Geoff Hinton (deep-learning luminary), Ed
Feigenbaum (Stanford, Turing Award winner), Rodney Brooks (leading
roboticist), and Peter Norvig (Google).

The respondents also shared several comments, including the following:

> "[Way, way, way more than 25 years.]{.underline} **[[Centuries most
> likely]{.mark}. But not never]{.underline}**."
>
> "[We're competing with millions of years' evolution of the human
> brain. [We can write single-purpose programs]{.mark} that can compete
> with humans]{.underline}, and sometimes excel, [[but the world is
> **not**]{.mark} **neatly [compartmentalized]{.mark} into
> single-problem questions**]{.underline}."
>
> "Nick [[Bostrom is a]{.mark} professional [**scare monger**.
> His]{.mark} Institute's [role is to find existential
> threats]{.mark}]{.underline} to humanity. [**[He sees them
> everywhere]{.mark}**. I am tempted to refer to him as [the '**Donald
> Trump' of AI**]{.mark}]{.underline}."

Surveys do, of course, have limited scientific value. They are
notoriously sensitive to question phrasing, selection of respondents,
etc. However, it is the one source of data that Bostrom himself turned
to.

Another methodology would be to extrapolate from the current state of AI
to the future. However, this is difficult because we do not have a
quantitative measurement of the current state of human-level
intelligence. We have achieved superintelligence in board games like
chess and Go (see "Google's AI Masters Go a Decade Earlier than
Expected"), and yet our programs failed to score above 60 percent on
eighth grade science tests, as the Allen Institute's research has shown
(see "The Best AI Program Still Flunks an Eighth Grade Science Test"),
or above 48 percent in disambiguating simple sentences (see "Tougher
Turing Test Exposes Chatbots' Stupidity").

[There are many valid concerns about]{.underline} AI, from its impact on
jobs to its uses in autonomous weapons systems and even to the potential
risk of [superintelligence. However, [predictions]{.mark}]{.underline}
that **[[superintelligence is on the foreseeable horizon are not
supported by]{.mark} the available [data]{.mark}]{.underline}**.
Moreover, [[doom-and-gloom predictions]{.underline}]{.mark} often
[[fail]{.mark} to consider the potential benefits of AI]{.underline} in
preventing medical errors, reducing car accidents, and more.

**Military Innovation DA**

**[1NC\-\--DA]{.underline}**

**Transatlantic AI innovation is surging now.**

Edward Hunter **Christie 22**, Senior Research Fellow at the Finnish
Institute of International Affairs, "Defence Cooperation in Artificial
Intelligence: Bridging the Transatlantic Gap for a Stronger Europe,"
European View, vol. 21, no. 1, SAGE Publications Ltd, 04/01/2022, pp.
13--21

Investment challenges

As noted in the introduction, [there is a significant **gap** between
overall **US** and **European** **defence** spending levels. This
general pattern]{.underline} **[also]{.underline}** [holds for
defence]{.underline} **[r]{.underline}**esearch [and]{.underline}
**[d]{.underline}**evelopment spending. In 2020, EU spending in this
area amounted to €8 billion (EDA 2021). For the US, with caveats as to
comparability, expenditure for 'research, development, test and
evaluation' totalled approximately €90 billion3 in the 2021 fiscal year
(from October 2020 to September 2021), or about 10 times more.

Investment [challenges go]{.underline} **[beyond]{.underline}** issues
of [**scale**. The US]{.underline} also [has]{.underline} **[greater
experience]{.underline}** [in]{.underline} the **[setting
up]{.underline}** [and]{.underline} **[operation]{.underline}**
[of]{.underline} **[structures]{.underline}** [to]{.underline}
**[promote]{.underline}** both [**military and dual-use innovation**.
While the best-known institution is the]{.underline}
**[D]{.underline}**efense **[A]{.underline}**dvanced
**[R]{.underline}**esearch **[P]{.underline}**rojects
**[A]{.underline}**gency, **[other]{.underline}** [US government
structures are also relevant in discussions on fostering innovation in
**AI**]{.underline} [for]{.underline} [**military applications**. A
much-discussed example is **In-Q-Tel**]{.underline}, which was
originally set up as the state venture-capital arm of the Central
Intelligence Agency. To illustrate the influence of the In-Q-Tel
example, one may note that both its current Chief Executive Officer,
Chris Darby, and one of its former Chief Executive Officers, Gilman
Louie, served among the 15 commissioners of the National Security
Commission on Artificial Intelligence.4 This was a temporarily created
expert commission mandated by the US Congress to provide policy
recommendations for a whole-of-government and whole-of-society approach
for US AI policy.5

With In-Q-Tel, the idea is to learn from private-sector practices in the
area of venture-capital investment and repurpose them for state needs
and more patient time horizons. A supported company should pursue
product development strategies aimed at serving both civilian markets
and government needs. In this way, rather than effectively taking over a
commercial company and limiting its growth potential to future
government contracts alone, the government body encourages an
intermediate trajectory made up of mixed revenue streams, in the hope
that this will generate greater returns to scale and higher efficiency
thanks to the disciplining effect of private-sector competition.
Conversely, the advantage of this approach as compared to not
intervening at all is that the commercial company will integrate current
and likely future government needs into its product and
business-development strategy, rather than ignoring them and finding
itself, at a later date, unable to supply the government sector
according to the latter's requirements.

A related issue which falls between what can be achieved with new
investment instruments and new protections that can be assured through
the screening of foreign direct investment is the provision of
investment from trusted private investors to the technology sector.
[Certain technology companies that are not part of the traditional
defence industry may be developing dual-use products]{.underline} that
are [of potential interest to the defence sector while having limited
awareness of national security concerns. This may make them vulnerable
targets for both licit and illicit attempts to **acquire their
technologies**]{.underline} [on the part of **foreign state
actors**]{.underline}. [At the same time, their business development
needs may lead them to seek **investment** from]{.underline} **[any
potential source]{.underline}**, thus [exposing them to potential
**risks**]{.underline}. To respond to this challenge, the US Department
of Defense has launched a scheme called the Trusted Capital Marketplace
(US Department of Defense 2021a).

[Building on these considerations]{.underline}, the
**[NATO]{.underline}** Innovation Unit [has developed two new
instruments for Allied use]{.underline} which were announced to the
public in October 2021 (NATO 2021a; 2021b). [Both]{.underline}
instruments [aim to foster]{.underline} **[tech]{.underline}**nological
**[innovation]{.underline}** [with a deliberate focus on dual-use
applications and on enterprises with mixed (potential) revenue streams.
The first instrument is the Defence Innovation Accelerator for the North
Atlantic (DIANA), which is a NATO instrument, that is, it involves the
participation of all 30 NATO Allies. The second instrument is the NATO
Innovation Fund, which in NATO terminology is a 'multinational'
instrument]{.underline}, namely one [that Allies freely opt
into]{.underline}.

[DIANA will aim to accelerate the]{.underline}
**[adoption]{.underline}** [of dual-use technological solutions through
several interlocking components.]{.underline}6 First, [it will develop a
network of national organisations, in particular test centres and
innovation accelerators]{.underline}. Second, [it will competitively
select private-sector innovators and allow them to use national
organisations in the network to interface with military end users and
military capability-development specialists]{.underline}. Third, [it is
envisaged that DIANA will provide mentorship and education services for
private innovators to familiarise them with the opportunities and
responsibilities inherent to the defence and security
sector]{.underline}. Fourth, [DIANA will develop a database of trusted
financial investors from Allied nations and support matchmaking between
investors and innovators]{.underline}. Fifth and finally, [DIANA will
also provide expert advice on defence and security innovation to all
relevant stakeholders, including private-sector and academic
entities.]{.underline}

[Regarding the NATO Innovation Fund, 17 Allies had **opted into the
Fund**]{.underline} [as of the date of its announcement]{.underline} in
October 2021. [The participating Allies will inject up to €1 billion
into Allied innovation ecosystems over the next 15 years]{.underline}.
[The Fund aims to attract **additional private
investments**]{.underline} [due to the de-risking effect, both financial
and technological, thanks to state co-funding and diligence and
screening efforts. The funds are intended to be used for **long-term
support of 'deep tech' innovative companies**]{.underline}, that is, for
advanced research into AI, quantum and related technologies that may
have both military and civilian applications. [Due diligence and
security screening practices will aim to ensure that both private
investors and fund recipients are **trusted** entities.]{.underline}

**The AFF saps funding for AI research AND eliminates beneficial
dual-use technology.**

**Castro & McLaughlin 19** \-\-- \*Vice President, ITIF, and Director,
Center for Data Innovation. \*\*Research Analyst Information Technology
and Innovation Foundation

Daniel & Michael, 2-4-2019, \"Ten Ways the Precautionary Principle
Undermines Progress in Artificial Intelligence,\" ITIF,
https://itif.org/publications/2019/02/04/ten-ways-precautionary-principle-undermines-progress-artificial-intelligence/

[Many groups have started movements to **ban lethal autonomous
weapons**---autonomous robotics systems that can independently identify
and engage targets based on programmed constraints---due to fears that
they will lead to armed conflict on a scale greater and faster than ever
before.]{.underline} For example, 116 founders of mostly small robotics
and AI companies, including Elon Musk, signed a letter to the United
Nations (UN) in 2017 that urges the body to ban lethal autonomous
weapons.36 In 2018, the UN Secretary-General António Guterres stated
that "machines that have the power and the discretion to take human
lives are politically unacceptable, are morally repugnant, and should be
banned by international law."37 Also in 2018, members of the European
Parliament adopted a resolution asking member states and the European
Council for "the start of international negotiations on a legally
binding instrument prohibiting lethal autonomous weapons systems."38 [If
policymakers enacted such a ban, it would **slow research into AI**, as
historically, at least in the United States, **defense agencies** have
been a **source of significant funding** for **technology advancement**,
such as the Internet]{.underline}. [And much of the research to
**support autonomous weapons** would **yield dual-use technology** that
could be used **for commercial purposes**]{.underline}. [For example, a
fully autonomous tank will likely rely on large portions of the same
algorithms and data used to develop a fully autonomous military
transport vehicle]{.underline}.39 [**These same algorithms would be
relevant** to developing autonomous vehicles **for civilian
use.**]{.underline}

**[Continued AI innovation]{.underline} enables us to out-compete
China.**

**Wheeler**, visiting fellow in Governance Studies at The Brookings
Institution, Chairman of the Federal Communication Commission (FCC) from
2013 to 2017, **'20**

(Tom, "Digital Competition With China Starts With Competition At Home,"
<https://www.brookings.edu/wp-content/uploads/2020/04/FP_20200427_digital_competition_china_wheeler_v3.pdf>)

[[The U]{.underline}]{.mark}nited [[S]{.underline}]{.mark}tates [[and
China]{.underline} [are engaged in]{.underline}]{.mark} a
[**[technology-based conflict]{.underline}** [to
**determine**]{.underline}]{.mark} [**21st-century** international
[economic **leadership**]{.mark}]{.underline}. [China's
approach]{.underline} [is to identify]{.underline} and support the
research and development efforts of a handful of "**[national
champion]{.underline}**" [companies]{.underline}. [The
**[dominant]{.mark} tech [companies]{.mark}**]{.underline} of the U.S.
**[[are de facto embracing this]{.underline}]{.mark}** Chinese
[policy]{.underline} in their effort to maintain domestic marketplace
control. [Rather than embracing a China-like consecration]{.underline}
of a select few companies, [[America's]{.mark} digital
[competition]{.mark}]{.underline} with China **[[should begin with
meaningful competition]{.underline}]{.mark}** at home and the
allAmerican reality that competition drives innovation.

America's dominant tech companies have seized upon the competition with
China as a rationale for why their behavior should not be subject to
regulatory oversight that would, among other things, promote
competition. "[China doesn't regulate its companies]{.underline}" [has
become a go-to policy response]{.underline}. When coupled with "of
course, we support regulation, but it must be responsible regulation,"
it throws up a smokescreen that allows the dominant tech companies to
make the rules governing their marketplace behavior.

[[At the heart of digital competition]{.underline}]{.mark} --- both at
home and abroad --- [[is the capital asset]{.mark} of the 21st
century:]{.underline} **[[data]{.underline}]{.mark}**. [Initiatives such
as **machine learning**]{.underline} [and **artificial
intelligence**]{.underline} are data-dependent, [requiring a large data
input]{.underline} [to enable algorithms to reach a
conclusion]{.underline}. [[China's immense
population]{.underline}]{.mark} of almost 1.5 billion [gives it an
advantage in this regard]{.underline}. By definition, a population that
approaches five times the size of the U.S. population produces more
data. The previously "backward" nature of the Chinese economy has
resulted in another Chinese data advantage: New smartphone-based apps,
created in place of the digital integration that China previously
lacked, produce a richer collection of data. [This bulk and richness of
Chinese data [creates]{.mark}]{.underline} **[[an inherent]{.mark}
digital [advantage]{.mark}]{.underline}** when compared to the United
States.

[[If the United States **will never out-bulk China**]{.underline} [in
the quantity and quality of]{.underline} [data**, it must
out-innovate**]{.underline}]{.mark} **[[China]{.underline}]{.mark}**.
[Here]{.underline}, [the U]{.underline}nited [S]{.underline}tates **[has
an advantage]{.underline}**, [should it choose]{.underline} to take it.
**[The [centralized control]{.mark}]{.underline}** of the Chinese
digital economy **[[is an anti-entrepreneurial
force]{.underline}]{.mark}**. In contrast, [**[innovation]{.underline}**
[is the hallmark of a free]{.underline}]{.mark} [and open
[market]{.mark}.]{.underline} [[But the]{.mark} domestic [market]{.mark}
[must]{.mark}, indeed]{.underline}, **[[be free]{.underline}]{.mark}**,
open, and competitive.

[Currently]{.underline}, [the]{.underline} American [digital marketplace
**is not competitive**]{.underline}. [A handful of
companies]{.underline} **[command]{.underline}** the marketplace by
hoarding the data asset others need to compete. [As innovative
as]{.underline} America's tech [giants may be]{.underline}, [they
represent a **bottleneck**]{.underline} **[that starves independent
innovators]{.underline}** **[of the mother's milk of digital
competition]{.underline}**. [If America is to **out-innovate
China**]{.underline}, [then]{.underline} American
**[innovators]{.underline}** [need access to the **essential data
asset** **required for that innovation**]{.underline}.

[The [nation's response]{.mark} to Chinese competition]{.underline}
[[must not be the adoption of]{.underline}]{.mark} China-like national
**[[champions]{.underline}]{.mark}**, nor the "China doesn't regulate
its companies that way" smokescreen. American [public [policy should
embrace]{.mark}]{.underline} the all-American concept of
**[[competition-driven innovation]{.underline}]{.mark}**. [[This begins
with **breaking the bottleneck**]{.mark} that withholds data from its
**competitive application**]{.underline}. [This **does not necessarily
mean** **breaking up** the dominant companies]{.underline}, but [it does
mean breaking]{.underline} open **[their mercenary lock]{.underline}**
on the **[assets essential for competition-driven
innovation]{.underline}**.

**Maintaining our innovative lead solves nuclear war**

**Kroenig and Gopalaswamy 18** -- Associate Professor of Government and
Foreign Service at Georgetown University and Deputy Director for
Strategy in the Scowcroft Center for Strategy and Security at the
Atlantic Council; Director of the South Asia Center at the Atlantic
Council

Matthew Kroenig and Bharath Gopalaswamy, \"Will disruptive technology
cause nuclear war?,\" Bulletin of the Atomic
Scientists, 11-12-2018, <https://thebulletin.org/2018/11/will-disruptive-technology-cause-nuclear-war/>

Rather, [we should think **more broadly** about how **[new
technology]{.mark}** might affect global politics]{.underline}, and, for
this, [it is helpful to turn to]{.underline} scholarly international
relations theory. The dominant theory of the causes of war in the
academy is [the "bargaining model of war." This theory [identifies
**rapid shifts**]{.mark} in the balance of power [as a **primary cause
of conflict**]{.mark}.]{.underline}

[International politics often presents states with conflicts that they
can settle through **peaceful bargaining**, but when bargaining **breaks
down, war results**. **Shi[fts]{.mark}** [in the balance of power are
**problematic** because they **undermine effective
bargaining**]{.mark}]{.underline}. After all, why agree to a deal today
if your bargaining position will be stronger tomorrow? And, [a clear
understanding of the **military balance of power** can contribute to
**peace**.]{.underline} (Why start a war you are likely to lose?) [But
shifts in the balance of power **muddy understandings** of which states
have the advantage.]{.underline}

You may see where this is going. [New technologies threaten to create
potentially **destabilizing shifts** in the balance of
power.]{.underline}

For decades, [stability in Europe and Asia has been supported by US
military power. In recent years]{.underline}, however, [the balance of
power in Asia has begun to shift, as China has increased its military
capabilities.]{.underline} Already, [[Beijing has become **more
assertive**]{.mark} in the region]{.underline}, claiming contested
territory in the South China Sea. [And the results of Russia's
**military modernization** have been on **full display** in its ongoing
intervention in Ukraine.]{.underline}

Moreover, [[China **may have the lead**]{.mark} over the United States
[in **emerging technologies**]{.mark} [that **could be decisive**
for]{.mark} the future of [military acquisitions]{.mark} and
warfare]{.underline}, [[including]{.underline}]{.mark} 3D
**[printing]{.underline}**, **[[hypersonic]{.underline}]{.mark}**
missiles, **[[quantum]{.underline}]{.mark}** computing,
**[[5G]{.underline}]{.mark}** wireless connectivity, [[and]{.underline}
**[a]{.underline}**rtificial **[i]{.underline}**ntelligence]{.mark}
(AI). And Russian President Vladimir Putin is building new unmanned
vehicles while ominously declaring, "Whoever leads in AI will rule the
world."

[[If China]{.mark} or Russia are able to **[incorporate new
tech]{.mark}nologies** into their militaries **[before the United
States]{.mark}**, then [this could lead to the kind of **rapid
shift**]{.mark} in the balance of power [that]{.mark} **often [causes
war.]{.mark}**]{.underline}

[If Beijing believes emerging technologies provide it with a **newfound,
local military advantage** over the United States]{.underline}, for
example, [it may be **more willing**]{.underline} than previously [to
**initiate conflict over Taiwan**. And if Putin thinks new tech has
**strengthened his hand**, he may]{.underline} be more tempted to
[launch a Ukraine-style **invasion of a NATO member**.]{.underline}

[[Either]{.mark} scenario [could bring]{.mark} these **[nuclear powers
into direct conflict]{.mark}** with the United States, and]{.underline}
once nuclear armed states are at war, [[there is an **inherent risk
of**]{.mark} **nuclear [conflict]{.mark}** [through limited]{.mark}
nuclear [war]{.mark} strategies, nuclear [brinkmanship]{.mark}, or
simple accident or [inadvertent escalation]{.mark}.]{.underline}

This framing of the problem leads to a different set of policy
implications. [The concern is]{.underline} not simply technologies that
threaten to undermine nuclear second-strike capabilities directly, but,
rather, any [technologies]{.underline} that [can result in a meaningful
shift in the broader balance of power]{.underline}. And [the solution
is]{.underline} not to preserve second-strike capabilities, but [to
**preserve prevailing power balances** more broadly.]{.underline}

When it comes to new technology, [this means that [the U]{.mark}nited
[S]{.mark}tates [should seek to **maintain an**]{.mark} **innovation
[edge]{.mark}**]{.underline}. Washington should also work with other
states, including its nuclear-armed rivals, to develop a new set of arms
control and nonproliferation agreements and export controls to deny
these newer and potentially destabilizing technologies to potentially
hostile states.

These are no easy tasks, but [the consequences of Washington **[losing
the race]{.mark}** for technological superiority to its autocratic
challengers just [might mean **nuclear
Armageddon**]{.mark}.]{.underline}

**[2NC\-\--Link]{.underline}**

**Forcing all NATO countries to adhere to uniform ethical guidelines
[hamstrings innovation]{.underline} and [the competitiveness of the
DIB]{.underline}.**

**Castro & McLaughlin 19** \-\-- \*Vice President, ITIF, and Director,
Center for Data Innovation. \*\*Research Analyst Information Technology
and Innovation Foundation

Daniel & Michael, 2-4-2019, \"Ten Ways the Precautionary Principle
Undermines Progress in Artificial Intelligence,\" ITIF,
https://itif.org/publications/2019/02/04/ten-ways-precautionary-principle-undermines-progress-artificial-intelligence/

1\. **[Slower and More Expensive AI Development]{.underline}**

[Policies based on the precautionary principle both slow and make the
development of AI more expensive]{.underline}. For example, if all fifty
U.S. states had laws such as New York's, which requires autonomous
vehicle firms to perform road testing under the paid supervision of
police, testing such vehicles would be more expensive. Moreover,
proposals to require even non-medical algorithms to undergo pre-market
trials would hurt the development of AI because such trials are
time-consuming and expensive. [Such proposals may also make AI systems
that use machine learning, and thus may change frequently and need more
testing, significantly less viable because such systems could constantly
need to go through a new approval process]{.underline}.96 [Finally,
policies that **increase the cost of developing AI** would likely
**discourage innovation in AI** by creating **a substantial barrier to
entry for startups** that lack sufficient funding to cover the cost of
proving their AI system is safe]{.underline}. For example, the GDPR has
dampened investment in European technology startups and led to a 30
percent decrease in the market share of small online advertising firms
that lack the resources to easily comply with the regulation.97

[**Restrictions on one AI technology** can also **limit ways to develop
another** AI technology. For example, researchers in Germany are using
drones hovering hundreds of meters above highways to record the
movements of vehicles. This data can help develop simulations to test
autonomous vehicles; such simulations are important tools for improving
the safety of autonomous vehicles because otherwise they would need to
travel billions of miles for safety validation]{.underline}.98 While
this novel method of collecting data to validate the safety of
autonomous vehicles may or may not prove valuable, [implementing it in
the United States would be would be difficult to do at scale until the
FAA implements its new rules that allow out-of-sight drone flights and
flights over people]{.underline}.99

**[2. Less Innovation]{.underline}**

[AI will spur innovation so policies that limit the development of AI
will limit innovation.100 For example, proposals to ban or limit the
introduction of autonomous vehicles would also limit the generation of
new businesses, business models, and ways to do deliver services through
the "passenger economy."]{.underline} The passenger economy, a term
coined by Intel and research firm Strategy Analytics, "is the economic
and societal value that will be generated by fully
autonomous...pilotless vehicles."101 The firms envision a world where a
significant portion of vehicle ownership is replaced by fleets of
autonomous vehicles that provide on-demand transportation. Productivity
would also increase as autonomous vehicles free employees to work during
their commutes and autonomous trucks to operate more efficiently. The
firms estimate the value of this economy could be \$7 trillion by
2050.102 Nations that ban autonomous vehicles will not experience the
benefits of such an economy.

**[3. Lower-Quality AI]{.underline}**

[There is often a negative correlation between making an AI system more
explainable and its accuracy.103 As a result, any policies that require
AI to be explainable could **lead to less accurate AI**]{.underline}.
For example, researchers at Mount Sinai Hospital in New York developed
an AI system called Deep Patient that can predict whether a patient is
contracting any of a wide variety of diseases.104 The researchers
trained Deep Patient on the health data from 700,000 patients, using
hundreds of variables, such as test results, which allow it to predict
diseases such as schizophrenia---which doctors struggle to
predict---extremely well.105 Even though its operators can verify its
accuracy by measuring outcomes, such as if a person is developing a
disease, it is difficult for its own developers to know why it made a
particular decision.106

Many sophisticated forms of AI pose a similar problem. [Developing an AI
system capable of explaining itself or justifying its decisions is an
incredibly challenging technical feat, so much so that the U.S. Defense
Advanced Research Projects Agency (DARPA) devoted \$75 million in 2017
to research how AI could achieve it.]{.underline}107 [Some groups are
skeptical that requiring explainability would chill
innovation]{.underline}. They cite DeepMind, a British company owned by
Google parent-company Alphabet, developing an AI system in 2018 that can
analyze eye scans to predict diseases while also providing doctors a map
of the features of disease it sees, such as hemorrhages.108 [However,
the fact that one of the world's leading AI companies could achieve a
form of explainability in a system it worked on for nearly two years is
not evidence that all other operators should or would be able to achieve
explainability for their AI easily]{.underline}.109 To be clear, it is
legitimate for companies, such as IBM, to create internal requirements
for AI explainability.110 [Requiring all firms to meet such a standard,
however, would **create a barrier to adopting AI,** because not all AI
systems are alike and not all businesses have a similar level of
expertise.]{.underline}

Nonetheless, it is important for AI operators to continually assess
their AI system's accuracy to ensure it is generating or predicting the
correct outcomes. The other option is to allow only AI applications that
operators can explain; this would lead to AI systems that consider fewer
variables and that use simpler algorithms to make decisions.  In turn,
this would reduce the effectiveness of AI that can generate significant
impacts such as identifying a terminal illness before a doctor can.

4\. Less AI Adoption

The right to human review illustrates how attempts to mitigate the
impact of AI could also stifle its adoption. One of the reasons firms
use AI is because it increases productivity as it can analyze large
amounts of data significantly faster and cheaper than humans. For
example, LawGeex, a firm that uses AI to automate the review and
approval of contracts, created an AI system that outperforms lawyers in
identifying risks in non-disclosure agreements (NDAs). During a test in
which 20 lawyers and LawGeex's AI were each given five NDAs to review,
the lawyers took an average of 92 minutes to review the contracts and
had a mean accuracy score of 85 percent. LawGeex's AI, however, achieved
94 percent accuracy and only took 26 seconds to review all the
contracts.111

A right to human review would require firms to review significant
decisions made by algorithms. Such a requirement is particularly
problematic because the complexity and amount of data used by some AI
systems to make accurate decisions can make it nearly impossible for
firms to explain exactly why a system made one decision, even though
they may be able to provide a general explanation of how the system
works. Thus, it would take significant time and expertise for a firm to
explain many decisions made by AI, which then makes using AI more
expensive---negating one of its benefits. Firms subject to a right to
human review can make one of three choices.  They can: 1) use
sophisticated AI, but face litigation if they cannot properly explain a
decision, 2) implement simple, and therefore more explainable but less
useful, forms of AI, or 3) leverage no AI at all. The first option is
not viable over the long term, leaving firms with only the latter two
options. And if firms choose either of these options, the economy will
be less productive.112

5\. Less Economic Growth

PricewaterhouseCoopers predicts AI can boost global gross domestic
product by 14 percent by 2030.113 Unfortunately, policies based on the
precautionary principle often discourage the use of AI out of fears that
AI will eliminate jobs. For example, Amy Webb, founder of the Future
Today Institute, which researches emerging technologies, professes, "We
need to address a difficult truth that few are willing to utter aloud:
AI will eventually cause a large number of people to be permanently out
of work\..."114

But policies that discourage the use of AI due to the prevalence of such
fears rob economies of ways to become more productive, something that
all developed nations will desperately need over the course of the next
three decades as populations age and dependency ratios increase. If
productivity growth really eliminates net jobs, then developed nations
should be in depression-like conditions, as productivity over the last
50 years has increased in most nations by over 75 percent.115 The
reality is that productivity leads to cost savings, most of which are
passed on to consumers in the form of lower prices or to workers in the
form of higher wages, both of which spur more spending, which in turn
spurs job creation. Consequently, virtually all economic studies show
that productivity gains lead to more jobs, even if there is short-term
job loss.116 Policies that aim to stem the introduction of AI, and thus
automation, will reduce per-capita income growth.

6\. Fewer Options for Consumers

Biometric laws show how passing legislation to address hypothetical
problems can discourage the use of AI, such that consumers have access
to fewer services or products. For example, Illinois users of Facebook,
Shutterfly, Google, and Snapchat have all sued the companies for
scanning their faces without consent, which is illegal under the state's
Biometric Information Privacy Act.117 Regardless, the companies were
typically sued for relatively innocuous uses of AI, such as for scanning
individuals' faces to tag them in photos or to add alterations to
photos.118

Such threats of legal action do and will lead to fewer services for
consumers. For example, Illinois and Texas' biometric laws led to Google
blocking individuals in those states from using its Arts and Culture
app.119 Millions of individuals have downloaded the app, which scans
users' faces and compares those images to those of paintings in Google's
database to find users' doppelgängers in famous art.120

Similarly, some lawmakers have already passed precautionary legislation
related to autonomous vehicles that limit consumers' options. For
example, Washington, D.C. enacted a law in 2013 that requires a licensed
human driver in the front seat of autonomous vehicles who is prepared to
take control of the vehicle at any moment. This requirement means people
with certain disabilities, who would like the independence that would
come from using autonomous vehicles but do not qualify as a capable
human driver under this law, are unable to use autonomous vehicles, even
if they can safely operate them.121 The requirement might be reasonable
given the current state of the technology, but locks in a standard that
is unhelpful over the long term. Instead of a broad restriction that
requires a capable individual in the driver's seat of autonomous
vehicles, government regulators, such as the National Highway Traffic
Safety Administration (NHTSA) in the United States, should develop and
enforce safety standards that preempt local laws, but allow the
operation of fully autonomous vehicles that meet safety standards.

7\. Higher Prices

By raising the costs of using AI for operators or by banning forms of
AI, policies based on the precautionary principle also keep prices high
for consumers. For example, some policies would require businesses to
get express consent before using facial recognition. Yet, U.S. stores
lose nearly \$50 billion every year due to shoplifting, and facial
recognition could reduce that figure by helping catch repeat
offenders.122 Shoplifting costs consumers because money lost from
shoplifting leads to higher prices---shoplifting cost the average U.S.
family over \$400 in 2009---instead of being put towards increased
investments in customer experience improvements.123

Another way the precautionary principle keeps prices artificially high
for consumers is by limiting the ways firms can offer their services or
products through bans. For example, delivery robots can perform the
"last mile" of a delivery---where transporters move packages from a
central hub to an individual's residence. Today the process is
time-intensive and can be up to 28 percent of a product's transportation
cost.124 As a result, efforts to ban robots on sidewalks, which could
reduce these costs, would rob consumers of faster and cheaper
deliveries.

Likewise, slowing the introduction of autonomous trucks hurts consumers.
There was a shortage of 51,000 truck drivers in the United States in
2017 which grew to 63,000 in 2018.125 Truck driver turnover rates are
also 94 percent, meaning employers in the for-hire trucking market need
to replace the vast majority of employees they hire every year.126 The
situation has already led to delayed deliveries and higher prices for
consumers and may only get worse because there will be 900,000 truck
driver openings in the United States over the next decade due to
retirements.127

8\. Inferior Consumer Experiences

Policies that require firms to get prior consent before using commercial
applications of AI, including facial recognition, can actually delay
improvements in consumer experiences. For example, AI may be able to
reduce the effects of implicit bias---the stereotypes that affect human
actions in an unconscious manner. These stereotypes lead to people of
color getting falsely accused of theft by store employees.128 Indeed,
employees for Nordstrom Rack, Staples, and Finish Line have all wrongly
accused African-Americans of theft in 2018.129 But AI technologies can
improve the consumer experiences of all people, including people of
color, by replacing or complementing human decision-making. Amazon Go,
one of Amazon's cash-register-less stores, uses cameras, sensors, and
computer vision technology to "see" who takes items off shelves, adding
these items to a virtual shopping cart so that checkout is seamless.
Many retailers are moving in this direction, with over 150 companies,
including 7-Eleven and two of China's largest e-commerce businesses,
Alibaba and JD.com, experimenting with using facial recognition and
other biometrics to eliminate the need for cashiers. As a result, store
employees are not looking for potential shoplifters because the
technology automatically charges customers for what they take when they
leave the store.130 After visiting Amazon Go, former CNET senior
associate editor Ashlee Clark Thompson, an African-American journalist,
wrote "No one cared what I was doing. Is this what it feels like to shop
when you\'re not black?"131

9\. Fewer Positive Social Impacts

AI can and already is generating positive social impacts, from mapping
poverty to measuring literacy rates to helping doctors treat deadly
infections.132 It is also helping make society safer, but the
demonization of such AI applications as facial recognition and proposals
to phase in AI could derail its benefits. While privacy advocates are
stoking fears of future mass surveillance, law enforcement is already
using facial recognition for several positive purposes. These purposes
include identifying uncooperative suspects, such as the Capital Gazette
shooter.133 In addition, some airports, such as the Washington Dulles
International Airport, employ the technology to catch individuals using
false documents.134

Law enforcement also uses AI to find victims. For example, the Fort
Worth Police Department uses a combination of AI tools from Marinus
Analytics, which builds AI tools to fight human trafficking, including
facial recognition, to identify victims of human trafficking. With
thousands of escort ads appearing online each day, AI can significantly
reduce the time it would take a detective to go through the ads
manually.135 While no government should use facial recognition to
undermine personal freedoms and rights among its citizens or to unfairly
target certain demographic groups, nations can mitigate negative uses
without creating bans that curtail the use of beneficial ones.

Unfortunately, misguided proposals to curtail negative impacts from AI
can create other negative impacts. For example, phasing in autonomous
trucks to lessen job loss would be detrimental to the environment.
Tractor trailers account for a disproportionate amount of greenhouse gas
emissions, but autonomous trucks can take advantage of platooning, a
form of driving where the trucks drive closer together than humans can
by using vehicle-to-vehicle communication and sensors to automatically
break and accelerate together.136 The trucks following the leader
experience less wind resistance, which improves fuel
efficiency.137 Limiting the number of autonomous trucks on roads,
however, keeps emissions from trucks higher than necessary. In addition,
banning autonomous vehicles in the United States would rob the nation of
a potential \$900 billion in yearly savings from fewer crashes.138

[10. **Reduced** Economic Competitiveness and **National
Security**]{.underline}

[**Nations that slow AI adoption will** metaphorically **tie one hand
behind the backs of their companies competing** in global markets.
Moreover, for nations such as the United States, finishing behind China
in the global race to be the leader in AI not only limits its ability to
influence the development of AI, but also raises **national security
concerns** due to the many **potential national security applications of
AI** and the **reduced competitiveness** of the **defense industrial**
base.139]{.underline}

**It stifles the positive benefits of AI development.**

**Gürkaynak 18** \-\-- Founding Partner of ELIG Gürkaynak
Attorneys-at-Law, LL.M. from Harvard Law School, İlay Yılmaz, Partner at
ELIG Gürkaynak Attorneys-at-Law, and Güneş Haksever, LLM from Istanbul
Bilgi University, Attorney at IBM Turkey.

Gönenç, "Stifling Artificial Intelligence: Human Perils", Computer Law &
Security Review, Volume 32, Issue 5, 12/12/2018,
https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3285264

[[Although scientists]{.underline}]{.mark} have [[calculated]{.mark} the
**[significant positive]{.mark} welfare [effects]{.mark}**
[of]{.mark}]{.underline} Artificial Intelligence [[(AI)]{.mark}, **fear
mongering** continues to **hinder** AI **development**. [If
**reg**]{.mark}**ulation[s]{.mark}** in this sector **[stifle]{.mark}**
our active imagination, [we risk **wasting**]{.mark} the **[true
potential]{.mark}** of AIs dynamic efficiencies]{.underline}. Not only
would Schumpeter dislike us for spoiling creative destruction, but the
AI thinkers of the future would also rightfully see our efforts as [[the
**'dark age'** of]{.mark} human [advancement]{.mark}]{.underline}. This
article provides a brief philosophical introduction to artificial
intelligence; categorizes artificial intelligence to shed light on what
we have and know now and what we might expect from the prospective
developments; reflects thoughts of worldwide famous thinkers to broaden
our horizons; provides information on the attempts to regulate
artificial intelligence from a legal perspective; and discusses how the
legal approach needs to be to ensure the balance between artificial
intelligence development and human control over them, and to ensure
friendly artificial intelligence.

Our technology, our machines, is part of our humanity. We created them
to extend ourselves, and that is what is unique about human beings. --
Ray Kurzweil1

1\. Introduction

The Chinese cardboard game "Go" is one of the most complex strategy
games humankind invented. Go was considered so important, there are
myths indicating that ancient kings played Go between their armies in
the battlefield to resolve the conflict in peace. Computers prevailed
against humanities best in many zero-sum, perfect-information, partisan,
deterministic strategy games2 before, with the exception of Go, which
was something to be proud of.

The strategy aspect of Go is very complex and emphasizes the importance
of balance on multiple levels and has internal tensions. A game of Go
cannot be won by using brute force: calculating every possible move,
similar to what IBM®'s then state of the art AI, Deep Blue® used to win
over Gary Kasparov. To manoeuvre through the countless possible moves on
the Go board and chose the most efficient path, one requires
capabilities beyond the conventional computing powers; capabilities only
our minds have (or so we thought), such as extremely accurate image and
pattern recognition and insight, all of which we thought granted us
superiority over the artificial minds we created.

In October 2015, a software called "AlphaGo®" became the first computer
to beat a professional human Go player in an un-handicapped game of Go
(Silver and Hassabis, 2016). AlphaGo's victory is probably one of the
most significant demonstrations of the capabilities of an AI. Firstly,
it shows that AIs are beginning to surpass us at things where success is
dependent on strategy as well as calculation. Things we classify as a
"game", from stock exchange to conflicts, from contract negotiations to
hostage situations. Second, AlphaGo developed strategies on its own,
through playing millions of games against itself. These feats sent the
chills down the spines of those who fear that AIs will overpower us in
the future.

We humans accelerate the future with our minds. This is a strength and a
weakness. [[Often]{.underline}]{.mark}, our [**[predictions]{.mark}** of
the future [are **highly inaccurate**. Based on]{.mark} predictions from
a book called ['The World in 2010']{.mark}, published [in]{.mark}
19[**76**, we]{.mark} should have **[be]{.mark}**en living [**above**
and **below**]{.mark} the surfaces of **[three planets]{.mark}** as of
**[five years ago]{.mark}**. Predictions [regarding]{.mark} the future
of **[AI]{.mark}** are **[equally]{.mark} likely** to be **[off
base]{.mark}**]{.underline}.

[To avoid **premature** regulation over AI, we should]{.underline} be
studying and **[search]{.underline}**ing [for the **meaningful point in
time** when a broader anxiety about AI becomes a genuine
concern]{.underline}. The study of a point of ripeness, a 'threshold
ability test,' asks when AI could really bring about concrete
disadvantages that might counter-balance the demonstrated contribution
to economic efficiency and welfare.

[In the absence of]{.underline} such [an **objective
benchmark**]{.underline} marking the point in time when AI becomes a
competitor with the human mind, [[regulators could]{.mark} easily
**[jump the gun]{.mark}** in regulating AI, [which]{.mark} would [lead
to **irreparable harm**]{.mark} in **total welfare** [of]{.mark} human
[societies]{.mark}]{.underline}.

Most of what we consider AI today is really our own intelligence
re-formatted and re-cycled, with the help of computers lacking any skill
of learning or consciousness of being. [Regulation at this stage would
be **perverse**. The economic efficiency **[potential]{.mark}**s of AI
[should be]{.mark} set **[entirely free]{.mark}** at **this point** in
time, [allowing]{.mark} us to **[active]{.mark}**ly [and
**aggressivel**]{.mark}y [research]{.mark} appropriate goals for them
which would **not** result in the **extinction** of
humankind]{.underline}.

[If you think]{.underline} our [future **robot overlords**
will]{.underline} one day [thank us for ignoring]{.underline} the risks
[and **under regulating**, **think again**]{.underline}. On the one
hand, [**[any issues]{.mark}** we may face [from **AI**]{.mark}s
[will]{.mark} likely [result from]{.mark} humanity [**failure**
to]{.mark} **effectively [direct]{.mark}** AIs [to]{.mark} our
**[needs]{.mark}**, **not** because we switched to a defensive AI
regulation regime **too early**]{.underline}. On the other hand, [[at
**some point**]{.mark} of time]{.underline} in the not too distant
future, [[**natural**, **human**]{.mark}**-related** [or
**external**]{.mark} factors may [**threaten** the **fate of the
Earth**, and we]{.mark} may **[need AI to save]{.mark} the planet and
[us]{.mark}**. One **[hope]{.mark}**s that [society has not **pulled
the**]{.mark} **hand [brakes]{.mark}** on the wheels of AI **[too
early]{.mark}**]{.underline}, fearing our own active imagination.

**Turns the AFF: Military regulations [destroys]{.underline} AI control
by driving it [underground]{.underline}, [abroad]{.underline}, or into
[higher-risk]{.underline} areas**

**Watson 21** \-\-- PhD in Engineering from the University of
Gloucestershire, Degree in AGI Safety Fundamentals from the University
of Cambridge, Senior Scientific Advisor to The Future Society at Harvard
University, Fellow at the British Computing Society and Royal
Statistical Society.

Dr. Nell, "Regulatory Challenges to Catastrophic AI Risk", ExO Insight,
11/24/2021, https://insight.openexo.com/regulatory-challenges-to-ai/

Rick Increase Factors:

Obfuscation: [**Reg**ulation**s** may **drive research underground**
where it is **harder to monitor**, or to **'flag of convenience'
jurisdictions** with **lax restrictions**, by **embedding** dangerous
**tech**nologies with**in** apparently benign **cover operations**
(multipurpose technologies), or by **obfuscating** the **externalized
effects** of a system, such as in the **vehicle emissions**
scandal]{.underline} (Wikipedia).

Arms race: Recent advances in machine learning such as multimodal
abstractions models (aka Transformers, Large Language Models, Foundation
Models) such as GPT-3 and DALL-E illustrate that dumping computing
resources (and the funds for them) in colossal models seems to be a
worthy investment. So far, there is no apparent limit or diminishing
return on model size, and so now state and non-state actors are
scrambling to produce the largest models feasible in order to access
thousands of new capabilities never before possible. An arms race is
afoot. Such [arms races can lead to **rapid** and **unexpected**
take-off in terms of AI capability, and the rush can blindside people to
risks, especially when]{.underline} the [loss]{.underline} of a race
[can mean an **existential threat**]{.underline} to a nation or
organization.

Perverse incentives: Incentives can be powerful forces within
organizations, and financialization, moral panic, or fear of political
danger may cause irrational or incorrigible behavior of personnel within
organizations.

Postmodern Warfare: Inexpensive Drones and other AI-enabled technologies
have tremendous disruptive promise within the realm of warfare,
especially given their asynchronous nature. Control of drone swarms must
be performed using AI technologies, and this may encourage the entire
theatre of war to be increasingly delegating to AI, perhaps including
the interpretation of rules of engagement and grand strategy. (Lsusr,
2021)

Cyber Warfare: Hacking of systems is increasingly being augmented with
machine intelligence (Cisomag, 2021), through GAN-enabled password
crackers (Griffin, 2019) and advanced social engineering tools (Newman,
2021). This is equally the case in the realm of defense, where only
machine intelligence may provide the swift execution required to defend
systems from attack. A lack of international cyberwar regulations, and
poor international policing of organized cybercrimes, may increase the
risk of catastrophic risks to societal systems.

Zersetzung: The human mind is becoming a new theatre of war, through
personalized generative propaganda, which may even extend to gaslighting
attacks on targeted individuals, significantly leading to
destabilization of societies (Williams, 2021). Such technologies are
also plausibly deniable, being difficult to prove who may be
responsible.

[Inflexibility: The German Military after WW1 was **not** allowed to
develop their **artillery** materiel, and so developed powerful
**rocket** **tech**nologies **instead**, as these were **not subject to
regulation**. Similarly, inflexible rules may permit **exploitable
loopholes**. They may also **not be sufficiently adaptive** to allow for
the **implementation** of **new technologies** and even improved
**industry standards**.]{.underline}

Limitation of problem spaces: -- [It may be taboo to allow machine
intelligence to work on sensitive issues or to be exposed to
controversial (if potentially accurate) datasets. This may limit the
ability of AI to make sense of out complex issues, and thereby
**frustrate finding** **solutions** for **crises**]{.underline}.

**[2NC\-\--AT: AI = No War]{.underline}**

**High tech warfare means [defense doesn't apply]{.underline}\-\--AI
escalation leads to [nuclear war]{.underline}**

**Saalman, 18**

Lorea Saalman, EastWest Institute Asia-Pacific Program Vice President,
"\"Fear of false negatives: AI and China\'s nuclear posture\"; Bulletin
of the Atomic Scientists. April 2018.
https://thebulletin.org/2018/04/fear-of-false-negatives-ai-and-chinas-nuclear-posture

New pockets of excellence. In its relations with Russia and the United
States, [China has long contended with nuclear asymmetry]{.underline}.
**[[AI]{.underline}]{.mark}** and autonomy, in contrast,
**[[offer]{.mark} Beijing the [long-term potential to disrupt
Washington's]{.mark} traditional [strengths]{.mark}]{.underline}**.
[They open the door for swarm and]{.underline} other [technologies that
could overwhelm conventional and nuclear platforms]{.underline} that are
larger, more cumbersome, and less agile. While China may be concerned
about potential adversaries tracking its own nuclear platforms and
systems, Beijing is just as likely to avail itself of these relatively
inexpensive methods of disrupting US activities. Also, Chinese
publications indicate that [[Beijing is building
autonomy]{.underline}]{.mark} into its own "bolt-out-of-the-blue"
systems, for example in hypersonic glide vehicles such as the DF-ZF. As
China debates integration of automation via launch-on-warning, [doing so
[with]{.mark} a **[greater]{.mark} range of [AI]{.mark}** and autonomy
in [it]{.mark}s tool kit [could lead to **destabilizing
trends**]{.mark}**.**]{.underline} Again, the most sensational advances
in these enabling technologies do not necessarily carry the greatest
implications for China's military and nuclear force structure. Instead,
[what counts is the level of AI and autonomy introduced into Beijing's
command and control structure.]{.underline}

When it comes to platforms, this author's preliminary review of Chinese
technical writings on AI and autonomy reveals that Beijing's greatest
emphasis, at least where the most flexible systems are concerned, is on
unmanned aerial and underwater vehicles. In China's view, these systems
can be leveraged for a range of activities, including enhanced accuracy
in: battlefield reconnaissance, surveillance, patrolling, electronic
reconnaissance, communications, electronic interference, combat
assessment, radar deception, projectile firearms, laser guidance, target
indication, precision bombing, interception and launch of tactical
missiles and cruise missiles, and anti-armor, anti-radiation, and
anti--naval vessel capabilities; as well as nuclear, chemical, and
biological detection and operations. When the topic turns to leveraging
new means of warfare, Chinese writings discuss the use of swarm systems
(link in Chinese) for a number of purposes, with battlefield
applications focusing on anti-submarine warfare and countering
integrated air defense.

AI and autonomy provide China an opportunity to exploit a new pocket of
excellence, but they are hardly ends in themselves. This is one of
myriad reasons that China has been reluctant to engage in arms control
efforts to constrain the deployment of autonomous systems. Moreover, the
amount of Chinese research already being conducted in this arena,
particularly at the university level, is substantial. Research is
unlikely to diminish any time soon. (Programs on AI and autonomy receive
ample government support through such funds as the Laboratory of
National Defense Technology for Underwater Vehicles, Project for
National Key Laboratory of Underwater Information Processing and
Control, National Key Basic Research and Development Program, China
Aviation Science Foundation, National Science and Technology Major
Project, National 973 Project, National Key Laboratory Fund, National
"863" High-tech Research and Development Program, and Ministry of
Communications Applied Basic Research Project, among a number of
others.)

Expansive programs to turn AI and autonomy into a weaponized reality,
even in challenging or illusory domains such as underwater swarms,
indicate the emphasis this research receives within the hierarchy of
Chinese defense planning. Whether or not China is able to achieve all of
these capabilities, the vast resources and manpower allocated to these
endeavors merit great attention by the United States. The direct
implications of aerial and underwater swarms for larger, more lumbering
US nuclear and conventional platforms remain to be seen. However, if the
US Congress provides funding for the low-yield submarine-launched
ballistic and cruise missiles proposed under the 2018 Nuclear Posture
Review, China could deploy swarms to track and potentially intercept US
dual-capable platforms. In short, whether intentionally or
unintentionally, an escalatory scenario could develop.

The evolution of smaller platforms mobilized in joint formations could
turn China's nuclear asymmetrical disadvantage on its head. Much like
decoys, which can be used as an inexpensive means of confusing and
saturating missile defenses, low-cost swarms of unmanned aerial and
underwater vehicles, along with cyber technologies, could provide a
"guerilla combat--style" advantage against systems that the United
States sees as providing an element of surprise, speed, and precision.
Some of these platforms are already destined for deployment and will
provide China with greater capability to monitor US activities in the
Asia-Pacific region. However, if these platforms are turned toward
actual engagement---in efforts to disrupt or confront lower-yield,
smaller-scale US nuclear or dual-capable platforms---the potential for
miscalculation may grow.

[[If China enhances]{.mark} its development of [cruise missiles and
hypersonic]{.mark} glide platforms [by applying AI]{.mark}]{.underline}
and autonomy, [close-range [encounters off]{.mark} the coast of [Taiwan
and in the]{.mark}]{.underline} East and
**[[S]{.underline}]{.mark}**outh **[[C]{.underline}]{.mark}**hina
**[[S]{.underline}]{.mark}**eas **[could [grow]{.mark} even [more
complicated]{.mark}]{.underline}**. China's ground-launched DH-10
missile is believed to carry a conventional warhead, but indications
have emerged that the air-launched CJ-10 may have both nuclear and
conventional variants. Moreover, China has hedged on what kind of
payload will be carried by hypersonic glide platforms such as the DF-ZF,
which are designed to break through missile defenses. With the release
of the 2018 Nuclear Posture Review and Vladimir Putin's subsequent
declaration that Russia has developed new nuclear weapons, the United
States and Russia have engaged in a game of tit-for-tat. If China
follows suit, [a new set of [destabilizing variables could be
introduced]{.mark} into a region that is already tense and
crowded]{.underline}, with freedom-of-navigation operations carried out
among competing territorial claims.

From asymmetry, advantage. Within this environment, China's integration
of AI and autonomy aligns with its attempts to avoid being surprised by
a false negative. Though the United States and Russia are both trending
toward intentional escalation in their official doctrines, China's
response to this trend indicates a desire to avoid getting dragged into
a nuclear arms race. Nonetheless, [Beijing's **assumptions** about US
preemptory behavior have shaped its efforts to leverage its nuclear
asymmetry into an advantage]{.underline}. [One significant step in this
direction comes through [greater Chinese integration of AI]{.mark} and
autonomy]{.underline}, meant to mitigate the risk of being caught off
guard, whether by a conventional or nuclear system. While some aspects
of this dynamic have stabilizing potential---as is true of enhanced
situational awareness---strong indications suggest that China is engaged
in other pursuits **[that [could lead to miscalc]{.mark}ulation [at
the]{.mark} conventional and [nuclear level]{.mark}]{.underline}**.

**Chinese AI dominance is the death knell of global peace\-\--sparks
great power wars**

**Allison 20 --** Professor of Government, Harvard Kennedy School

Graham Allison, August 2020, \"Is China Beating the U.S. to AI
Supremacy?,\" Belfer Center for Science and International Affairs,
<https://www.belfercenter.org/publication/china-beating-us-ai-supremacy>

An AI Arms Race?

During the Cold War, the stakes in the nuclear arms race with the Soviet
Union were obvious. [In today's **Thucydidean rivalry** between a
**meteorically** rising **China** and a colossal ruling **United
States**]{.underline}, [what are the risks of an escalating AI arms
race?]{.underline}

Like it or not, **[[future war will be AI-driven]{.underline}]{.mark}**.
As Secretary of Defense Mark Esper recently noted at the conference of
the National Security Commission on AI, "[[Advances]{.mark} in AI
[have]{.mark} the [potential to change]{.mark} the character of [warfare
for generations]{.mark} to come. **[Whichever nation harnesses AI first
will have a decisive advantage]{.mark} on the battlefield [for]{.mark}
many, many [years]{.mark}."**]{.underline} [AI's ability to accelerate
decision cycles in conflict will compel militaries to adopt
it.]{.underline} In air-to-air combat, pilots begin with an ooda loop:
observe, orient, decide, act. If A can "get inside B's OODA loop," A
wins---since he can maneuver to escape A's fire and attack where he
calculates B's path will leave him when A's missile arrives. Because AI
can observe, orient, decide and act at multiples of a human pilot, it
will become irresponsible to send a human pilot into battle with an AI
piloted aircraft.51 As former Chairman of the Joint Chiefs of Staff
Joeseph Dunford put it: "**[Whoever has the competitive advantage in
artificial intelligence and can field systems informed by artificial
intelligence, could very well have an overall competitive
advantage]{.underline}**."52

The demonstrated success of AlphaGo, and more recently, AlphaStar, in
defeating all competitors in one of the world's most complex real-time
strategy video games suggests that [in any structured contest between
offense and defense, **[AI will dominate humans]{.mark}.**]{.underline}
[The company, country or team with [the best AI will
win]{.mark}]{.underline}. As an example, consider American football. In
what commentators often discuss as a "chess match," the offense and
defense coordinators know that if the defense guesses correctly whether
the next play will be a pass or a run, most nfl teams' defenses can
successfully stop most opponents' offense. Reading all the variables in
a situation, [AI should be able to tilt the scales [on the
field]{.mark}]{.underline}---or in analogous military competitions on
land, sea, and in the air and space.

[The domain's leader will also be the first to know which of today's
military mainstays AI will upend]{.underline}. Germany discovered the
power of submarines before World War I because it led in their
development. [British admirals did not wake up to their deadly
efficiency until a lone German U-boat in 1914 sank three armored
cruisers on a single morning.]{.underline} **[By then, it was too
late]{.underline}**---the British had already invested their treasure in
building battle fleet that had become largely obsolete. The coordination
of drones and cruise missiles that successfully attacked Saudi Arabia's
most valuable target and cut its oil exports by half is suggestive. Will
[AI-empowered [drone swarms make aircraft carriers]{.mark} equally
[obsolete]{.mark}, all for one one-thousandth of the cost? Will
[AI]{.mark} analysis of data from all sources [pierce]{.mark} the
[invisibility of]{.mark} stealthy systems like [the F-35]{.mark} in
which the United States has invested so substantially? **[The first
country to know will be]{.mark} the one [driving the]{.mark} research
and [development frontier.]{.mark}**]{.underline}

**Chinese AI dominance increases incentives for China to be assertive in
foreign policy**

**Chang 18** -- Benjamin Angel Chang is the inaugural Andrew W. Marshall
Fellow at Georgetown University\'s Center for Security and Emerging
Technology (CSET).

Benjamin Angel Chang, December 2018, "Chapter 14. AI and US-China
Relations," in "AI, China, Russia, and the Global Order: Technological,
Political, Global, and Creative Perspectives,"
https://nsiteam.com/social/wp-content/uploads/2019/01/AI-China-Russia-Global-WP_FINAL_forcopying_Edited-EDITED.pdf

Independent of effects on the US-China relationship, [[intensified PRC
use of AI]{.mark} for domestic security [may]{.mark} also [encourage
greater Chinese assertiveness]{.mark}. Again, I highlight two potential
reasons. First, a pacified domestic sphere might free up attention for
expanded external aims]{.underline}. China's relative ability to weather
the 2008 financial crisis significantly motivated its recently more
assertive turn (Chen & Wang, 2011). Whereas many Chinese intellectuals
had previously sought to emulate Western economic development,
[**[viewing]{.mark} the [American stage of development as]{.mark} if [a
higher rung on a universally climbable ladder]{.mark}**, the **[crisis
incubated the view]{.mark} that, [instead, the Chinese model might be a
fine endpoint in and of itself]{.mark}**]{.underline}. Similarly, i[f
the CCP were to feel AI had successfully and permanently allowed it to
address the full panoply of possible sources of broad public unrest,
r**anging from unbalanced growth to Xinjiang to income inequality,** it
w]{.underline}ould likely see this as one of the Party\'s Chang 109
crowning achievements in its leadership of the Chinese people. Chinese
spending on domestic security has exceeded spending on external defense
since 2010, with the gap increasing each year. In 2017, according to the
best open-source estimate available, the former exceeded the latter by
18.6 percent (Zenz, 2018). Were [t]{.underline}he domestic sphere to be
"solved," some of this attention might then be turned outward. [Second,
**[concentrations of power generally]{.mark} tend to [lead to more
belligerence on the international]{.mark}** stage. In particular, by
substituting technology for manpower in carrying out the state\'s
policing functions]{.underline}, an [[AI]{.mark}**-empowered [PRC may
enable ever-smaller groups of elites to retain equivalent amounts
of]{.mark} power**]{.underline}. For de Mesquita et al. (1999, 2003),
[as the size of the coalition required for political survival (the
\"winning coalition\") shrinks, corruption and war may become more
likel]{.underline}y, as [[l**eaders no longer fear being
punished**]{.mark} **by other domestic actors [for selfish arrangements
or military defeats.37]{.mark}**]{.underline}

**[2NC\-\--AT: US Too Far Ahead]{.underline}**

**China's catching up\-\--continued innovation by America is necessary
to outpace them**

**Allison 20 --** Professor of Government, Harvard Kennedy School

Graham Allison, August 2020, \"Is China Beating the U.S. to AI
Supremacy?,\" Belfer Center for Science and International Affairs,
<https://www.belfercenter.org/publication/china-beating-us-ai-supremacy>

China's AI Surge

Though still in their infancy, [[AI tech]{.mark}nologies [will]{.mark}
be [drive]{.mark}rs of future economic growth and [national
security]{.mark}.]{.underline} From facial recognition and fintech to
drones and 5g, **[[China is not just catching up]{.mark}. [In many
cases]{.mark}, [it has]{.mark} already overtaken the United States to
[become the world's]{.mark} undisputed [No.
1]{.mark}]{.underline}**[.]{.mark} [In some arenas]{.underline}, because
of constitutional constraints and different values, [the United States
willfully forfeits the race. In others, **China is simply more
determined to win.**]{.underline}

China's AI surge is so recent that anyone not watching closely has
likely missed it. As late as 2015, when assessing its international
competition, American industry leaders---Google, Microsoft, Facebook and
Amazon---saw Chinese companies in their rearview mirrors alongside
German or French firms in the third tier. But this changed four years
ago---in 2016---when leading AI application company DeepMind fielded a
machine that defeated world champion Lee Sedol in the world's most
complex board game, Go.9 Even after several American companies' machines
had bested the chess masters of the universe10, most Chinese remained
confident that machines could never beat Go champions, since Go is ten
thousand times more complex than chess. Thus, DeepMind's decisive
victory became for China a "Sputnik moment"11---a jolt as dramatic as
the Soviet Union's launch of the first satellite into space that sparked
America's whole-of nation surge in math and science, nasa's creation and
the original "moon shot."

Kai-Fu Lee's book AI Superpowers offers an insightful summary of China's
engagement in the field. It began with President [[Xi]{.mark}
Jinping's]{.underline} personal reaction to the defeat of the world's Go
champion. **[[Declaring that]{.mark} this was a technology in which
[China had to lead]{.mark}]{.underline}**, [he set specific targets for
2020 and 2025 that p[ut China on a path to dominance over AI]{.mark}
technology and related applications by 2030]{.underline}.12 Recognizing
that this would have to be led by entrepreneurial companies rather than
agencies of government[, he designated five companies to become China's
national champions: Baidu, Alibaba, Tencent, iFlytek and
SenseTime]{.underline}.13 **[Twelve months after Xi's directive,
[investments in Chinese AI startups]{.mark} had [topped investments in
American]{.mark} AI [startups]{.mark}]{.underline}**.14 By 2018, [China
filed 2.5 times more patents in AI technologies than the United
States.15 And this year China is graduating three times as many computer
scientists as the United States.]{.underline}

In contrast to nuclear weapons---where governments led in discovery,
development and deployment---[AI and related technologies have been
created and are being advanced by private firms and university
researchers]{.underline}. **[The military establishments in
[Washington]{.mark}]{.underline}** and Beijing **[[are]{.mark}
essentially [playing catch-up, adopting]{.mark} and adapting
[private-sector products.]{.mark}]{.underline}**

Where do these two competitors stand in the AI race today? Consider
leading indicators under six key headings: product market tests,
financial market tests, research publications and patents, results in
international competitions, talent and national operating environments.

[Consumers' choices of products in markets speak for
themselves]{.underline}. In fintech, China stands alone. Tencent's
[WeChat Pay has nine hundred million Chinese users,16 while Apple Pay
only has 22 million in the United States]{.underline}.17 And when it
comes to capability, [WeChat Pay can do much more than Apple
Pay.]{.underline} [Chinese consumers]{.underline} use their app to buy
coffee at Starbucks and new products from Alibaba, pay bills, transfer
money, take out loans, make investments, donate to charity and manage
their bank accounts. In doing so, they [generate a treasure trove of
granular data about individual consumer behavior that AI systems use to
make better assessments of individuals']{.underline} credit-worthiness,
interest in products, capacity to pay for them and other
[behavior]{.underline}. In mobile payments, Chinese spend \$50 for every
dollar Americans spend, in total, \$19 trillion in 2018.18 U.S. mobile
payments have yet to reach \$1 trillion. Credit cards are as
old-fashioned to Chinese millennials as handwritten checks are to their
American counterparts. Mark Zuckerberg has noticed: Facebook's major
moves last year into digital payments,19 including the recent
introduction of Facebook Pay, are copying Tencent, rather than the other
way around.

In facial recognition, the world's most valuable AI startup is Chinese
company SenseTime20---a company whose headquarters Graham visited in
October. (While there, Graham also took a tour of Zhongguancun---China's
version of Silicon Valley---guided by Kai-Fu Lee whose hedge fund is one
of the leading VC investors in Chinese AI startups.) In 2018's
international competition for facial recognition, Chinese teams claimed
the top five places.21 Chinese firms---such as Hikvision and Dahua
Technology, which control a third of the world's security camera
market22; Tiandy, whose cameras need light from only a single star at
night to capture high-definition color images23; and Wuhan Guide
Infared, which specializes in infrared and thermal imaging---are working
hand in glove with their government to perfect facial recognition for
profit and control. In this domain, there is no U.S.-China contest; the
United States has essentially conceded the race because of concerns over
the average individual's privacy, and deep reservations about how this
technology could be deployed. Westerners were alarmed in 2017 when
researchers at Stanford created an AI algorithm that could detect with
shocking accuracy individuals' sexual orientation simply by scanning a
single photo24. It does not take much imagination to consider how less
socially liberal governments would apply this technology. So while San
Francisco recently banned facial recognition technologies, the Party has
given China's top four facial recognition firms access to its database
of over 1.4 billion citizen photos. One well-informed venture capitalist
in this arena estimates that Chinese facial recognition firms have 1
million times more images than their U.S. counterparts.

In speech tech, Chinese are beating American firms in all
languages---including English. The world's top voice recognition startup
is China's iFlytek. Its user base is seven hundred million, almost twice
the 375 million people who speak to Apple's Siri.25 In system
performance competitions, iFlytek regularly beats teams from Google,
Microsoft, Facebook, ibm and mit, all in its second language.26 At
Stanford's international challenge for machine reading comprehension,
Chinese teams won three of the top five spots, including first place.
Baidu developed a human-level speech recognition system a year before
Microsoft did.

Who was the U.S. Army's major supplier of commercial drones until
2017---when the United States prohibited purchases for foreign
suppliers?27 Shenzhen drone maker DJI, which controls 70 percent of the
global market28. Drones would be just miniature hobby helicopters
without elementary AI, which gives them computer vision for targeting
weeds or weapons, and enables them to operate in swarms. As the recent
attack on Saudi Arabia's principal oil facilities demonstrated, the
world has just begun to discover the security consequences of
AI-enhanced drones operating literally below the radar. Of the world's
top five commercial drones brands, 3 are Chinese; 1 American.29

[5g infrastructure will be the backbone that enables AI to reach further
into everyday life, from automated cars to smart glasses.]{.underline}
[China's Huawei is the world's leading supplier of this telecom
equipment. Not only does it own the Chinese market, which will be the
world's largest, but its 28 percent global market share nearly equals
the combined shares of its two top competitors]{.underline}.30 Of the
top four brands that will build 5g infrastructure, two are Chinese and
zero are American. [Chinese firms own twice as many 5g -essential
patents as American firms.]{.underline} While the outcome of the current
U.S. government campaign against Huawei remains uncertain, [the company
is currently delivering 5g systems well ahead of all competitors and is
bringing a 5g phone to market a year ahead of Apple, the company that
invented the iPhone.]{.underline}

[Financial markets reflect these realities]{.underline}. Five years ago,
two of the world's twenty most valuable internet companies were Chinese;
today, nine are. The "Seven Giants of the AI age"---Google, Amazon,
Facebook, Microsoft, Baidu, Alibaba and Tencent---are split on either
side of the Pacific. Of every ten venture capital dollars invested in AI
in 2018, five went to Chinese startups; four to American firms.31 Of the
world's top ten AI startups, half are American and half are Chinese.

**[[Chinese investments]{.mark} in AI research [and development]{.mark}
have [surged to American levels]{.mark}, [and]{.mark} the [results are
beginning to show]{.mark} it.]{.underline}** **[The blunt truth is that
China is laying the intellectual groundwork for a generational advantage
in AI.]{.underline}** According to the Allen Institute for Artificial
Intelligence's authoritative assessment, China would overtake the United
States in 2019 in the most-cited 50 percent of AI papers. It will take
the lead in the most-cited 10 percent this year. And by 2025, the United
States will fall to second in the top 1 percent of papers.32
(Fortunately, in breakthrough papers, China remains behind.) In public
patents for AI technologies, China passed the United States in 2015, and
in 2018 filed 2.5 times more than America.33 In machine learning's
hottest subfield---deep learning---China has six times more patent
publications than the United States. (Raw numbers, however, must be
taken with a grain of salt, since not all patents are equal.)

[China is investing heavily in the necessary hardware as
well.]{.underline} In 2001, China had none of the world's five hundred
fastest supercomputers. Last year, it had 219 (the United States has
116).34And while China's supercomputers previously relied on American
semiconductors, its top machine today was built entirely with
domestically-manufactured processors.

**[2NC\-\--AT: China Wins Now]{.underline}**

**Close, but *not inevitable*\-\--[regulatory environment]{.underline}
and maintaining [comparative advantages]{.underline} in the private
sector are key**

**Allison 20 --** Professor of Government, Harvard Kennedy School

Graham Allison, August 2020, \"Is China Beating the U.S. to AI
Supremacy?,\" Belfer Center for Science and International Affairs,
<https://www.belfercenter.org/publication/china-beating-us-ai-supremacy>

Clues for a Winning Strategy

**[Is AI a race China is destined to win?]{.underline}** With a
population four times the size of the United States, there is no
question that China will have the largest domestic market for AI
applications. With many multiples of the United States in data,
substantially larger numbers of computer scientists and a government for
which there is a first-order priority, [we can understand colleagues who
are pessimistic]{.underline}. Indeed, **[it is our best judgment that on
the current trajectory, [while the U]{.mark}nited [S]{.mark}tates [will
maintain a narrow lead]{.mark} over the next five years, [China will
then catch up]{.mark} and pass us quickly thereafter]{.underline}**.

Nonetheless, we **[believe that [this is an arena]{.mark} in which [the
U]{.mark}nited [S]{.mark}tates [can]{.mark} compete---and
[win]{.mark}]{.underline}**. Congress recently established the "National
Security Commission on Artificial Intelligence," with Eric Schmidt as
its chair, and Bob Work, who served as Deputy Secretary of Defense under
both Obama and Trump, as Vice Chair. Its mission is to develop that
strategy "to ensure America's national security enterprise has the tools
it needs to maintain U.S. global leadership."55 In the hope of being
helpful to that effort, we conclude with five pointers toward a winning
strategy.

First, Americans must wake up to the challenge. [[Recognition that that
the U]{.mark}nited [S]{.mark}tates [faces a serious competitor]{.mark}
in a contest in which the outcome will be decisive for our future [is
necessary to get]{.mark} our [competitive juices
flowing]{.mark}.]{.underline} The Olympics offers an instructive analogy
for thinking about a competitive strategy for AI. It also reminds us
that competition is inherently a good thing. Competition produces
superior performance. Participants in a marathon run faster than they do
when running alone. Indeed, competition is a core American value. Free
markets organize a competitive process that produces better products at
cheaper prices. Science and its applications advance as research teams
compete to better understand the world.56

Second, in this competition, the United States cannot hope to be the
biggest---in that category, China wins by default due to the size of its
population. However, what the United States can be is the smartest. In
the seeking to improve and advance the most advanced of technologies,
the brightest 0.0001 percent of individuals make the difference. The
United States can succeed by recruiting talent from all 7.7 billion
people on Earth and enabling these individuals to realize their full
potential.57 In fact, U.S. companies have now recruited more than half
of the top 100 recognized AI geniuses. In sharp contrast, China is a
closed society---limited essentially to 1.4 billion Chinese speakers.
Just 1000 foreign born individuals became Chinese citizens last year. So
while the United States will not win competitions in which bulk numbers
are the dominant factor, where brilliance, creativity and innovation
matter most, the United States has a decisive advantage.58

Third, platforms matter. [Here [the U]{.mark}nited [S]{.mark}tates
[begins with a huge sustainable]{.mark} competitive [advantage]{.mark}:
[English is the]{.mark} universal [language for]{.mark} science,
business and [the web]{.mark}]{.underline}. Chinese face the choice of
either speaking English, or simply talking to themselves. Not only do
the Chinese, but also the French and others often complain that this is
unfair---and it may be. But it is a fact. To transform Singapore from a
third-world city into one of the world's most successful and prosperous
global trading hubs, Lee Kuan Yew insisted on making English its first
language. (Indeed, at one point in counseling Chinese leaders, he
suggested that China make English its first language.) Today, more than
half of the 7.5 billion people on Earth speak English---and another
billion are seeking to learn.

Fourth, [[American companies have a]{.mark} significant [first mover
advantage]{.mark} in the establishment of the major platforms [in AI,
including operating systems]{.mark}]{.underline} (Android and Apple),
[design of advanced semiconductors]{.underline} (arm), [[and killer
apps]{.underline}]{.mark}---including Instagram, YouTube and Facebook.
Instagram has 1 billion monthly active users; Facebook more than 2.4
billion. While Chinese competitors will certainly attempt to displace
the current leaders in both platforms and applications, [if American
companies are smart enough to continue enlarging their users'
opportunities]{.underline}, improving their experiences, and expanding
the number of people using their platforms and applications, [Chinese
and others who want to speak to the world could have to continue relying
on U.S.-dominated platforms.]{.underline}

**IR K**

**[Link -- AI -- Tech Thesis]{.underline}**

**The advent of modernity is marked by the disappearance of humanity --
the global integration of AI is a strategy of [racialized
governance]{.underline} via digitalized corporatization that has
exceeded sovereignty and become a [Leviathan]{.underline} built on
[speed]{.underline} and [acceleration]{.underline} into a dystopic
future that marks populations deemed unworthy for [death]{.underline}**

**Mbembe 19** -- member of the staff at the Wits Institute for Social
and Economic Research (WISER) at the University of the Witwatersrand,
visiting appointment at the Franklin Humanities Institute at Duke
University PhD in History at the Sorbonne, DEA in Political Science at
the Instituts d\'études politiques, \[Achille, "Bodies as Borders," From
the European South 4, pg. 5-18, DKP\]

My intervention is a set of urgent, fragmentary, and unfinished
reflections on our global present. When I say 'our global present', what
I truly have in mind is the sustainability and durability of our planet.
As a matter of fact, this is an almost existential preoccupation, which
is increasingly expressed in many different voices and shared by various
people all over the world.

Indeed, many are wondering how we should inhabit anew and share as
equitably as possible a planet whose life-support system has been so
severely damaged by human activities and that is in dire need of repair.
[In view of the deep state of fragmentation the planet finds itself in,
they are asking: how should we re-member it, that is, put back together
its different parts, reassemble it and reconstitute it as an integrated
system in which humans and nonhumans, physical, chemical and biological
components, oceans, atmosphere and land-surface are all interlinked in a
grand gesture of mutuality?]{.underline}

[These [questions of]{.mark} inhabitation and interconnection, of
[mutuality]{.mark}, sustainability and durability, of the interlacing of
human history and Earth's history [are far from abstract]{.mark}
concerns.]{.underline} In fact, the ongoing long-term planetary
environmental changes have only further dramatized them, and [there is
little doubt that [they will be at the centre of any debate on the
future of life and]{.mark} the future of [reason]{.mark} in this
century.]{.underline} To properly attend to them forces us to refocus
our attention on three mega processes that have an almost overwhelming
bearing on what humanity and the planet we live on (the only one, so
far, where life is known to exist) might become.

Early 21st-century corporate sovereignty

[The first mega process is the unprecedented **[consolidation of power
and knowledge]{.mark}** (political, financial, and technological)
**[in]{.mark}** the hands of]{.underline} private
[high-tech]{.underline} corporate [entities whose sphere of action is
not one country or one region, but the globe. '**[Corporate
sovereignty']{.mark}** has taken various forms throughout
history.]{.underline} Take, for instance, the English East India Company
and its political dominance in some parts of the Indian subcontinent in
the 18th century. A composite, diffuse and hybrid entity, it exercised
powers customarily associated with formal state institutions. It could
acquire territories and exercise authority over people. It could engage
in wide ranging operations such as tax collection and war making. In
competition with the monarchical and national state, [it **[was a key
part of]{.mark}** the different institutional and constitutional forms
that shape]{.underline}d **[[imperial expansion]{.underline}]{.mark}**
(see Stein 2011).

The conditions that have enabled the expansion of privatized government
in the first half of the 21st century are well known. [Many of these
have to do with the various legal frameworks behind international trade
agreements, foreign investment treaties and other mechanisms that have
turned markets into the single most undisputed forces of our
times.]{.underline} Others have to do with the computational
transformations of financial markets and the possibilities afforded by
media technologies (see Beverungen and Lange 2018). Furthermore, whether
the old distinction between the economic power of corporations and the
political sovereignty of states still holds is more and more open to
debate (read Barkan 2013). Most global corporations aspire to secede
from everybody else while exercising surveillance on everybody else.
Their big dream is to be exempt from taxes and to be free from
accountability; in short, to enjoy the kind of immunity and state of
exceptionality we used to recognize only to truly sovereign powers.

In a recent book about what she terms "surveillance capitalism," Shohana
Zuboff argues that **[[a global architecture of behaviour modification
is under way. Driven by powerful states, high-tech corporations and
military apparatuses, surveillance capitalism
threatens]{.mark}]{.underline}** what she calls [["**human
nature"**]{.mark} in the 21st century, just as industrial capitalism
disfigured the natural world in the 20th.]{.underline} She shows the
extent to which [vast wealth is accumulated in what she terms new
"behavioural futures markets," that is, markets where predictions about
our behaviour are bought and sold, and the production of goods and
services is subordinated to new means of behavioural
modification.]{.underline} Indeed, **[[capital,]{.underline}]{.mark}**
especially finance capital, **[[has become]{.mark} our shared
infrastructure, [our nervous system]{.mark}, the transcendental maw
[that]{.mark} nowadays [maps out our world and its psycho-physical
limits]{.mark}]{.underline}** (Zuboff 2018). Around us, it looks as if
[nothing escapes its control. **[Affects, emotions]{.mark}** and
**[feelings,]{.mark}** manifestations of desire, **[dreams]{.mark}** or
thoughts -- **[no sphere]{.mark}** of contemporary life **[has been left
untouched]{.mark}**]{.underline} by the spread of capital. [Capital now
extends its grasp deep into the underbelly of the world. In its wake, it
leaves vast fields of debris and toxins, waste heaps of
humans]{.underline} ravaged by sores and boils. [Now that everything is
a potential source of capitalization, it has made a world of itself: a
hallucinatory phenomenon of planetary dimensions]{.underline}.

Early 21st -century corporate sovereignty is therefore an unprecedented
form of power, whose main aspiration is to free itself from democratic
oversight. As a result, we might no longer live in an epoch when
sovereignty was exercised by the demos. **[[The demos properly
understood might no longer be the sovereign]{.underline}]{.mark}**.
Finance capital in the guise **[[of a ubiquitous digital
architecture]{.mark} might have definitely [become the new
Leviathan.]{.mark} [We are witnessing t]{.mark}he historical
[bifurcation between liberal democracy and finance capitalism]{.mark},
and the emergence of a new form of sovereignty -- corporate sovereignty
-- which claims for itself the law of immunity and the powers of
exception.]{.underline}**

The computational speed regime

The second mega process I would like to invoke is **[[technological
escalation]{.underline}]{.mark}** and the ways in which it
[**[has]{.mark} totally [redefined]{.mark} the nature of [speed,
unshackled markets and the economy, and]{.mark}**]{.underline} the way
it **[[constantly monitors]{.mark} our [behaviour]{.mark} in an attempt
at [revealing how it could be]{.mark} modified and
[optimized.]{.mark}]{.underline}** As a matter of fact, some of the
fastest expanding markets in the world today are 'markets for future
behaviour'. They rely on better understanding incipient future intent.
This "could be future voting intentions, the intent to commit fraud, the
intent to buy life insurance, or the intent to stream a specific video,"
argues Louise Amoore (2019, 4). These markets also rely on the
extraction and mining of new forms of raw material, mostly consisting of
information and details about individuals' behaviour taken, as Zuboff
writes, from the distant corners of our unconscious. It is raw material
"plumbed from intimate patterns of the self" -- "our personality, our
moods, our emotions, our lies, our vulnerabilities, every level of our
intimacy" (2018, 201). **[[The purpose is not only to heighten the
predictability of our behaviour. It is also to make life itself amenable
to 'datafication'.]{.mark}]{.underline}**

[A key feature of our times is therefore the extent to which [all
societies are organized according to]{.mark} the same principle -- [the
computational]{.mark}.]{.underline} [We are surrounded with ubiquitous
computing, technologies that weave themselves [into the fabric
of]{.mark} our [everyday lives]{.mark},]{.underline} devices, sensors,
things we interact with and [which have become part of our presence in
the world all the time.]{.underline} How the boundary between us and
these devices is enacted is a matter of open debate (Matzner 2019).

But, what is the computational? [**The computational is generally
understood as a technical system whose function is to capture, extract,
and automatically process data that must be identified, selected,
sorted, classified, recombined, codified and activated**.]{.underline}
Yet we shouldn't forget that **[[the computational
is]{.underline}]{.mark}** also **[a force and
[energy]{.mark}]{.underline}** of a special kind, a speed regime with
its own qualities and infrastructures. It is a force and energy [**[that
produces]{.mark}** and serializes **[subjects]{.mark}**, objects,
phenomena; that splits reason from consciousness and memory, codes
**[and stores data that can be used to
manufacture]{.mark}**]{.underline} new types of services and devices
sold for profit. **[Whether operating on bodies, nerves, material,
blood, cellular tissues, the brain or energy, the aim is the same, i.e.
the conversion of all substances into quantities; [the conversion of
organic and vital ends into technical means]{.mark}; the capture of
forces and possibilities and their [annexation by the language of a
machine-brain transformed into an autonomous]{.mark} and automated
[system.]{.mark}]{.underline}**

But [the computational is also the institution through which a common
world, a new common sense and new configurations of power, of perception
and of reality are nowadays brought into being.]{.underline} The
globalization of corporate sovereignty, the extension of capital into
every sphere of life and technological escalation in the form of the
computational are all part of one and the same process.

The dialectics of entanglement and separation

The third mega process is what we should call the dialectics of
entanglement and separation. All over the world, [the combination of
**[fossil capital, soft-power warfare, and the saturation of the
everyday]{.mark}** by digital and computational technologies **[has led
to the acceleration of speed]{.mark}** and the intensification of
connections, creating a new redistribution of the Earth]{.underline} and
of population movements. **[[To be alive,]{.mark} or to remain alive,
[is]{.mark} increasingly [tantamount to]{.mark} being able to move
[speed]{.mark}ily.]{.underline}**

[In the process, the human race has come up against terrestrial
limits.]{.underline} [Such limits are not only the consequence of the
sphericality of the planet. They are also limitations on the expansion
of life as such.]{.underline} **[[As the planet increasingly seems bound
to burn, it is not only the individuated bodies that are imperilled. It
is earthly existence]{.mark}, the fate of everything on earth, the
fluidity of life which is [at stake]{.mark}]{.underline}** (Pyne 1997;
Parisi and Terranova 2000).

Meanwhile, we are, more than ever before at any other time in human
history, not only in close proximity to each other but also exposed to
each other. This close proximity and exposure is experienced less and
less as opportunity and possibility and, more and more, as heightened
risk. But entanglement and exposure to each other are not all that
characterize the now. Wherever we look, the drive is simultaneously and
decisively towards contraction, towards containment, towards enclosure
and various forms of encampment, detention, and incarceration.

[Typical of this **logic of** contraction**, containment,
incarceration** and enclosure is the worldwide erection of all kinds of
walls and fortifications, gates and enclaves. In other words, various
practices of partitioning space, of]{.underline} offshoring and [fencing
off wealth, of splintering territories, of fragmenting spaces, saddling
them with various kinds of borders whose function is to decelerate
movement, to stop it in some instances, for certain classes of
populations, in order to manage risks.]{.underline} Various reasons are
mobilized to account for this renewed infatuation with borders taken as
the best way to manage risks. Security and the preservation of one's
identity are some of these reasons. And as it happens, physica[l **and
virtual [barriers of separation,]{.mark} [digitalisation of
databases]{.mark}, filing systems, the development of [new tracking
devices,]{.mark} sensors, drones, satellites and sentinel robots,
infrared detectors and various other cameras, biometric controls, and
new microchips containing personal details -- everything is put in
place**]{.underline} to transform the very nature of the [**border [in
the name of security]{.mark}**.]{.underline} Borders are increasingly
turned into mobile, portable, omnipresent and ubiquitous realities. The
goal is to better control movement and speed, accelerating it here,
decelerating it there and, in the process, sorting, recategorizing,
reclassifying people with the goal of better selecting anew who is whom,
who should be where and who shouldn't, in the name of security.

As a result, borders are no longer merely lines of demarcation
separating distinct sovereign entities. Increasingly, they are the name
we should use to describe the organised violence that underpins both
contemporary capitalism and our world order in general. But perhaps, to
be exact, we should not speak of borders in general but, instead, of
'borderization', that is, the process by which **[certain spaces are
transformed into uncrossable places for certain classes of
[populations]{.mark}, who thereby [undergo a process of
racialization;]{.mark} places where speed must be disabled [and the
lives of a multitude]{.mark} of people [judged to be undesirable are
meant to be]{.mark}]{.underline}** immobilized if not
[**[shattered]{.underline}**.]{.mark} Whatever the case, the
technological transformation of borders is in full swing. In a sense,
one of the major consequences of the acceleration of technological
innovations has been the creation of a segmented planet of multiple
speed regimes.

A key development, of late, is the extent to which border security
practices have taken a keen interest in the connection between the human
body and identity, as a means to achieve detailed control over movement
and speed. This being the case, the question we must ask is the
following: what precisely is at stake in the extension of the biometric
border into multiple realms of social life and, in particular, the human
body? In other words, what explains the migration from the border
understood as a particular point in space to the border as the moving
body of the undesired masses of populations? The answer is [a new global
partitioning between potentially risky bodies vs. bodies that are
not.]{.underline}

[It is in the nature of risk to be hidden from view. That which is
hidden from view is generally unknown. For it to be known, it must be
visualized.]{.underline} The screening of bodies at border checkpoints
aims at making visible "that which is hidden from view, opening up new
visualizations of the unknown, potentially risky body" (Amoore and Hall
2009, 444). In such a context, biometric technologies are supposed to
fragment the human body in order to recompose it for the purpose of
securitization, of elimination and neutralization of the risk. This
happens because the human body is seen as an indisputable anchor from
which data can be safely harnessed or extracted. As a result, we are
witnessing a gradually extending intertwinement of individual physical
characteristics with information systems -- a process that has served to
deepen faith in data as a means of risk management and faith in the body
as a source of absolute identification. In this sense, biometric
technologies should perhaps be best understood as techniques that govern
both the mobility and enclosure of bodies (see van der Ploeg 2003). They
are perceived as infallible and unchallengeable verifiers of the truth
about a person -- the ultimate guarantors of identity. They are supposed
to produce the identification of a person beyond question, and lend
authenticity and credibility to all of the data that are connected to
that identity. [According to this logic, the world would be safer if
only ambiguity, ambivalence and uncertainty could be controlled. These
technologies are assumed to provide a complete picture of who someone
is, to fix and secure identity as a basis for prediction and
prevention]{.underline}, leaving people to dispute their own identity.

The three mega processes I have briefly sketched are driving the
movement towards what I have called 'planetary entanglement', as well as
its opposite, that is, enclosure, contraction, containment, encampment,
and incarceration. Once again, [they are shaped by the alliance between
military power, the industries that surround it (contractors), and tech
giants.]{.underline} They are also driven by corporate elites
increasingly detached from their countries of origin and who store most
of their capital in tax heavens (see Davis 2019). These elites can no
longer be 'forced to account' through traditional means such as
elections or protests. They defeat citizens' scrutiny via complexity and
secrecy, often under the pretext of national security or via an economic
rationale that puts capital first, before people. This movement is
erratic, uneven. [But everywhere it heightens uncertainty and
insecurity. Everywhere it institutionalizes the risks inherent in the
misfortunes of reality.]{.underline}

Life and mobility

Part of what we are witnessing as a result is a novel imbrication, a
symbiotic merging of life and mobility. To be alive, or to survive, is
more and more co-terminus with the capacity to move. Just as living,
movement, in turn, involves continual doublings, the incessant crossing
of multiple lines and thresholds, multiple transitions across layers.
**[[Life itself is more and more taken as something that can be
calculated and recombined rather than merely
represented]{.underline}]{.mark}**. Furthermore, we are witnessing a
bifurcation between life on the one hand and bodies on the other hand.
[Nowadays, **not every body is thought of as containing life.
[Discounted bodies are believed to contain no life]{.mark} as such.
[They are,]{.mark} strictly speaking, [bodies at the limits of life,
trapped in uninhabitable worlds]{.mark} and inhospitable
places**.]{.underline} The kind of life they bear or contain is not
insured or is uninsurable, folded as it is in extreme and thin
envelopes.

[**[Such bodies]{.mark}** on the precipice **[are the most exposed to
droughts, storms]{.mark}** and **[famines, toxic waste]{.mark}**
and]{.underline} various experiences of [effacement. Their livelihoods
made impossible, **[they]{.mark}** are the most likely to
**[sustain]{.mark}** the most crippling **[wounds]{.mark}**]{.underline}
and injuries. [**[Trapped human subjects]{.mark}**]{.underline} often
[**[without escape,]{.mark}** they bear the brunt of terrestrial life on
a damaged planet]{.underline} (Tsing et al. 2017). At the same time,
they exceed all attempts to contain them. These bodies are not simply in
motion. Interactive and generative, they are movements and events. The
inside of such bodies is not separated from their outward environments.
From the perspective of discounted bodies, to be alive is always and
already to breach boundaries or to be exposed to the risk of the outside
entering the inside (read Litvintseva 2019).

This disentanglement of life from discounted bodies, this redistribution
of life on differential scales of insurability and non-insurability, is
a key dimension of contemporary migration regimes. The latter aim either
at slowing down the dynamics of people's interactions, at creating
distance or at shattering the chains of relations between them, so as to
institute new patterns of separation. Contemporary movement restrictions
are not limited to national boundaries. They are at work on a global
scale. They are deepening the space and time asymmetries between
different categories of humanity while leading to the progressive
ghettoization of entire regions of the world. To a large extent, this is
akin to a universalization of the Israeli model. In this model, the
restriction of movement does not necessarily aim "to confine unwanted
people territorially or to dissociate their movements from those of
citizens, but to inscribe them into temporalities and spatialities that
are disjointed to the point of giving these populations the illusion of
being territorially separated" (Parizot 2018, 38).

Furthermore, at a time when the material components and biological
organization of the body can be reengineered and redesigned, the latter
are more than ever based on the ideas of repressive selection,
reproduction and the rejuvenation of species. Only what can potentially
generate value counts as life. In this context, borders are meant to
concretize the principle of dissimilarity rather than that of affinity.
They are not only obstacles to free movement. They are boundaries
between species and varieties of the human. As such, they play a crucial
role in contemporary modes of production of human difference and
relatedness. Human bodies are increasingly divided between those that
matter and those that do not, those who can move and those who cannot or
should not, or should only move under very strict conditions. Bodies
that should not move are those that are uninsured. [**[They must be
tracked, captured, and dispensed]{.mark}** of. Such bodies are kept
shifting between invisibility, waiting and effacement. They are trapped
in fragmented spaces, stretched time and indefinite waiting]{.underline}
(Peteet 2018). [As for the dream of perfect security, **[it requires not
only complete systematic surveillance, but also a cleansing
policy.]{.mark}**]{.underline} [This dream is symptomatic of the
structural tensions that, for decades, have accompanied our transition
into a new technical system of increased automation -- one that is
increasingly complex yet also increasingly abstract.]{.underline}

One of the major contradictions of the liberal order has always been the
tension between freedom and security. Today, this question seems to have
been cut in two. Security now matters more that freedom. A society of
security is not necessarily a society of freedom. A society of security
is a society dominated by the irrepressible need for adhesion to a
collection of certainties. It is one fearful of the type of
interrogation that delves into the unknown, unearthing the risks that
must surely be contained within. This is why in a society of security,
the priority is, at all cost, to identify what lurks behind each new
arrival -- who is who, who lives where, with whom and since when, who
does what, who comes from where, who is going where, when, how, why, and
so on and so forth. Moreover, who plans to carry out which acts, either
consciously or unconsciously. The aim of a society of security is not to
affirm freedom, but to control and govern the modes of arrival.

The current myth claims that technology constitutes the best tool for
governing these arrivals; that technology alone allows for the
resolution of this problem -- a problem of order, but also of awareness,
of identifiers, of anticipation and predictions. It is feared that [the
dream of a humanity transparent to herself, stripped of mystery, might
prove to be a catastrophic illusion]{.underline}. For the time being,
migrants and refugees are bearing the brunt of it. In the long run, it
is by no means certain that they will be the only ones.

The mega processes highlighted above leave us with foundational
questions that will haunt us for most of this century. The first
foundational question is related to what I called 'borderization', or
the logics of containment, enclosure, and contraction. [Perhaps more
than at any other moment in our recent past, **[we are increasingly
faced with the question of what to do with those whose very
existence]{.mark}** does not seem to be necessary for our reproduction;
those whose mere existence or proximity **[is deemed to represent
a]{.mark}** physical or **[biological threat]{.mark} to** our own
life.]{.underline} Throughout history, and in response to this
foundational question, various paradigms of rules have been designed for
human bodies deemed either in excess, unwanted, illegal, dispensable, or
superfluous. One historical response has consisted in putting in place
spatial exclusionary arrangements. **[[Such was,]{.underline}]{.mark}**
for instance, [**[the case during]{.mark} the early phases of modern
settler or [genocidal colonialism]{.mark} [in]{.mark} relation to Native
American reservations in the United States, [island prisons, penal
colonies]{.mark} such as Australia, [camps and Bantustans]{.mark} in
South Africa**.]{.underline} A late modern example is Gaza, and [Gaza
might well prefigure what is yet to come.]{.underline} Here, [**[control
of]{.mark}** vulnerable, unwanted, surplus or **[racialized people is
exercised through]{.mark}** a combination of tactics,]{.underline} chief
among which is 'modulated blockade'. A blockade prohibits, obstructs,
and limits who and what can enter and leave the Strip. The goal might
not be to cut the Strip off entirely from supply lines, infrastructural
grids or trade routes. It is nevertheless relatively sealed off in a way
that effectively turns it into an imprisoned territory. [Comprehensive
or relative closure is accompanied by]{.underline} periodic **[[military
escalations and]{.underline}]{.mark}** the generalized use of
**[[extra-judicial assassinations.]{.underline}]{.mark}** [Spatial
violence, humanitarian strategies, and a peculiar biopolitics of
punishment all combine to produce, in turn, a peculiar detention space
in which people deemed surplus, unwanted, or illegal are governed
through abdication of any responsibility for their lives and their
welfare.]{.underline}

allBut there is another, early 21st -century example, which consists in
waging new forms of wars, which can be called wars on speed and
mobility. [Wars on mobility are wars whose aim is to turn into dust the
means of existence and survival of vulnerable people taken as
enemies.]{.underline} These kinds of wars of attrition, methodically
calculated and programmed, and implemented with new methods, are wars
against the very ideas of mobility, circulation, and speed, whilst the
age we live in is precisely one of velocity, acceleration, and
increasing abstraction and algorithms. Moreover, [[the targets
of]{.mark} this kind of [warfare are not]{.mark} by any means [singular
bodies, but]{.mark} rather [great swathes of humanity judged
worthless]{.mark} and superfluous.]{.underline}

All of the above belongs to the current practice of remote
borderization, carried out from afar, in the name of freedom and
security. This battle, waged against certain undesirables and reducing
them to mounds of human flesh, is rolled out on a global scale. It is on
the verge of defining the times in which we live. [Wars on mobility are
peculiar wars on bodies. They have to do with two broad questions that
confront us today and will haunt us for most of this century: on the one
hand the question of life futures, that is, of the self-organization of
being and matter; on the other hand, that of the future of
reason.]{.underline}

The future of life and the future of reason

For a long time, the human race has been concerned with how life emerges
and the conditions of its evolution. The key question today is how it
can be reproduced, sustained, made durable, preserved and universally
shared, and under what conditions it ends. Overall, these debates about
how life on Earth can be reproduced and sustained, and under what
conditions it ends, are forced upon us by the epoch itself,
characterized as it is by the impending ecological catastrophe and by
technological escalation.

It is a fact that[, today, unprecedented numbers of human beings are
embedded in increasingly complex technostructures. The latter are
increasingly intervening in the dynamics of the Earth system on a
planetary scale. This has led to the transgression of planetary
boundaries such as those related to anthropogenic climate change,
degenerative land-use change, accelerated biodiversity loss,
perturbation of the global biogeochemical cycles of nitrogen and
phosphorus, and the creation and release of novel entities such as
nanoparticles and genetically engineered organisms]{.underline} (see
Donges et al.).

Furthermore, both metabolically (for example in terms of their energy
needs) and reproductively, technologies are becoming more and more tied
in complex networks of extraction and predation, manufacturing and
innovation. An example is recent developments in the domain of genes and
molecules. As Margarida Mendes shows, the heyday of DNA study has
allowed the cracking and public dissemination of the genetic codes of
humans, plants, and animals. This, in turn, has given way to an
exponential rise of biological patents, as currently nearly 20% of the
human genome is now privately owned, in a context of a market logic that
addresses life as a commodity to be manipulated and replicated under the
volatility of market consumption. Studies after studies have shown for
instance that corporations are intervening directly in the natural
cycles of life and ecosystems through the widespread genetic
modification of key elements in the food chain (see Mendes 2017). As
patented GMO genes are absorbed into our bodies in a proprietary
relationship of biological subjugation, the body itself becomes an
expanded, multiple infrastructure, where intervention can happen at many
different scales. It is therefore correct to argue [that there is a
shifting distribution of powers between the human and the technological,
in the sense that technologies are moving towards 'general intelligence'
and self-replication.]{.underline} They are being granted the powers of
reproduction and independent teleonomic purpose rather than having them
taken awayOver the last decades, we have witnessed the development of
algorithmic forms of intelligence. They have been growing in parallel
with genetic research, and often in its alliance. [[The integration of
algorithms and big data]{.mark} analysis [in the bio]{.mark}logical
[sphere does not only bring with it]{.mark} an increasingly greater
belief in [techno-positivism]{.mark} and modes of statistical thought.
**[It also paves the way for regimes of assessment]{.mark}** of the
natural world, **[and modes of prediction]{.mark}** and analysis **[that
treat life itself as a computable object.]{.mark}**]{.underline}
Concomitantly, algorithms inspired by the natural world, and ideas of
natural selection and evolution are on the rise. Such is the case with
genetic algorithms -- a subset [**[of evolutionary algorithms]{.mark}**
that **[mimic actions inspired in biological operators]{.mark}**, such
as cells, **[seeking to optimize]{.mark}** the **[responses]{.mark}** to
the problems of their environments **[by self-generating]{.mark}**, and
encompassing processes of mutation and **[natural selection.]{.mark}**
The latter are designed to evolve and further adapt to the environment,
in a process of self-generation. **[The belief]{.mark}** today **[is
that everything is]{.mark}** potentially [**computable and
predictable.**]{.mark} In the process, **[what is rejected is the fact
that life itself is]{.mark} an [open]{.mark} system, [non-linear, and
exponentially chaotic.]{.mark}**]{.underline}

These are also times when many are gradually coming to the realization
that reason may well have reached its limits. Or, in any case, it is a
time when reason is on trial -- [[we are]{.underline}]{.mark}, in other
words[, [in a]{.underline}]{.mark} sort of [[Dark
Enlightenment]{.mark}.]{.underline} Reason is a faculty we used to
recognize in humans and in humans alone. In the Western tradition we
have all, willingly or not, become the inheritors of reason, always seen
as the highest of all human faculties, the one that opened the doors to
knowledge, wisdom, virtue and, most importantly, freedom. Although
unequally redistributed among them, it was the prerogative of humans
alone. It distinguished the latter from other living species. Thanks to
their superior capacity to exercise this faculty, humans could claim to
be exceptional. [Today, reason is on trial in two ways. First, [reason
is]{.mark} increasingly replaced and [subsumed by]{.mark} instrumental
rationality, when it is not simply reduced to procedural or [algorithmic
processing]{.mark} of information. In other words, the logic of reason
is morphing from within machines and computers and algorithms. The human
brain is no longer the privileged location of reason. **[The human brain
is being "downloaded" into nano-machines.]{.mark}** An inordinate amount
of power is gradually being ceded to abstractions of all kinds. Old
modes of reasoning are being challenged by new ones that originate
through and within technology in general and digital technologies in
particular, as well as through the top-down models of artificial
intelligence. As a result, **[techne is becoming the quintessential
language of reason.]{.mark}**]{.underline}

Furthermore, **[[instrumental reason]{.underline}]{.mark}**, or reason
in the guise of techne **[[is increasingly
weaponized]{.underline}]{.mark}**. Time itself is becoming enveloped in
the doing of machines. Machines themselves do not simply execute
instructions or programs. They start generating complex behaviour. [The
computational reproduction of reason has made it such that reason is no
longer, or is a bit more than, just the domain of human species. We now
share it with various other agents. **[Reality itself is]{.mark}**
increasingly **[construed via statistics]{.mark},** metadata, modelling,
mathematics.]{.underline}

**[Link -- AI Integration]{.underline}**

**The integration of AI via security cooperation constitutes the
[unshackling]{.underline} the nation-state from the population at the
level of [economic]{.underline} and [military]{.underline} power -- that
turns case -- it paves the way for [unchecked]{.underline} racialized
necropolitics as a [value]{.underline} that informs politics and
replaces human governance with AI that kill with impunity and result in
[endless, endemic warfare]{.underline}**

**Grove 20** -- Associate Professor of Political Science and Director of
the Hawai'i Research Center for Future Studies at the University of
Hawai'I at Mānoa, PhD in International Relations at Johns Hopkins
University \[Jairus, "From geopolitics to geotechnics: global futures in
the shadow of automation, cunning machines, and human speciation,"
International Relations 2020, Vol. 34(3) 432 --455, DKP\]

[[The automation of war]{.underline}]{.mark} and the reduction of human
troop sizes has a similar effect. Wars [aided by drones]{.underline} and
as a result significantly smaller numbers of soldier casualties
[continue]{.underline} on for decades [in a kind of sustainable
warfare.]{.underline}28 [The political and material cost of
casualties]{.underline} like the material cost of striking [are being
removed from the political equation [making states less]{.mark} and less
[accountable in]{.mark} the case of social justice and the [pursuit of
violence]{.mark} outside their borders.]{.underline}

[The feedback]{.underline} between these two trends [is]{.underline}
potentially [catastrophic. At the same time that war becomes easier,
governments become less accountable to their people]{.underline}, and
people are deprived of the means to support themselves, it is also the
case that [[people]{.mark} will matter less to their governments as they
[will not possess the labor power to cause pain to the economic
productivity]{.mark}]{.underline} of the country [[by means of striking
nor the capacity to refuse to fight.]{.mark}]{.underline} Zygmunt Bauman
has spoken of disposable populations, a kind of human waste or surplus
where the value of one's existence is meaningless for the state.29
However, we ought to go further down this path by way of Achille
Mbembe's creeping necropolitics.30 [It is not merely that
chronically]{.underline} or even intergenerational [unemployed people
have no value; it is that [the]{.mark}]{.underline} marginalization and
even [[murder of people can now generate value]{.mark}. In what Mbembe
refers to as the 'enclave economies' of war machines:]{.underline}

> [The concentration of activities connected with [the extraction of
> valuable resource]{.mark} around these enclaves has]{.underline}, in
> return, [[turned the enclaves into privileged spaces of war and death.
> War itself is fed by the increased sales of the products
> extracted]{.mark}.]{.underline}31

**[[In]{.mark} these [enclave economies fueled by petroleum]{.mark},
diamonds]{.underline}**, but increasingly things like
**[[lithium]{.underline}]{.mark}** or even **[sand [or water,]{.mark}
the outright [murder]{.mark} of people, [clearing space, generates
value]{.mark}]{.underline}** even in the supposedly post-resource
digital economy.32 However, beyond the instrumental value of security
there is also the [explosion of security services as its own economic
sector rather than as a merely means to secure other economic sectors.
International security corporation]{.underline}s such as Wackenhut
industries, once a private prison service provider in the U.S., [now
generate profits from refugee management]{.underline} in Australia and
Europe.33 The nearly 200 billion dollar private security industry and
\$1917 billion dollar defense sector suggest that **[the [economy of
making death and deprivation]{.mark} is more than merely a
means.]{.underline}** What few normative and [legal limitations exist on
the lethality of these corporations and institutions could disappear.
This [is already taking place]{.mark} in the global South and [amongst
African-Americans and indigenous people]{.mark} around the
planet.]{.underline}

However, [one can foresee]{.underline}, with little imagination, [the
extreme injustices of the contemporary era as a general condition of
global life]{.underline}. What requires imagination on our part is
reaching a turning point where these crimes become themselves normative,
that is, the 'good' the state pursues. Contrary to our sensibilities
such ideologies already exist and are even gaining attention outside the
obscure chat rooms where they began.

Under the heading of 'negative messianism', Mbembe reviews [the growing
movement of the '[Dark Enlightenment',]{.mark} 'a political religion. .
. \[that\] calls for the exit from democratic society and total
corporate and absolute dictatorship'.]{.underline}34 The movement
**[[calls for a global, racial, culling of the population in the name of
'human biodiversity' and expounds the value of using racially inferior
populations for]{.mark} radical [experimentation]{.mark} to jumpstart
technological breakthrough.]{.underline}** [If this sounds]{.underline}
too [implausible]{.underline} even for speculation **[it is worth
considering the spate of recent [terrorist attacks]{.mark} in the U.S.
[by the vanguard]{.mark} of the Dark Enlightenment. The [mass
shooter]{.mark} who killed 20 people [in El Paso]{.mark}]{.underline}**
Texas in August of 2019 **[posted his Dark Enlightenment manifesto
before beginning his rampage]{.underline}**.35 In 2020, **[there have
been multiple attacks by]{.underline}** the so-called
**[[Boogaloos]{.mark} who [have infiltrated the U.S. military and
police]{.mark} forces and seek to spark the Dark Enlightenment by
[escalating]{.mark} the [B]{.mark}lack [L]{.mark}ives [M]{.mark}atter
protests [into a full scale civil war]{.mark}.]{.underline}**36 And then
there is the most famous and vocal theorist of the Dark Enlightenment,
Steve [Bannon,]{.underline} who in addition to being a key architect of
the Donald Trump administration, [works tirelessly to build the Dark
Enlightenment movement amongst the burgeoning far right of
Europe]{.underline}.37 Whether this world view succeeds or actually
becomes normative globally is not really the point. Instead, as is the
mode in the speculation here I propose that **[[in
the]{.mark}]{.underline}** burgeoning **[[Dark Enlightenment]{.mark}
movement [we can see a political community built around necropolitics as
a value rather than a necessary evil.]{.mark}]{.underline}**

It would be too much to draw a direct line from the Dark Enlightenment
to all of the neo-nationalist, neo-authoritarian, and neo-fascist
movements around the planet. However, [the accelerating [global right
wing has been institutionalized at]{.mark} the [highest levels]{.mark}
of power [in]{.mark} liberal democratic nation-states such as [the
U]{.mark}]{.underline}nited [[S]{.underline}]{.mark}tates, [[U.K. and
India,]{.mark} suggesting that liberal institutions cannot subsist on
autopilot. **Neo-authoritarian politics have also moved from shaping
domestic polities to the shaping of the international
order.**]{.underline}38

In such an order, what would liberal democratic states look like? The
[constraints on the genocidal dictatorships of the twentieth century
was]{.underline} of course that [they needed a substantial portion of
their populations.]{.underline} Genocide could only be pursued against
minority populations. State behavior even in the extremes of the Nazi
state among others still required full mobilization and therefore at
some level the necessity of willing obedience even if not quite
legitimacy that could be supplemented through terror.39

[What of the behavior of future states for whom their people are in some
sense an afterthought? At a minimum the basic conceits of survival that
underwrite practices like deterrence or coercion would change
dramatically.]{.underline} The very logic and mechanics of biopolitics
would have to change. Without a necessary or strict relationship to the
nation, would states differ significantly from some kind of corporate
entity? Would the state more closely resemble the ancien regime? What
would become of territoriality? These are the grammatical questions
raised by the dark imagination of an automated future sufficiently
comprehensive to create the material condition whereby a state could
survive without the majority of their population's cooperation.

Can **[[we]{.mark}]{.underline}** not **[already [see]{.mark} the
outlines of such a [future in the decisions of Bolsanaro, Trump, Xi,
Modi, and Duterte, who]{.mark} blithely [write off
millions]{.mark}]{.underline}** of their own citizens **[[in the face of
COVID]{.mark}-19]{.underline}** and the nearly 50 per cent unemployment
rate it has created where the virus has been allowed total freedom of
movement?40 [One need not be conspiratorial to see how quick
authoritarian leaders have been to give up on disease containment once
the data came back regarding the overwhelming racial disparity in COVID
fatalities]{.underline}.41

If we consider the ways in which the shift from coal to oil changed the
character of economic and labor relations with states in the twentieth
century, [the]{.underline} nearly [[50 per cent loss of jobs due to
computerization]{.underline}]{.mark} in the twenty-first century,42
[[combined with a]{.mark} corresponding [decline in the necessity of
humans for military power]{.mark},]{.underline} then these new
conditions [[could change the very nature of what a state
is.]{.underline}]{.mark} The biopolitical raison d'être of the
nation-state which emerges in the nineteenth century and becomes truly
geopolitical in the twentieth century is premised on the mobilization
and securing of a national population.43 The revolutionary states emerge
from and rationalize the hyphen of the nationstate as essential both in
terms of democratic values and military-economic necessity. What will
emerge in the aftermath of such necessities and values is the horizon of
alternative futures we must consider.

Section 3: from Bergsonian machines to cunning machines

"Hello," whispered Montag, fascinated as always with the dead beast, the
living beast. . . Montag touched the muzzle. The Hound growled. . . "It
doesn't like me," said Montag. "What the Hound?" The Captain studied his
cards. "Come off it. It doesn't like or dislike. It just 'functions.'
It's like a lesson in ballistics. It has a trajectory we decide on for
it. It follows through. It targets itself, homes itself, and cuts off.
It's only copper wire, storage batteries, and electricity. . .

--Fahrenheit 451 A Wiener Filter or The Yellow Peril

![Text, letter Description automatically
generated](media/image2.png){width="4.0023709536307965in"
height="1.583992782152231in"}

The equation above is called a Wiener Filter. In mathematical terms,
Norbert Wiener used it with a number of other steps to calculate the
future. Despite the claims in the first section that the future does not
exist, the territory or probable limits of the future do, at least most
of the time. What Wiener was representing mathematically was that even
with little data on which one would normally make a prediction you can
define the space of possibility or in Wiener's terms the distribution of
probabilities even for non-linear or non-existent causal systems. In
practical terms it meant that artillery could be automated to shoot
where planes were going to be rather than where they were when the radar
signal returned. The mathematicians did this by considering and then
modeling the limits of the system being predicted.

It is impossible to predict what an individual pilot will choose to do
but it is possible to describe in mathematical terms what a pilot is
capable of doing and similarly what a plane with a particular maximum
velocity was capable of doing. The predictions made by the Wiener Filter
allowed the artillery guns to fire in a significantly more restricted
area with minimal radar information rather than just blasting away at
the sky in hopes of hitting something. According to Steve Heims, more
predictable systems like the V2 rocket could be successfully targeted
and shot down 99 out 100 times by the Wiener Filter.44 The seemingly
'dumb' artillery could adjust or read their environment and work in
concert adjusting further as information from rudimentary radar systems
or the assemblage of radar, operators, and canons. The artillery was in
the most basic sense becoming aware.

Wiener's 'solution' which made unpredictable systems targetable was
another version of what Claude Shannon very soon after solved for
communication with his theory of information. Shannon developed the
techniques which allow the efficient transmission of information through
imperfect media such as telephone lines by similarly modeling the range
of noise and compensating or repeating signal to exceed it. Rather than
predicting the noise which is impossible because of its chaotic nature
Shannon was able to treat all noise as a system rather than individual
events of noise such that the range of noise could stand in place of the
individual incidents. In both cases, the breakthroughs of Wiener and
Shannon created the world of computers, the internet, automation, and
machine learning we now inhabit. All systems after Wiener and Shannon
could be treated in some sense as information and communication problems
to be solved.45

After his experience in the war and further experiments after, Wiener
began to describe a more general principle of informatics and machine
technology. What he would later call the last science or the science of
everything saw every system, whether physical, chemical, mechanical,
biological, as computable and alterable. Following this insight Wiener
believed humanity was at the cusp of something unprecedented. In 1948,
he declared that a new kind of machine had emerged in the history of
human evolution. Although still rudimentary, cybernetic machines of the
1940s were capable for the first time of simple self-regulation based on
interactions with their external environment. Unlike thermodynamic
machines that sought equilibrium, cybernetic machines could pursue a
goal or objective in the world. Wiener referred to these new machines as
Bergsonian machines, after the French Philosopher Henri Bergson and his
idea of elan vital.46 For Wiener, machines possessed for the first time
the spark of a vital impulse. While these Bergsonian machines have so
far disappointed the expectation of those hoping for and others fearing
human-like artificial intelligence, machinic intelligence, whether
learning algorithms or self-steering and targeting weapons systems, have
exploded into a variable rainforest ecology of new species.

What is important for the purposes of this article is that Wiener was
able to demonstrate that very simple feedback mechanisms could produce
complex emergent results or what 'appeared' like intelligence even if
the machines were not conscious of that intelligence. What I explore
throughout the rest of the section is how [[even small advances in
machine intelligence could produce dramatic changes]{.mark} in what we
think of now as human dependent drones. Already [AI platforms have the
capacity to strategize and win complex games]{.mark} like Go, AI via
drones have the capability to target or execute operations on their own,
robots can 3D print and construct other robots, that is, a simple form
of reproduction. The only thing missing is]{.underline} what in
philosophical terms we call [will or desire.]{.underline} However, the
insight from Wiener is that the difference between rudimentary will and
a command code is insignificant in effect if a feedback exists between
the machine and the external environment which can shape or direct the
now desiring machine. To put it somewhat simply, [we do not need human
general intelligence for robots to change the world and
[geopolitics;]{.mark} the world [could change overnight if mechanical
life emerged]{.mark}]{.underline} or was released into the wild [and was
[as sophisticated,]{.mark} resilient and procreative [as the
cockroach.]{.mark}]{.underline}

**[We are already experiencing the burgeoning capability of cunning
machine.]{.underline}** If one considers to the underlying political and
economic pressure to move away from human combatants not unlike the
globalization of the labor market more broadly, the incentives for
innovations continuing are difficult to deny.47 Even before 9/11 [combat
was becoming too costly in both economic and political terms and
therefore required an alternative in order for empires and smaller
states to stay afloat]{.underline} in lean times. The globally modeled
War on Terrorism brought the crises of military expenditure still
lingering after the Cold War to a head. **[However, the [drive to cut
costs and political liability has not stopped at the
battlefield]{.mark}.]{.underline}** [Attempts to remove humans further
and further from the battlefield follows this inhuman trajectory into
the arena of decision-making and contestation.]{.underline}48 [**[The
reliance on algorithmic warfare creates the opportunity for increasingly
unilateral warmaking]{.underline}**. **[Cunning
machines,]{.underline}**]{.mark} **[not machines of reason but machines
capable of hunting and trapping, [represent the possibility of the
command and control developed for nuclear arsenals]{.mark} with the
micro-scale to pursue and kill of [assassins or special
forces.4]{.mark}9]{.underline}**

**[This process of [automating politics as well as war]{.mark} creates
further incentive for the development of increasingly autonomous
machines and actually [undermines security as it makes the capacity to
wage war cheaper]{.mark} and more accessible around the
planet.]{.underline}** **[[The drive for]{.underline}]{.mark}** more
autonomous machines is heading toward **['[sustainable
warfare']{.mark},]{.underline}** a kind of weird parallel to sustainable
development. Like sustainable development, sustainable warfare really
**[[makes warfare endemic]{.underline}]{.mark}** rather than providing a
real alternative to war making. So war as we know it may be coming to an
end but a permeating martial transformation is just getting started.

As the transformation in domestic policing, military planning, and
combat takes place, the tactical landscape will also mutate, amplifying
the corrosive effects on politics. A security complex indifferent to the
differences between the war and policing, battlefield and lifeworld will
increasingly target Internet exchanges, servers, monitoring, and
listening stations, civilian communication and media infrastructure. [As
populations cease to matter to states]{.underline}, either those
attacking or being attacked, [infrastructure becomes the whole of the
strategic landscape.]{.underline} Also, [as the size of autonomous
machines shrink, the [incentive for hacking or]{.mark} indiscriminate
attacks such as [el]{.mark}ectro[m]{.mark}agnetic [p]{.mark}ulse attacks
[will become more desirable]{.mark} as drone to drone or human to drone
combat will be prohibitively difficult.]{.underline}

After all, how reliably can one expect to track a drone the size of a
dragonfly or as low to the ground as a snake? Thus, we face the
possibility of a confluence of unaccountable decision-making, even the
absence of human decisions at all with the saturation of living spaces
with the dissonance of combat, killing and destruction. **[Rather than
simply automating the 'hunt' for enemies chosen by political processes,
already reliance on things like [signature strikes signal a shift to the
automation of the political decision of who is and is not an enemy in
the first place.]{.mark}]{.underline}** This shift from what Human
Rights Watch has termed 'human on the loop' practices to 'human out of
the loop' practices pushes the posthuman50 character of war further into
the nightmare zone in which everything is an object to be targeted but
never encountered or recognized. An algorithmic cunning replaces enmity
and martial judgment in the recognizable terms.

Furthermore, in a future with a receding human public and that states
are indifferent to moral catastrophe, these changes in machine
capability and autonomy as well as the deployment of such machines would
not be political events. **[[Switches would be flipped by military
planners or software developers along technical rather than ethical or
political lines.]{.underline}]{.mark}** Lewis Mumford referred to this
as the advent of 'post-historic' humanity in which a process that 'began
innocently by eliminating fallible human impulses from science will end
by eliminating human nature from the whole world of reality. In
posthistoric culture life itself is reduced to predictable, mechanically
conditioned and controlled motion, with ever incalculable -- that is,
every creative -- element removed'.51 I would add that [what emerges in
its place is a mechanic creativity allowed to thrive within the
constraints of a limited martial logic.]{.underline} If we continue on
this trajectory **[practicality could replace both strategic and moral
thinking.]{.underline}**52 Further, the fora in which such decisions
will be made (if at all) are likely to be constricted as secrecy
predominates in an environment charged by a dangerous mix of paranoia
and real danger.

**The expansion of even "friendly AI" builds a bridge to a post-human
hellscape, where geopolitics is structured around techno-dystopic
racialized violence**

**Grove 20** -- Associate Professor of Political Science and Director of
the Hawai'i Research Center for Future Studies at the University of
Hawai'I at Mānoa, PhD in International Relations at Johns Hopkins
University \[Jairus, "From geopolitics to geotechnics: global futures in
the shadow of automation, cunning machines, and human speciation,"
International Relations 2020, Vol. 34(3) 432 --455, DKP\]

In Cavell's account [the general economy of violence that characterized
the sadism of slavery could return again but differently. Rather than a
great chain of being or the superiority or some races over others, the
very concept of violence as a category distinct from force or change
could be lost.]{.underline} Although extreme, can we not already see
this transformation underway in the extreme forms of instrumentality
that characterize decisions regarding collateral damage, counter-value
targeting, or economized discourse on immigration and refugees?56

[More than a transformation of moral economies, the automation of humans
and the augmentation of humans, represents the possibility of making
physical and habitual what is now normative and discursive.]{.underline}
Resembling Cavell, David Roden proposes what he calls the disconnection
thesis, in which Cavell's nightmare scenario unfolds only among some
humans for whom the sentimentality of bodies, reproduction, and human
connection impede further evolution of the species.57 Whether it is
those who dream of a singularity in which human consciousness becomes
digital or one of the U.S. veterans who have had mood altering computer
chips implanted into their brains, [some humans will increasingly alter
or altered their brain-body networks to alter their cognitive and
perceptive capacities.]{.underline}58

During the summer of 2018 researchers at the University of Washington
and Carnegie Mellon successfully networked three humans via EEGs and
transcranial magnetic stimulation. The three individuals were able to
collaborate to play a simple video game resembling Tetris.59 The
participants were able to communicate and sense each others' thoughts
without the use of language or even being in the same room. Similar
experiments have successfully sent text message from one side of the
country to the other making at least a limited version of brain to brain
communication a reality.

[In the dark light of geopolitics one can imagine what today takes the
form of geographic and class divides in connectivity and medicine taking
the form of different classes and territories of consciousness and
communication. **Given the**]{.underline} already gossamer **[fragility
of international solidarity and trans-border empathy one can further
imagine cyborg cultures quite literally tuning out of the world left
behind.]{.underline}** Roden's disconnection thesis argues that as these
new forms of networks and augmentation develop so too will cultures and
moral awareness diverge.60 For those without the need or desire to use
oral language accelerating the pace of technological change within new
kinds of communities it is not difficult to follow Cavell to the
precipice of his posthuman horror. **[While the biological racial
fictions of colonialism, apartheid, and settler-colonialism still hold
on in the face of overwhelming scientific evidence to the contrary how
much more would real material differences in forms of life accelerate
existing geopolitical violence?]{.underline}**61 **[Even the beginnings
of disconnection could intensify the already renewed fights between
extractive industrial modernity and those indigenous communities
fighting for their ancestral lands and ways of life.]{.underline}** And
what of the swelling numbers of multi-generationally unemployed masses
who will lack the capital to upgrade? **[One can imagine
class]{.underline}** no longer **[being marked by]{.underline}**
linguistic markers or knowledge of wine but **[the physical ability to
interface with white color working spaces.]{.underline}** More and more
companies have already begun microchipping their employees for security
and tracking crossing the threshold of the skin in the process of making
labor.62 The digital divide in labor of who can and cannot telecommute
is already determining the patterns of employment and unemployment in
the first 6 months of COVID-19 shutdowns. The speciation of interfaces
and sensory capabilities could amplify the already growing trend.63

The point of Roden and Cavell's thought experiments are to show that
such a separation would be more than just a return to or intensification
of racial or class divisions. Instead the very embodied character of
moral appreciation, the shared languages and cultures, the perceptive
capacities to experience beauty or tragedy could be altered to the point
that the diffracted species of once human beings would live in a state
more closely resembling that of Homo sapiens 100,000 years ago in which
there were multiple species of upright anthropoids and none of them
could live without the fear of predation by other non-human animals or
each other. The medium of encounter fundamentally altered. However, [in
this]{.underline} speculative history of the [future the divergence
would not have been by happenstance but to lock in interests and
geopolitical advantage. Difference by design.]{.underline}

This may all seem too far-fetched. How could humans lose their most
basic capacity for socio-emotional intercourse? I want to argue that
**[things need not change that dramatically to see the beginnings of
such a divergence.]{.underline}** One can look around a crowded bus
filled with people each glued to their smart phone, tables of families
at restaurants each separated by their individuated devices or an office
filled with screens each telecommuting the pilot to a drone in the field
thousands of miles away to see the beginnings of such a speciation. Or
we could return to the beginnings of international thought, the first
moments of European geopolitics and remember its multispecies beginnings
when just 50 years after the arrival of Christopher Columbus Bartolomé
de las Casas pleaded with the Castille thrown to recognize the soul and
therefore humanity of the 'Indios'. Instead, of course, the
extermination continued which treated the people of the Americas as
'piles of dung in the middle of the road'.64 **[Geopolitics was in some
sense founded on the premise of many human species rather than one human
species.]{.underline}**65 **[The inability for so many to see their
human counterpoint at a moment of encounter in the new world speaks to
the precedent of a truly dark enlightenment. That is, technological and
martial advance without any corresponding moral
awareness.]{.underline}** A new such speciation that included the
inability to even speak to one another much less recognize some common
heritage or shared community of value would make the efforts of Las
Casas and those who continue to fight against the finishing of the
settler-colonial project entirely potentially invisible.

Conclusion: geotechnics and a planetary state of war

when utilized to perform work highly organized collective enterprises, I
shall call it the 'labor machine': when applied to acts of collective
coercion and destruction, it deserves the title, used even today, the
'military machine'. But when all of the components, political and
economic, military, bureaucratic and royal, must be included, I shall
usually refer to the 'megamachine'.

Lewis Mumford66

Mumford's megamachine is instructive. What he is describing is an
ancient past where the political, economic, military, bureaucratic,
royal all converged to form the empires of the Aztecs and Egyptians.
What I have in mind is this same convergence in the future but with a
twist. The 'royal' may come to relate to the economic and political and
the military such that what we understand as politics becomes
indiscernible. [The megamachine of the future presented here could
better be called geotechnics. The global mobilization of people, the
conditions of competition and coercion, who and what was doing the
competing and their relations would be fundamentally
altered.]{.underline} The relations would no longer be linguistic or
even sensory in the way that humans hold experience in common even if
their subjectivizations of that experience, that is the phenomenology of
body of experience, may be singular.

**[In a world of]{.underline}** possible full **[automation, cunning
machines, and posthuman speciation the equality of]{.underline}**
Hobbes' **[state of nature as well as the state of war is no longer
operable.]{.underline}** If these metaphors ever did more than
underwrite one particular logic of international politics they would in
the future be meaningless as the people of the leviathan, **[the metric
by which order or disorder is experienced may no longer exist in the
mortal meat suit so much of political theory rests.]{.underline}** In
some sense the enmity of war in the Hobbesian sense rested on the equal
finitude of every mortal human as well as the general desire to live
something we could agree was a good life free from the ever presence of
murder. As Hobbes was recontextualized to imagine an international
system of states similarly a sense of mortal equality was present.
**[The ability to be killed underwrote the decision to
kill.]{.underline}**

And what of the English school's society of states? If such sociality
persisted amongst neo-authoritarian states without nations what dark
vision of order would that be? [Basic assumption about the international
system even those based on other less dour models than a realist
anarchic system similarly presumes some equality of communication, the
good, or the desire to live in a particular way. The material limits of
homo sapiens, the necessity of water, air, food, family, and sociality
underwrites everything from deterrence to diplomacy.]{.underline} **[A
geotechnical system populated with intelligent things and governed by
nation-less states and further populated by incommensurate branches of
humanity fundamentally alters the limits and therefore the possibilities
of global life and order.]{.underline}** By what rules those relations
would be conceptually governed, that is, how we could describe such a
planetary system would have to reach for ways of thinking well beyond
even the most radical or critical theory of international relations.
**[In some ways efforts to consider what geopolitics looked like at the
peak of the Atlantic slave trade or during the first 100 years of the
conquest of the Americas more closely resemble what could become of a
posthuman planet than the highly rationalized cosmopolitan institutions
of the United Nations.]{.underline}**67

Just as IR is finally accepting that global politics is inhabited by
more than just nation-states that is, non-state actors, we now must also
come to grips with the fact that global politics is no longer populated
solely by humans and could in the future not even be dominated by
humans. [What new forms of intelligence mean for the transformation of
peace and security is murky at best. What is clear is that a theory of
automation as mere means is no longer sufficient to understanding the
vast infrastructure of machines and sensory data collecting systems and
the new collaborations those systems will create for former humans with
which we are already beginning to share our planet. The horizon of such
a technical transformation has to be thought alongside the normative
upheaval and radicalization of global enmity taking place simultaneously
with the transformation of the very mechanics of political and military
action.]{.underline}

To consider a future where the actors, relations, and order of the
planet could be fundamentally reconfigured by the gradual accretion of
robots, algorithms, bodily and political modification poses to us the
possibility of systemic change well beyond whether the world will be
unipolar or multipolar. No one of these trajectories will be total or
play out as described here but all of these trajectories present us with
the real possibility of altering the basic rules of human planetary
existence from a geopolitical condition to one that is increasingly
geotechnical. [Hundred years from now, what new grammar of planetary
relations could be prepared to describe such a world?]{.underline}

**[Link -- AI = Whiteness]{.underline}**

**The fantasy of AI is the fantasy of Whiteness -- a futuristic world
where white servants serve white masters -- the aff
[cements]{.underline} the domination of the future by an Anglo-European
worldview of White Supremacy that conflates Whiteness with
intelligence**

**Cave and Dai 20** -- \* Leverhulme Centre for the Future of
Intelligence, University of Cambridge, Cambridge, UK, \*\* Leverhulme
Centre for the Future of Intelligence, University of Cambridge,
Cambridge, UK, \[Stephen, Kanta, "The Whiteness of AI," Philosophy &
Technology volume 33, pages685--703 (2020), DKP\]

This paper focuses on the fact that [[AI is]{.mark}]{.underline}
predominantly portrayed as [[white]{.mark}---in colour, ethnicity, or
both.]{.underline} We first illustrate [[the prevalent Whiteness of real
and imagined intelligent machines in four categories: humanoid robots,
chatbots and virtual assistants, stock images of AI, and portrayals of
AI]{.mark}]{.underline} in film and television. [We then offer three
interpretations of the Whiteness of AI, drawing on critical race theory,
particularly the idea of the White racial frame. First, we examine the
extent to which this [Whiteness might simply reflect the predominantly
White milieus from which these artefacts arise.]{.mark} Second, we argue
that to imagine machines that are intelligent, professional, or powerful
is to imagine White machines because the White racial frame ascribes
these attributes predominantly to White people. Third, we argue that [AI
racialised as White allows for a full erasure of people of colour from
the White utopian imaginary]{.mark}. Finally, we examine potential
consequences of the racialisation of AI, arguing it could exacerbate
bias and misdirect concern.]{.underline}

Overall, I construe race, racialization, and racial identities as
on-going sets of political relations that require, through constant
perpetuation via institutions, discourses, practices, desires,
infrastructures, languages, technologies, sciences, economies, dreams,
and cultural artefacts, the barring of nonwhite subjects from the
category of the human as it is performed in the modern west.

Alexander G. Weheliye
(Weheliye [2014](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR63),
2)

[[Technology as an abstract concept functions as a white
mythology.]{.underline}]{.mark}

Joel Dinerstein (Dinerstein 2006, 570)

Introduction

It is a truth little acknowledged that a machine in possession of
intelligence must be white. Typing terms like "robot" or "artificial
intelligence" into a search engine will yield a preponderance of stock
images of white plastic humanoids. Perhaps more notable still, these
machines are not only white in colour, but the more human they are made
to look, the more their features are made ethnically
White.[Footnote1](https://link.springer.com/article/10.1007/s13347-020-00415-6#Fn1) In
this paper, we problematize the often unnoticed and unremarked-upon fact
that intelligent machines are predominantly conceived and portrayed as
White. We argue that this [[Whiteness]{.mark} both illuminates
particularities of what]{.underline} (Anglophone Western) [society hopes
for and fears from these machines, and [situates these affects
within]{.mark} long-standing [ideological structures that relate race
and technology.]{.mark}]{.underline}

[Race and technology are two of the most powerful and important
categories for understanding the world as it has developed since at
least the early modern period.]{.underline} Yet, as a number of scholars
have noted, their profound entanglement remains understudied
(Sinclair [2004](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR55);
de la
Peña [2010](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR18)).
[There are a number of possible reasons for this---and]{.underline}, as
Bruce Sinclair writes, "[[racial prejudice dominates]{.mark} all of
them]{.underline}"
(Sinclair [2004](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR55),
1[). [They include the lack of]{.mark} first- or secondhand [accounts of
the role of people of colour in]{.mark} the [development and use of
tech]{.mark}nology; persistent [stereotypes about tech]{.mark}nology [as
the province]{.mark} and product [of]{.mark} one particular racial
group---[White people; and]{.mark} the persistent tendency of members of
that group, who dominate the academy in the [US and Europe]{.mark}, to
[refuse to see themselves as racialised]{.mark} or race as a matter of
concern at all.]{.underline}

This lack of scholarly attention is surprising because, as Michael Adas
elucidated in 1989, [the idea of [tech]{.mark}nological [superiority was
essential to]{.mark} the logic of [colonialism.]{.mark} Not only was
[superior weaponry]{.mark} and transportation]{.underline} (etc.)
[[necessary for]{.mark} large-scale [conquest and control]{.mark} of
foreign territory, [it was also]{.mark} part of its
[justification:]{.mark} [proof]{.mark} that [White Europeans]{.mark}
were an advanced civilisation with a [right to rule]{.mark} over
other]{.underline}s (Adas 1989). Fortunately, this lack of attention is
increasingly being remedied, and the relationship between race and
technology is beginning to garner the kind of attention that has since
the 1970s been given to gender and technology, following the pioneering
work of Donna Haraway, Sandra Harding, and Evelyn Fox Keller (Haraway
1991; Harding 1986; Keller 1985). This includes attention to this
century's ubiquitous digital technologies. In 2006, Lisa Nakamura asked,
"How do we make cyberculture studies a field that as a matter of course
employs critical race theory and theories of cultural difference...?"
(Nakamura 2006, 35). Since then, a number of significant works have
attempted to do just that, including Safiya Noble's Algorithms of
Oppression and Ruha Benjamin's Race After Technology (Noble 2018;
Benjamin 2019).

This paper aims to contribute to this body of literature on race and
technology by examining how [the ideology [of race shapes]{.mark}
conceptions and portrayals of artificial intelligence
[(AI).]{.mark}]{.underline} Our approach is grounded in the philosophy
of race and critical race theory, particularly the Black feminist
theories of bell hooks, Sylvia Wynter and Alexander G. Weheliye
(hooks [19921997](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR39);
Wynter [2003](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR67);
Weheliye [2014](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR63)),
and work in Whiteness studies, including that of Richard Dyer, Joe R.
Feagin, and Ruth Frankenberg
(Dyer [1997](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR20);
Feagin [2013](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR23);
Frankenberg [1997a](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR26)).
In 2006, Feagin coined [the term "white racial frame" to describe those
aspects of the Anglophone Western worldview that perpetuate a racialised
hierarchy of power and privilege]{.underline}
(Feagin [2006](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR22)).
In his words, ["[the white racial frame includes]{.mark} a broad and
persisting set of racial [stereotypes, prejudices, ideologies]{.mark},
interlinked interpretations and narratives, and visual
images"]{.underline}
(Feagin [2013](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR23),
xi). Although it reached its peak in the age of colonial expansion, this
framing persists: ["Today, as whites move through their lives, they
frequently combine racial stereotypes and biases (a beliefs aspect),
racial metaphors and concepts (a deeper cognitive aspect), racialised
images (the visual aspect), racialised emotions (feelings), interpretive
racial narratives, and inclinations to discriminate within a broad
racial framing"]{.underline}
(Feagin [2013](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR23),
91). In essence, this paper examines how [[representations of AI reflect
this White racial frame.]{.underline}]{.mark}

One of the main aims of critical race theory in general, and Whiteness
studies in particular, is to draw attention to the operation of
Whiteness in Western culture. [[The power of Whiteness's]{.mark} signs
and symbols [lies]{.mark} to a large extent [in]{.mark} their [going
unnoticed]{.mark} and unquestioned, concealed by the myth of
colour-blindness.]{.underline} As scholars such as Jessie Daniels and
Safiya Noble have noted, [this myth of colour-blindness is particularly
prevalent in Silicon Valley and surrounding tech culture, where it
serves to inhibit serious interrogation of racial framing]{.underline}
(Daniels [2013](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR16), [2015](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR17);
Noble [2018](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR48)).
Hence [[the first step f]{.mark}or such an interrogation
[is]{.mark}]{.underline}, in Richard Dyer's term, [to "make strange"
this Whiteness, de-normalising and [drawing attention]{.mark} to
it]{.underline}
(Dyer [1997](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR20),
10). As Steve Garner puts it, [the reason "for deploying whiteness as a
lens is that it strips a normative privileged identity of its cloak of
invisibility"]{.underline}
(Garner [2007](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR31),
5). [This is our primary intention in examining intelligent machines
through the White racial frame.]{.underline}

In the next section of this paper, we first lay out current evidence for
the assertion that conceptions and portrayals of AI---both embodied as
robots and disembodied---are racialised, then evidence that such
machines are predominantly racialised as White. In the third section of
the paper, we offer our readings of this Whiteness. Our methods are
qualitative. As de la Peña writes: ["[Studying
whiteness]{.mark}]{.underline} means working with evidence more
interpretive than tangible; it [[requires imaginative analyses of
language and]{.mark} satisfaction with [identifying]{.mark} possible
[motivations of subjects,]{.mark} rather than definitive trajectories of
innovation, production, and consumption"]{.underline} (de la
Peña [2010](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR18),
926). We offer [three interpretations of the Whiteness of AI. First, the
[normalisation of Whiteness in the Anglophone West
can]{.mark}]{.underline} go some way to
[[explai]{.mark}n]{.underline}ing [[why]{.mark} that sphere's products,
including [representations of AI, are White.]{.mark}]{.underline} But we
argue that this argument alone is insufficient. Second, [we argue that
[to imagine an intelligent]{.mark}]{.underline} (autonomous, agential,
powerful) [[machine is to imagine a White machine]{.mark} [because the
White racial frame ascribes these attributes]{.mark} predominantly [to
White people]{.mark}.]{.underline} Thirdly, [we argue that **[AI
racialised as White allows for a full erasure of people of colour from
the White utopian imaginary.]{.mark} Such machines** are conceived as
tools that **will replace "dirty, dull, or dangerous"
tasks**]{.underline}
(Murphy [2000](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR46),
16), **[including replacing human interactions that are considered
metaphorically dirty: [White robot servants will allow the White master
to live a life of ease unsullied by interaction with people of other
races.]{.mark}]{.underline}**

**[Alt -- Paradigm Shifts]{.underline}**

**The alternative is to vote negative to [refuse]{.underline} the 1AC's
prescriptions in favor of paradigm shifting experiments that center
de-racialization against white supremist techno-futurity**

**Mbembe 22**, interviewed by TORBJØRN- Achille is a member of the staff
at the Wits Institute for Social and Economic Research (WISER) at the
University of the Witwatersrand, visiting appointment at the Franklin
Humanities Institute at Duke University PhD in History at the Sorbonne,
DEA in Political Science at the Instituts d\'études politiques
\[Achille, "Thoughts on the Planetary: An Interview with Achille
Mbembe," Decolonizing the Neoliberal University -- Law, Psychoanalysis
and the Politics of Student Protest, Interview first Conducted in 2018,
Re-Published in this book and Edited by Jaco Barnard-Naudé, Professor of
Jurisprudence in the Department of Private Law, University of Cape Town,
DKP\]

TORBJØRN: Some would then argue that there are still colonial or
postcolonial structures operating in the neoliberal project. Would you
say that there is then still a genocidal potential?

MBEMBE: Perhaps more than at any other moment in our recent past, we are
increasingly faced with the question of what to do with those whose very
existence does not seem to be necessary for our reproduction; those
whose mere existence or proximity is deemed to represent a physical or
biological threat to our own life.

[Throughout history]{.underline}, and in response to this question,
[various [paradigms of rules have been designed for human bodies
deemed]{.mark} either in [excess,]{.mark} unwanted, illegal,
dispensable, or superfluous. One historical response has consisted in
putting in place spatial exclusionary arrangements. Such
was]{.underline}, for instance, [the case during]{.underline} the early
phases of modern [settler or [genocidal colonialism i]{.mark}n relation
to Native American reservations]{.underline} in the United States,
[[island prisons, penal colonies]{.underline}]{.mark} such as Australia,
[[camps]{.mark} and]{.underline} even [Bantustan]{.underline}s in South
Africa.

[Two late modern examples are [Gaza]{.mark} and the en[caging of]{.mark}
migrant [children]{.mark} in the context of the ongoing planetary war on
mobility.]{.underline} Gaza and the encaging of migrant children might
well prefigure what is yet to come.

In the case of Gaza, control of vulnerable, unwanted, surplus or
racialized people is exercised through a combination of tactics, chief
among which is modulated blockade or molecular strangulation. A blockade
prohibits, obstructs, and limits who and what can enter and leave the
Strip. The goal might not be to cut the Strip off entirely from supply
lines, infrastructural grids or trade routes. The Strip is nevertheless
relatively sealed off and strangulated in a way that effectively turns
it into an imprisoned territory. [Comprehensive or relative [closure is
accompanied by]{.mark} periodic [military escalations and]{.mark} the
generalized use of [extra-judicial assassinations]{.mark}. Spatial
violence]{.underline}, humanitarian strategies, [and a]{.underline}
peculiar [biopolitics of punishment all combine to produce]{.underline},
in turn, [a]{.underline} peculiar [carceral space in which people deemed
surplus, unwanted, or illegal are governed through abdication of any
responsibility for their lives and their welfare.]{.underline}

But as I have intimated, [there is another, early twenty-first century
example, which consists in waging new forms of wars, which can be called
wars on speed and mobility. **[Wars on mobility]{.mark} are wars whose
[aim]{.mark} is [to turn discounted bodies into
borders]{.mark}.**]{.underline} They generally begin by turning into
dust and piles of ruins the milieux as well as means of existence and
survival of vulnerable people thus forced to flee in search of a refuge.
**[These kinds of wars against milieux and ecosystems rendered toxic and
uninhabitable are not accidental. [They are methodically
programmed]{.mark} and conducted. [Such]{.mark}]{.underline}** milieux
and **[[ecosystems are sites of experimentation of new weapons.]{.mark}
[The targets]{.mark} of this kind of warfare [are]{.mark}]{.underline}**
not by any means singular bodies, but rather **[great [swathes of
humanity]{.mark} [judged worthless]{.mark} and
superfluous.]{.underline}**

TORBJØRN: Can you elaborate a bit more on that?

MBEMBE: Let me put it differently. Nowadays [the project is to render as
many people as superfluous as possible. The novelty is the production at
a massive scale of [discounted bodies]{.mark}, a residual humanity [that
is akin to]{.mark} [waste.]{.mark} With our entry into a new climatic
regime, this process will only intensify.]{.underline} As the global
conditions for the production and reproduction of life on Earth keep
changing, [population politics at a planetary level will increasingly
become synonymous with excess and waste management**. In terms of the
[future geopolitics]{.mark} of our world, [populations will be]{.mark}
more and more [treated]{.mark}**]{.underline} not only in the Darwinian
terms of sexual selection, but also **[[within a
utilitarian]{.mark}]{.underline}** and biophysiologico-organic
**[[framework.]{.underline}]{.mark}**

Take a place such as South Africa where a very high percentage of the
total population is unemployed. This is not because there is no "work as
such". This is not because people do not want to work.

In fact, here as elsewhere in Africa and other parts of the global
South, almost everything remains to be done. [The amount of work needed
in order to create a better life for all is incalculable. **But [the
structure of the economy doesn't]{.mark} really [need us all.]{.mark}**
Nor does it need our time. It doesn't really need every single body, all
of our muscles or energies or even the bulk of our social and collective
intelligence**. And this will be more and more the case in the future,
as we move to a phase of human history in which [only that which is
computable counts.]{.mark}**]{.underline} As we speak, **[[many
bodies]{.mark} already [fall beyond the scope of calculation. Unless we
reinvent the terms of what counts and]{.mark}, in the process,
[resignify]{.mark}]{.underline}** what **[value]{.underline}** stands
for **[as well as the [procedures]{.mark} of assigning
value]{.underline}**, of measuring value, of exchanging value, **[things
[won't change.]{.mark}]{.underline}** These are some of the key
questions any decolonization project worthy of its name has to address
if the injunction to decolonize is to be more than a mere ideological
phantasm.

TORBJØRN: Back to the debate on decolonization: There was a heated
debate in Norway, during the summer of 2018, about the decolonization of
academia. How can #RhodesMustFall in South Africa be relevant for
universities worldwide?

MBEMBE: **[[The need for a critical re-appraisal of the relationship
between knowledge, power and institutions]{.underline}]{.mark}** is not
an exclusively South African preoccupation. In South Africa, the term
"decolonization" **[[is]{.mark} one way in which concerns about
["deracialization"]{.mark} are expressed.]{.underline}** The imperative
to "deracialize" is also valid for Europe, for the United States, for
Brazil and for other parts of the world. **[The [emergence of]{.mark}
new varieties of [racism]{.mark} in Europe and elsewhere, the
reassertion of global [white supremacy,]{.mark} of
populism]{.underline}** and retro-nationalism, **[the [weaponization of
difference]{.mark}]{.underline}** and identity **[[are]{.mark} not only
symptoms]{.underline}** of a deep distrust of the world. **[They are
also [fostered by]{.mark} transnational [forces capable of making
that]{.mark} same [world]{.mark}]{.underline}** inhospitable,
**[[uninhabitable]{.mark} and unbreathable]{.underline}** for many of
us.

All of this is of course important. But part of what truly frightens me
is the recolonization of various fields of knowledge by all kinds of
determinisms. **[What frightens me is the active confusion between
knowledge and data, [the reduction of knowledge to information.]{.mark}
It's the idea that the world is a matter of numbers and the task of
knowledge is to handle quantities.]{.underline}** Furthermore, it's the
belief that the best way to generate information is with computers and
that which is not computable does not exist. **[It's the creeping sense
that [the computer is our new brain.]{.mark}]{.underline}**

In such a context, **["[to decolonize" must start from the assumption
that knowledge cannot be reduced to]{.mark} computational
[info]{.mark}rmation [processing.]{.mark} There is therefore a massive
need to recover the ability to think.]{.underline}** And for me,
knowledge is on the verge of being reduced to a reified metaphor. As a
result, [we are witnessing almost everywhere a tremendous impoverishment
of thought.]{.underline}

TORBJØRN: In the Norwegian debate on decolonization, one of the demands
from the young student activists was to have a more global curriculum.
What's your take on that?

MBEMBE: Right now [we are literally assaulted by [forces that want
to]{.mark}]{.underline} retreat from the world and [[rebuild a certain
idea]{.mark} of the nation, [of]{.mark} the
[community]{.mark}]{.underline}[,]{.mark} of identity and difference
[that [is premised on the capacity to determine]{.mark}]{.underline} who
belongs[, [who must be excluded]{.underline}]{.mark} [and shouldn't
belong]{.underline}, who can settle where, why, how and for how long.
**[Such forces are preoccupied with the erection of all kinds of borders
[and how they must be policed. They buy in the dream of a "pure"
community]{.mark}, a community of people who]{.underline}** look the
same **[and act the same.]{.underline}** They are sustained by the
belief that we can go back to the past because the past is, in truth,
our future. **[Let me just call it the dream of
apartheid.]{.underline}**

**[There is [another dream]{.mark}]{.underline}**, maybe not unrelated
to the first. As I have just highlighted, it's the dream of reducing
knowledge to calculation by computers. In fact, it's the dream [**[of
reducing everything to calculation]{.mark} and explaining everything
from within biological and neurological strictures**. [A planetary
library]{.mark}]{.underline}, archive or, for that matter, curriculum is
one [[whose s]{.mark}trategic [project is to understand the
incalculable]{.mark} and the incomputable.]{.underline} It can only be
based on the will to go beyond cognitivism. I am not against calculation
or mathematics. Nor am I against computation. I am simply saying that
[neither calculation]{.underline}, nor mathematics, [nor computation are
sufficient for explaining life. It can't be enough to do correct
math]{.underline}ematics. **[Once we have done correct mathematics, we
still need to determine what this exercise implies for the life of
beings.]{.underline}** Pushed to a certain level, correct mathematics
alone impoverish thought and destroy theory.

Otherwise, we only have one world. We might dream about colonizing Mars
or Venus or other unknown planets in the future, but for the time being
that is not part of our actuality. **[[We only have one
world,]{.underline}]{.mark}** one solar system **[and for this world to
last]{.underline}** as long as possible and for this solar system to not
calcinate life as such, **[we need to become]{.underline}** a bit more
intelligent and **[wiser.]{.underline}** This Earth is our shared roof
and our shared shelter. **[[Sharing]{.mark} this roof]{.underline}** and
shelter **[[is the]{.underline}]{.mark}** great **[[condition
for]{.mark} the sustainability of [life on Earth.]{.mark}]{.underline}**
We have to share it as equitably as possible. And in any case **[our
lives]{.underline}**, here and elsewhere, **[have become so entangled,
that [trying to separate]{.mark} them [will require]{.mark} a
[tremendous]{.mark} amount of [violence.]{.mark}]{.underline}** It will
require a lot of violence to disentangle humanity from itself and from
the rest of the living species. And therefore, especially in the face of
the kinds of ecological challenges we face, **[it is]{.underline}**
absolutely **[important to reinvent forms of life]{.underline}** in
common **[that go beyond the requisite of the nation state, ethnicity,
race, religion, and so on.]{.underline}** A curriculum that takes
seriously such concerns is absolutely necessary.
