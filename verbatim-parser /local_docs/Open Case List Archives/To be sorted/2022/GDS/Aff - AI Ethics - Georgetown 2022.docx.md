<https://carnegieeurope.eu/2019/11/28/artificial-intelligence-and-future-of-conflict-pub-80421>

<https://ccdcoe.org/uploads/2021/12/Strategies_and_Deployment_A4.pdf>

<https://nationalinterest.org/blog/techland-when-great-power-competition-meets-digital-world/shared-responsibility-enacting>

# AFF

## Case

### Plan Text

#### The United States federal government should increase its cooperation with the North Atlantic Treaty Organization to restrict its use of artificial intelligence to principles of responsible use. 

### Advantage 1\-\--Joint Operations

#### Lack of joint standards on AI undermines interoperability. That will [collapse]{.underline} the ability of NATO to respond AND contain emerging threats.

**Merwe 21** \-\-- MA in International Relations and Global Conflict in
the Modern Era, from Leiden University. She conducted her research in
collaboration with the Land Warfare Centre of the Netherlands Ministry
of Defense, focusing on Artificial Intelligence and the future of
combat.

Joanna van der, 2-17-2021, \"NATO Leadership on Ethical AI is Key to
Future Interoperability,\" CEPA,
https://cepa.org/nato-leadership-on-ethical-ai-is-key-to-future-interoperability/

In October 2020, Deputy Secretary General of NATO Mircea Geoană
highlighted the benefits of establishing a "[transatlantic community
cooperating on Artificial Intelligence
(AI](https://www.nato.int/cps/en/natohq/news_179231.htm))." The Deputy
Head of NATO's Innovation Unit followed with a [commitment to its
responsible
use](https://www.nato.int/docu/review/articles/2020/11/24/artificial-intelligence-at-nato-dynamic-adoption-responsible-use/index.html).
[The US Department of Defense (DoD) adopted [Ethical Principles for
AI](https://www.ai.mil/docs/Ethical_Principles_for_Artificial_Intelligence.pdf) in
2020 and has [committed to bringing together NATO member and
partners](https://breakingdefense.com/2020/09/13-nations-meet-on-ethics-for-military-ai/) to
operationalize these principles. Despite these statements and
developments, **more work is required** to tackle the very
real [challenge that ethical
AI](https://tnsr.org/2020/03/allies-and-artificial-intelligence-obstacles-to-operations-and-decision-making/) will
pose to future interoperability within NATO]{.underline}.

[**Without a NATO-led initiative** focused on aligning these ethical
principles across the Alliance, the **interoperability risk** of nations
fielding AI-based systems **that hinder joint operations is
high**]{.underline}. [As the **foremost security framework** for Europe
and North America, as well as the **leading defense alliance** for
promoting and protecting democratic values, **NATO is able to facilitate
alignment** on this issue. As part of a [broader strategy on emerging
and disruptive
technologies](https://www.defensenews.com/opinion/2020/12/08/nato-needs-a-strategy-for-emerging-and-disruptive-technologies/),
**NATO must prioritize ethical AI** if it wishes to promote the shared
values upon which it was founded, play a key role in facilitating
innovation across the Atlantic, and ultimately retain the ability of its
members to undertake **joint operations**.]{.underline}

[Establishing NATO ethical AI principles is the first step toward both
technical and political alignment, in turn enhancing and fostering
interoperability, which is the **foundation** for NATO to **respond to
emerging threats** as an Alliance, in a flexible and timely
manner]{.underline}.

[A key challenge for NATO is raising awareness that the answers to
ethical questions can no longer be left to later stages of the
development and procurement cycle.]{.underline} [[Decisions made at the
**political and legal
level**](https://hcss.nl/sites/default/files/files/reports/Towards%20Responsible%20Autonomy%20-%20The%20Ethics%20of%20RAS%20in%20a%20Military%20Context.pdf) will
have a significant impact on the engineering practices used to develop
AI, as well as the technical characteristics of the AI-based
systems.]{.underline} The answers to questions such as respecting human
dignity, human control, and accountability will be the foundation upon
which many technical elements are programed. [Systems developers need to
make a number of calls throughout the development cycle informed by the
answers to key questions, including:]{.underline}

[how to label data]{.underline}

[what data to use, and]{.underline}

[what is an acceptable outcome?]{.underline}

[These answers will also impact how AI systems are evaluated and
ultimately deployed.]{.underline}

[If individual nations or groups are left to develop their own ethical
principles without wider alignment to NATO, the result will be a number
of AI-based systems with **varying technical specifications** based on
the legal and policy decisions made by **individual governments** when
answering the key questions]{.underline}. As has been demonstrated in
areas such as [facial
recognition](http://sitn.hms.harvard.edu/flash/2020/racial-discrimination-in-face-recognition-technology/) and [policing
algorithms](https://www.technologyreview.com/2020/07/17/1005396/predictive-policing-algorithms-racist-dismantled-machine-learning-bias-criminal-justice/),
the assumptions made by those developing the tools and answering the key
questions have a significant impact on the real-world functioning of the
tool and societal acceptance of its ethics. [The risk of tools failing
to gain acceptance depends on the legal and ethical decisions made by
governments. For the military, this may mean one state using an AI-based
system that is seen as unacceptable by another, and in a joint operation
one state fielding a system that cannot be used by another]{.underline}.
[Or worse yet, this could render a joint operation
impossible]{.underline}. [Without the ability to interoperate across
NATO, the inability to **effectively and efficiently respond** to future
threats would **undermine the Alliance**.]{.underline}

The role of the private sector is another aspect of ethical AI
development that has proved a challenge to governments and the
transatlantic relationship. [Within states, governments have struggled
to adequately regulate Big Tech firms, which has led to these [companies
encroaching on government
responsibilities](https://www.ft.com/content/7f85a5ff-326f-490c-9873-013527c19b8f) to
protect and uphold the public interest]{.underline}. This encroachment
permeates all aspects of government, including defense and security. As
Deputy Secretary of Defense Kathleen Hicks discussed during her
confirmation hearings, the lack of competition is also [a challenge to
innovation](https://www.defensenews.com/congress/2021/02/02/to-keep-up-with-rivals-dod-nominee-will-weigh-consolidation-vs-innovation/) in
the private defense industry. This, along with a lack of regulation,
feeds into the [power
imbalance](https://www.centre4innovation.org/stories/data-driven-public-private-partnerships-3-areas-of-risk-for-public-organisations-to-understand/) between
the sectors. [Consequently, private sector companies building the AI and
AI systems that are or will be deployed on the battlefield are deciding
the ethics policies for themselves.]{.underline}

[The transatlantic partnership must focus on coordinating these core
principles and systematic governance to ensure AI systems development
aligns with the rule of law and democracy]{.underline}. In particular,
this must ensure answering questions about human dignity, human control,
and accountability. **[NATO is the ideal defense and security forum for
this alignment]{.underline}**. [Given the US lead on adopting ethical
principles for the entire DoD and the EU's drive to assert checks and
balances for private-sector tech companies, NATO remains the
organization that can **bring these two together** and establishes the
**ethical bottom line**]{.underline}. [These will then ensure
the [diverging legal and ethical stances towards Big
Tech](https://fivebooks.com/best-books/luciano-floridi-philosophy-information/) do
not lead to an interoperability barrier in the future]{.underline}.
[If [developments
surrounding](https://fas.org/sgp/crs/row/IF10896.pdf) the General Data
Protection Regulation (GDPR) and the challenges it brought
for [U.S.-based, data-driven
companies](https://www.wsj.com/articles/companies-face-uncertainty-over-challenges-to-trans-atlantic-data-transfers-11569013484) are
any indication, a strong transatlantic led initiative is needed in order
to ensure the same challenges do not hinder NATO.]{.underline}

[The solution to the challenge that ethical AI poses for the future of
interoperability within NATO is for the Alliance to establish shared
transatlantic ethical principles, informed by the US DoD, the EU, and
others. Establishing these principles will not only strengthen
transatlantic political relations; more technically, it will allow for
the establishment of standardization agreements and inform training and
education initiatives of the Alliance in the future]{.underline}.

#### Interoperable allied AI systems are critical to [future military effectiveness]{.underline}. 

**Reeves 21** \-\-- Lead Partner, Digital Defense.

Thomas, 2021, "Military interoperability in the intelligent age of
warfare," Deloitte,
https://www2.deloitte.com/content/dam/Deloitte/global/Documents/Public-Sector/gx-gps-fowf-military-interoperability-in-the-intelligent-age.pdf

[**Interoperability** has become the **cornerstone** of successful
military operations and the **critical element** for **future military
effectiveness** against threats ranging from **grey zone**
disinformation campaigns, to defending the **rules-based international
order**, and peer warfare. Future conflict success will require rapid
pace, precise understanding, quick decisions, and coordinated effects to
disrupt enemy activity. **Interoperability between** departments,
agencies, **allies**, and domains will deliver critical outcomes to
achieve campaign goals faster at strategic and operational
levels]{.underline}.

There is just one problem: current military interoperability is highly
people intensive, and people are slower than machines. It takes enormous
teams to create interoperability environments, staff the processes for
effective integration, and create the tools and products that deliver
the results. For example, completing a multinational 24-hour Air Tasking
Order can require hundreds of people to plan and interact across
domains, forces, and services, and the process is continuously repeated.
It is a demanding and time-consuming activity that needs to be accurate
and trusted or else the mission may fail.

But is that the best use of human talent? Analyzing data points,
deconflicting with other militaries, and planning logistics simply to
provide air operations? [And can such human-centric processes provide an
advantage on a future battlefield suffused with data and where decisions
need to be made faster than ever before? **Arguably, no**]{.underline}.
[To make interoperability the strategic and operational advantage we
need it to be, we must **automate more of it.**]{.underline}

[Combining automation and interoperability isn't new]{.underline}.
[Outside the military we are witnessing significant reductions in human
activities in the current Intelligent Age as machines and automation
replace human talent]{.underline}. [Intelligent organizations are
enhancing people with AI, where machines support all decisions,
improving trust between humans and machines and their outcomes. But more
than just automation, digital **supply networks merge smart tools, like
AI, with integration**.]{.underline} Smart factories and production
facilities are connected across borders in a manner increasingly
necessary to keep pace with the rate of consumption and trade today.
[The combination of Intelligent Age machines, like AI, with Intelligent
Age practices, like digital supply networks]{.underline}, [has changed
global commerce, and it **can change warfare** too]{.underline}.

#### That's because every [facet of modern warfare]{.underline} is being revolutionized by AI. 

**Carnegie 19**, 11-28-2019, \"Artificial Intelligence and the Future of
Conflict,\" Carnegie Europe,
https://carnegieeurope.eu/2019/11/28/artificial-intelligence-and-future-of-conflict-pub-80421

[Modern warfare is based on unprecedented connectivity between and
within three categories of the battlefield, which together build complex
battle spaces.]{.underline} [The first category is the **physical
domain**, in which ballistic missiles, main battle tanks, aircraft, the
weaponry of ground infantries, and other military hardware are used to
degrade or destroy an adversary's physical resources]{.underline}.

[The second battlefield is the **information technology space.** Here,
each side tries to gain superiority by improving the way information is
shared, connecting space-based intelligence to weapons systems, or
calculating the trajectory of an incoming ballistic
missile]{.underline}. For example, a combatant may use electronic
warfare to try to blind an adversary's acquisition radars before an
airstrike.

[The third battlefield is the **cognitive space**, where information
operations and political warfare take place. Cyberspace straddles the
informational and cognitive battlefields. Fifth-generation aircraft such
as the F-35 and Russia's influence operations use cyberspace to produce,
disseminate, control, and monitor information]{.underline}.

[In the future, victories will increasingly depend on the systematic
synchronization of the physical, informational, and cognitive
battlefields, **all augmented by algorithmic warfare**]{.underline}.
[This triad will redefine essential military concepts such as the center
of gravity, the fog of war, and the concentration of forces. In the age
of AI, big data, and robotics, concept development will be more
important than ever. This will be an unending task because new concepts
will need to constantly change to keep up with countermoves such as
adversarial algorithms and data-poisoning attempts, which involve
feeding adversarial data to AI systems. Such attacks try to alter what
AI learns from training data or how it solves classification or
prediction problems.]{.underline}

[In the near future, more breakthroughs seem imminent]{.underline}.
[Advances in neuroscience, behavioral biology, and other fields will
enable new technological leaps such as human-machine teaming and
increased autonomy in military systems]{.underline}.3 Robotic
swarms---the "collective, cooperative dynamics of a large number of
decentralized distributed robots," in the words of AI researcher Andrew
Ilachinski---form another field in which computer science and robotics
follow in biology's wake.4

Human-machine collaboration is likely to bring about faster and better
decisionmaking by enabling enhanced management of massive data streams.
Humans and AI systems have very different decisionmaking mechanisms,
which result in completely different kinds of errors when they fail. By
combining the strengths of humans and machines, it may be possible to
eliminate those weaknesses. Such teaming trials have already been
carried out in the military realm.5

New technologies encourage people, groups, and states to conduct
influence operations and manipulation at scale. Intelligent machines can
identify susceptible groups of people and "measure the response of
individuals as well as crowds to influence efforts," according to Rand
Waltzman, deputy chief technology officer at RAND Corporation. Cognitive
hacking, a form of attack that seeks to manipulate people's perceptions
and behavior, takes place on a diverse set of platforms, including
social media and new forms of traditional news channels. The means are
increasingly diversified, as distorted and false text, images, video,
and audio are weaponized to achieve the desired effects. Cognitive
security is a new multisectoral field in which actors engage in what
Waltzman called "a continual arms race to influence---and protect from
influence---large groups of people online."6

[**AI** could cause **drastic changes in hybrid warfare**, which is a
major concern for NATO. States and nonstate actors can use cyberspace to
influence large groups of civilians and opposing forces]{.underline}.
[From reconnaissance activities and the profiling of target audiences to
the weaponization of distorted or fake information and psychological
operations, AI broadens the potential of information
operations]{.underline}.

#### Streamlining the process through [NATO itself]{.underline} is key. No other institution has the capacity. 

**Stanley-Lockman & Trabucco 22** \-\-- \*Defense and Strategic Studies,
Nanyang Technological University. \*\*Political Science, University of
Copenhagen.

Zoe & Lena, "NATO's Role in Responsible AI Governance in Military
Affairs," Oxford Handbook,
https://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69

[At the core, this chapter argues that **NATO is well positioned** to
steward the development of military AI and institute governance
mechanisms towards coalition inclusion of responsible AI while
simultaneously maintaining incentives for comparative
advantage]{.underline}. [Using the three pillars---ethics and values,
legal norms, and safety and security---as issue areas which present AI
governance challenges, we show that NATO has space to emerge as a leader
in AI governance and contribute to responsible adoption of EDTs in the
international security environment]{.underline}. This builds on
foundations that derive NATO's responsibilities to govern AI according
to its values, legal obligations, and institutional interests. [These
foundations from both STS and military innovation studies offer ways
that the Alliance can activate its existing governance mechanisms to
exert influence in new ways]{.underline}. [Not only is this influence
important for the Alliance to bolster its institutional relevance in an
evolving international security architecture, but it also dovetails with
its capacity to **shore up military effectiveness** and
**interoperability** as Allies modernize their arsenals and associated
concepts into the frontier of AI.]{.underline}

[Importantly, we do not argue NATO is the only]{.underline}---or even
the most important---[actor shaping AI governance in international
security]{.underline}. Other contributors in this Handbook impressively
detail efforts at both state and regional levels. [Our aim has been to
convince sceptics that NATO has a **role that is not replicated by other
stakeholders** in the international security environment]{.underline}.
[NATO has particular influence, procedures, and the competency to
institute certain governance mechanisms---namely **standardization** and
policy planning---that it can build on without needing to expend time
building new institutions from scratch]{.underline}. [Beyond just a
role, NATO is incentivized to emerge as a steward of AI governance and
use these mechanisms for future operations, should the Alliance wish to
maintain its unique position as a leader encouraging policy alignment,
defense planning, and military standardization.]{.underline}

**That's key to a litany of impacts\-\--[terrorism]{.underline},
[authoritarianism]{.underline}, and [disinformation]{.underline}.**

**Kolga 21** -- founder of DisinfoWatch.org and is a senior fellow at
the Macdonald-Laurier Institute's Centre for Advancing Canada's
Interests Abroad

Marcus Kolga, \"Improving NATO's cohesion is critical to combat Russia
and China's threat: Marcus Kolga for Inside Policy,\" Macdonald-Laurier
Institute, 10-5-2021, https://macdonaldlaurier.ca/improving-natos-cohesion-critical-combat-russia-chinas-threat/

[A **united NATO** is **critically important** to **projecting credible
deterrence**]{.underline}. The erosion of domestic trust and confidence
in the Alliance among its member states, including Canada, represents a
threat to this cohesion. A proposal to withdraw Canada from NATO was
tabled at a recent policy conference for one of Canada's three major
political parties. The proposal was defeated, but it represents a fringe
anti-NATO narrative within Canada's illiberal left; if left unaddressed,
such a narrative could grow.

[If countries like Russia **perceive NATO** as an **atomized
collection** of states with **varied priorities** rather than a
**unified front**, the Alliance is exposed to a **significant risk of
miscalculation** in which a foreign adversary might believe they can
**cross a red line** and only face a limited response.]{.underline}
Thus, [**gaps in cohesion** within the alliance **directly threaten** to
undermine political and **military** **deterrence**. The
Alliance]{.underline} and members states [must work towards **improving
communications strategies** to foster greater basic general
understanding of]{.underline} NATO's purpose, its missions and its role
in [protecting its members against **external threats.**]{.underline}

Similarly, if we see threats as atomized or disparate, we may lack the
capacity to adequately respond. **[Organized]{.underline}** GRU
**[terrorist attacks]{.underline}** in Czechia, the Salisbury
[poisonings, **transnational repression** and **censorship**,
**cyberwarfare**, **disinformation**, and **overt military posturing**
all pose threats that are aimed at]{.underline} the same essential goal:
[undermining and supplanting the power of **liberal democracy** and
**advancing authoritarianism**.]{.underline} Through this lens,
[challenges posed by other actors, including China, must also be
considered as part of the **broader range** of **shared threats** posed
to the **democratic community**]{.underline} as a whole.

[If we are to **succeed** in tackling these shared threats, **greater
transatlantic cooperation is needed**]{.underline}. It cannot remain
stagnant, however; [it must **evolve** and **expand**. The **serious
nature** of the threats, their potential to **become kinetic**, and the
possibility of **adversarial coordination**]{.underline} (whether formal
or informal) [means that we must **expand our tools** to meet these
challenges.]{.underline}

In the case of Ukraine, on whose border the Kremlin mobilized over
100,000 troops this past summer, the Alliance should consider extending
a Membership Action Plan despite the skepticism of some allies. Ukraine
must also be empowered in a similar fashion to frontline NATO states
like the Baltic states and Poland. After all, the eFP mission in Latvia
not only provides military deterrence, but strengthens interlinkages,
develops societal resilience, and provides clear and sustained
solidarity.

Finally, [the growing threats of **foreign interference**, **information
warfare**, **cyber attacks** and **emerging threats**]{.underline} to
Canada's Arctic [requires a **coherent long-term strategy** and an
evolved notion of **collective defence**]{.underline}, which includes
strengthening our partnerships with non-NATO allies in Europe, Asia, and
around the world.

#### Russia's integrating [autonomous systems]{.underline} into their military. Failure to adapt will drastically change the [global balance of power]{.underline}. 

**Garamone 20** -- Reporter - United States Department of Defense.

Jim Garamone, September 9 2020, "Esper Says Artificial Intelligence Will
Change the Battlefield," U.S. Department of Defense,
https://www.defense.gov/Explore/News/Article/Article/2340972/esper-says-artificial-intelligence-will-change-the-battlefield/

[Artificial intelligence has the **potential to change the
battlefield**, and the country that\'s first to field it will have
enormous advantages over competitors, he told participants
today. ]{.underline}

\"[History informs us that those who are first to harness
once-in-a-generation technologies often have a decisive advantage on the
battlefield for years to come]{.underline},\" the secretary said. \"I
experienced this firsthand during Operation Desert Storm, when the
United States\' military\'s smart bombs, stealth aircraft and
satellite-enabled GPS helped decimate Iraqi forces and their Soviet
equipment.\" 

[Artificial intelligence has the potential to be **even more
far-reaching than those technologies**.]{.underline} \"[Unlike advanced
munitions or next-generation platforms]{.underline}, [artificial
intelligence is in a league of its own, with the **potential to
transform nearly every aspect of the battlefield**, from the back office
to the front lines,\" he said.]{.underline} \"That is why [we cannot
afford to cede the high ground to revisionist powers intent on bending,
breaking or reshaping international rules and norms in their
favor]{.underline} --- to the collective detriment of others.\" 

Esper noted that Russian President Vladimir [**Putin** said the nation
that leads in AI will be the \"ruler of the world,\" and Russia has
increased investments in the technology. \"His intent is to **employ any
possible advantage** to **expand Russia\'s influence** and chip away at
the sovereignty of others,\" Esper said. ]{.underline}

[The Russians used a sophisticated and well-coordinated combination of
unmanned aerial vehicles, cyberattacks, and artillery barrages to
inflict severe damage on Ukrainian forces when they invaded that
country.]{.underline} \"[Since then, Moscow has announced the
development of **AI-enabled autonomous systems**]{.underline} [across
**ground vehicles**, aircraft, **nuclear submarines** and **command and
control**,\" he said. \"We expect them to deploy these capabilities in
**future combat zones.\"**]{.underline}

 These principles make clear to the American people --- and the world
--- that the [United States will once again lead the way in the
responsible development and application of emerging technologies,
reinforcing our role as the global security partner of
choice]{.underline}.\"

#### Ukraine's [only the beginning]{.underline}. AI warfare will be an [intractable factor]{.underline} in every future confrontation with Russia. 

**Sharma 5/30** \-\-- Dr Sanur Sharma is Associate Fellow at Manohar
Parrikar Institute for Defence Studies and Analyses.

Sanur, NATO's AI Push And Military Implications -- Analysis, May 30,
2022, Manohar Parrikar Institute for Defence Studies and Analyses
(MP-IDSA) 

Introduction

[The technological advancements in Artificial Intelligence
(AI),]{.underline} machine learning, big data analytics, robotics,
quantum computing and virtual reality [have led to the **rise in use of
autonomous systems** in military applications. This is **changing the
face of the battlefield** by enabling new forms of military
functions]{.underline}, over and above the conventional systems, thus
enabling the execution of higher coercive actions. The North Atlantic
Treaty Organization [(NATO) countries are also adopting such emerging
technologies to maintain their strategic advantage and to mitigate
transnational threats.]{.underline}

Russia's offensive cyber hostilities and China's military adoption of AI
for augmenting its high-tech warfare mechanisms have emerged as the
contributing factors for NATO to upscale its technological efforts in
Emerging and Disruptive Technologies (EDTs). NATO is making ambitious
investments in EDTs to ensure interoperability and standardisation among
member states.

This Issue Brief takes stock of the current strategic surge by NATO in
AI adoption and its ongoing efforts to exploit EDTs for defence
innovation and adoption. It discusses the role of AI in contemporary
conflicts, specifically NATO's response to the Russia--Ukraine conflict,
and explores the vulnerabilities in the AI systems as well as the
challenges and limitations in AI adoption by NATO.

NATO's Technological Push

The US National Security Commission Report of 2021 states that China is
leapfrogging to new technologies by investing in intelligentised warfare
like swarm drones and using AI for reconnaissance, electromagnetic
countermeasures and coordinated firepower strikes.1 The US is jointly
working with its allies on the policy implications of such new
technology. It is also partnering with countries like Canada, Denmark,
Estonia, the UK, France and Norway, to work on military standards on
AI.2

In October 2021, NATO formally adopted the first AI strategy on the
responsible military use of AI with three core tasks: collective
defence, crisis management and cooperative security.3 NATO's strategy
aims to accelerate the uptake of AI for military systems.4 The six
principles of the NATO's AI strategy include: Lawfulness, Responsibility
and Accountability, Explainability and Traceability, Reliability,
Governability and Bias Mitigation.5 This strategy aims to protect,
monitor and innovate AI and related disruptive technologies in a phased
manner to establish political support for AI military projects.

The strategic surge in EDTs is driven by the accelerated investment
towards the military adoption and innovation of EDTs and maintaining a
sustainable innovation ecosystem that can be achieved through
civil--military collaboration. In 2021, NATO endorsed the strategy on
EDTs that included AI and machine learning among the seven identified
key technologies (Data, AI, Autonomy, Quantum, Space, Biotechnology, and
Hypersonic).6 The strategy plans to invest US\$ 1 billion in building
test centres across Europe and North America, focusing on emerging
technologies like AI, Quantum and hypersonics.7

In the NATO Summit held at Brussels in 2021, as a part of the NATO 2030
Agenda, NATO's new Defence Innovation Accelerator for the North Atlantic
(DIANA) was launched. It aims to maintain NATO's technological edge
compared to nations like China and Russia, which are challenging the
West with their accelerated investments to build technological capacity
and use offensive subversive measures.

DIANA has been assigned to manage the NATO Innovation Fund, receiving a
funding of US\$ 82.6 million a year for 15 years.8 It will explore the
future roadmap of implementation of advanced technologies and
competition to foster transatlantic cooperation.9 At present, there are
10 accelerator sites with more than 50 test centres in technological
hubs across the states.10 The NATO advisory group on EDTs is an external
body that advises NATO on the optimisation of its innovation efforts.
This group provides recommendations on improving collaboration and
partnerships with the private sector, industry, and academia. In
addition, there are other bodies like the NATO Advisory board, Allied
Command Transformation (ACT), NATO's Science and Technology Organisation
(STO), and NATO Communication and Information Agency (NCIA) that support
the alliance's adoption of deep technologies and EDTs.

[**NATO's AI Influence in Russia**--Ukraine Confrontations
 ]{.underline}

[AI has been a contributing agent in weaponising cyberspace and
augmenting cyberwarfare to the next level in modern battlefield
scenarios]{.underline}. While some of its uses such as in scaling of
data analytics, data fusion, deep fakes, cyber defence have matured, its
use in autonomous weapon systems and other complex operational
applications are at a nascent stage.

[AI has been aggressively used to spread disinformation in the
Russia--Ukraine War. Machine learning algorithms have been used to
amplify misleading and fake content on social media platforms, like
doctored videos of invading forces and fake live streams]{.underline}.
On the other hand, [it has also been used for anomaly detection,
identification of disinformation and for cybersecurity. AI uses natural
language processing algorithms, machine learning and deep learning to
identify anomalies in the text data, images and videos.]{.underline}

[Russia is said to have used **AI-enabled systems** not only **on the
battlefield** but also in cyberspace, targeting the critical
infrastructures of Ukraine.11 Russian troll farms have been alleged to
have used AI-enabled systems to generate human faces for fake
propagandist personas on social media]{.underline} platforms like
Twitter, Instagram and Facebook.12 [NATO countries have also used AI to
help Ukraine counter such AI-based attacks]{.underline}. Private
companies are also playing a role in the unfolding AI battlespace.
US-based companies like Snorkel AI, a data science platform, has made
its services accessible to federal authorities for the detection of
anomalous signals and adversary communications in order to access
high-value information for better decision-making.13

[Similarly, Ukraine has been given free access to Clearview AI facial
recognition software, which has a database of 2 billion
photos]{.underline} crawled from Russian social media platforms. This
software is being used [for the detection of Russian forces and to
identify the dead and gauge the spread of disinformation in
cyberspace]{.underline}.14 [AI's analytical potential has been tapped by
companies even before the Russia--Ukraine war started. In December 2021,
a geospatial data firm, SpaceKnow, claimed to have detected a military
presence in Yelna, a Russian town.]{.underline}

[The **Russia--Ukraine conflict** has become a **test case for AI
adoption in modern warfare**. The US is using the conflict as a test-bed
for many of its AI projects with the Pentagon's 'Maven' project having
contributed to the detection and classification of objects of interest
from various drone footage through AI and Machine Learning (ML)
algorithms.]{.underline} It has been reported that the Pentagon has been
using AI and ML tools to collect a vast amount of data on the
Russia--Ukraine war and analyse it to learn and generate battlefield
intelligence about the Russian command and control strategies.15

The advanced AI-enabled systems with the US Department of Defense (DoD)
are said to have been used for overseeing the battlefield and collecting
and archiving signals intelligence. It was stated at the Defense One's
Genius AI Summit in April 2022 that all this information will be fed
into systems for training of machine learning algorithms to support
future decision-making processes.16 It is believed that [the US and NATO
allies have already built such AI-enabled cyber weapons and
defences]{.underline}, information about which is said to be highly
classified.17

The US DoD and its allies have taken advantage of these advanced tools
to gather critical information from the publically available image data
to thwart Russian attacks in Ukraine. This war data will also help NATO
allies anticipate adversary attacks, their behaviour, and the use of
advanced technologies in the real world by countries like China and
Russia. This intelligence will also augment multifactor analysis and
modelling changes dynamically by integrating different technological
platforms.

Due to the sanctions imposed on Russia as a result of the
Russia--Ukraine war, its AI development is expected to slow down. The
ongoing conflict highlights the constraints around the use of AI.
Despite AI-enabled cyber-attacks and misinformation campaign by Russia,
Ukraine has mounted effective counter-cyber operations.18 Russia's
limited use of AI in the conflict can be explained through the existing
vulnerabilities in the AI systems that can be exploited in many ways.
One hypothesis for Russia's limited use of AI could be the trust in such
systems where it is a matter of lives and military objectives at
stake.19

The vulnerabilities in the AI systems can include data poisoning and
input attacks, attacking the supply pipelines by simply crafting data
and feeding it to public resources, white-box and black-box
attacks.20 There is always a chance of orchestrated and conflicting data
in the face of AI models to derail them and to exploit the
vulnerabilities in the algorithms, and active manipulation by the
adversaries can be induced.

Defense Advanced Research Projects Agency ([DARPA) has launched a
Guaranteeing AI Robustness against Deception (GARD)
programme.]{.underline} Under this programme, development efforts are
being made to establish a theoretical foundation for defensible ML and
the creation and testing of such systems.21 The Army Research Laboratory
(ARL) is working with the Internet of Battlefield Things Collaborative
Research Alliance (IoBT-CRA) to explore the use of ML and intelligent
technology on the battlefield and strengthen the collaboration between
autonomous actors and human soldiers in combat. They are also working on
methods to understand the challenges of AI-enabled systems employed on
the battlefield and to make them less susceptible to attacks.22

**[AI technology in modern warfare will be an intractable weapon in
future conflicts beyond Ukraine.]{.underline}** Countries trying to
achieve a technological edge over others have started considerable
investments in AI technology to strengthen their militaries. [NATO has
invested US\$ 1 billion to develop new AI defence technologies. The US
DoD has also planned to invest US\$ 874 million in AI-related
technologies as a part of their army research and development
budget]{.underline} (federal fiscal year 2022 DoD budget).[23 The UK DoD
is funding suppliers to work]{.underline} with Defence Science &
Technology Lab (Dstl) [on AI projects which were £7million for the year
2021/22 and is supposed to increase to £29 million in the next
year.]{.underline}[24](https://www.idsa.in/issuebrief/natos-ai-push-and-military-implications-ssharma-240522#footnote24_sxbrlaa)

#### Failure to successfully check Russia causes cascading conflicts throughout Europe \-\-- great power war.

**Graham 22** --- Thomas Graham, Distinguished Fellow at the Council on
Foreign Relations, Cofounder of the Russian, East European, and Eurasian
Studies Program at Yale University, 2022 ("Preventing a Wider European
Conflict," *Council on Foreign Relations,* March 8^th^, Available Online
at
https://www.cfr.org/report/preventing-wider-european-conflict#chapter-title-0-1)

[The large-scale Russian invasion of Ukraine now underway could quite
**plausibly precipitate** a wider conflict in Europe]{.underline}. The
United States is focused primarily on raising the costs to Russia with
punishing sanctions and reassuring North Atlantic Treaty Organization
(NATO) allies neighboring Russia of its commitment to collective
defense. [Less attention has been given to containing the war to Ukraine
and preventing its escalation into a **broader European
conflict**.]{.underline}

[The stakes are **enormous**]{.underline}. [The ripple effects of a
wider conflict in Europe would spread **across the globe**, stressing
the **geopolitical**, **economic**, and **institutional foundations** of
the **international order**]{.underline} the United States has fashioned
and underwritten since the end of the Second World War. [It would test
the resilience of the U.S. **global system of alliances**, the
international **financial system**, **global energy markets**, **arms
control regimes**, and **global institutions** in the face of ever more
violent **great power competition**]{.underline}. [**No region** of the
world would be spared]{.underline}, although developments on the
Eurasian supercontinent, the other locus of world power and economic
might outside North America, would bear the gravest consequences for
U.S. interests.

The Contingency

[The Russian military intervention in Ukraine could **easily escalate**
into a larger conflict stretching from the Baltic to the Black Sea and
further west into Europe]{.underline}. Although Russia, wielding massive
military superiority, might overrun Ukrainian forces in a matter of
weeks, stabilizing and pacifying the country will likely prove to be a
grueling and costly affair. A significant Ukrainian resistance movement
is almost certain to emerge. With sustained Western support, it could
prolong the warfare for months, if not years. The first wave of
sanctions that Washington has levied on Moscow could be followed by
others in a continuing effort to raise the cost to Moscow and force it
to yield. A negotiated end to the conflict will not come easily, since
Washington has framed it in Manichean terms as a world historical
struggle between the democratic West and the aggressive, malevolent, and
autocratic Russia. Anything short of "victory" will be decried as
surrender or appeasement in the West, while Russia will not capitulate
on a matter it considers vital to its security and prosperity.

[The stage is thus set for an **escalating cycle** of violence, with
Moscow seeking to stamp out a Ukrainian insurgency and retaliate against
Western efforts to stop Russia's advance. If the conflict wears on,
Moscow could be **increasingly tempted** to expand its military
operations further into Europe to achieve its goals.]{.underline}

As a first option, [Russia could **intensify pressure** on states
neighboring Ukraine (e.g., Hungary, Poland, Romania, and Slovakia) that
could provide safe havens for insurgents or the inevitable
government-in-exile]{.underline}. It will doubtless reinforce its
military presence in Kaliningrad and elsewhere in the Baltics and patrol
the Baltic Sea more aggressively. [It could deploy hybrid-war
tactics---**cyberattacks**, **disinformation campaigns**, and **economic
sabotage**---to destabilize countries providing safe
havens]{.underline}. If those actions did not sufficiently degrade the
resistance, [Moscow could even launch direct attacks on insurgents and
their supporters outside Ukraine, as well as attempt to assassinate
leading figures in the government-in-exile, akin to the attacks it has
made on Chechen rebels and Federal Security Service (FSB) defectors in
Europe in recent years]{.underline}. Such steps could, at a minimum,
draw frontline NATO states directly into the military conflict with
Russia, obligating the United States and other allies to come to their
defense.

To build up further pressure, [Moscow could also "**weaponize**" the
inevitable refugee flows into neighboring states]{.underline}. Refugees,
who would likely number in the millions, would move first into
unoccupied Ukrainian territory but eventually into adjacent European
states, which have shown little tolerance for outsiders. Moscow could
use harsh military and police tactics that would increase the number of
refugees and seek to guide them into countries where they would create
the greatest socioeconomic stress, such as Moldova. In addition, [Moscow
could increase the tension by pushing Belarusian President Aleksandr
Lukashenko to again seek to push thousands of Middle Eastern migrants
across the borders into Poland and Lithuania. That could lead to
**border clashes**, as it almost did on occasion last fall, with Russia
supporting its ally, Belarus, and **NATO states coming** to the defense
of allies under attack.]{.underline}

A second option [Moscow could pursue is opening up a second front in the
**Balkans**.]{.underline} In recent years, Russia has taken a number of
destabilizing actions in the region, seeking to weaken Montenegro after
its accession to NATO, exacerbate tensions between Serbs and Bosniaks in
Bosnia-Herzegovina, and undermine relations between Serbia and Kosovo.
As it fought in Ukraine, [Russia could encourage Republika Srpska leader
Milorad Dodik to press for separation from Bosnia, threatening to
reignite the bitter wars of the 1990s in the former
Yugoslavia.]{.underline} A Balkans war would complicate the security
calculus of all countries in the region, as well as that of Germany and
France, which have significant interests there. [To quell the fighting,
NATO countries could decide to use military force against Bosnian Serb
forces enjoying Russian support.]{.underline}

A third, riskier, [option would be to **directly attack** the United
States, the country that Moscow believes is orchestrating a larger
anti-Russia campaign. In response to Western sanctions designed to
crater Russia's financial system and undermine critical industries,
Moscow could launch major cyberattacks against U.S. critical
infrastructure]{.underline}. If a cyberattack were to take down a major
financial institution or corrupt its records, the ensuing havoc in U.S.
markets could prompt overwhelming public and congressional pressure for
a forceful response.

[The U.S. and NATO response to Russian actions will impact Moscow's
decisions on the conduct of the conflict. Both a weak response and an
excessively harsh one could **lead to escalation**]{.underline}. In the
first case, Moscow could be tempted to press militarily even further
into Europe to enlarge its sphere of influence. Vladimir Putin has
demanded that NATO withdraw its forces back to the lines they held in
1997, when the NATO-Russia Founding Act was signed and the first wave of
post−Cold War expansion remained in the future. His remarks announcing
the start of hostilities against Ukraine hinted at a broader effort to
restore Russia's control over all of the former Soviet Union. [That
could include military action against the Baltic states, especially
Lithuania, through which Moscow could try to carve out a land corridor
to Kaliningrad, a Russian exclave on the Baltic Sea. NATO would have
little choice but to provide military aid to those states if it did not
want to forfeit its role as the central pillar of European
security.]{.underline}

Crippling sanctions, meanwhile, could provoke Putin to lash out with
greater violence. If Putin felt cornered, he could escalate the conflict
either horizontally to other countries or vertically to the nuclear
level in a desperate effort to save himself, his regime, and, in his
mind, Russia itself. And he could find considerable public support for
such a reaction. Already, some Russians believe that U.S. and EU
sanctions are aimed not simply at the leaders behind the war but, by
cratering the economy, at all Russians.

Warning Indicators

As is the case with the current crisis in Ukraine, [Moscow's intentions
will remain **ambiguous**.]{.underline} The indicators of an approaching
escalation in the conflict beyond Ukraine are likely to fall into three
categories.

[The first indicators that political and military conditions are
increasing the risk of broader conflict include a breakdown in channels
of communication with Moscow]{.underline}. The absence of active
diplomatic ties would preclude a negotiated resolution of the conflict
in Ukraine. An end to U.S.-Russian military-to-military channels would
undermine any effort to avoid direct military conflict between the two
countries. Another indicator would be major insurgent successes that
dramatically increase Russian casualties. Moscow would be tempted to
move more aggressively against insurgent safe havens rather than
capitulate on what it considers to be its vital interest in Ukraine.

[Second are the indicators that Moscow is preparing for a broader
conflict, which it would undoubtedly argue had been forced by Western
actions]{.underline}. Such signs include Kremlin efforts to prepare the
Russian public for a wider conflict, which could entail official
statements, greater media focus on escalating Western "aggression," an
increased pace of civil defense drills, and mobilization of reserves.
Another indicator includes the massing of Russian forces in the Baltic
region. It could include such moves as aggressive hybrid actions to
destabilize Poland and the Baltic states, coupled with efforts to rally
indigenous ethnic Russian communities against their governments.

[Third are the indicators that Moscow is intentionally seeking to widen
the conflict]{.underline}. This could include greater support for
Bosnian Serb leader Dodik, such as diplomatic and financial backing, and
provision of weapons. They could also encourage Serb leaders to more
assertively pursue their grievances against Kosovo.

Implications for the United States

[A wider European conflict would pose the stiffest challenge to the
**global standing** of the United States since the end of the Cold War
and to the international system it has built and underwritten for
**decades longer**]{.underline}. [It would test the durability of its
global system of alliances and the efficacy of international regimes and
institutions that have guarded world **peace**, **security**, and
**prosperity**. The challenge would come at a time when the United
States itself is in **immense disarray**, as a deeply polarized polity
confronts massive domestic problems---the **pandemic**, **inflation**,
**racial justice**, and **cultural wars**---that leave less time and
fewer resources for foreign matters]{.underline}. [The United States
will be tested to see whether it can muster the **will**, **energy**,
and **creativity** to execute an **effective policy** toward the
unfolding crisis in Europe.]{.underline}

#### Independently, fragmented allied AI systems risk accidents and miscalculated escalation. 

**Stanley-Lockman & Trabucco 22** \-\-- \*Defense and Strategic Studies,
Nanyang Technological University. \*\*Political Science, University of
Copenhagen.

Zoe & Lena, "NATO's Role in Responsible AI Governance in Military
Affairs," Oxford Handbook,
https://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69

[Even without being attacked, governability of AI in a NATO context also
means understanding how AI-enabled and autonomous systems developed by
the 30 Allies -- and other partners -- will interact with one
another]{.underline}. NATO has expressed interest in governability as a
principle of AI "to disengage or deactivate in case of unintended
behaviour,"86 which echoes the U.S. Department of Defense definition of
governable AI.87 Disengaging adversaries is important to maintain
de-escalation measures in conflict. [For NATO, interoperability between
systems also relates to governable AI because allies must also consider
how the interactions between the **30 Allies' own AI-enabled and
autonomous systems** may **result in unintended or emergent
behaviour**]{.underline}.88 [This means that NATO has a responsibility
to coordinate]{.underline} activities -- be they technical exchanges,
[standardisation efforts]{.underline}, or training and exercises -- [to
build confidence that the systems perform as humans
intend.89]{.underline} [Without this coordination, the **lack of
interoperability** of allied systems **could lead to accidents**, and
separately, the potential loss of operational effectiveness also
presents vulnerabilities for adversaries to exploit.]{.underline}

[In addition to governability, NATO and its Allies are assessing the
risks that bias, attacks, and lack of interpretability can introduce in
relation to the anticipated uses of a given AI system]{.underline}.90
[In security and defence, new and heightened risks include **poisoning
of the information environment,** deception systems and techniques,
uncertainty about the performance of systems in new and unknown
environments, and the possibility that **tensions or accidents
escalate** at a **faster tempo than humans and institutions can
process**, among others]{.underline}. [These risks can manifest either
in motivated attacks or unintentional failure modes.91 In both cases,
assuring and certifying that military assets are safe and secure is
important given the inherently high risk in operational
environments]{.underline}. [These operational environments include the
presumption that an adversary is disrupting one's own systems, be it by
directly attacking the AI systems themselves, or disrupting the broader
command, control, and communications systems under which the AI systems
are operating.92]{.underline}

#### The AFF solves\-\--[it standardizes AI rules]{.underline} for NATO members that builds upon existing principles. 

**Sharma 5/30** \-\-- Dr Sanur Sharma is Associate Fellow at Manohar
Parrikar Institute for Defence Studies and Analyses.

Sanur, NATO's AI Push And Military Implications -- Analysis, May 30,
2022, Manohar Parrikar Institute for Defence Studies and Analyses
(MP-IDSA) 

NATO's AI Adoption: Challenges and Limitations

The influence of AI on NATO comes with a set of opportunities,
challenges and risks. Its adoption process has been incremental and
prescriptive. [The rising geopolitical conflicts and the use of AI in
such conflicts have required the establishment of a **dynamic ecosystem
to support interoperability**. The military adoption of AI requires an
innovation ecosystem that is self-sufficient, supports deterrence and
resilience, and encompasses the strategic innovation
process.]{.underline}

[NATO's AI strategy raises many concerns related to the AI-driven
autonomous weapon systems, as it does not adequately address the
development of such systems, its deployment and governance]{.underline}.
The AI strategy mostly talks about the ethical and responsible use of AI
and [has omitted the challenges related to the use of lethal autonomous
weapon systems. For the US, its **priorities lie in ensuring responsible
us**e of AI-enabled systems with their allies for operational and data
sharing]{.underline}. It remains to be seen if all the 30 NATO states
agree on the same rules and would be willing to agree on practical
guidelines for the operational use of AI-enabled systems.

[Another challenge for NATO is to **standardise rules for all member
states** in dealing with **AI-enabled autonomous weapon
systems**]{.underline}. Countries like Turkey are working on autonomous
weapons and have developed AI-enabled loitering munitions. Turkey has
requested the US for upgraded F-16 fighter jets that are said to be
AI-enabled.25 The Biden Administration has asked the Congress to approve
the upgrade of Turkey's F-16 fighter jet fleet.26 Turkey's armed drones
have also been used in the Ukraine conflict. [For **smooth functioning**
of such systems, it will be necessary for all NATO members to have
standardised rules when it comes to deployment of such
systems.]{.underline}

Also[, there is no transparent allocation of roles for different NATO
bodies, and "no dedicated line of funding" for its AI strategy.27 The
finances are shared through multiple funding like NATO Innovation Fund
and DIANA which manages funding for various other projects leading to
uncertainty over availability of funds and budget cuts. This will be a
significant challenge for the effective implementation of the AI
strategy.28 Some other challenges with the adoption of AI strategy
through innovation include fragmented national innovation initiatives,
allied technological categorisation and digitisation gaps, speed of
adoption and spending levels and the underuse of NATO's mechanisms to
undertake collaborative defence innovation.29]{.underline}

[NATO will also have to focus on the vulnerabilities and intrusion
issues with the AI-enabled systems and will need to set up dedicated
centres for AI development and testing in order to maintain a
test-safety regime for systems-of-systems employed using AI. The
challenges related to **AI use in wars and geopolitical conflicts** need
to be addressed to generate confidence in the use of such systems.
Additionally, testing mechanisms and accuracy standards need to be
implemented for system components. Policymakers need to address the
operational risks and ethical considerations of employing AI in military
systems.]{.underline}

Conclusion

In future, [AI will act as an enabler to out-adapt competitors and
adversaries. The current AI strategy of NATO needs to **address the
vulnerabilities in AI systems** and related measures for effectively
using autonomous weapon systems and military governance of
AI]{.underline}. The NATO accelerator has been devised to address,
prioritise, and promote interoperability in transatlantic cooperation to
drive the strategic innovation process. The key drivers for Innovation
in AI and other EDTs will be the establishment of the
NATO-Civil-Military Technology capability that will include various
actors from the military, civil, state and private sectors as a part of
the EDT innovation ecosystem[. Another critical factor is the broadening
of the NATO--EU cooperation through a joint taskforce on defence
innovation and EDTs to regularise and provide strategic capabilities on
ethical and adoption challenges of EDTs like AI and ML.]{.underline}

Furthermore, [NATO needs to protect the use of AI from manipulation and
disruption and align it with its stated principle of "**Responsible use
of AI".** NATO needs to work on AI adoption challenges centred on
innovation and arms control. It can look towards bringing in guiding
principles on use of AI-driven lethal autonomous weapon
systems.]{.underline} It is expected that in the next 2--3 years, AI's
use will be confined to the field of military logistics, reconnaissance,
mission planning and support, predictive maintenance of a military
facility, data fusion and analysis, cyber defence and optimisation of
processes. [In the long run**, NATO could employ AI** for more **complex
military applications** as it generates greater political support for
**offensive AI military projects**.]{.underline}

#### Every member says yes\-\--US [initiating the cooperation]{.underline} ensures allies toe the line. 

**Sperling 19** -- Professor of Political Science at the University of
Akron, PhD from the University of California, Santa Barbara, and Dr.
Mark Webber, Professor of International Politics at the University of
Birmingham, PhD from the University of Birmingham, Master of Social
Science from the University of Birmingham, BA from the University of
Warwick.

James Sperling, January 20 2019, "Trump's foreign policy and NATO: Exit
and voice," Review of International Studies,
https://www.cambridge.org/core/services/aop-cambridge-core/content/view/CECD6A4DA95D3C177531E8C10A6E562B/S0260210519000123a.pdf/trumps_foreign_policy_and_nato_exit_and_voice.pdf

If exit is a credible option for the US, why has it not taken place? The
answer lies in the institutional character of the Alliance.
Institutional analysis of NATO is often seen as a counter to realism.
The latter views alliances as mechanisms of balancing or bandwagoning in
the international system with alliance formation, stability, and
durability being a reflection of power configurations among states.
Realism can account for the formation of NATO, its cohesion when
confronted with a commonly recognised existential threat such as the
Soviet Union, and its adaptation after the Cold War as the US harnessed
the Alliance to new security tasks[. Here, what matters is national and
especially **American preferences** not NATO's institutional
qualities.]{.underline}33 Discounting institutions in this case is,
however, misplaced[. NATO's permanent mechanisms of intra-alliance
**political consultation** alongside a standing command structure
(embracing defence planning, standardisation, interoperability, and a
recurrent rather than one-off ability to deploy) are unique among both
historical alliances and contemporary international
organisations]{.underline}.34 Two consequences follow from the presence
of these arrangements. [First, NATO has **assumed an elevated status in
American strategic calculations**. Here, the burden of defending allies
is **offset by NATO's political role** in **aligning allied preferences
with those of the US**. NATO's institutional mechanisms
(]{.underline}the North Atlantic Council above all[) make that alignment
possible, ensure it is embedded, and deliver efficiencies and **gains to
all allies** in the process. NATO thus takes on alliance-centric tasks
(the security of Europe and the stabilisation of its periphery) that are
of clear benefit to Europeans but which provide, simultaneously, an
**important security externality to the US**. Second,
institutionalisation has assumed a social character -- the
sophistication and permanency of intra-alliance mechanisms provide ample
opportunities for voice and renders that articulation
legitimate]{.underline}. One need not characterise NATO as a community
organisation of democratic values35 in order to allow for this outcome.
It can be seen also as the consequence of more formal properties that
pertain to a sophisticated multilateral security arrangement: acceptance
of the principle of consultation, agreement on common security threats
and, in NATO's case, a sense of shared endeavour built up over a
decades' long history.36 These properties are certainly open to
exploitation. [However, even the most powerful ally will be wont to play
within the multilateral rules of the game. These, after all, are stacked
in its favour and so offer a **reliable means of exercising leadership**
and **getting fellow allies to toe the line**.37]{.underline}

All of this is not simply realism by another route. Institutions act as
a vehicle within which the demands of the powerful are articulated and
modified. The institution, in other words, exerts its own effect[. The
interaction of exit and **voice in NATO** bears out this assumption. A
**member as powerful** as the US could well hold the view that NATO is
underperforming its core defence function or is neglecting other tasks
the US considers important]{.underline}. Equally, it might believe that
the cost of contributing to NATO's public security goods is too great
particularly if other allies are seen to be shirking their
responsibilities. [America's history of **engagement with NATO has been
characterised by the periodic recurrence** of such tensions yet, as we
shall see below, throughout it has exercised the option of voice.
**Voice has proven effective** both in expressing dissatisfaction with
NATO's allies and **advocating changes to allied business**. NATO's
institutionalisation, in other words, has served to **minimise the cost,
and to maximise the benefits** of exercising voice, just as it has
served to minimise the benefits and to maximise the cost of
exit.38]{.underline}

### Advantage 2\-\--Norm Setting

#### NATO taking an active role in AI norm setting serves as a [bulwark]{.underline} against [illiberal]{.underline} AI deployments. 

Zoe **Stanley-Lockman &** Lena **Trabucco 22**, Stanley-Lockman is an
Associate Research Fellow in the Military Transformations Programme at
the Institute of Defence and Strategic Studies at the S. Rajaratnam
School of International Studies in Singapore; Lena Trabucco is a dual
degree candidate pursuing a PhD in political science at Northwestern
University and a PhD in Law at iCourts Center of Excellence in
International Courts at the University of Copenhagen, "NATO's Role in
Responsible AI Governance in Military Affairs," The Oxford Handbook of
AI Governance, edited by Justin Bullock et al., Oxford University Press,
03/18/2022, DOI.org (Crossref),
doi:10.1093/oxfordhb/9780197579329.013.69

Ethics and values

[One of the]{.underline} vital [aspects of AI which]{.underline} has
[garnered significant global attention is the]{.underline} ethical
[implications of **a**]{.underline}rtificial
**[i]{.underline}**ntelligence [as a **military
tech**]{.underline}nology---[an issue that has]{.underline}
**[divided]{.underline}** much of the global community, including
**[NATO]{.underline}** member states. As a starting point, [researchers
and analysts have considered the implications of]{.underline}
[emerging]{.underline} military **[tech]{.underline}**nology [in terms
of]{.underline} **[ethical responsibility]{.underline}**
[and]{.underline} [**regulation**, especially as states and
organizations **continue**]{.underline} [to]{.underline} **[release AI
ethical principles, guidelines, and standards]{.underline}**.55

We explore how [NATO can]{.underline} **[operationalize]{.underline}**
[the debate around ethics and values of military AI to]{.underline}
**[garner coordination]{.underline}** [and]{.underline}
**[continue]{.underline}** progress of EDT **[harmonization among
partners]{.underline}**. Building on the theoretical discussion from STS
and military innovation literature above, the [adoption of]{.underline}
**[tech]{.underline}**nologies [that reinforce **values**]{.underline}
[serves the]{.underline} **[strategic interest of NATO]{.underline}**
[to **shape**]{.underline} technological **[innovation
against]{.underline}** current waves of **[illiberalism]{.underline}**.

Additionally, infusing AI development with certain ethical principles
and values can have operational advantages and benefits, and NATO can,
in particular, promote the ethical principles as operational standards
for the Allies. A common critique within the ethics debate is that
approaching new technology with an ethical or democratic values-driven
perspective translates into comparative military disadvantage.
Essentially, if your adversary develops technology without the
constraints of ethical principles then there will be diminished
effectiveness on the battlefield.56 We find this critique unfounded
because it assumes there is a false trade-off between ethics and
effectiveness; instead, we argue ethical foundations are built into the
architecture of modern warfare.57 As such, ethics is a background
condition for battlefield effectiveness, which is already infused in
military decision-making and helping to guide the boundaries of
international humanitarian law. As such, ethical guidelines do not have
to detract from a military's capacity or competency to devise means and
methods of warfare that will serve their national or coalition
interest.58 If anything, a first-mover advantage can incentivize an
ethical and values-driven AI to establish the threshold of technological
standards globally.59

[The]{.underline} **[political]{.underline}** [dimension of the Alliance
rests on the]{.underline} **[bedrock]{.underline}** [of]{.underline} a
**[shared commitment to]{.underline}** the "principles of
**[democracy]{.underline}**, individual liberty [and]{.underline} the
**[rule of law]{.underline}**," as enshrined in the foundational North
Atlantic Treaty of 1949.60 Shared values are important for NATO
operations because they help constitute their legitimacy. [In addition
to the]{.underline} **[N]{.underline}**orth **[A]{.underline}**tlantic
**[C]{.underline}**ouncil [exerting]{.underline}
**[civilian]{.underline}** [oversight over NATO operations,
**legitimacy**]{.underline} also [includes respect for]{.underline}
[international]{.underline} **[legal]{.underline}** [principles
including the core principles of]{.underline}
**[i]{.underline}**nternational **[h]{.underline}**umanitarian
**[l]{.underline}**aw, [or]{.underline} the **[l]{.underline}**aws
**[o]{.underline}**f **[a]{.underline}**rmed **[c]{.underline}**onflict,
distinction, proportionality, and necessity. [Without]{.underline}
**[political]{.underline}** oversight and [**legitimacy**,
NATO's]{.underline} **[military]{.underline}** [power would
be]{.underline} **[less effective]{.underline}** [at
shaping]{.underline} **[norms]{.underline}** [and promoting]{.underline}
**[stability]{.underline}** [in the]{.underline} [**international
system**. The introduction of]{.underline} **[AI]{.underline}**
[means]{.underline} that [NATO has the]{.underline}
**[moral]{.underline}** [and]{.underline} [**strategic imperative** to
adopt technologies that **confer legitimacy and responsible
innovation**]{.underline}.61 [Acting on a shared commitment
to]{.underline} **[democratic values]{.underline}** [is]{.underline}
**[vital]{.underline}** [to the]{.underline} [**political cohesion of
the NATO Alliance**, just as much as it is a determinant of]{.underline}
**[military effectiveness]{.underline}** [in a predictable security
environment]{.underline}.

Put simply, **[shared values]{.underline}** [are]{.underline}
**[important]{.underline}** [to both]{.underline}
**[political]{.underline}** [and]{.underline} **[operational coherence
between Allies]{.underline}**. In its 2018 Framework for Future Alliance
Operations, the strategic command Allied Command Transformation urged
discussion of the legal and ethical dimensions of technological
advancement to both know how it would impact NATO decision-making and
how the Alliance would be prepared to address adversaries who do not
share in that vision.62 As such, [NATO is contending with the ways that
ethical AI impacts its **own** cohesion **internally**]{.underline} [and
how **differences** between allies may **project outward**]{.underline}
[in the face of]{.underline} **[competitors]{.underline}** [whose
ethical frameworks and commitment to the rule of law differ. Internally,
there is a strong **national** government commitment to responsible
AI]{.underline}. **[Recently]{.underline}**, [transatlantic cooperation
has **initiated partnerships**]{.underline} [of]{.underline} largely
**[NATO states]{.underline}** [committed to]{.underline} **[advancing
responsible AI]{.underline}** [with goals towards data sharing and
future interoperability]{.underline}.63 AI defense partnerships are not
restricted to military innovation but rather aim to facilitate civilian
innovation cooperation for defense purposes.

Externally, [as AI-enabled autonomous systems enter the arsenals of more
technologically advanced countries,]{.underline}
**[uncoordinated]{.underline}** [ethical frameworks between Allies could
pose **operational risks**. Without wider alignment, AI systems will
have "**varying**]{.underline} technical
**[specifications]{.underline}** [based on]{.underline} the
**[legal]{.underline}** [and]{.underline} **[policy
decisions]{.underline}** [made by]{.underline} **[individual
governments]{.underline}** when answering the key questions."64 Further,
[although one motivation of autonomous systems is]{.underline} the
[increased safety of **military**]{.underline} [personnel]{.underline}
by removing them from dangerous situations, the **[lack of
alignment]{.underline}** [could lead **some**]{.underline} [Allies to
perceive **other**]{.underline} [capitals' deployments of unmanned
forces as a **lack of commitment to put lives on the
line**]{.underline}, therein [posing]{.underline} **[credibility risks
for Allies to assure one another]{.underline}**.65 [These credibility
risks can be]{.underline} **[mitigated]{.underline}** [by]{.underline}
**[accountability]{.underline}** [and]{.underline} **[verification
standards]{.underline}** [and procedures that]{.underline}
**[NATO]{.underline}** [can]{.underline} **[implement]{.underline}**
[for]{.underline} [**multinational operations**, and efforts
to]{.underline} **[institutionalize]{.underline}** [these procedures for
AI are **underway**]{.underline}.66 [While the NATO AI Strategy is
expected to create a common foundation for the Alliance's pursuit of AI,
it is]{.underline} the **[implementation]{.underline}** of principles
for safe, ethical, legal, and interoperable AI [that will reveal **how
coherent**]{.underline} [different]{.underline} national [perspectives
are]{.underline}. As of August 2021, [only the]{.underline}
**[U]{.underline}**nited **[S]{.underline}**tates [and]{.underline}
**[France]{.underline}** [have publicly issued their military AI
strategies]{.underline}.67 Other allies, including Canada and the United
Kingdom, have emerging views on responsible military AI, but little
official information about how they implement their ethical risk
assessments is publicly available.68

NATO's influence in the functioning of joint operations and
multinational military operations situates the Alliance to coordinate
between how Allies implement ethical principles in their own national AI
development. Specifically, NATO is well-situated to advocate for
transparency, accountability, and data governance, which are also
adoption factors that can translate into operational benefits, among
other values.69 For example, these factors can promote coordination
among Allies on ethical guidelines on the development and use of AI, as
this will be a necessary foundation in any future joint operation that
uses this technology. "The transatlantic partnership must focus on
coordinating these core principles and systematic governance to ensure
AI systems development aligns with the rule of law and democracy. In
particular, this must ensure answering questions about human dignity,
human control, and accountability ... NATO remains the organization that
can bring these two (U.S. and EU) together and establishes the ethical
bottom line."70 The issues of transparency and accountability will
define the scope of future implementation.

Many remaining questions and uncertainty will be addressed in NATO's
forthcoming AI ethical principles guidelines. But [the guidelines
adopted in]{.underline} **[2021]{.underline}** [do]{.underline} **[not
address every]{.underline}** ethical [**dilemma**.
Regarding]{.underline} **[accountability]{.underline}**, especially,
likely **[major questions]{.underline}** [will continue to affect the
Alliance]{.underline}. As Assistant Secretary-General for Emerging
Security Challenges David van Weel recently clarified, [NATO will offer
a]{.underline} **[framework]{.underline}** [of responsible use for the
Allies---but the question]{.underline} [of]{.underline}
**[accountability]{.underline}** [for]{.underline} member
**[states]{.underline}**, as opposed to civilian technology
manufacturers for example, is one principle that [will]{.underline}
**[not have an easy solution]{.underline}**.71

#### [NATO is key]{.underline}. It occupies a unique role to [credibly spearhead]{.underline} norm setting in emerging tech. 

**Ehlert 21** \-\-- PhD. Head of Strategy and Policy in the Office of
the Chief Scientist at NATO headquarters.

Ulf, 12-16-2021, \"NATO Review,\" NATO Review,
https://www.nato.int/docu/review/articles/2021/12/16/why-our-values-should-drive-our-technology-choices/index.html

[It would be short-sighted to assume that Western countries could
**globally enforce emerging technologies'** compliance with Western
values. Instead, **differences in values** may well result in
**divergent technological competences** that can, in turn, affect the
global distribution of power.]{.underline}

[Setting norms -- a role for NATO?]{.underline}

[Emerging and Disruptive Technologies (EDTs) came into NATO's political
focus in 2019, when NATO leaders adopted an implementation roadmap for
seven such technologies.]{.underline} Regardless of their tremendous
promise, we must realise that these technologies are not yet mature, not
yet "fully out there". [Therefore, considerable uncertainty remains to
which extent these fledgling technologies and their foreseeable
applications are appropriately contained within established legal,
ethical, and moral norms]{.underline}. [These questions are not limited
to military applications, nor do they stop at national borders: rather,
they cut across many government departments and business sectors, and
they affect humanity in its entirety.]{.underline}

[In this complex, fast moving, high-stake setting, we must view
**technology and values as intertwined**. While our values should guide
our use of technology, we must recognise that our technology choices
will, whether intended or not, reflect the values we adhere
to.]{.underline}

As inaction is not an option, we must take active measures to establish
norms for the future use of technologies; norms that are deeply rooted
in our values; technologies that are currently emerging and have
recognised disruption potential (such as AI, biotechnology, and quantum
technology). How could we realistically master this novel challenge? The
following three proposals could pave the way.

[We must effectively cope with the uncertainties of technology
evolution. Hence, I suggest evolutionary policy-making, building on
current knowledge, but flexible enough so that today's decisions can be
adjusted or corrected in the future.]{.underline}

[We must strive **to limit potential harm** without unduly constraining
the benefits a technology can bring. Therefore, our policies should set
limits for the application of technologies]{.underline} ([such as
genetically optimised super-soldiers]{.underline}) [rather than banning
entire technology areas (in this case, biotechnology).]{.underline}

We need to understand when policy changes are necessary and what those
changes should be. Reflecting the diversity of interests, we need to
institutionalise a broad stakeholder engagement that reaches out to all
parties affected by a technology and influencing its evolution.

[Within this broadly applicable framing, **NATO's role is
specific.**]{.underline} [As the international organisation committed to
defence and security in the North Atlantic area, it convenes
considerable political, military, economic, and technological
power]{.underline}. [Building in particular on its political and
intellectual capital, the Alliance can **credibly spearhead norm
setting** for technology applications in defence to comply with Western
values.]{.underline}

#### Global development is inevitable\-\--try or die for norm setting. 

**Horowitz 18** \-\-- Michael C. Horowitz is a professor of political
science and the associate director of Perry World House at the
University of Pennsylvania.

Michael Horowitz, May 2018, "Artificial Intelligence, International
Competition, and the Balance of Power," Texas National Security Review,
https://tnsr.org/2018/05/artificial-intelligence-international-competition-and-the-balance-of-power/

[Whether AI capabilities diffuse relatively slowly or quickly, major
military powers will likely face security dilemmas having to do with AI
development and deployment]{.underline}. [In a slow diffusion scenario,
if countries fear that adversaries could get ahead in ways that are hard
to rapidly mimic]{.underline} --- and small differences in capabilities
will matter on the battlefield --- [that will foster incentives for
quick development and deployment]{.underline}. [In a rapid diffusion
scenario, competitive incentives will also exist, as countries feel like
they have to race just to keep
up]{.underline}.[114](https://tnsr.org/2018/05/artificial-intelligence-international-competition-and-the-balance-of-power/#_ftn114) Moreover,
[it will be inherently difficult to measure competitors' progress
with]{.underline} AI (unlike, say, observing the construction of an
aircraft carrier), [causing countries to assume the worst of their
potential rivals.]{.underline}

[Competition in developing AI is underway. Countries around the world
are **investing heavily in AI**, though the United States and China seem
to be ahead.]{.underline} Yet even if the space-race analogy is not
precise, understanding AI as a competition can still be useful. Such
[frameworks help people and organizations understand the world around
them,]{.underline} from how to evaluate international threats to the
potential trajectory of
wars.[115](https://tnsr.org/2018/05/artificial-intelligence-international-competition-and-the-balance-of-power/#_ftn115) [If
likening competition in AI to the space race clarifies the stakes in
ways that generate incentives for bureaucratic action at the government
level, and raises corporate and public awareness, the analogy stands to
have utility for the United States.]{.underline}

#### The plan is key to prevent rising authoritarian AI from undermining democracy. 

**Imbrie et al. 20** \-\-- Senior Fellow at Georgetown\'s Center for
Security and Emerging Technology (CSET).

Andrew Imbrie, Ryan Fedasiuk, Catherine Aiken, Tarun Chhabra & Husanjot
Chahal. February 2020, \"Agile Alliances: How the United States and its
Allies Can Deliver a Democratic Way of AI," CSET,
https://cset.georgetown.edu/publication/agile-alliances/#:\~:text=How%20the%20United%20States%20and,a%20Democratic%20Way%20of%20AI&text=The%20United%20States%20must%20collaborate,wield%20AI%20for%20authoritarian%20ends.

[How can the United States collaborate with allies and partners to shape
the trajectory of artificial intelligence in ways that will promote
liberal democratic values and protect against efforts to wield AI for
authoritarian ends?]{.underline}

This question is both important and urgent. [It is important because
America's broad network of alliances and security partnerships is a
singular asset in defending liberal values. It is urgent because China,
Russia, and other authoritarian powers seek to achieve **strategic
advantage through AI** and the **export of censorship and surveillance
technologies** to countries across the globe]{.underline}.1 By [one
estimate, **more than 100 countries purchase** surveillance and
censorship gear **from China and Russia**, receive training on these
technologies, or simply imitate methods of surveillance and censorship
that are designed to control public opinion and stifle
dissent.2]{.underline}

[As the digital and physical environments become intertwined,
authoritarian practices in one domain will increasingly encroach upon
the other.]{.underline} At stake are the core values of liberty,
equality, and justice that underpin free and open societies. [All
democratic nations must work together to uphold basic principles, set
international rules of the road, and articulate a positive vision for
the future in the age of AI.]{.underline}

[Within the United States, and certainly within allied countries, debate
persists over the threat of digital authoritarianism and how to counter
it. While U.S. allies will likely vary in their strategic orientations
toward China and Russia, there is a growing consensus on the need to
**showcase a democratic way of AI**.]{.underline} [These debates will
take shape in a world of globalized markets for AI talent and integrated
supply chains. In this context, the right U.S. approach would leverage
its network of allies and partners to safeguard democracy and liberal
values]{.underline}. [An **alliance-centric strategy** provides a
**competitive advantage** over **any single country** that attempts to
develop a robust AI ecosystem on its own.]{.underline}

The United States and its allies should play to their strengths. [This
positive agenda begins with shaping the ecosystems for the development
and deployment of **safe and reliable AI**]{.underline}. [The most
effective approach would capitalize on advances in AI and machine
learning to foster sustainable and inclusive economic growth, improve
service delivery, and promote transparent and accountable
governance]{.underline}. The United States and its allies should pursue
a vision of the future in which AI enables strengthened data privacy
standards and respect for civil liberties; economic empowerment of
citizens within rules-based market economies; cleaner, safer, and more
efficient transportation; precision medical diagnosis; greater access to
education; and more effective disaster response.

#### Democracy solves war. 

**Tomz & Weeks 13** \-\-- Michael Tomz, professor of political science
at Stanford University, Ph.D. in Political Science, Jessica L. Weeks,
assistant professor of government, Ph.D., Political Science.

Michael & Jessica, 2013, "Public Opinion and the Democratic Peace,\"
*American Political Science Review*, February, Available Online at
http://web.stanford.edu/\~tomz/pubs/TomzWeeks-2013-02.pdf

[Our research supports the hypothesis that peace among democracies could
be due, at least in part, to public opinion]{.underline}. Countless
studies have shown that democratic leaders are responsive to public
opinion on matters of foreign policy; we demonstrate that the public
discriminates between democratic and autocratic targets. [Public opinion
may, therefore, foster a special zone of peace among
democracies.]{.underline}

[Moreover, our experimental approach allows us to conclude with
confidence that the effect of democracy is **genuinely causal.**
Democracy affects preferences independent of confounders such as
alliances, power, and trade]{.underline}. While our experiments confirm
the intuition of skeptics that [at least part of the peace among
democracies is due to shared interests, military power, and economic
ties, we nonetheless find clear evidence that democracy has an
independent effect on support for war.]{.underline}

Our experiments also reveal the mechanisms through which **[democracy
dampens support for war]{.underline}**. [The finding that democracies
view other democracies as less threatening, which in turn reduces
support for using force, accords with major works on the democratic
peace emphasizing threat perception]{.underline} (Russett 1993,
Risse-Kappen 1995). Understanding how and why democracies trust fellow
democracies, but not autocracies, is an important avenue for future
research (Kahl 1998, Williams 2001). [We also found that perceptions of
cost do not explain the public aversion to fighting democracies, and
that expectations about success explain only a small amount of the ^35^
effect]{.underline}.

Finally, we found that [morality plays an important role in the
democratic peace. The regime type of the target affects moral
calculations, which in turn changes preferences about the use of force.
Surprisingly few scholars have explored morality as a potential source
of peace.]{.underline} This should be a major topic for future research.

#### Authoritarian AI is an [existential threat]{.underline}

Di **Minardi 20**, Communications Officer at the Georgia Tech School of
Economics and School of History & Sociology, "The grim fate that could
be 'worse than extinction'," Georgia Tech, 10/15/2020,
https://www.bbc.com/future/article/20201014-totalitarian-world-in-chains-artificial-intelligence

[What would totalitarian governments]{.underline} of the past have
**[look]{.underline}**ed [like if]{.underline} they were **[never
defeated?]{.underline}** The Nazis operated with 20th Century technology
and it still took a world war to stop them. How much more powerful --
and permanent -- could the Nazis have been if they had beat the US to
the atomic bomb? [Controlling the]{.underline} **[most advanced
technology of the time]{.underline}** [could have]{.underline}
**[solidified Nazi power]{.underline}** [and]{.underline}
**[changed]{.underline}** the course of **[history]{.underline}**.

[When we think of existential risks, events like]{.underline} **[nuclear
war]{.underline}** [or]{.underline} **[asteroid]{.underline}**
impact**[s]{.underline}** often [come to mind. Yet there's one future
threat that is]{.underline} **[less well known]{.underline}** --
[and]{.underline} while it doesn't involve the extinction of our
species, it could be **[just as bad]{.underline}**.

It's called [the]{.underline} **["world in chains"]{.underline}**
[scenario, where]{.underline}, like the preceding thought experiment,
[a]{.underline} **[global totalitarian government]{.underline}**
[uses]{.underline} a **[novel tech]{.underline}**nology [to]{.underline}
**[lock]{.underline}** a majority of [the]{.underline}
**[world]{.underline}** [into]{.underline} **[perpetual
suffering]{.underline}**. If it sounds grim, you'd be right. But is it
likely? Researchers and philosophers are beginning to ponder how it
might come about -- and, more importantly, what we can do to avoid it.

**[Existential risks]{.underline}** (x-risks) are disastrous because
they **[lock humanity]{.underline}** [into a]{.underline} [**single
fate**, like]{.underline} the **[permanent collapse of
civilisation]{.underline}** [or]{.underline} the
**[extinction]{.underline}** of our species. These catastrophes can have
natural causes, like an asteroid impact or a supervolcano, or be
human-made from sources like nuclear war or climate change. [Allowing
one to happen would be "an abject]{.underline} [**end to the human
story**\" and would let down]{.underline} the **[hundreds of
generations]{.underline}** that came before us, says Haydn Belfield,
academic project manager at the Centre for the Study of Existential Risk
at the University of Cambridge.

Toby Ord, a senior research fellow at the Future of Humanity Institute
(FHI) at Oxford University, believes that the odds of an existential
catastrophe happening this century from natural causes are less than one
in 2,000, because humans have survived for 2,000 centuries without one.
However, when he adds the probability of human-made disasters, Ord
believes the chances increase to a startling one in six. He refers to
this century as "the precipice" because [the risk]{.underline} of losing
our future [has]{.underline} **[never been so high]{.underline}**.

Researchers at the Center on Long-Term Risk, a non-profit research
institute in London, have expanded upon x-risks with the
even-more-chilling prospect of suffering risks. These
**["s-risks"]{.underline}** [are]{.underline} defined as
**["suffering]{.underline}** [on an]{.underline} [**astronomical
scale**, vastly]{.underline} **[exceeding all suffering]{.underline}**
that has existed [**on Earth so far**." In these scenarios, life
**continues**]{.underline} for billions of people, [but]{.underline} the
[quality is]{.underline} **[so low]{.underline}** [and]{.underline} the
[outlook]{.underline} **[so bleak]{.underline}** [that]{.underline}
**[dying out]{.underline}** [would be]{.underline}
**[preferable]{.underline}**. In short: [a future with]{.underline}
**[negative value]{.underline}** [is]{.underline}
**[worse]{.underline}** [than]{.underline} one with **[no value at
all]{.underline}**.

This is where the "world in chains" scenario comes in. [If
a]{.underline} **[malevolent]{.underline}** group or
**[government]{.underline}** suddenly [gained]{.underline}
**[world-dominating power]{.underline}** through technology, [and there
was nothing to stand in its way, it could lead to]{.underline} an
**[extended]{.underline}** period of **[abject suffering and
subjugation]{.underline}**. A 2017 report on existential risks from the
Global Priorities Project, in conjunction with FHI and the Ministry for
Foreign Affairs of Finland, warned that ["a]{.underline} **[long
future]{.underline}** [under a]{.underline} **[particularly brutal
global totalitarian state]{.underline}** [could]{.underline} arguably
[be]{.underline} **[worse than complete extinction]{.underline}**".

Singleton hypothesis

Though global totalitarianism is still a niche topic of study,
researchers in the field of existential risk are increasingly turning
their attention to its most likely cause: artificial intelligence.

In his "singleton hypothesis", Nick Bostrom, director at Oxford's FHI,
has explained how [a]{.underline} global [government could form
with]{.underline} **[AI]{.underline}** or other powerful technologies --
[and]{.underline} why it [might be]{.underline} **[impossible to
overthrow]{.underline}**. He writes that a world with "a single
decision-making agency at the highest level" could occur
[if]{.underline} that [agency "obtains a]{.underline} **[decisive
lead]{.underline}** [through a]{.underline}
**[tech]{.underline}**nological **[breakthrough]{.underline}**
[in]{.underline} **[a]{.underline}**rtificial
**[i]{.underline}**ntelligence or molecular nanotechnology". Once in
charge, [it would control advances in]{.underline}
**[tech]{.underline}**nology [that]{.underline}
**[prevent]{.underline}** internal [**challenges**, like]{.underline}
**[surveillance]{.underline}** [or]{.underline}
**[auto]{.underline}**nomous [**weapons**, and, with this monopoly,
remain]{.underline} **[perpetually stable]{.underline}**.

[If the singleton is totalitarian, life would be **bleak**]{.underline}.
Even in the countries with the strictest regimes, news leaks in and out
from other countries and people can escape. A [global totalitarian rule
would]{.underline} **[eliminate]{.underline}** even these small **[seeds
of hope]{.underline}**. To be worse than extinction, "that would mean
[we feel]{.underline} [**absolutely no freedom**, no]{.underline}
[**privacy**, no]{.underline} **[hope]{.underline}** of escaping,
[no]{.underline} **[agency]{.underline}** [to]{.underline} **[control
our lives at all]{.underline}**\", says Tucker Davey, a writer at the
Future of Life Institute in Massachusetts, which focuses on existential
risk research.

"In totalitarian regimes of the past, \[there was\] so much paranoia and
psychological suffering because you just have no idea if you\'re going
to get killed for saying the wrong thing," he continues. "And now
imagine that [there\'s]{.underline} [**not even a question**, every
single thing you say]{.underline} **[is]{.underline}**
[being]{.underline} **[reported]{.underline}** [and]{.underline} being
**[analysed]{.underline}**."

"We may not yet have the technologies to do this," Ord said in a recent
interview, "but it looks like the kinds of technologies we're developing
make that easier and easier. And it seems plausible that this may become
possible at some time in the next 100 years."

AI and authoritarianism

Though life under a global totalitarian government is still an unlikely
and far-future scenario, **[AI]{.underline}** [is]{.underline}
**[already]{.underline}** [enabling authoritarianism in some countries
and strengthening infrastructure that could be **seized**]{.underline}
[by an]{.underline} **[opportunistic despot]{.underline}** in others.

"We\'ve seen sort of a reckoning with the shift from very utopian
visions of what technology might bring to much more sobering realities
that are, in some respects, already quite dystopian," says Elsa Kania,
an adjunct senior fellow at the Center for New American Security, a
bipartisan non-profit that develops national security and defence
policies.

[In the past, surveillance required **hundreds of thousands of
people**]{.underline} -- one in every 100 citizens in East Germany was
an informant -- [but]{.underline} **[now]{.underline}** [it can be done
by]{.underline} **[tech]{.underline}**nology. In the United States, the
National Security Agency (NSA) collected hundreds of millions of
American call and text records before they stopped domestic surveillance
in 2019, and there are an estimated four to six million CCTV cameras
across the United Kingdom. Eighteen of the 20 most surveilled cities in
the world are in China, but London is the third. The difference between
them lies less in the tech that the countries employ and more in how
they use it.

[What if the definition of what is illegal]{.underline} in the US and
the UK **[expanded]{.underline}** [to include criticising the government
or practising certain religions?]{.underline} [The infrastructure is
**already in place to enforce it**, and]{.underline}
**[AI]{.underline}** -- which the NSA has already begun experimenting
with -- [would enable]{.underline} agencies to **[search]{.underline}**
[through]{.underline} our **[data]{.underline}**
**[faster]{.underline}** [than]{.underline} **[ever
before]{.underline}**.

[In addition to enhancing]{.underline} [**surveillance**,
AI]{.underline} also [underpins the growth of online misinformation,
which is]{.underline} **[a]{.underline}**nother **[tool]{.underline}**
[of the]{.underline} [**authoritarian**. AI-powered **deep
fakes**]{.underline}, which [can spread]{.underline} fabricated
**[political messages]{.underline}**, and [algorithmic]{.underline}
**[micro-targeting]{.underline}** [on social media are making
**propaganda**]{.underline} more [**persuasive**. This
undermines]{.underline} our **[epistemic security]{.underline}** -- the
ability to determine what is true and act on it -- [that]{.underline}
**[democracies depend on]{.underline}**.

"Over the last few years, we\'ve seen the rise of filter bubbles and
people getting shunted by various algorithms into believing various
conspiracy theories, or even if they're not conspiracy theories, into
believing only parts of the truth," says Belfield. "You can imagine
things getting much worse, especially with deep fakes and things like
that, until it\'s increasingly harder for us to, as a society, decide
these are the facts of the matter, this is what we have to do about it,
and then take collective action."

Preemptive measures

The Malicious Use of Artificial Intelligence report, written by Belfield
and 25 authors from 14 institutions, forecasts that trends like these
will expand existing threats to our political security and introduce new
ones in the coming years. Still, Belfield says his work makes him
hopeful and that [**positive trends**, like more]{.underline}
**[democratic discussions]{.underline}** [around AI]{.underline} [and
actions by **policy-makers**]{.underline} (for example, the EU
considering pausing facial recognition in public places), keep him
optimistic that we [can]{.underline} **[avoid catastrophic
fates]{.underline}**.

Davey agrees. "[We need to]{.underline} **[decide now]{.underline}**
[what are]{.underline} **[acceptable]{.underline}** [and]{.underline}
**[unacceptable uses]{.underline}** of AI," he says. "And [we need to be
careful about letting it control]{.underline} so much of our
[infrastructure. If we\'re arming]{.underline} police [with]{.underline}
facial recognition and the federal government is collecting all of [our
data, that\'s a bad start."]{.underline}

[If you remain sceptical that AI could offer such power, consider the
world before **nuclear weapons**. Three years before the first nuclear
chain reaction]{.underline}, even [scientists trying to achieve it
believed it was unlikely. Humanity, too, was unprepared]{.underline} for
the nuclear breakthrough and teetered on the brink of "mutually assured
destruction" [before]{.underline} **[treaties]{.underline}**
[and]{.underline} **[agreements]{.underline}** **[guided]{.underline}**
the global proliferation of [the deadly weapons **without**]{.underline}
an **[existential catastrophe]{.underline}**.

[We can do the **same with AI**]{.underline}, [but only if we
combine]{.underline} the lessons of **[history]{.underline}**
[with]{.underline} the **[foresight]{.underline}** to prepare for this
powerful technology. [The world may not be able to stop totalitarian
regimes]{.underline} like the Nazis [rising again]{.underline} in the
future -- [but we **can**]{.underline} [avoid]{.underline} **[handing
them the tools to extend their power indefinitely]{.underline}**.

#### Failure of [emerging tech]{.underline} governance guarantees [extinction]{.underline}

Ash **Jain 19**, Senior fellow with the Scowcroft Center for Strategy
and Security, "Present at the Re-Creation: A Global Strategy for
Revitalizing, Adapting, and Defending a Rules-Based International
System," Strategic Studies Quarterly, October 2019,
<https://www.atlanticcouncil.org/wp-content/uploads/2019/10/Present-at-the-Recreation.pdf>

[The system must]{.underline} also [be adapted to deal with]{.underline}
new issues that were not envisioned when the existing order was
designed. Foremost among these issues is [emerging and disruptive
technology, including **[AI]{.mark}**, **additive
manufacturing**]{.underline} (or **[[3D
printing]{.underline}]{.mark}**), [quantum computing]{.underline},
[**genetic [engineering]{.mark}**, **robotics**, **directed
[energy]{.mark}**[, the]{.mark}]{.underline} Internet of things
([[**IOT**), **5G**, **space**, **cyber**]{.underline}]{.mark}, and many
others. Like other disruptive technologies before them, [these
innovations [promise]{.mark} great [benefits, but]{.mark} also
[carry]{.mark} **serious [downside risks]{.mark}**]{.underline}. For
example, AI is already resulting in massive efficiencies and cost
savings in the private sector. Routine tasks and other more complicated
jobs, such as radiology, are already being automated. In the future,
autonomous weapons systems may go to war against each other as human
soldiers remain out of harm's way.

Yet, [AI is]{.underline} also transforming economies and societies, and
[generating new security challenges]{.underline}. Automation will lead
to widespread unemployment. The final realization of driverless cars,
for example, will put out of work millions of taxi, Uber, and long-haul
truck drivers. Populist movements in the West have been driven by those
disaffected by globalization and technology, and mass unemployment
caused by automation will further grow those ranks and provide new fuel
to grievance politics. Moreover, some fear that [autonomous
weapons]{.underline} systems will become "killer robots" that select and
engage targets without human input, and [could [even]{.mark}tually
**turn on their creators, resulting in [human extinction]{.mark}**. The
other technologies on this lisgt similarly balance great potential
upside with great downside risk. [3D printing]{.mark}]{.underline}, for
example, can be used to "make anything anywhere," reducing costs for a
wide range of manufactured goods and encouraging a return of local
manufacturing industries.61 At the same time, advanced 3D printers
[[can]{.underline}]{.mark} also [[be used by]{.mark} revisionist and
[rogue states]{.mark} to print component parts for advanced weapons
systems or]{.underline} even [WMD]{.underline} programs, **[[spurring
arms races and]{.mark} weapons [prolif]{.mark}eration]{.underline}**.62
[[Genetic engineering can]{.underline}]{.mark} wipe out entire classes
of disease through improved medicine, or [[wipe out]{.mark} entire
[classes of people]{.mark} through genetically engineered superbugs.
[Directed-energy]{.mark} missile defenses [may]{.mark} defend against
incoming missile attacks, while]{.underline} also
**[[undermin]{.mark}ing [global]{.mark} strategic
[stability]{.mark}]{.underline}**.

Perhaps [the [greatest risk]{.mark} to global strategic stability from
new technology]{.underline}, however, [[comes from]{.mark} the
[risk]{.mark}]{.underline} that **[revisionist [autocracies]{.mark} may
[win the]{.mark} new [tech]{.mark} arms [race]{.mark}]{.underline}**.
Throughout history, states that have dominated the commanding heights of
technological progress have also dominated international relations. The
United States has been the world's innovation leader from Edison's light
bulb to nuclear weapons and the Internet. Accordingly, [stability has
been maintained in Europe and Asia]{.underline} for decades [because the
**U**]{.underline}nited **[S]{.underline}**tates [and its democratic
allies possessed a favorable economic and military balance of
power]{.underline} in those key regions. Many believe, however, that
China may now have the lead [[in]{.underline}]{.mark} the new
technologies of the twenty-first century, including [[AI]{.mark},
quantum, 5G, [**hypersonic missiles**, and others]{.mark}. If China
succeeds in mastering the technologies of the future [before the
democratic core]{.mark}]{.underline}, then [[this could lead to]{.mark}
a drastic and [rapid shift]{.mark} in the balance of power,
[upsetting]{.mark} global [strategic stability, and the]{.mark} call for
a democratic- led, **[rules-based system]{.mark}**]{.underline} outlined
in these pages.63

[[The **U**]{.underline}]{.mark}nited **[[S]{.underline}]{.mark}**tates
[[and]{.mark} its [democratic allies need to]{.mark} work with other
major powers to develop a framework for **[harness]{.mark}**ing emerging
**[tech]{.mark}**nology [in a way that
**maximizes**]{.mark}]{.underline} its [**[upside]{.mark} potential**,
[while **mitigating**]{.mark}]{.underline} against its **[[downside
risks]{.underline}]{.mark}**, and also [contributing to the maintenance
of global stability]{.underline}. The existing international order
contains a wide range of agreements for harnessing the technologies of
the twentieth century, but they need to be updated for the twenty-first
century. The world needs an entire new set of arms-control,
nonproliferation, export-control, and other agreements to exploit new
technology while mitigating downside risk. These agreements should seek
to maintain global strategic stability among the major powers, and
prevent the proliferation of dangerous weapons systems to hostile and
revisionist states.

### 

### 2AC\-\--Say Yes 

#### Allies want AI defense cooperation\-\--they'll sign on to a US lead initiative. 

**Kahn & Horowitz 21** \-\-- Research and Senior Fellows at the Council
on Foreign Relations.

Lauren and Michael, 2021, The Washington Quarterly 44:4 "Leading in
Artificial Intelligence through Confidence Building Measures"
[https://doi.org/10.1080/0163660X.2021.2018794](https://doi.org/10.1080/0163660X.2021.2018794%20Acc%206/6/22)

[An informal multilateral agreement could be proposed and opened for
signature to all nations. **If the United States leads**, American
**allies and partners would be likely to sign on**, both due to the
impact of American leadership in shaping attitudes and the likely
perception that following US-led principles would **facilitate defense
cooperation** in this area]{.underline}. [One might argue that US
leadership in multilateral AI standards could create risks for the
United States if it involves commitments that prevent the US deployment
and use of militarily important AI-enabled systems. These risks,
however, are minimal]{.underline}. [The standards the United States
would promote involve commitments to international humanitarian law and
responsible behavior that the United States already follows when it
comes to the development and use of military systems. Thus, it would not
require changes in US behavior that might slow down responsible military
AI adoption]{.underline}.

### 2AC\-\--Interoperability Key

#### Intra NATO AI gap decks interoperability\-\--cooperation through NATO is key

Matej **Tonin 19**, current Slovenian Minister of Defense, was an active
member of the NATO PA from 2012 to 2020. He served as rapporteur and
Chairperson of the Assembly\'s Sub-Committee on Technology Trends and
Security and as Deputy Head of the Slovenian delegation to the NATO PA.
\"ARTIFICIAL INTELLIGENCE: IMPLICATIONS FOR NATO'S ARMED FORCES\" Report
from the Sub-Committee on Technology Trends and Security. October 13.
<https://www.nato-pa.int/download-file?filename=/sites/default/files/2019-10/REPORT%20149%20STCTTS%2019%20E%20rev.%201%20fin-%20ARTIFICIAL%20INTELLIGENCE.pdf>
//pipk

63\. Second, [the defence technology gap between Allies must remain
small enough to be bridged by interoperability]{.underline}. [The large
diversity of Allies is ultimately a primary source of NATO's strength,
but it also means that large differences exist in defence
capabilities]{.underline}. [There is a danger that the significant
investment in AI in leading Allied nations could lead to substantial
interoperability problems and a loss of NATO's overall military
effectiveness in the future]{.underline}. [However]{.underline}, the
good news is that [AI efforts do not need to be capital
intensive]{.underline}, as the Committee witnessed during its
fact-finding visit to Singapore in May 2019. [Small]{.underline}- and
medium-sized [Allies]{.underline} with smart scientists and engineers
[can play an outsized role in AI development]{.underline} and adoption
if they so choose. [This could]{.underline} indeed [be a very effective
contribution to Allied burden sharing from the smaller Allied
nations]{.underline}. **[To increase interoperability, cooperation
through NATO' structures has a large role to play.]{.underline}**
Interoperability should be at the heart of AI efforts carried out by the
STO, ACT, the NCI Agency, NIAG, and others. Allies leading in the S&T
sector should encourage open architecture standards and regulations for
technology sharing and transfer among Allies in order to narrow the
technology gap, in line with all national obligations and the sensitive
nature of technologies

64\. [Allied armed forces alone will not be able to solve the
AI-specific challenges laid out in this report, including the ethical
and legal questions]{.underline}. [This will need a much broader push
across the entire AI ecosystem.]{.underline} However, governments,
[NATO]{.underline}, and the EU can and [must play a critical role in
overcoming the]{.underline} investment, innovation, and workforce
[challenges of adopting AI.]{.underline} Just as national governments
across the Alliance are rising to the challenge of AI, so should their
armed forces. [They should move beyond scanning the horizon
and]{.underline}, instead, [invest in real]{.underline} research,
[experimentation]{.underline}, development, and adoption efforts. It
should be underlined that all dual-use and military AI efforts should,
however, tackle all ethical, legal, and social questions right from the
beginning, including privacy considerations and the definition of
appropriate human involvement in decisions about the use of force.
Allies should consider examining whether an ethics code of conduct could
put the adoption of AI in the armed forces on a more stable foundation.
At a strategic level, Allies must also address the geopolitical
challenges, including the ones arising from Chinese and Russian
investments in military AI systems. As this report has shown, Russia and
China see AI as critical to future military power and invest heavily
into AI-enabled military systems. For its part, the NATO PA Science and
Technology Committee will continue to monitor AI developments in the
defence sector through fact-finding visits and expert testimony.

## DAs

### 2AC\-\--AT: Military Innovation DA

#### No link\-\--standards [enable]{.underline}, NOT [hurt]{.underline}, military dominance 

Zoe **Stanley-Lockman &** Lena **Trabucco 22**, Stanley-Lockman is an
Associate Research Fellow in the Military Transformations Programme at
the Institute of Defence and Strategic Studies at the S. Rajaratnam
School of International Studies in Singapore; Lena Trabucco is a dual
degree candidate pursuing a PhD in political science at Northwestern
University and a PhD in Law at iCourts Center of Excellence in
International Courts at the University of Copenhagen, "NATO's Role in
Responsible AI Governance in Military Affairs," The Oxford Handbook of
AI Governance, edited by Justin Bullock et al., Oxford University Press,
03/18/2022, DOI.org (Crossref),
doi:10.1093/oxfordhb/9780197579329.013.69

Additionally, **[infusing]{.underline}** [AI development
with]{.underline} certain **[ethical principles and
values]{.underline}** [can have]{.underline} **[operational
advantages]{.underline}** and benefits, and [NATO can]{.underline}, in
particular, **[promote]{.underline}** the [ethical principles
as]{.underline} [**operational standards for the Allies**. A common
critique within the ethics debate is that approaching new technology
with an ethical or democratic values-driven perspective translates into
comparative **military disadvantage**]{.underline}. Essentially, if your
adversary develops technology without the constraints of ethical
principles then there will be diminished effectiveness on the
battlefield.56 [We find this critique **unfounded**]{.underline} because
[it]{.underline} **[assumes]{.underline}** [there is a]{.underline}
false **[trade-off]{.underline}** [between ethics and effectiveness;
instead,]{.underline} we argue [ethical foundations are]{.underline}
**[built]{.underline}** [into the]{.underline} **[architecture of modern
warfare]{.underline}**.57 As such, [ethics is a]{.underline}
[**background condition for battlefield effectiveness**, which
is]{.underline} **[already infused in military
decision-making]{.underline}** [and helping]{.underline} to
**[guide]{.underline}** the **[boundaries]{.underline}**
[of]{.underline} **[i]{.underline}**nternational
**[h]{.underline}**umanitarian **[l]{.underline}**aw. [As such, ethical
guidelines do not]{.underline} have to **[detract]{.underline}** [from a
military's capacity or competency to devise means and methods of warfare
that will serve their national or coalition interest]{.underline}.58 [If
anything, a first-mover advantage can]{.underline}
**[incentivize]{.underline}** [an]{.underline} **[ethical]{.underline}**
and **[values-driven AI]{.underline}** [to establish the]{.underline}
**[threshold of technological standards globally.]{.underline}**59

#### Turn: Standardization [enhances]{.underline} leadership\-\--doesn't degrade it. 

Andrew **Imbrie et al. 20**, Center for Security and Emerging
Technology, "Agile Alliances," CSET, 2020,
<https://cset.georgetown.edu/wp-content/uploads/CSET-Report-Agile-Alliances-1.pdf>

First, [the]{.underline} **[U]{.underline}**nited
**[S]{.underline}**tates [and its allies face a]{.underline}
**[trade-off]{.underline}** [between]{.underline}
**[capability]{.underline}** [and]{.underline}
**[dependency]{.underline}**.10 **[Showcasing]{.underline}** [a
democratic way of AI will require the]{.underline}
**[U]{.underline}**nited **[S]{.underline}**tates [and]{.underline} its
[allies to]{.underline} **[pool resources]{.underline}**, **[coordinate
policies]{.underline}**, [and]{.underline} **[share best
practices]{.underline}** and information. [Leveraging]{.underline} the
capabilities of its [allies]{.underline} and partners [will]{.underline}
**[amplify U.S. power and influence]{.underline}**, but will also create
inefficiencies and require compromise. While the United States can
manage these challenges, it cannot eliminate them entirely---nor should
it. [As long as AI-related supply chains are global and AI talent both
mobile and globally distributed, innovation in AI]{.underline}
**[requires]{.underline}** [international collaboration]{.underline}.11
[To]{.underline} [excel]{.underline} in this new context, [America will
need to]{.underline} **[embrace its role]{.underline}** [as]{.underline}
a "**[systems integrator]{.underline}**" among like-minded allies and
partners.12 [Embedding cooperation in dense, decentralized networks
plays to the]{.underline} **[U]{.underline}**nited
**[S]{.underline}**tates' **[strengths]{.underline}** [as a]{.underline}
**[democratic power]{.underline}** [that favors]{.underline} **[market
approaches]{.underline}** [to technological
**coop**]{.underline}eration. By [combining top-down vision with
dynamic, bottom-up innovation and entrepreneurship, the]{.underline}
**[U]{.underline}**nited **[S]{.underline}**tates [and its allies can
foster a]{.underline} **[competitive ecosystem that enables the best
ideas to flourish]{.underline}**.

#### There's no AI [race]{.underline}\-\--first mover advantages don't exist, and US lead in AI [leverage]{.underline} is baked in 

Lauren A. **Khan 21**, research fellow at the Council on Foreign
Relations, 10/28/21, "US Leadership in Artificial Intelligence Is Still
Possible,"
https://www.cfr.org/blog/us-leadership-artificial-intelligence-still-possible

Much of the [[debate over]{.mark} military [AI leadership]{.mark} and
U.S. technological competition [with China **hinges on**]{.mark} **the
[assumption]{.mark}**]{.underline} that **[[there is a]{.mark}
significant [first-mover advantage]{.mark}]{.underline}** when it comes
to these technologies, [meaning the first to develop them could
reap]{.underline} substantial **[economic and military
effects]{.underline}**. However, [[fear of]{.mark} pronounced AI
[first-mover advantages]{.mark}]{.underline} instead [[reflects]{.mark}
how AI is prone to "**[overhyping]{.mark}**" where incredibly high
[expectations]{.mark} of capabilities **[surpass]{.mark}** the
**[reality]{.mark}** of what is possible. [Overhyping]{.mark} can
[obscure]{.mark} real [progress and generate]{.mark} an **[inappropriate
perception of an]{.mark} ​​​​​​AI [arms race]{.mark}** that
"misrepresents]{.underline} the [competition]{.underline} going on among
countries." **[[Any]{.underline}]{.mark}** possible [[first-mover
advantage]{.mark} for AI [would be
**unsustainable**]{.mark}]{.underline}.

[AI is a general-purpose, enabling technology]{.underline} not
dissimilar to electricity. Moreover, [the private sector drives its
development]{.underline}, rather than the defense sector. While
technologies that are singularly applicable to military contexts diffuse
more slowly, those that are multi-use like AI have the added prodding of
market incentives to speed up their spread.

AI is Open Source and Available to All

Even when compared to other private sector-driven technologies, AI could
spread even faster, since most [AI research and development is open
source with an unprecedented exchange of code and talent between tech
companies and academia]{.underline}. This is a relatively new phenomenon
in tech - "there is no business need to make closed infrastructure
solutions, because within a few months everything will be totally
different," which has led to actors releasing even the most
cutting-edge, proprietary AI. In 2015, Google opened up its sourcing
framework TensorFlow. Facebook followed suit just a few years later with
Caffe2 and PyTorch. OpenAI published GPT-2 in 2019, a large language
processing model. The culture of keeping this work open-source and
collaborative is widespread. A survey of AI and machine learning
researchers showed that a majority believed that both a high-level and
detailed description of methods, the results, and the actual algorithms
should always be published, absent compelling risks from openness.

How to Become a World Leader in AI, if Everyone has the Models

What does it mean to be competitive, if not a leader, in AI if AI
techniques themselves will spread quickly, leading to a similar nature
and quality level across the board? The [[competitive advantage]{.mark}
for countries will [lie in]{.mark} a state's [ability to]{.mark}
successfully [**leverage** AI]{.mark}]{.underline}. Renewing America
through military AI leadership will not succeed if focused purely on
acquiring a technical edge, as opposed to organizational capacity and
integration.

This idea isn't new---the 2018 National Defense Strategy said that when
it comes to adopting and deploying emerging technologies like AI,
"[Success no longer goes to the country that develops a new technology
first, but rather to the one that better integrates it and adapts its
way of fighting]{.underline}." AI integration leadership will not only
improve operations in DoD and beyond in the US government, but it will
also enhance US economic competitiveness by setting a model and serving
as a catalyst for broader innovation. But success will require both a
significant mindset shift within DoD, as well as an elevation of the
value of data.

Algorithms are continuously evolving, being tested against new data and
updated and verified accordingly---to stay competitive in the 21st
century DoD must operate and move in a similar way. In parallel with how
tech companies are developing new algorithms---whatever state manages to
adopt the latest open-source model, train and benchmark against their
own data and models, and discard the losing model while implementing the
more efficient one, will be the one to "win" military AI leadership.

[Successful [military AI leadership]{.mark} will]{.underline} also
**[[require]{.mark} U.S. [data leadership]{.mark}]{.underline}**. As
Andrew Ng explains, "[data is food for AI]{.underline}," and with models
and algorithms being open source---data will become the differentiating
factor. [Labeling, standardization, and sharing of data across
DoD]{.underline}, therefore, [is a critical precursor to AI integration
and adoption]{.underline}. As it currently stands, **[[DoD has]{.mark}
access to [large, diverse streams of
data]{.mark}]{.underline}**---however much of it is unlabeled,
uncleaned, unconsolidated, and further complicated by security
restrictions. When it comes to creating algorithms, it has been
estimated that up to 80% of the time spent is allocated to processing
the data needed for training them. Google released a paper in 2021 that
discussed how data cascades---"compounding events causing negative,
downstream effects from data issues" are pervasive. Moreover, [[DoD
already has]{.mark} a competitive [advantage]{.mark} when it comes to
[processing data]{.mark}---an existing cadre of data scientists,
analysts, and more with particular knowledge of "how to assemble
high-quality data in their domain]{.underline}," it just needs to use
them.

[The **[U]{.mark}**]{.underline}nited **[[S]{.underline}]{.mark}**tates
[[has]{.mark} the [capacity to become the **world leader**]{.mark} **in
AI**]{.underline}---but it needs to take the necessary steps to
revitalize its ability to adopt innovations in order to do so.

#### AI's not key to heg. 

Andrea **Gilli 19**, Senior Researcher in the Research Division, NDC,
"Preparing for 'NATO-mation': the Atlantic Alliance toward the age of
artificial intelligence", NDC Policy Brief, No. 4, pg. 3, Feb. 2019,
http://nato-70.upt.pt/wp-content/uploads/2019/04/Preparing_NATO_mation.pdf

Military transformation and emerging technologies

[A second]{.underline}, and related, [issue is the risk
that]{.underline}, in the age of intelligent machines, [AI]{.underline},
ML and BD [may easily enable any actor to **catch up**, or even
**outpace**, its adversaries in military terms]{.underline}. Here too,
skepticism is warranted. First of all, these two concerns logically
contradict each other. If we are witnessing a military transformation
based on dual-use, general-purpose technologies such as AI, ML and BD
that can be easily exploited in battle, then no actor can achieve a
significantly enduring military advantage -- at the tactical,
operational or strategic level -- as competitors can quickly catch up or
deploy effective counter-systems.8

Next, [[military power is **more than hardware**]{.underline}]{.mark}.
[[**Tactical fluency** and]{.mark} **operational [competence]{.mark}**
[are]{.mark} in fact **[extremely important]{.mark}** for victory on the
battlefield]{.underline} -- along with other variables. [There is **no
reason to believe** that this will change **anytime soon**]{.underline},
as warfare, war and by extension strategy are inherently adversarial:
winners succeed because they defeat their adversaries -- i.e., they
neutralize enemy counter-measures, tactics, systems and innovations.
[Possessing capable [**hardware** is]{.mark} thus,]{.underline} per se,
[[**not sufficient** and]{.mark}, [at times, **not**]{.mark} **even
[necessary for winning]{.mark}**]{.underline}. [Commercial technologies
offer great potential but are easily vulnerable to even **basic
counter-measures**]{.underline} as they are not designed for combat.

By the same token, [[emerging tech]{.mark}nologies]{.underline} --
whether developed for commercial or military applications -- [[face
**performance trade-offs**]{.mark} that **constrain** their immediate
military utility]{.underline}. The French Marine Nationale's mid-19th
century bid to offset British naval superiority is telling: [the steam
engine granted independence from wind but suffered from **limited
endurance**]{.underline}; iron hulls could not keep afloat when hit;
and, explosive shells had shorter ranges than solid shots. [When mature,
these technologies **ultimately** transformed naval warfare, but it took
**almost a century for this to happen**]{.underline}.9

[There is no reason to believe that [with
AI]{.mark}]{.underline}[,]{.mark} ML and BD [things will be
**different**]{.underline}. When it comes to software, in fact, [even
subtle and apparently [minor details lead to **catastrophic
failure**]{.mark}]{.underline}[:]{.mark} [[because of]{.mark} simple
[mistakes in **data**]{.mark} **gathering** [or **processing**]{.mark}
such as automatic path control, military platforms may end up exceeding
their maximum depth or altitude ceilings and thus expose themselves
to]{.underline} almost certain mission [failure]{.underline}. Software
already represents the primary source of procurement delays and cost
overruns. [As software becomes **more central** in weapon systems, the
problems it creates can **only exponentially increase**]{.underline}.
Additionally, through generative adversarial networks (GNAs), actors can
increasingly feed compromised data into enemy systems to negatively
affect tactical performance or operational success. Competent armed
forces will thus deploy intelligent machines only in so far as the
risks, problems and constraints they face are, slowly and progressively,
addressed.

This brings us to a final consideration. In order to address these very
risks, problems and constraints, investments in a broad range of fields
are also needed so as to counterbalance investments by enemies and
adversaries. [[Improving]{.mark} all the underlying technologies related
to [A]{.mark}]{.underline}[I]{.mark}, ML and BD, [learning about their
potential, integrating them into existing military platforms and
exploiting them for]{.underline} maximum strategic, operational or
tactical [effectiveness [require **time**, **human capital**,]{.mark}
**institutional backing**, **technological [competence]{.mark}** [and
**financial resources**]{.mark}]{.underline}. [In other words, [the
idea]{.mark} that [countries can]{.mark} **quickly [exploit]{.mark} the
[tech]{.mark}nologies** of the fourth Industrial Revolution [for]{.mark}
**building [military power]{.mark}** [seems
**exaggerated**]{.mark}]{.underline}.10

### 

### 1AR -- No Link

#### No link -- regulations won't undermine innovation -- empirics. 

**Heikkilä 21** - Politico's AI Correspondent in London

\[Melissa, Politico March 31 "AI Decoded: NATO on AI warfare --- AI
treaty consultation --- Unions call for more AI protections"
https://www.politico.eu/newsletter/ai-decoded/politico-ai-decoded-nato-on-ai-warfare-ai-treaty-consultation-unions-call-for-more-ai-protections/
Acc 4/9/22 TA\]

AI LAWS WHY [REGULATION WON'T KILL INNOVATION]{.underline}: The Council
of Europe, the Strasbourg-based human rights organization, is hard at
work on a draft proposal on artificial intelligence. If ratified, the
treaty could become national law in the group's 47 member countries. AI:
Decoded rang up Gregor Strojin, the chair of the group's committee,
called CAHAI, that's drawing up the rules to hear the latest
developments. The goal: [CAHAI is working on an AI treaty with
additional rules for specific sectors,]{.underline} such as social
affairs and justice systems, and problems, like the discrimination of
minorities. The plan is to have a draft ready by the end of they year,
after which the Committee of Ministers --- national representatives to
the Council of Europe --- will debate it. "In the past, there have been
examples of treaties that were adopted in a matter of months. But
sometimes it can take years. Sometimes it can be never. But I think
we're making a pretty strong point that in this case, delaying it could
lead to irreparable damage," [Strojin said. "We are seeing increasing
use of technologies that's being imported from other parts of the world,
without any risk assessment, without any impact assessment in a way
that's actually dumping the technology on certain countries," he
continued.]{.underline} Been there done that: [Strojin also pushed back
against industry jeremiads that regulation would "hamper innovation." He
said that AI regulators can actually learn a lot from past negotiations
around pharmaceuticals and bioethics as an example of how regulation can
help innovation.]{.underline} In 1964, the Council of Europe adopted the
European Pharmacopoeia, which is the official standard and scientific
basis for the quality control of pharmaceuticals. ["Before that medical
products and also services were like snake oil. There was no common
assessment of]{.underline} what are the ingredients \[or\] [what are the
side effects of drugs," Strojin]{.underline} [said]{.underline}. (Sound
familiar?) ["I don't think we have a problem with the lack of innovation
in the pharmaceutical sector at this point," Strojin said.]{.underline}

### 1AR -- No Race 

#### The AI "arms race" isn't a race\-\--China can't win, their only advantage is sheer data and that doesn't matter

Carl Benedikt **Frey &** Michael **Osborne 20**, Carl Benedikt Frey is
Oxford Martin Citi Fellow and Future of Work Director at the Oxford
Martin School at Oxford University and the author of The Technology
Trap: Capital, Labor, and Power in the Age of Automation. Michael
Osborne is Professor of Machine Learning at the University of Oxford, a
Fellow at the Oxford Martin School, and Co-Founder of Mind Foundry.,
6-19-2020, \"China Won't Win the Race for AI Dominance,\" Foreign
Affairs,
<https://www.foreignaffairs.com/articles/united-states/2020-06-19/china-wont-win-race-ai-dominance>

DATA ALONE ARE NOT ENOUGH

[[China]{.mark} made international headlines by effectively leveraging
its surveillance technology for contact tracing in response to
COVID-19,]{.underline} the disease caused by the novel coronavirus. And
yet [the country's alleged [data advantage is hugely
overblown]{.mark}.]{.underline} [One reason is that data are highly
domain specific and don't often solve more than the problem for which
they were gathered]{.underline}. **[China's [disregard for privacy
enables]{.mark} it to [snoop on its citizens, but not much
else]{.mark}]{.underline}**. And [an abundance of [surveillance data
doesn't give China an advantage in applying a]{.mark}rtificial
[i]{.mark}ntelligence]{.underline} to such ends as drug discovery or
self-driving cars, for example.

[[The puzzle of a]{.mark}rtificial [i]{.mark}ntelligence [lies not
in]{.mark} the [quantity of data]{.mark} to which its algorithms have
access [but]{.mark} in the [efficiency]{.mark} with which it learns from
that data. Even]{.underline} with huge amounts of data, artificial
intelligence systems are easily tricked into making errors. The Google
researcher Christian Szegedy and his collaborators proved this point by
fooling an algorithm that had once confidently and correctly classified
images of dogs and school buses. The researchers manipulated the pixels
of images in a manner that would have been completely undetectable to
the human eye---but that led the algorithm to classify both dogs and
school buses as ostriches. [[A]{.mark}rtificial [i]{.mark}ntelligence
algorithms can often identify objects, but they [lack]{.mark} any
[conceptual understanding of]{.mark} the [relationships]{.mark} between
those objects or of their respective properties.]{.underline} As the
deep learning researcher Yoshua Bengio has warned, "We can't
realistically label everything in the world and meticulously explain
every last detail to the computer."

Many think of China as "the Saudi Arabia of data." But if data are the
new oil, they might just be China's natural resource curse. For example,
in the early twentieth century, electric cars looked more promising than
gasoline-powered cars. Huge oil discoveries, among other things, tipped
the balance in favor of the internal combustion engine. A century later,
we are trying to get back into electric cars. The current focus on
data-thirsty AI applications could lead to a similar lock-in into the
wrong sort of AI.

We have seen this movie before. In the 1980s, the grand promises and
overwhelming focus on symbolic AI prompted immense funding and media
hype. This meant that funding for "deep learning" dried up. But deep
learning has its own problems and has recently caused companies to focus
on easy AI problems, such as classifying cats and dogs, where data are
abundant. This approach alone is likely to run into diminishing returns
that could even prompt another AI winter.

Data [[efficiency is the holy grail]{.mark} of further progress in
artificial intelligence]{.underline}. [The reason most people [associate
the steam engine with]{.mark} James [Watt]{.mark} and not Thomas
Newcomen (who developed a coal-powered steam engine decades earlier)
[is]{.mark} that [Watt's]{.mark} separate [condenser]{.mark} first
[made]{.mark} the [tech]{.mark}nology energy
[efficient]{.mark}.]{.underline} [[A]{.mark}rtificial
[i]{.mark}ntelligence [is]{.mark} still [waiting for its]{.mark}
separate [condenser mom]{.mark}ent]{.underline}. Indeed, to learn enough
to win a game of Go against Lee Sedol, a champion of the strategic board
game, DeepMind's AlphaGo software first had to play many millions of
games against itself. It learned to play far slower than any human.
[Humans are incredibly data efficient; recent breakthroughs in
artificial intelligence are much less so. [Whether the U]{.mark}nited
[S]{.mark}tates [or China will lead]{.mark} the world in artificial
intelligence [depends far]{.mark} [less on who controls]{.mark} the most
[data]{.mark} than on who will be the first to innovate past this
impasse.]{.underline}

#### No Chinese AI arms race\-\--it's not zero sum\-\--significant academic coop and opportunities for growth

Kai-Fu **Lee 19**, Transcript of Interview by Stephen Orlins, President
of the National Committee on U.S.-China Relations, with Kai-Fu Lee,
Ph.D. in Computer Science from Carnegie Mellon, Fellow at the Institute
of Electrical and Electronics Engineers, "Kai-Fu Lee on the Future of AI
in the United States and China", 2/6/2019,
https://www.ncuscr.org/media/podcast/uschinainsights/kai-fu-lee-future-ai-united-states-china

Kai-Fu Lee: Well, I\'ve been an AI researcher for a long time, and I
have worked in the U.S. and China. And I\'m seeing a lot of excitement
and a lot of challenges ahead of us. I\'ve done AI as a researcher, a
product executive, and an investor now. And I think AI is taking off
faster than we think. [[China is becoming an AI superpower.]{.mark} With
the U.S. and China, there is a lot of **complementarity**]{.underline},
and [we face a lot of similar challenges]{.underline}. And [there are a
lot of approaches that could be **shared**]{.underline}. So I thought I
had that unique perspective to write a book that describes that.

Orlins: Is this something which the U.S. and China are going to
cooperate on in the future, or compete on?

Lee: I know [[everyone thinks about this as
competition]{.underline}]{.mark}, but **[[it]{.mark} really
[isn\'t.]{.mark}]{.underline}** [[The U.S. is stronger in research;
China is stronger in implementation]{.underline}]{.mark}. So they could
learn, at least from each other. And also, I think China is building
Chinese products for Chinese people, [[Chinese VCs fund]{.mark}ing
[Chinese companies]{.mark} doing Chinese products [for Chinese
people]{.mark}]{.underline}[, [American VCs
fund]{.underline}]{.mark}[ing [American companies]{.mark} building
products for the developed countries. [The two don\'t collide]{.mark},
so it\'s not a zero-sum game]{.underline}, not as though the growth of
one side would shrink the other. So given they\'re in parallel,
theoretically, this should be a wonderful collaborative opportunity.

Orlins: You focus a lot on, kind of Alipay or WeChat Pay. How does that
change the landscape for AI in China versus the United States, where we
still are heavily reliant on a credit card system that seems quite old
and outdated when you\'re in China?

Lee: It\'s a very unique opportunity for China to leapfrog. The U.S. had
the world\'s most leading transaction tool, which was the credit card,
but it became outdated. It charges too much, it\'s inconvenient, it\'s
only customer to merchant. In China, with WeChat and Alipay, anybody can
pay anybody. We can do micro payments and there are no fees, almost no
fees, so the 2% extra charge is almost like a tax on the American
economy charged by the credit cards. But with respect to AI, now
everybody, including WeChat and Alibaba, but also, if you build an app,
you know who your customers are, and what they paid and why. And if
you\'re a retail shop and people scanned you, you know who pays you and
why. There are even beggars in the street holding up a sign, \"Scan me
and give me money,\" and they know who paid them and why. So I think
this is creating a huge amount of data that will help AI.

Orlins: How will it be used?

Lee: Well, each merchant will get data with respect to his or her
business, and it may or may not include the customers\' name. You may
have to go to extra steps to solicit user consent, but in the end, if
you\'re able to get user consent, you will know who came to your store,
what they bought, on which day, and from which, you can make better
sales projections, product placements\...

Orlins: But doesn\'t a credit card receipt do the same?

Lee: A credit card receipt does not give the same organized information.
Nor does it give a channel to communicate. So if you came to my store
and bought this book, and I got you to sign up for my WeChat accounts, I
can send messages to you. I can say, \"We have a sale today.\"

Orlins: So it\'s the merchant, as opposed to the credit card company
that has that data?

Lee: That\'s right. The merchant has it. Obviously, Tencent has it, and
both can use it to datamine and make better decisions that help the
companies make more money.

Orlins: Are Tencent and Ali going to be the focus of AI development in
the future in China?

Lee: They are the two strongest right now. In the future, I think there
are a lot of opportunities, because there are many other spaces that are
not contiguous to this space, the payment space. Tencent is very strong
with social gaming and now, payment. Alibaba is very strong with
commerce and now, payment. But there will be health care, medical, there
will be manufacturing, there will be transportation. So I think there
are many other areas where new companies still could emerge with the
data and the AI and the monetization.

Orlins: Who will be the leaders in the U.S? What companies will lead
that in the U.S?

Lee: Well, Google currently leads in the diversity of their products,
the amount of data they collect, and also the AI expertise they have
accumulated. After that, there is Facebook, Microsoft, Amazon. So it\'s
a similar situation, except that in China, I think the data collection
goes a little deeper, because the Chinese people use the phone more
aggressively for more services.

Orlins: How can we use AI to improve the U.S.-China relationship?

Lee: Well[, [the academics]{.mark} in the U.S. and China [are]{.mark}
wonderful [friends. If you go to]{.mark} NIPS (conference on Neural
information Processing Systems) or one of the [AI conferences, you will
see]{.mark} that [the connections are good]{.mark}]{.underline}. [The
sharing is very open,]{.underline} so that could be an inspiration to
the parts that may not be focused on it.

And I think the National Committee could publish more information that
the U.S. and China are not competing in AI in a commercial sense. And
also, that they each have something to offer. And that\'s why I wrote
this book: to let people know that, while the media, and [some
[politicians]{.mark}]{.underline}[, [have focused
on]{.underline}]{.mark} [U.S.-China competition--- even using [terms
like \"cold war]{.mark}\" and describing this as a zero-sum game,
[but,]{.mark} in fact[, both countries are doing great. There\'s a lot
of sharing, there\'s very little competition]{.mark} academically or
commercially]{.underline}. So I don\'t think we should continue to
represent this as a war.

#### China tech fears are unfounded\-\--they can't catch up. 

Fred **Hu 18,** economist and chairman of Primavera Capital Group,
8-22-2018, \"The U.S. Is Overly Paranoid About China'S Tech Rise,\"
Washington Post,
https://www.washingtonpost.com/news/theworldpost/wp/2018/08/22/us-china-3/?utm_term=.ed8dd0d27f82

[But much of the [fear over China's **tech**]{.mark}nological [rise is
unfounded]{.mark}. Fundamentally, [China]{.mark} is [like most emerging
economies]{.mark} around the world: [still trying]{.mark} hard [to close
the enormous tech]{.mark}nological [gap with]{.mark} advanced economies
led by [America]{.mark}.]{.underline} China has undoubtedly made more
progress than many of its developing peers in that race. Its tech
industries have grown at a faster pace and achieved a global scale
beyond those of most developing countries. In a broad range of
manufacturing sectors --- notably consumer electronics, steel, ship
building, high-speed rail systems and solar panels --- China has
established itself as the world's leading producer. In areas such as
consumer Internet and financial technology, it has arguably overtaken
even the United States and now leads the rest of the world. Yet China
hawks such as Robert Lighthizer and Peter Navarro charge that whatever
progress China has made on the tech front is due to the country's
blatant theft of U.S. technology. Considering the enormous investments
China has made in science and technology over recent decades, such
claims do not hold water. China has devoted vast resources to research
and development --- \$409 billion in 2015 (21 percent of the global
total), according to the U.S. National Science Foundation. China's
investment in research and development grew over 20 percent annually
between 2000 and 2010 and almost 14 percent from 2010-2015. U.S.
research and development hovered around 4 percent over the same period.
For a country with an average per capita income a mere one-sixth of
America's, China's research and development investments reflect a real
and sustained national commitment. At the same time, China has vastly
expanded and improved STEM education and has one of the largest pools of
STEM graduates in the world. The devotion of significant resources to
research and development and human capital has in turn enabled China to
reap some of the early fruits of innovation. China now tops the world in
new patent filings. As the first country to receive more than 1 million
patent applications in a single year --- a record the World Intellectual
Property Organization said reflected "extraordinary" levels of
innovation --- China accounts for almost 40 percent of the global total
and more than that of the United States, Japan and South Korea combined.
China has also significantly boosted venture capital investment, which
supports the commercialization of emerging technologies. While the
United States attracts the most investment worldwide (nearly \$70
billion), venture capital investment in China rose from approximately
\$3 billion in 2013 to \$34 billion in 2016, climbing from 5 percent to
27 percent of the global share --- the fastest increase of any economy.
China's start-up ecosystem is both vast and vibrant; it has successfully
incubated more tech unicorns than any other country except the United
States. Too often, U.S. critics claim that Chinese industrial policies
like Made in China 2025 are behind the country's ascendancy in tech. In
fact, virtually none of China's leading tech firms, such as Alibaba,
Baidu and Tencent, are state-owned or meaningful beneficiaries of state
support. They are all founded and led by smart and risk-taking private
entrepreneurs, just like their Silicon Valley brethren. Tellingly, many
Chinese tech start-ups have received U.S. venture financing. And Chinese
technology companies and venture firms have made significant investments
in U.S. start-ups. Sadly, the virtuous two-way venture capital flows are
now in jeopardy because of Washington's growing paranoia about China.
[As impressive as China's innovation and progress may be, however, it is
premature to declare that China has caught up with the U.S. tech
industry]{.underline}. Interventionist government bureaucracy, stodgy
state-owned enterprises, a rigid school system and --- above all ---
harsh restrictions on individual freedoms continue to stifle independent
thinking and creativity and constrain China from realizing its full
innovation potential. [[While China is]{.mark} well [positioned to
succeed in "strategic" industries]{.mark}]{.underline} such as
semiconductors, pharmaceuticals and commercial aircraft due to its vast
pool of engineering talent and the size of its domestic market, [**so
far [it has remained a laggard]{.mark}.** [China has failed to develop
an indigenous chip industry]{.mark} despite a state-led drive to do so,
with tens of billions spent ov]{.underline}er th[e past four
decades.]{.underline} Despite its status as the "world's factory,"
making everything from cell phones and laptops to numerous other
devices, [[China continues to import 90 percent of its
microchips]{.mark} from foreign countries, predominantly from the United
States.]{.underline} That is why the U.S. threat to cut off critical
chip supply to ZTE, a Chinese telecom equipment firm, has been dubbed
the "Sputnik moment" in China: a sober reminder of China's continued
weaknesses in critical technologies. [While China has made spectacular
progress on the tech front]{.underline}, **[the United States remains
the undisputed global leader in science and technology]{.underline}**.
The [**[U]{.mark}**nited **[S]{.mark}**tates [holds]{.mark} most of [the
world's leading research universities]{.mark}; it [deploys the highest
amounts of]{.mark} both public and private [funding in
**r**]{.mark}esearch **[and]{.mark}** **[d]{.mark}**evelopment;
[attracts the most venture capital]{.mark}; [awards the most advanced
degrees]{.mark}; provides the most advanced business, financial and
information services [and is the largest producer in]{.mark}
knowledge-intensive, [high-tech sectors]{.mark}, from pharmaceuticals to
semiconductors. **The fear that China will displace the United States as
the global tech superpower is grossly exaggerated**]{.underline}.
[Unfortunately, such paranoia dominates the minds of protectionist U.S.
politicians and China hawks and has already amplified a destructive
trade war between the world's two largest economies.]{.underline} For
China's part, its soul-searching is overdue. Beijing should resist the
prevalent yet ill-justified self-complacency and triumphalism that
contributed to the fear in Washington in the first place, and it should
make serious efforts to reform and open its domestic economy. [[Unless
Beijing amends its]{.mark} heavy-handed [statist approach to economic
development, China's potential]{.mark} as a leading nation in science
and technology [could be]{.mark} seriously
[curtailed]{.mark}.]{.underline}

## CPs

### 2AC\-\--OSCE CP 

#### NATO's [key]{.underline}\-\--failure to engage the [institution itself]{.underline} means [military AI]{.underline} can't be made [interoperable]{.underline}, which causes [political gridlock]{.underline} and [tactical]{.underline} conflict

Zoe **Stanley-Lockman &** Lena **Trabucco 22**, Stanley-Lockman is an
Associate Research Fellow in the Military Transformations Programme at
the Institute of Defence and Strategic Studies at the S. Rajaratnam
School of International Studies in Singapore; Lena Trabucco is a dual
degree candidate pursuing a PhD in political science at Northwestern
University and a PhD in Law at iCourts Center of Excellence in
International Courts at the University of Copenhagen, "NATO's Role in
Responsible AI Governance in Military Affairs," The Oxford Handbook of
AI Governance, edited by Justin Bullock et al., Oxford University Press,
03/18/2022, DOI.org (Crossref),
doi:10.1093/oxfordhb/9780197579329.013.69

Safety and security

[For humans to meet **ethical and legal commitments**]{.underline} [when
developing and deploying AI, the **systems themselves**]{.underline}
[must be]{.underline} **[safe]{.underline}**, secure, and reliable. More
simply put, [if humans and institutions interacting with AI do not have
**confidence**]{.underline} [that the systems will perform as
expected]{.underline}, then [they cannot assure that]{.underline} its
[development and deployment are **responsible**]{.underline}. [This
makes **safety** and]{.underline} **[security]{.underline}**
[a]{.underline} **[key pillar of responsible AI
governance]{.underline}** for any actor.82 As this section explores
[for]{.underline} **[NATO in particular]{.underline}**,
**[safety]{.underline}** [and]{.underline} **[security]{.underline}**
[are]{.underline} **[indispensable to the Alliance's stated
goals]{.underline}** to focus its approach to EDTs in the areas of
"deterrence and defense, capability development, legal and ethical
norms, and arms control aspects."83

Politically, [democratic militaries using AI cannot be
**accountable**]{.underline} to their citizenries nor their coalition
partners [if they lack mechanisms to trace and explain how their systems
are reliable. Accidents and interference with AI systems could likewise
create political risks for the Alliance]{.underline}. For example, [if
deepfakes and micro-targeted information attacks compromise confidence
in the integrity of **information**]{.underline} used [to build a
**common operating picture**]{.underline}, then the
**[operational]{.underline}** [difficulties could]{.underline} also
**[erode political trust]{.underline}** [between]{.underline}
**[Allies]{.underline}** in a few key ways. [In the North Atlantic
Council]{.underline}, **[disagreement]{.underline}** [about]{.underline}
the **[integrity of information]{.underline}** [could]{.underline}
**[slow]{.underline}** [the]{.underline} decision-making [body's ability
to **react to fast-changing operational realities**]{.underline}.84
Further, **[compromised]{.underline}** [AI systems]{.underline} may not
only [make it harder]{.underline} for forces [to prevent **harm to
non-combatants**]{.underline}, [but]{.underline} **[also]{.underline}**
[to prevent **friendly fire**. In this way, coalition
forces]{.underline} arguably [face even **higher
obligations**]{.underline} [to]{.underline} **[coordinate]{.underline}**
[on]{.underline} the **[reliability]{.underline}** of their systems,
relative to adversaries and near-peer competitors that tend to operate
alone. As such, responsible AI governance is not purely technical;
**[policy alignment and strategic planning]{.underline}**
[are]{.underline} likewise **[necessary]{.underline}** [to draw
attention to risk management **above the tactical level**]{.underline}.

# NEG

## Case

### \*JOINT OPERATIONS ADV\*

### 

### Say No\-\--1NC 

#### NATO allies say no\-\--divergent demands and public opposition. 

**HeikkilÄ 22**, 7-4-2022, \"NATO wants to set AI standards. If only its
members agreed on the basics.,\" POLITICO,
https://www.politico.eu/article/nato-ai-artificial-intelligence-standards-priorities/

[On paper, NATO is the ideal organization to go about setting standards
for military applications of artificial intelligence. **But the widely
divergent priorities** and budgets of its 30 members **could get in the
way.**]{.underline}

[The Western military alliance
has [identified](https://www.nato.int/nato_static_fl2014/assets/pdf/2020/12/pdf/201201-Reflection-Group-Final-Report-Uni.pdf) artificial
intelligence as a key technology needed to maintain an edge over
adversaries, and it wants to lead the way in establishing common ground
rules for its use. ]{.underline}

"We need each other more than ever. No country alone or no continent
alone can compete in this era of great power competition," NATO Deputy
Secretary-General Mircea Geoană, the alliance's second in command, said
in an interview with POLITICO.

[The standard-setting effort comes as China is pressing ahead with AI
applications in the military largely free of democratic
oversight]{.underline}.

David van Weel, NATO's assistant secretary general for emerging security
challenges, said Beijing\'s lack of concern with the tech\'s ethical
implications has sped along the integration of AI into the military
apparatus.

\"I\'m \... not sure that they\'re having the same debates on principles
of responsible use or they\'re definitely not applying our democratic
values to these technologies," he said.

[Meanwhile, the EU --- which has pledged to roll out the world\'s first
binding rules on AI in coming weeks --- is seeking closer collaboration
with Washington to oversee emerging technologies, including artificial
intelligence. But those **efforts have been slow in getting off the
ground**.]{.underline}

For Geoană, that collaboration will happen at NATO, which is working
closely with the European Union as it prepares AI regulation focusing on
"high risk" applications.

The pitch

NATO does not regulate, but "once NATO sets a standard, it becomes in
terms of defensive security the gold standard in that respective field,"
Geoană said.

The alliance\'s own AI strategy, to be released before the summer, will
identify ways to operate AI systems responsibly, identify military
applications for the technology, and provide a "platform for allies to
test their AI to see whether it\'s up to NATO standards," van Weel
said. 

The strategy will also set ethical guidelines around how to govern AI
systems, for example by ensuring systems can be shut down by a human at
all times, and to maintain accountability by ensuring a human is
responsible for the actions of AI systems.

"If an adversary would use autonomous AI powered systems in a way that
is not compatible with our values and morals, it would still have
defense implications because we would need to defend and deter against
those systems," van Weel said. 

"We need to be aware of that and we need to flag legislators when we
feel that our restrictions are coming into the realm of \[being
detrimental to\] our defense and deterrence," he continued.

Mission impossible?

[The problem is that NATO\'s members are at **very different stages**
when it comes to thinking about AI in the military context.]{.underline}

[The U.S., the world\'s biggest military spender, has prioritized the
use of AI in the defense realm. But in Europe, most countries --- France
and the Netherlands excepting --- barely mention the technology's
defense and military implications in their national AI
strategies. ]{.underline}

["It's absolutely no surprise that the U.S. had a military AI strategy
before it has a national AI strategy,\" but the Europeans \"did it
exactly the other way around,\" said Ulrike Franke, a senior policy
fellow at the European Council on Foreign Relations, said:]{.underline}

[That echoes familiar transatlantic differences --- and previous U.S.
President Donald Trump\'s complaints --- over defense spending, but also
highlights the different approaches to AI regulation more
broadly.]{.underline}

The EU\'s AI strategy takes a cautious line, touting itself as
\"human-centric,\" focused on taming corporate excesses and keeping
citizens\' data safe. The U.S., which tends to be light on regulation
and keen on defense, sees things differently.

[There are also **divergences** over **what technologies the alliance
ought to develop**, including lethal autonomous weapons systems ---
often dubbed "killer robots" --- programmed to identify and destroy
targets without human control. ]{.underline}

[Powerful NATO members including France, the U.K., and the U.S. have
developed these technologies and oppose a treaty on these weapons, while
others like Belgium and Germany have [expressed serious
concerns](https://www.stopkillerrobots.org/action-and-achievements/) about
the technology.]{.underline}

[These weapons systems have also faced **fierce public opposition** from
civil society and human rights groups, including from United Nations
Secretary-General António Guterres, who in
2018 [called](https://www.un.org/sg/en/content/sg/speeches/2018-11-05/remarks-web-summit) for
a ban. ]{.underline}

[Geoană said the alliance has "retained autonomous weapon systems as
part of the interests of NATO." The group hopes that its upcoming
recommendations will allow the ethical use of the technology without
"stifling innovation." ]{.underline}

#### NATO says no\-\--[political frition]{.underline} prevents unity on AI standards. 

Zoe **Stanley-Lockman &** Lena **Trabucco 22**, Stanley-Lockman is an
Associate Research Fellow in the Military Transformations Programme at
the Institute of Defence and Strategic Studies at the S. Rajaratnam
School of International Studies in Singapore; Lena Trabucco is a dual
degree candidate pursuing a PhD in political science at Northwestern
University and a PhD in Law at iCourts Center of Excellence in
International Courts at the University of Copenhagen, "NATO's Role in
Responsible AI Governance in Military Affairs," The Oxford Handbook of
AI Governance, edited by Justin Bullock et al., Oxford University Press,
03/18/2022, DOI.org (Crossref),
doi:10.1093/oxfordhb/9780197579329.013.69

On that note [**NATO**, or]{.underline} **[any]{.underline}** other
**[i]{.underline}**nternational **[o]{.underline}**rganization,
[is]{.underline} **[not exempt]{.underline}** [from]{.underline} these
[**political hurdles**. As EDTs increasingly become a focal
point]{.underline} in the geopolitical space, [any approach of AI
governance in the international security environment will have global
**political undertones**. This will]{.underline} undoubtedly [be
a]{.underline} **[significant hurdle]{.underline}** [for NATO as it
balances responsible AI development and Allied]{.underline} coordination
and **[coop]{.underline}**eration in a changing geopolitical landscape.
And [certainly]{.underline}, the **[political]{.underline}** [realities
may]{.underline} well [represent the]{.underline} **[greatest
challenge]{.underline}** [and]{.underline}
**[disincentivize]{.underline}** [NATO to emerge as a]{.underline}
**[leader]{.underline}** in responsible military AI. Nevertheless, the
three pillars indicate that NATO is an institution with considerable
opportunity to shape responsible AI governance. More specifically, this
entails urging and facilitating Allied standards and policies to
establish foundations for emerging military technology built on informed
and ethical principles and enhance the international security
environment.

### 

### Interop Fails\-\--1NC

#### Interoperability challenges are [structural]{.underline}\-\--they [can't be fixed]{.underline} through consultation or dialogue. 

Edward Hunter **Christie 22**, Senior Research Fellow at the Finnish
Institute of International Affairs, "Defence Cooperation in Artificial
Intelligence: Bridging the Transatlantic Gap for a Stronger Europe,"
European View, vol. 21, no. 1, SAGE Publications Ltd, 04/01/2022, pp.
13--21

Interoperability challenges

Interoperability can be defined as 'the ability of systems, units or
forces to provide services to, and accept services from other systems,
units or forces and the use the services so exchanged to enable them to
operate effectively together' (Dufour 2018, 1).

[The]{.underline} first [general challenge to interoperability is the
**overall gap**]{.underline} [between the US and Europe in terms
of]{.underline} [**total defence investment**, as well as
in]{.underline} terms of **[civilian technological
attainment]{.underline}** [with]{.underline} respect to
**[AI]{.underline}** and related technologies. [There is]{.underline}
**[no]{.underline}** single [**solution to this problem**, which is
much]{.underline} **[broader]{.underline}** [in scope than]{.underline}
[**traditional military--technical standards**, such as those pursued
in]{.underline} the **[NATO]{.underline}** context [through]{.underline}
[**existing mechanisms**. For this **broad**]{.underline}
[challenge]{.underline}, **[overall]{.underline}** [policy decisions
relating to]{.underline} national **[investment]{.underline}** choices
[and]{.underline} **[tech]{.underline}**nology **[policy]{.underline}**
coordination [between the two sides]{.underline} of the Atlantic [are
of]{.underline} **[particular importance]{.underline}**. Further
discussion of this follows in the sections on investment challenges and
international security challenges.

[A]{.underline} **[second]{.underline}** [challenge]{.underline} to
interoperability [is that]{.underline}, as far as digital technologies
are concerned, [the]{.underline} **[civilian]{.underline}**
[sector]{.underline} of the economy, [on both sides]{.underline} of the
Atlantic, [is]{.underline} **[more advanced]{.underline}**, more
**[dynamic]{.underline}** [and]{.underline} also **[not]{.underline}**
especially **[oriented]{.underline}** [towards]{.underline} meeting
**[military needs]{.underline}**. For decades, the military sector has
represented only a very small share of the total sales volume of the
computing and semiconductor industries. The same pattern is repeating
itself currently with AI. This stands [in]{.underline} **[great
contrast]{.underline}** [to]{.underline} **[narrower]{.underline}**
[dual-use technologies, for example aerospace, where the military sector
remains inherently]{.underline} **[important]{.underline}**. With
digital technologies, defence institutions are under much more pressure
to either adapt to civilian industry products and standards or to pay a
significant premium to suppliers to secure military-grade equipment and
software.

[A third challenge]{.underline} to interoperability [lies in how AI is
implemented in **practice**]{.underline}. To set up a bespoke
machine-learning algorithm in a given data environment, best practice in
the software industry is to pursue some variant of **['agile'
development]{.underline}**. This involves a very different
product-development cycle, essentially proceeding [with
multiple]{.underline} **[rapid iterations]{.underline}** [of
an]{.underline} **[imperfect product]{.underline}** that is released in
preliminary versions and later revised---like software products released
in various 'beta versions'---with upgrades developed over time. This
**[contrasts greatly]{.underline}** [with the traditional production of
major military platforms, which puts a]{.underline}
**[premium]{.underline}** [on]{.underline} strict **[quality
control]{.underline}** [and]{.underline} **[compliance]{.underline}**
with requirements [at]{.underline} **[every development
step]{.underline}**---an approach referred to in the software industry
as 'waterfall' development (Christie 2021b, 87). **[Agile]{.underline}**
product [development may pose **challenges**]{.underline}
[to]{.underline} [**interoperability**. Unless very tight standards are
applied, there is a considerable risk of]{.underline}
**[divergences]{.underline}** in how different national institutions go
about solving a particular AI or data analytics problem.

With large traditional military platforms there are long time frames
during which states can take coordination steps, either by purchasing
the same platforms, or by building consensus in terms of requirements
and standards. However, [when a]{.underline} comparatively **[small
team]{.underline}** [works **dynamically**]{.underline} [to generate
an]{.underline} **[algorithmic solution]{.underline}** [to
a]{.underline} **[particular problem]{.underline}** [in]{.underline} a
matter of **[weeks]{.underline}** or months, [traditional coordination
through existing consultation mechanisms may pose]{.underline} **[risks
to the speed advantage inherent to agile development]{.underline}**.
Conversely, once a solution has been developed, its adoption in somewhat
different environments may be challenging for a range of technical
reasons. None of these issues is insurmountable, but they do pose, in a
new light, classical trade-offs between the benefits of inventiveness
and dynamism, on the one hand, and those of imposing constraints through
standards and other harmonising measures to ensure that new products can
be broadly used and shared on the other. In the case of AI, a typical
observation is that there are many excellent prototypes and pilot
projects in numerous defence institutions, but [there are]{.underline}
also **[serious]{.underline}** outstanding **[challenges]{.underline}**
[in terms of **scaling up** to]{.underline}
**[enterprise]{.underline}**-wide [solutions, **let alone Alliance-wide
solutions**]{.underline}.

### 

### Alt Causes\-\--1NC

#### [Tons]{.underline} of issues are fracturing NATO. It's a [structural]{.underline} problem of [interest divergence]{.underline}, not something that can be solved through limited dialogue. 

Eugene **Rumer &** Richard **Sokolsky 4/11**, Rumer, a former national
intelligence officer for Russia and Eurasia at the U.S. National
Intelligence Council, is a senior fellow and the director of Carnegie's
Russia and Eurasia Program; Sokolsky is a nonresident senior fellow in
Carnegie's Russia and Eurasia Program, "Putin's War Against Ukraine and
the Balance of Power in Europe," Carnegie Endowment for International
Peace, 4-11-2022,
https://carnegieendowment.org/2022/04/11/putin-s-war-against-ukraine-and-balance-of-power-in-europe-pub-86832

[Notwithstanding the allies']{.underline} **[early]{.underline}** [show
of unity]{.underline} in the wake of the Russian attack on Ukraine, some
of [their]{.underline} **[differences]{.underline}** [and]{.underline}
**[challenges]{.underline}** [to a]{.underline} **[more robust NATO
posture]{.underline}** [have]{.underline} **[not
disappeared]{.underline}** entirely. [These include the
varying]{.underline} **[interests]{.underline}** [and]{.underline}
**[priorities]{.underline}** [of]{.underline} the EU's and NATO's
[**diverse members**, as well as likely disagreements over **which
threats and challenges**]{.underline} [should be]{.underline}
**[privileged]{.underline}** [in]{.underline} **[resource
allocation]{.underline}** decisions ([among issues ranging from the
Russian threat, China, climate change, pandemics, immigration, borders,
refugees, or diversification of energy supplies]{.underline}). [It would
be prudent]{.underline} [to]{.underline} **[not take for
granted]{.underline}** [that Europe will forge]{.underline} the
**[political unity]{.underline}** [and]{.underline}
**[raise]{.underline}** [the]{.underline} **[billions]{.underline}** of
euros [it will require to create a]{.underline} **[first-class
military]{.underline}** that might substitute for or provide a
substantial addition to NATO's military kit.

Moreover, [the unanimity with which Europe came together to impose
sanctions on Russia and help Ukraine is likely due to the fact that
Ukraine is **not a NATO member**]{.underline}, and demonstrations of
solidarity with it do not involve defense commitments through NATO's
Article 5. [In the event of a Russian attack against a]{.underline}
**[NATO member]{.underline}** country, [the specter of]{.underline} an
**[all-out war]{.underline}** with Russia [may lead some]{.underline}
allies [to demonstrate]{.underline} **[less resolve]{.underline}**
[and]{.underline} **[more caution and hesitation]{.underline}**.

One headline is likely to become a trend line: [Putin has]{.underline}
**[confirmed]{.underline}** [that]{.underline} **[nuclear weapons are
useful]{.underline}** for a wide range of deterrence and coercive
purposes to go along with what will still be formidable conventional
capabilities in a short-war scenario, such as a quick land grab in the
Baltic region. Several implications flow from this development.

First, [notwithstanding]{.underline} **[rhetoric]{.underline}** about
defending every inch of NATO territory and the alliance's impressive
show of resolve, [NATO may be **unable**]{.underline} [or]{.underline}
**[unwilling]{.underline}** [to conduct an Article 5 intervention
against a Russian attack. The alliance may choose]{.underline}
**[instead]{.underline}** [to form a]{.underline} **[coalition of
willing NATO countries]{.underline}** [to defend]{.underline} vulnerable
countries on [its eastern flank]{.underline}.

### 

### AT: Russia War Impact\-\--1NC

#### Larger Russia war is [impossible]{.underline}\-\--they don't have [capabilities]{.underline} AND [deterrence]{.underline} prevents going [nuclear]{.underline}. 

Limor **Simhony 22**, policy advisor and researcher based in London,
"NATO Intervention in Ukraine Won't Spark World War III," Foreign
Policy, 4/1/2022,
https://foreignpolicy.com/2022/04/01/nato-intervention-in-ukraine-wont-spark-world-war-iii/

[The]{.underline} main [concern is any]{.underline} such [escalation
could lead to]{.underline} **[World War III]{.underline}**. [There
are]{.underline} two [reasons that this is]{.underline}
**[unlikely]{.underline}**. The [first]{.underline} is that
[Russia's]{.underline} **[military capabilities]{.underline}**
[are]{.underline} **[poor]{.underline}** relative to those of Western
armies. [Their forces are]{.underline} **[not]{.underline}**
sufficiently [**trained**; their equipment and weapons are]{.underline}
**[dated]{.underline}** [and]{.underline} [**inferior**; they
experience]{.underline} **[major logistical, operational, and tactical
difficulties]{.underline}**; and [their soldiers have]{.underline}
**[low morale]{.underline}**.

[Damaging]{.underline} economic **[sanctions]{.underline}** also
[mean]{.underline} that [Russia may not be able to]{.underline}
**[fund]{.underline}** [a wider war. The expectation that Moscow will be
**able** to]{.underline} **[escalate]{.underline}** the war into other
theaters in an effective way, especially by conventional means,
[is]{.underline} [**unrealistic**. It is possible that]{.underline} if
the Russian military continues to struggle, Russian President Vladimir
[Putin will deploy]{.underline} chemical or even
**[nuclear]{.underline}** [weapons]{.underline} to increase gains and
deter the West from interfering---[but that is]{.underline}
**[unlikely]{.underline}**.

The [second]{.underline} is that [Russia has become **isolated**. To
fight a]{.underline} [**world war**, Russia needs]{.underline} powerful
[**allies**, which it]{.underline} **[does not have]{.underline}**. Its
strongest ally, **[China]{.underline}**, [has]{.underline} largely
[remained on the]{.underline} **[sidelines]{.underline}** since the war
started. It abstained from voting against the U.N. resolution demanding
that Russia ends its offensive, and it is worried about secondary
sanctions if it aids Russia. The only countries besides Russia that
voted to reject the resolution were Belarus, North Korea, Eritrea, and
Syria---hardly a winning alliance. Both [world wars saw blocks of
powerful allies fight one another. Currently, such a bloc
does]{.underline} **[not exist]{.underline}** [on]{.underline}
**[Russia's]{.underline}** [side]{.underline}.

[These factors mean]{.underline} that [there is]{.underline}
**[not]{.underline}** a **[high risk of substantial escalation into
total global war]{.underline}**. This should be enough to convince
Western nations to change their engagement policy and help Ukraine win
the war by repulsing an opponent that is considerably inferior
militarily to their own forces. It is unlikely to happen for two main
reasons: fear of Russian nukes and the West's aversion to casualties.

[The most widely discussed reason is the concern that Russia will
use]{.underline} **[nuclear weapons]{.underline}** if NATO intervenes
militarily. Putin has reasserted Russia's right to use nuclear weapons
in Ukraine, making this a legitimate concern. [However, it is **more
likely**]{.underline} [that]{.underline} nuclear
**[deterrence]{.underline}**---albeit different to Cold War
deterrence---[will]{.underline} [**hold**. Russia's deployment of
nuclear weapons, either against Ukraine or against]{.underline} a
[NATO]{.underline} member state, [could incur]{.underline}
**[devastating consequences]{.underline}** for Russia.

As then-U.S. Defense Secretary James Mattis said in 2018, dismissing the
notion that tactical nuclear weapons are somehow a lesser threat,
"**[Any]{.underline}** [nuclear weapon used]{.underline} ... [is
a]{.underline} **[strategic game-changer]{.underline}**." Therefore, [if
NATO retaliates with a]{.underline} **[powerful response]{.underline}**,
either nuclear or conventional, [it may target
**strategic**]{.underline} Russian **[military positions]{.underline}**
[and]{.underline} perhaps [even sites of]{.underline} [**political
power**, aiming at]{.underline} **[wiping out]{.underline}** Russian
**[military capabilities]{.underline}** [and targeting]{.underline}
those in positions of authority---a move that could threaten Putin's
**[leadership]{.underline}**. A NATO **[retaliation]{.underline}**
[should therefore be considered a]{.underline} **[major
threat]{.underline}** [to Putin]{.underline}, especially because rivals
include numerous nations with considerable nuclear capabilities, such as
the United States, United Kingdom, and France.

[In addition, at the heart of this conflict]{.underline}
[stands]{.underline} [**national identity**. Putin has]{.underline}
**[little motivation]{.underline}** [to devastate a]{.underline}
**[county]{.underline}** that [he]{.underline} **[wishes to
annex]{.underline}** [and has]{.underline} **[not knowingly made any
preparations for using nuclear weapons]{.underline}**. Fear of the bomb
accounts for one reason behind the West's decision to leave Ukraine to
fight on its own.

Another consideration is fundamental to the West: casualty sensitivity.

Sensitivity to casualties---specifically deaths among troops---has
become a major element affecting liberal democracies' war preparedness,
use of force, and decision-making regarding participation in wars.

The trauma of Britain's so-called lost generation followed the loss of
750,000 troops in World War I. It overwhelmed the public and affected
interwar foreign policy and military preparedness in a misguided attempt
to avoid another war. The same happened in other liberal democracies
scarred by the war, such as France, whereas countries with shallower
liberal and democratic traditions---such as Germany, which suffered
heavier losses than France and Britain---consequently gravitated toward
fascism and reverted to militarism.

Conflict behavior and public attitudes toward wars have undergone deep
changes during the 20th and 21st centuries as a result of extensive
liberalization and democratization processes. Liberal concepts of
individualism, personal freedoms, a reduction in internal violence, and
a comfortable lifestyle that includes longer life expectancy brought
about changes in attitudes about war---primarily, that it is an
undesirable way to resolve conflicts. Rejecting the violence and
suffering that comes with it has made it difficult for leaders of
liberal democracies to justify to the public participation in wars,
especially wars of choice, in which the nation is not under direct
threat.

The United States' interventions in Vietnam, Lebanon, Somalia, and Iraq,
for example, were shaped by the casualties incurred. The 1983 bombing of
the Marine Corps barracks in Lebanon that killed 241 U.S. service
members and the 1993 Battle of Mogadishu, where 18 U.S. soldiers died,
provoked powerful reactions against the missions, bringing them to an
abrupt end despite them initially enjoying wide public support.

A similar reaction came after the Tet Offensive in Vietnam in January
1968, which resulted in 1,500 American fatalities. It was a watershed
moment that changed the debate about the war and led to the shelving of
plans for escalation. Support for the second war in Iraq also fell
dramatically as deaths mounted, causing the American public to question
the necessity of the war or its conduct and chances of success.

Israel's use of force against Hezbollah in Lebanon has been heavily
influenced by casualty aversion. This included an overreliance on air
power in an attempt to limit fatalities among ground forces during the
2006 Lebanon War at the price of undermining military effectiveness.
Then-Israeli Chief of Staff Lt. Gen. Dan Halutz famously commented: "We
didn't send ground troops into Lebanon because the public couldn't
stomach any more deaths."

Israel's withdrawal from southern Lebanon, where forces had been
deployed between 1985 and 2000, was also heavily influenced by the
public's dissatisfaction with the casualties incurred, particularly
after several costly incidents during the 1990s undermined support for a
continued military presence and enhanced criticism of the government.

Nondemocracies and guerrilla and terrorist organizations do not exhibit
such an aversion to casualties. During the Iran-Iraq War, both sides
callously scarified children by using them as human minesweepers and
shields. Similarly, both the Viet Cong in Vietnam and Hezbollah in
Lebanon showed considerable willingness to sacrifice lives despite
suffering more losses than their liberal enemies. Then-Egyptian
President Anwar Sadat famously said, "Egypt would sacrifice a million
Egyptian soldiers" during the October 1973 war against Israel despite
not facing an existential threat or serious strategic concerns.

There has been little evidence to suggest there is heightened
sensitivity to losses among troops in Russia, a nation with a history of
mass deaths in both the world wars, its own civil war, and from the
brutal suppression and killing of its own people. The continued use of
force in Ukraine, which has resulted in as many as 15,000 Russian
military deaths so far according to the Washington Post, indicates that
casualties are of no concern to Russia's top brass. This stands in
contrast to Ukraine, which accepts its causalities because it is
fighting an existential war for independence and national survival.

Casualty sensitivity has been one of the factors shaping democracies'
behavior, with Western politicians preferring to avoid direct engagement
in wars or to limit the use of ground forces, even at the price of
compromising objectives and deterrence. It is one of the reasons that a
policy of nonengagement was adopted, without question or hesitation,
regarding Ukraine, long before Putin raised the alert status of Russia's
nuclear arsenal.

Fear of casualties among soldiers meant that a policy of nonengagement
has existed prior to Russia's invasion---and therefore separately to a
concern about escalating into a broader war. This has been understood by
Putin, who bet---correctly---that Western nations will not take an
active role in the war by using direct force against Russian troops, not
only out of fear of escalation but as a result of a preexisting doctrine
that seeks to minimize casualties. Had the West exhibited less casualty
aversion, this could have acted as a greater deterrent against Russian
aggression.

For the war in Ukraine, unlike the risk of escalation and use of nuclear
weapons, the risk of incurring casualties is high. Considering how
formative aversion to casualties has been, committing troops to fight
Russia will require liberal democracies to undergo a major paradigm
shift.

But there are ways to mitigate the effect of casualty sensitivity on
public opinion. Adjusting the public's expectations regarding the length
of the war and the casualties that will result as well as displaying
internal political unity could help. Employing force that relies
primarily on air power, which limits casualties, can be used; during
Israel's 2006 war in Lebanon and other wars, this has proved to have
only limited effectiveness. However, if done in collaboration with
Ukrainian ground forces, this could have better chances of success.

This war brought a shift in attitudes toward wars in Europe. The
Germans, famously pacifist since 1945, have undergone the largest shift
and now support military aid to Ukraine and a considerable increase in
funds to rebuild Germany's military power. But a bigger shift is needed
considering Russia's aggression.

Russia is no stranger to targeting civilians, as it has done in the
carpet-bombing of Grozny in Chechnya, in 1994 to 1995 and 1999 to 2000.
It is doing this again now. It is time for the West to stop being afraid
of limited threats that are not likely to materialize and to use its
military superiority to help Ukraine defend its independence.

[Intervention will]{.underline} [**not turn this local conflict into
World War III**. It runs the risk of causing a tactical nuclear attack
on Ukraine, but this risk is]{.underline} **[limited]{.underline}**
[given what]{.underline} any **[retaliation]{.underline}** [could mean
for]{.underline} **[Russia]{.underline}**. The West must therefore
decide how long it will refrain from engagement and allow Russia to sow
devastation in pursuing expansionist ambitions for fear of casualties or
the bomb.

### AT: Russia War Impact\-\--AT: Invasion

#### Zero chance Russia attacks NATO after Ukraine

Paul **Miller 22**, professor of the practice of international affairs
at Georgetown University, "Ukraine Is Not World War III," The Dispatch,
3/8/2022, https://thedispatch.com/p/ukraine-is-not-world-war-iii?s=r

[War **gets the blood up**]{.underline}. Gary
**[[Kasparov]{.underline}]{.mark}**---former world chess champion turned
dissident against Putin's Russia---**[[claimed]{.underline}]{.mark}** on
March 3 [that "[this is **already World War III**]{.mark}]{.underline}."

"Putin started it long ago & Ukraine is only the current front,"
Kasparov [[argued]{.underline}]{.mark}. [[He will]{.underline}
**[escalate anyway]{.underline}**]{.mark}, and it\'s even more likely if
he succeeds in destroying Ukraine because you have again convinced him
you won\'t stop him even though you could."

Kasparov has warned about Putin's aggression for years, and his book
Winter Is Coming largely predicted what we're witnessing today. But
sayijeng we are already fighting World War III is the classic
never-appease-aggressors logic by which any authoritarian is likened to
Hitler in 1939: if we don't stop him now, he will only be emboldened to
invade the next country, and the next, until he is knocking on our front
door with an armored division or two. Better to accept reality and start
World War III now than wait for Putin to initiate it and force us to
fight it on his terms.

[[The]{.underline} **[logic]{.underline}**]{.mark} **[is
familiar]{.underline}** and the danger is plain, [which [is
why]{.mark}]{.underline} [**[some]{.underline}**]{.mark} people
[[seem]{.underline}]{.mark} more [**[willing]{.underline}** [to
risk]{.underline} **[general war]{.underline}**]{.mark} **[against
Russia]{.underline}** [in an]{.underline} [**all-out effort to stop
Putin [now, before he invades the next country]{.mark}**.
Kasparov's]{.underline} **[argument]{.underline}** has been echoed by
other commentators who warn Putin will not stop at Ukraine, or who
insist the U.S. and NATO must militarily intervene in the war in
Ukraine. The head of the European Council on Foreign Relations openly
called for regime change in Russia. Ukrainian President Volodymyr
Zelensky called on NATO to impose a no-fly zone over Ukraine, an idea
former National Security Adviser John Bolton partially endorsed. A
no-fly zone, of course, would involve NATO aircraft shooting down
Russian warplanes over Ukrainian skies. [To [put]{.mark} it]{.underline}
**[[plainly]{.underline}]{.mark}**: A no-fly zone [is
[a]{.mark}]{.underline} **[[declaration of war]{.mark} against
Russia]{.underline}** [[and]{.mark} the]{.underline} **[first step on a
path]{.underline}** [that]{.underline} would [lead to]{.underline}
**[general war]{.underline}**.

The war in [Ukraine is]{.underline} [not]{.underline}
**[yet]{.underline}** [World War III. To act as if it]{.underline}
**[were]{.underline}** [by]{.underline} **[proactively
escalating]{.underline}** [or]{.underline} **[expanding the
war]{.underline}** [is both]{.underline} **[strategically
unnecessary]{.underline}** [and]{.underline} [**immoral**. It
[would]{.mark} be to]{.underline} **[[trigger the very war
we]{.underline}]{.mark}** should [**[most want to avoid]{.mark}**. The
war in Ukraine is]{.underline} an **[extremely dangerous]{.underline}**
development for world order, [the only thing]{.underline}
**[more]{.underline}** [dangerous than which would be to]{.underline}
**[overreact]{.underline}** and recklessly expand the war.

Prelude to a conflict.

[Treating the war as if it were]{.underline} **[already]{.underline}**
[World War III]{.underline}, and Russia's invasion of Ukraine a prelude
to general European conflict, [is]{.underline}
**[unnecessary]{.underline}** [because [Russia]{.mark}]{.underline}
[**[cannot]{.underline}** [and]{.underline} **[will not expand the war
beyond Ukraine]{.underline}**]{.mark}[. The]{.underline}
**[historical]{.underline}** [analogy---[Putin as]{.mark}]{.underline}
[**[Hitler]{.underline}**]{.mark} [hellbent on **continental
conquest**---[is]{.mark}]{.underline} [[**flawed**]{.mark}. While Putin
may have]{.underline} [**boundless ambition**, [his]{.mark}]{.underline}
actual [**[capabilities]{.underline}** [are]{.underline}]{.mark}
**[severely [bounded]{.mark}]{.underline}** by reality.

[[The **German**]{.underline} [military]{.underline}]{.mark}
[in]{.underline} **[1940]{.underline}**, as its blitzkrieg swept across
Europe, [[numbered]{.underline}]{.mark} some **[6 million]{.underline}**
soldiers in all branches. [Over the course of the war, some]{.underline}
**[[18 million]{.mark} Germans served]{.underline}** in uniform,
[approaching]{.underline} [**one-third of its total population**.
Germany was the]{.underline} economic **[powerhouse of
Europe]{.underline}** in 1940 and could outproduce any European
competitor in military equipment and supplies.

[At the start of the war, the Germans]{.underline} arguably [[had
the]{.underline} **[best tank]{.underline}**]{.mark} (the Panzer)
[[and]{.mark} the]{.underline} **[best [fighter]{.mark}]{.underline}**
plane (the Messerschmitt). [The German scientific and industrial base
was among the best in Europe and had a head start in its focus on
military technology. German military scientists invented the jet,
rocket, cruise missile, and helicopter before any of the Allies. And the
German military was infamous---again, at the beginning of the war---for
its extraordinary training, discipline, and cohesion.]{.underline}

**[[None]{.mark} of that is [true of Russia]{.mark} or the Russian
military]{.underline}** today. [The Russian military [has]{.mark}
about]{.underline} **[[1 million]{.underline}]{.mark}** active-duty
[soldiers]{.underline}, a fraction of what Germany had at the beginning
of its conquests. Russia **[could]{.underline}** [call up]{.underline}
vast [**reserves**, but it would take]{.underline}
**[years]{.underline}** [to turn them into a]{.underline}
**[trained]{.underline}** [and]{.underline} [**capable fighting force**.
Russian]{.underline} **[[tanks]{.underline}]{.mark}** [[and]{.underline}
**[jets]{.underline}** [are]{.underline}]{.mark} better than Germany's
of 1940---but **[[not better]{.mark} than NATO's]{.underline}** in 2022.
[Over the past week, the Russian military [has
proven]{.mark}]{.underline} [**[inadequate in basic
tasks]{.underline}**]{.mark} like vehicle maintenance, let alone
operational planning, combined arms operations, air assault, and air
defense.

[The 21s century **Russia**n military overwhelmed **smaller** opponents
in **Chechnya**]{.underline} [and]{.underline} **[Syria]{.underline}**
[through]{.underline} **[sheer]{.underline}** force of
**[numbers]{.underline}** [and]{.underline} **[utter disregard for the
laws]{.underline}** of armed conflict. [But]{.underline} it has
**[clearly struggled]{.underline}** [when faced with a]{.underline}
moderately **[larger]{.underline}** [and]{.underline} **[more
challenging opponent]{.underline}** in Ukraine. [The Russian army
is]{.underline} **[hardly ready to invade the next
country]{.underline}** over, or the one after that.
**[[No]{.underline}]{.mark}** Russian [**[blitzkrieg is in the
offing]{.underline}**. [It is]{.underline} **[materially
incapable]{.underline}**]{.mark} [of doing so. **[Hitler]{.mark}**
[spent]{.mark} the **better part of [a decade]{.mark}**]{.underline}
[[rearming]{.mark} and preparing]{.underline} for his war
([[and]{.underline} **[still lost]{.underline}**]{.mark}).

And [[Russia is]{.underline} **[utterly incapable
of]{.underline}**]{.mark} waging a [pro**[long]{.mark}**ed
**[war]{.mark}**. Even]{.underline} **[before]{.underline}** global
economic **[sanctions]{.underline}** [cratered the Russian economy last
week, it was **smaller than Italy's**. The GDP of the]{.underline}
**[U]{.underline}**nited **[S]{.underline}**tates [and]{.underline}
**[E]{.underline}**uropean **[U]{.underline}**nion [combined account for
about]{.underline} **[42 percent]{.underline}** [of the world's
wealth;]{.underline} **[Russia]{.underline}** [about]{.underline} **[3
percent]{.underline}** ([and]{.underline} **[shrinking]{.underline}**).
[Russia does have an advanced scientific and knowledge base, but because
of its economic woes struggles to translate its knowledge into
superior]{.underline} **[weaponry]{.underline}** that it can produce at
scale. If the Russians tried today, [[the]{.underline} **[Polish
army]{.underline}**]{.mark} **[backed by the American Air Force [would
win]{.mark} a [decisive]{.mark} and [rapid
victory]{.mark}]{.underline}**.

### AT: Russia War Impact\-\--AT: Invasion\-\--Defense\-\--Ext

#### [Zero chance]{.underline} of an attack on NATO. Ukraine's [different]{.underline} because it's not covered by a [defense commitment]{.underline}. NATO's a [clear redline]{.underline} Putin's [deliberatly avoiding]{.underline}. Even if he [wants]{.underline} to take over Europe, he [can't]{.underline} because of [clear economic]{.underline}, [manpower]{.underline}, and [technical]{.underline} constraints. That's Miller. 

#### He's worried about NATO's [nukes]{.underline}\-\--he [won't risk it]{.underline}

Nina **Tannenwald 3/10**, teaches international relations in the
Political Science Department at Brown University, "'Limited' Tactical
Nuclear Weapons Would Be Catastrophic," Scientific American, 3/10/2022,
https://www.scientificamerican.com/article/limited-tactical-nuclear-weapons-would-be-catastrophic/

Since Russia invaded Ukraine on February 24, Russian President Vladimir
Putin has given orders to increase the alert level of Russia's nuclear
forces and has made veiled nuclear threats. The blatant aggression
against Ukraine has shocked Europe and the world. The war is a tragedy
for **[Ukraine]{.underline}**. It also [exposes the]{.underline}
**[limits]{.underline}** [of the West's]{.underline}
**[reliance]{.underline}** [on]{.underline} **[nuclear
deterrence]{.underline}**.

Deterrence refers to the idea that possessing nuclear weapons protects a
nation from attack, through the threat of overwhelming retaliation. This
concept is widely credited for helping prevent war between the United
States and the Soviet Union during the Cold War. However, Russia's
invasion of Ukraine casts a harsh light on its downsides. Most obvious
is that [[Putin is using]{.underline}]{.mark} nuclear
[**[deterrence]{.mark}** **not**]{.underline} [to]{.underline}
**[protect Russia]{.underline}** [but rather [to]{.mark} **have his way
in Ukraine**. Russia's nuclear weapons]{.underline} **[[deter the
West]{.underline}]{.mark}** [from]{.underline} **[[intervening with
conventional]{.mark} military [forces]{.mark}]{.underline}** to defend
Ukraine. Despite scattered calls in the U.S. for the creation of a
"no-fly zone" over some or all of Ukraine, the
[[Biden]{.underline}]{.mark} administration [has]{.underline} **[wisely
[resisted]{.mark}]{.underline}**. In practice this would mean shooting
down Russian planes. [It could lead to]{.underline} [**World War III**.
On the other side of the ledger, [**NATO's** nuclear weapons]{.mark}
presumably [**deter Russia** from expanding the war to **NATO
countries**]{.mark}, such as Poland, Romania or the Baltic states.
[Thus, the]{.mark}]{.underline} nuclear **[[balance of
terror]{.underline}]{.mark}** [likely]{.underline} [**[deters a wider
European war]{.underline}** [but leaves]{.underline}
**[Ukraine]{.underline}** [to]{.underline}]{.mark} [struggle on with
only]{.underline} **[limited support]{.underline}** [and perhaps
eventually to [be]{.mark}]{.underline}
[**[swallowed]{.underline}**]{.mark}. On balance, NATO states do not
seem very reassured by their vaunted nuclear deterrence. They continue
to worry about the (remote) possibility of a Russian conventional attack
beyond Ukraine.

#### Residual tensions can be [managed]{.underline} to avoid miscalculation\-\--[even if]{.underline} Russia [wins]{.underline}

Liana **Fix &** Michael **Kimmage 2/18**, Liana Fix is a Resident Fellow
at the German Marshall Fund, in Washington, D.C.; Michael Kimmage is
Professor of History at the Catholic University of America and a
Visiting Fellow at the German Marshall Fund, served on the Policy
Planning Staff at the U.S. Department of State, where he held the
Russia/Ukraine portfolio, "What If Russia Wins?," Foreign Affairs,
2/18/2022,
https://www.foreignaffairs.com/articles/ukraine/2022-02-18/what-if-russia-wins

IMPERILING EUROPE\'S EAST

[[In]{.mark} the event of a]{.underline} **[[Russian
victory]{.underline}]{.mark}** [in Ukraine]{.underline}, Germany's
position in Europe will be severely challenged. Germany is a marginal
military power that has based its postwar political identity on the
rejection of war. The ring of friends it has surrounded itself with,
especially in the east with Poland and the Baltic states, risks being
destabilized by Russia. France and the United Kingdom will assume
leading roles in European affairs by virtue of their comparatively
strong militaries and long tradition of military interventions. The key
factor in Europe, however, will remain the United States. NATO will
depend on U.S. support as will the anxious and imperiled countries of
Europe's east, the frontline nations arrayed along a now very large,
expanded, and uncertain line of contact with Russia, including Belarus
and the Russian-controlled parts of Ukraine.

Eastern member states, including Estonia, Latvia, Lithuania, Poland, and
Romania, will likely have substantial numbers of NATO troops permanently
stationed on their soil. A request from Finland and Sweden to gain an
Article 5 commitment and to join NATO would be impossible to reject. In
Ukraine, EU and NATO countries will never recognize a new Russian-backed
regime created by Moscow. But they will face the same challenge they do
with Belarus: wielding sanctions without punishing the population and
supporting those in need without having access to them. Some NATO
members will bolster a Ukrainian insurgency, to which Russia will
respond by threatening NATO members.

Ukraine's predicament will be very great. Refugees will flee in multiple
directions, quite possibly in the millions. And those parts of the
Ukrainian military that are not directly defeated will continue
fighting, echoing the partisan warfare that tore apart this whole region
of Europe during and after World War II.

[The permanent state of **escalation** [between Russia and **Europe**
may **stay cold**]{.mark} from a **military perspective**. It is likely,
though, to be **economically hot**]{.underline}. The sanctions put on
Russia in 2014, which were connected to formal diplomacy (often referred
to as the "Minsk" process, after the city in which the negotiations were
held), were not draconian. They were reversible as well as conditional.
Following a Russian invasion of Ukraine, new sanctions on banking and on
technology transfer would be significant and permanent. They would come
in the wake of failed diplomacy and would start at "the top of the
ladder," according to the U.S. administration. In response, Russia will
retaliate, quite possibly in the cyber-domain as well as in the energy
sector. Moscow will limit access to critical goods such as titanium, of
which Russia has been the world's second-largest exporter. [This [war of
**attrition**]{.mark} will **test both**]{.underline} sides. Russia will
be ruthless in trying to get one or several European states to back away
from economic conflict by linking a relaxation in tension to these
countries' self-interest, thus undermining consensus in the EU and NATO.

Europe's strong suit is its economic leverage. Russia's asset will be
any source of domestic division or disruption in Europe or in Europe's
transatlantic partners. Here Russia will be proactive and opportunistic.
If a pro-Russian movement or candidate shows up, that candidate can be
encouraged directly or indirectly. If an economic or political sore
point diminishes the foreign policy efficacy of the United States and
its allies, it will be a weapon for Russian propaganda efforts and for
Russian espionage.

Much of this is already happening. But a war in Ukraine will up the
ante. Russia will use more resources and be unchained in its choice of
instruments. The massive refugee flows arriving in Europe will
exacerbate the EU's unresolved refugee policy and provide fertile ground
for populists. The holy grail of these informational, political, and
cyberbattles will be the 2024 presidential election in the United
States. Europe's future will depend on this election. The election of
Donald Trump or of a Trumpian candidate might destroy the transatlantic
relationship at Europe's hour of maximum peril, putting into question
NATO's position and its security guarantees for Europe.

TURNING NATO INWARD

For the United States, a Russian victory would have profound effects on
its grand strategy in Europe, Asia, and the Middle East. First, Russian
success in Ukraine would require Washington to pivot to Europe. No
ambiguity about NATO's Article 5 (of the kind experienced under Trump)
will be permissible. Only a strong U.S. commitment to European security
will prevent Russia from dividing European countries from one another.
This will be difficult in light of competing priorities, especially
those that confront the United States in a deteriorating relationship
with China. But the interests at stake are fundamental. The United
States has very large commercial equities in Europe. The European Union
and the United States are each other's largest trade and investment
partners, with trade in goods and services totaling \$1.1 trillion in
2019. A well-functioning, peaceful Europe augments American foreign
policy---on climate change, on nonproliferation, on global public
health, and on the management of tensions with China or Russia. If
Europe is destabilized, then the United States will be much more alone
in the world.

NATO is the logical means by which the United States can provide
security reassurance to Europe and deter Russia. A war in Ukraine would
revive NATO not as a democracy-building enterprise or as a tool for
out-of-area expeditions like the war in Afghanistan but as the
unsurpassed defensive military alliance that it was designed to be.
Although Europeans will be demanding a greater military commitment to
Europe from the United States, a broader Russian invasion of Ukraine
should drive every NATO member to increase its defense spending. For
Europeans, this would be the final call to improve Europe's defensive
capabilities---in tandem with the United States---in order to help the
United States manage the Russian-Chinese dilemma.

The nuclear superpowers would have to keep their outrage in check.

For a Moscow now in permanent confrontation with the West, Beijing could
serve as an economic backstop and a partner in opposing U.S. hegemony.
In the worst case for U.S. grand strategy, China might be emboldened by
Russia's assertiveness and threaten confrontation over Taiwan. But there
is no guarantee that an escalation in Ukraine will benefit the
Sino-Russian relationship. China's ambition to become the central node
of the Eurasian economy will be damaged by war in Europe, because of the
brutal uncertainties war brings. Chinese irritation with a Russia on the
march will not enable a rapprochement between Washington and Beijing,
but it may initiate new conversations.

The shock of a big military move by Russia will likewise raise questions
in Ankara. President Recep Tayyip Erdogan's Turkey has been enjoying the
venerable Cold War game of playing off the superpowers. Yet Turkey has a
substantial relationship with Ukraine. As a NATO member, it will not
benefit from the militarization of the Black Sea and the eastern
Mediterranean. Russian actions that destabilize the wider region could
push Turkey back toward the United States, which could in turn drive a
wedge between Ankara and Moscow. This would be good for NATO, and it
would also open up greater possibilities for a U.S.-Turkish partnership
in the Middle East. Rather than a nuisance, Turkey could turn into the
ally it is supposed to be.

A bitter consequence of a wider war in Ukraine is that
[**[Russia]{.underline}** [and the]{.underline}
**[U]{.underline}**]{.mark}nited **[[S]{.underline}]{.mark}**tates would
now encounter each other as enemies in Europe. Yet they [[will be
**enemies** who]{.underline} **[cannot afford to take hostilities beyond
a]{.underline}**]{.mark} [**certain [threshold]{.mark}**[.
However]{.mark} far **[apart their]{.mark}** world[**views**,
however]{.mark}]{.underline} [**ideologically [opposed]{.mark}**[, the
world's]{.mark} two most significant [nuclear powers will]{.mark} have
to **[keep their outrage in check]{.mark}**. This will amount to
[a]{.mark}]{.underline} fantastically tricky [**[juggling act]{.mark}**:
a state [of **economic warfare** and **geopolitical
struggle**]{.mark}]{.underline} across the European continent, yet a
state of affairs [that [does]{.mark}]{.underline} [**[not allow
escalation]{.mark} to tip [into]{.mark} outright [war]{.mark}**. At the
same time, U.S.-Russian confrontation can in the worst case extend to
**proxy wars**]{.underline} in the Middle East or Africa if the United
States decides to reestablish its presence after the catastrophic
Afghanistan withdrawal.

[[Maintaining]{.underline} **[communication]{.underline}**]{.mark},
especially on strategic stability and cybersecurity, [[will
be]{.underline} **[crucial]{.underline}**]{.mark}[. It is notable that
U.S.-Russian cooperation on]{.underline} **[malicious
cyber-activities]{.underline}** **[continues]{.underline}**
[even]{.underline} [**during the current tensions**. The necessity of
maintaining rigorous arms control agreements will be even greater after
a Ukraine war and the sanctions regime that follows it]{.underline}.

#### Putin's aims are [limited]{.underline}

Mitch **Clarke 3/16**, director of news and content for Jacobs Media,
citing Craig Greathouse, associate department head in political science
and international affiars at UNG, "UNG prof: Conflict unlikely to expand
beyond Ukraine," AccessWDUN, 3/16/2022,
https://accesswdun.com/article/2022/2/1080789/ung-prof-conflict-unlikely-to-expand-beyond-ukraine

Experts are divided over what Russian President Vladimir [[Putin\'s end
game]{.underline}]{.mark} in Ukraine is, but [an international
affairs]{.underline} **[expert]{.underline}** [at]{.underline}
**[UNG]{.underline}** **[[doesn\'t]{.mark} think]{.underline}** [he\'ll
try to [invade]{.mark}]{.underline} [**[any]{.underline}**]{.mark} of
the **[[former Soviet bloc countries]{.underline}]{.mark}**.

Craig Greathouse, the associate department head in political science and
international affairs, believes [Putin [would]{.mark}]{.underline}
[**[like]{.underline}** [to reconstitute]{.underline}]{.mark}
[the]{.underline} old [Soviet Union. [But that might
be]{.mark}]{.underline} **[[out of]{.mark} his
[reach]{.mark}]{.underline}**, Greathouse said.

Former Soviet bloc [[countries]{.underline}]{.mark} like Estonia,
Latvia, Lithuania [[are]{.mark} now]{.underline} [**[members of
NATO]{.mark}**, and]{.underline} the provisions of the NATO treaty\'s
**[Article 5]{.underline}** might [cause]{.underline}
**[concern]{.underline}** for Russia.

\"[If he moves to]{.underline} **[[attack]{.underline}]{.mark}** these
countries, [it]{.underline} **[[activates Article
5]{.underline}]{.mark}** of the NATO Treaty,\" Greathouse said. \"And
Article 5 is very specific. It says, \'If any member of NATO is
attacked, all the other members of NATO will come to their defense.\'
And that includes the United States.\"

[**[Ukraine]{.mark}**, on the other hand, [is]{.mark}]{.underline}
[**[not]{.underline}**]{.mark} [a NATO member]{.underline} and has
perhaps the closest historical ties to Russia.

\"Before the Soviet Union broke apart, Ukraine was a significant element
of the Soviet Union,\" Greathouse said. \"In the past, it\'s been
described as the Soviet Union\'s breadbasket. There was also a lot of
industry, especially in the eastern part of the country. Also it holds
close ties to the Crimea region, which holds one of the few ports that
Russia can use to get into the Mediterranean.\"

Greathouse said [it\'s too early to know what Putin\'s ultimate goal is.
[Putin]{.mark}, in fact, [may only be trying to claim
a]{.mark}]{.underline} **[[portion]{.mark} of Ukraine]{.underline}**.

\"That\'s going to be an interesting question, because
[[it\'s]{.underline} **[not]{.underline}**]{.mark} quite
[**[clear]{.underline}** [how **far**]{.underline} [he\'s **going to
go**]{.underline}]{.mark} [with]{.underline} **[Ukraine
yet]{.underline}**,\" he said. \"[Is he just going to take]{.underline}
**[parts]{.underline}** of it**[?]{.underline}** [Or]{.underline} is he
going to try and take [the]{.underline} **[whole country?]{.underline}**
If the reports are correct, with 190,000 Russian soldiers, I don\'t know
if he can basically control the entire Ukraine.\"

[[Greathouse]{.underline} **[doesn\'t believe the conflict will spread
beyond Ukraine]{.underline}**]{.mark} **[in a physical
war]{.underline}**. But an increase in cyberattacks is likely.

### AT: Russia War Impact\-\--AT: Ukraine\-\--Not Nuclear\-\--Ext

#### Won't go nuclear or draw in NATO

Tom **Rogan 2/28**, foreign policy/national security writer for the
Washington Examiner, Bachelor of Arts in War Studies from King\'s
College London, a Master of Science in Middle East politics from SOAS,
and a Graduate Diploma in Law from the University of Law, London, "Why
Russia is highly unlikely to use nuclear weapons," Washington Examiner,
2/28/22,
https://www.washingtonexaminer.com/restoring-america/courage-strength-optimism/why-russia-is-highly-unlikely-to-use-nuclear-weapons

[As Russia struggles to **conquer Ukraine**]{.underline}, Vladimir
[Putin has moved his **strategic nuclear forces** to a **heightened
alert posture**]{.underline}.

Satellite imagery also indicates that the Russian Northern Fleet has
moved more ballistic missile submarines into Arctic and Barents sea
patrol sectors. While U.S. nuclear forces remain at standard readiness
levels, the U.S. military has a greater baseline readiness and redundant
nuclear strike capability than does Russia.

I suspect [the]{.underline} ultimate [**[intent]{.underline}** [of
Putin\'s]{.underline}]{.mark} [public nuclear [threat is]{.mark}
to]{.underline} **[[dangle]{.underline}]{.mark}** [the **[risk of
escalation]{.mark}**]{.underline} [so as [to]{.mark}]{.underline}
**[[deter]{.mark} Western unity]{.underline}** [on]{.underline} further
**[[sanctions]{.underline}]{.mark}**. This would not be the first time
--- in October 2020, Russian state media threatened to turn Germany into
a \"radioactive desert\" following that nation\'s hosting of NATO
nuclear exercises. The pressure worked. Nudged by left-wing elements in
his Social Democratic Party, Chancellor Olaf Scholz cooled Germany\'s
nuclear commitments under NATO.

In Ukraine\'s case, [Putin\'s nuclear threats likely come in his
anticipation of massive Russian **conventional attacks
upon**]{.underline} Ukrainian **[civilian population
centers]{.underline}** such as Kyiv. Russian forces are struggling to
break through determined Ukrainian resistance. Putin\'s form in Chechnya
and Syria suggests he will attempt to smash Ukraine\'s civilian morale
and thus its government\'s will to resist. But Putin also needs the West
to hesitate before further punishing him for the terror yet to come.

[**Regardless**, the [risk of]{.mark} a]{.underline} Russian **[nuclear
[strike]{.mark}]{.underline}** [[remains]{.underline} **[very
low]{.underline}**]{.mark} for two further reasons.

First off, [a nuclear strike would]{.underline} [**[not]{.mark} be [in
Russia\'s]{.mark} or Putin\'s [interest]{.mark}**. The Kremlin appears
to have been shocked by the significant]{.underline} Western
**[sanctions]{.underline}** **[already]{.underline}**
[imposed]{.underline} upon its economy and against Putin\'s person. Yet
[were Russia to **detonate a nuclear warhead**]{.underline} over
Ukrainian forces or Kyiv, [[it would]{.mark} likely
[precipitate]{.mark}]{.underline} [[**total economic
isolation**]{.mark}. This would have]{.underline} a **[profound
impact]{.underline}** [on Russian **society**]{.underline}, likely
[precipitating]{.underline} **[mass protests]{.underline}** against
Putin\'s rule [and]{.underline} perhaps [[encouraging
a]{.underline}]{.mark} [**palace [coup]{.mark}**. Even]{.underline}
**[erstwhile]{.underline}** Russian [partners such as]{.underline}
[**[China]{.underline}** [would]{.underline}]{.mark} likely [be pushed
into]{.underline} **[[support]{.mark}ing
[sanctions]{.mark}]{.underline}** in such a scenario, fearing the
catastrophic public relations damage of failing to do so. (China has a
vested interest in strengthening its relations with the European Union.)
[[Putin]{.mark} may be many things, but]{.underline} **[he [is not
stupid]{.mark}]{.underline}**. And [despite]{.underline} the
**[speculation]{.underline}**, I understand that [there is]{.underline}
**[no]{.underline}** high-quality [**evidence** to suggest]{.underline}
that Putin is mentally ill or has otherwise lost his mind.

Second, [it is [far from certain]{.mark} that [Russian]{.mark}
**military [forces]{.mark}** [would]{.mark} actually [**carry out**
a]{.mark} nuclear attack [order]{.mark}]{.underline}. Like the U.S.,
Russian nuclear command and control has traditionally relied upon two-
to three-person release protocols to ensure a legitimate nuclear order.

The exact [Russian nuclear release protocols]{.underline} are highly
classified and unknown but [would]{.underline} likely [involve
both]{.underline} Defense Minister Sergei **[Shoigu]{.underline}**
[and]{.underline} Chief of the General Staff Valery **[Gerasimov\'s
authentication]{.underline}** [of Putin\'s order.]{.underline} While
Putin\'s more recent centralization of power may have altered these
protocols, [the general staff would]{.underline} still [need
to]{.underline} **[distribute attack orders]{.underline}** [to nuclear
forces]{.underline}. Those forces would then need to carry out the
order. That matters because [these personnel know that any nuclear
strike would entail]{.underline}, as a minimum, **[catastrophic
sanctions]{.underline}** [and the degradation of Russian military
history and honor. In the worst-case scenario, a nuclear strike would
risk an]{.underline} **[escalation spiral]{.underline}** that ends with
nuclear war against NATO.

[**[Gerasimov isn\'t crazy]{.underline}**. **[Nor]{.underline}**]{.mark}
**[are]{.underline}** most of **[the [security elite]{.mark} around
Putin.]{.underline}** They know that once one nuclear weapon is used,
U.S., British, and French nuclear forces would immediately move to very
high alert status. Russian forces would then do the same. The Russians
know that this dynamic would greatly exacerbate the risk of
miscalculation.

Consider, for example, that Russian ballistic missile submarines are
almost constantly shadowed by U.S. and British attack submarines while
on patrol. After a Russian nuclear strike on Ukraine, one miscalculation
might lead to one undersea battle. Fearing an imminent attack at scale,
this might then lead to one nation\'s preemptive strike against the
other nation\'s nuclear assets. This is just a hypothetical scenario,
but it illustrates how even the hint of nuclear warfare could lead to a
worldwide shooting war. The Russians know this.

The bottom line: [Putin and his ultra-hawk spymaster Nikolai Patrushev
might support a nuclear strike, but it\'s **highly unlikely they will
order one**]{.underline}. It\'s even less likely that others in Putin\'s
inner circle would support it. [They would more likely
strike]{.underline} **[him]{.underline}** out [before agreeing to fire
off nukes.]{.underline}

#### There are [intermediate steps]{.underline} in the escalatory ladder\-\--ongoing conflict doesn't necessarily mean nuclear war

Ryan **Faith 3/11**, former defense and national security editor at VICE
News and congressional staffer, writes about defense and space policy,
"Ukraine Isn't World War III. It's Not Even Close.," Daily Beast,
3/11/2022,
https://www.thedailybeast.com/ukraine-isnt-world-war-iii-its-not-even-close

[[However]{.underline} **[unnerving]{.underline}**]{.mark} [Russia's
invasion of [Ukraine is]{.mark}, the fight is [a]{.mark}]{.underline}
**[[long, long way from]{.mark} the titanic, globe-spanning conflict
that would constitute a "[world war]{.mark}."]{.underline}**

[For]{.underline} **[Ukraine]{.underline}**, [this is]{.underline} an
**[existential]{.underline}** conflict for national survival. [For
the]{.underline} **[rest]{.underline}** of the world, [[this]{.mark}
conflict [may]{.mark}]{.underline} [[**seem terrifying**, but that's
what]{.underline} **[all wars look like]{.underline}**]{.mark} to anyone
paying attention up close---especially one involving a nuclear-armed
combatant. The world hasn't seen a high-intensity conflict between two
relatively modern militaries in Europe since World War II. Of course
this is a shock to the system.

If the U.S. and NATO want to constrain Russia's actions in Ukraine,
[there are **many** options **short of full conflict.**]{.underline}

For instance, during the Korean War, the Soviet Union sent both fighter
aircraft and pilots to fly them against U.S. aircraft. This playbook
could be repeated with NATO countries contributing equipment and troops.
More recently, Russia deployed military "contractors" throughout the
eight years of destabilization in Ukraine to provide Moscow with
plausible deniability. The U.S. and NATO could likewise deploy
contractors, even if they are used in limited non-combat roles such as
supply and building fortifications. Plans for Pentagon cyberattacks have
been on the books for a while. The point is, there are options for the
U.S. and NATO to exert military pressure on Russia without escalating to
an all-out war.

The problem now is that preemptively panicking over potential escalation
effectively grants Vladimir Putin control over the size and scale of the
conflict.

Crucially, [[just because a conflict]{.underline}
**[could]{.underline}** [grow]{.underline}]{.mark} [into a larger-scale,
multi-nation fight [doesn't mean it]{.mark}]{.underline} **[necessarily
[will]{.mark}]{.underline}**. The [[management of]{.mark} a
[conflict\'s]{.mark}]{.underline} [**[size]{.underline}**
[and]{.underline} **[scope]{.underline}** [are
things]{.underline}]{.mark} that [[participants]{.underline}]{.mark} try
to [**closely [monitor and manage]{.mark}**[. Jumping to]{.mark} the
conclusion that]{.underline} **[literally every move by
NATO]{.underline}** [will lead to]{.underline} an **[[apocalyptic
war]{.mark} for the ages]{.underline}** [[is]{.underline}]{.mark}
[**grossly premature**. It's [like]{.mark}]{.underline}
[**[forwarding]{.mark} matches [from]{.mark} a [dating]{.mark} app [to a
wedding]{.mark} planner**. [There are]{.mark}]{.underline} some
**[important [intermediate steps]{.mark}]{.underline}** you can't skip.

### 

### \*NORMS ADV\* 

### Squo Solves\-\--1NC

#### The US is already innovating, AND [existing]{.underline} NATO structures can help set norms

Edward Hunter **Christie 22**, Senior Research Fellow at the Finnish
Institute of International Affairs, "Defence Cooperation in Artificial
Intelligence: Bridging the Transatlantic Gap for a Stronger Europe,"
European View, vol. 21, no. 1, SAGE Publications Ltd, 04/01/2022, pp.
13--21

Investment challenges

As noted in the introduction, [there is a significant **gap** between
overall **US** and **European** **defence** spending levels. This
general pattern]{.underline} **[also]{.underline}** [holds for
defence]{.underline} **[r]{.underline}**esearch [and]{.underline}
**[d]{.underline}**evelopment spending. In 2020, EU spending in this
area amounted to €8 billion (EDA 2021). For the US, with caveats as to
comparability, expenditure for 'research, development, test and
evaluation' totalled approximately €90 billion3 in the 2021 fiscal year
(from October 2020 to September 2021), or about 10 times more.

Investment [challenges go]{.underline} **[beyond]{.underline}** issues
of [**scale**. The US]{.underline} also [has]{.underline} **[greater
experience]{.underline}** [in]{.underline} the **[setting
up]{.underline}** [and]{.underline} **[operation]{.underline}**
[of]{.underline} **[structures]{.underline}** [to]{.underline}
**[promote]{.underline}** both [**military and dual-use innovation**.
While the best-known institution is the]{.underline}
**[D]{.underline}**efense **[A]{.underline}**dvanced
**[R]{.underline}**esearch **[P]{.underline}**rojects
**[A]{.underline}**gency, **[other]{.underline}** [US government
structures are also relevant in discussions on fostering innovation in
**AI**]{.underline} [for]{.underline} [**military applications**. A
much-discussed example is **In-Q-Tel**]{.underline}, which was
originally set up as the state venture-capital arm of the Central
Intelligence Agency. To illustrate the influence of the In-Q-Tel
example, one may note that both its current Chief Executive Officer,
Chris Darby, and one of its former Chief Executive Officers, Gilman
Louie, served among the 15 commissioners of the National Security
Commission on Artificial Intelligence.4 This was a temporarily created
expert commission mandated by the US Congress to provide policy
recommendations for a whole-of-government and whole-of-society approach
for US AI policy.5

With In-Q-Tel, the idea is to learn from private-sector practices in the
area of venture-capital investment and repurpose them for state needs
and more patient time horizons. A supported company should pursue
product development strategies aimed at serving both civilian markets
and government needs. In this way, rather than effectively taking over a
commercial company and limiting its growth potential to future
government contracts alone, the government body encourages an
intermediate trajectory made up of mixed revenue streams, in the hope
that this will generate greater returns to scale and higher efficiency
thanks to the disciplining effect of private-sector competition.
Conversely, the advantage of this approach as compared to not
intervening at all is that the commercial company will integrate current
and likely future government needs into its product and
business-development strategy, rather than ignoring them and finding
itself, at a later date, unable to supply the government sector
according to the latter's requirements.

A related issue which falls between what can be achieved with new
investment instruments and new protections that can be assured through
the screening of foreign direct investment is the provision of
investment from trusted private investors to the technology sector.
[Certain technology companies that are not part of the traditional
defence industry may be developing dual-use products]{.underline} that
are [of potential interest to the defence sector while having limited
awareness of national security concerns. This may make them vulnerable
targets for both licit and illicit attempts to **acquire their
technologies**]{.underline} [on the part of **foreign state
actors**]{.underline}. [At the same time, their business development
needs may lead them to seek **investment** from]{.underline} **[any
potential source]{.underline}**, thus [exposing them to potential
**risks**]{.underline}. To respond to this challenge, the US Department
of Defense has launched a scheme called the Trusted Capital Marketplace
(US Department of Defense 2021a).

[Building on these considerations]{.underline}, the
**[NATO]{.underline}** Innovation Unit [has developed two new
instruments for Allied use]{.underline} which were announced to the
public in October 2021 (NATO 2021a; 2021b). [Both]{.underline}
instruments [aim to foster]{.underline} **[tech]{.underline}**nological
**[innovation]{.underline}** [with a deliberate focus on dual-use
applications and on enterprises with mixed (potential) revenue streams.
The first instrument is the Defence Innovation Accelerator for the North
Atlantic (DIANA), which is a NATO instrument, that is, it involves the
participation of all 30 NATO Allies. The second instrument is the NATO
Innovation Fund, which in NATO terminology is a 'multinational'
instrument]{.underline}, namely one [that Allies freely opt
into]{.underline}.

[DIANA will aim to accelerate the]{.underline}
**[adoption]{.underline}** [of dual-use technological solutions through
several interlocking components.]{.underline}6 First, [it will develop a
network of national organisations, in particular test centres and
innovation accelerators]{.underline}. Second, [it will competitively
select private-sector innovators and allow them to use national
organisations in the network to interface with military end users and
military capability-development specialists]{.underline}. Third, [it is
envisaged that DIANA will provide mentorship and education services for
private innovators to familiarise them with the opportunities and
responsibilities inherent to the defence and security
sector]{.underline}. Fourth, [DIANA will develop a database of trusted
financial investors from Allied nations and support matchmaking between
investors and innovators]{.underline}. Fifth and finally, [DIANA will
also provide expert advice on defence and security innovation to all
relevant stakeholders, including private-sector and academic
entities.]{.underline}

[Regarding the NATO Innovation Fund, 17 Allies had **opted into the
Fund**]{.underline} [as of the date of its announcement]{.underline} in
October 2021. [The participating Allies will inject up to €1 billion
into Allied innovation ecosystems over the next 15 years]{.underline}.
[The Fund aims to attract **additional private
investments**]{.underline} [due to the de-risking effect, both financial
and technological, thanks to state co-funding and diligence and
screening efforts. The funds are intended to be used for **long-term
support of 'deep tech' innovative companies**]{.underline}, that is, for
advanced research into AI, quantum and related technologies that may
have both military and civilian applications. [Due diligence and
security screening practices will aim to ensure that both private
investors and fund recipients are **trusted** entities.]{.underline}

### Interop Fails\-\--1NC

#### Interoperability challenges are [structural]{.underline}\-\--they [can't be fixed]{.underline} through consultation or dialogue. 

Edward Hunter **Christie 22**, Senior Research Fellow at the Finnish
Institute of International Affairs, "Defence Cooperation in Artificial
Intelligence: Bridging the Transatlantic Gap for a Stronger Europe,"
European View, vol. 21, no. 1, SAGE Publications Ltd, 04/01/2022, pp.
13--21

Interoperability challenges

Interoperability can be defined as 'the ability of systems, units or
forces to provide services to, and accept services from other systems,
units or forces and the use the services so exchanged to enable them to
operate effectively together' (Dufour 2018, 1).

[The]{.underline} first [general challenge to interoperability is the
**overall gap**]{.underline} [between the US and Europe in terms
of]{.underline} [**total defence investment**, as well as
in]{.underline} terms of **[civilian technological
attainment]{.underline}** [with]{.underline} respect to
**[AI]{.underline}** and related technologies. [There is]{.underline}
**[no]{.underline}** single [**solution to this problem**, which is
much]{.underline} **[broader]{.underline}** [in scope than]{.underline}
[**traditional military--technical standards**, such as those pursued
in]{.underline} the **[NATO]{.underline}** context [through]{.underline}
[**existing mechanisms**. For this **broad**]{.underline}
[challenge]{.underline}, **[overall]{.underline}** [policy decisions
relating to]{.underline} national **[investment]{.underline}** choices
[and]{.underline} **[tech]{.underline}**nology **[policy]{.underline}**
coordination [between the two sides]{.underline} of the Atlantic [are
of]{.underline} **[particular importance]{.underline}**. Further
discussion of this follows in the sections on investment challenges and
international security challenges.

[A]{.underline} **[second]{.underline}** [challenge]{.underline} to
interoperability [is that]{.underline}, as far as digital technologies
are concerned, [the]{.underline} **[civilian]{.underline}**
[sector]{.underline} of the economy, [on both sides]{.underline} of the
Atlantic, [is]{.underline} **[more advanced]{.underline}**, more
**[dynamic]{.underline}** [and]{.underline} also **[not]{.underline}**
especially **[oriented]{.underline}** [towards]{.underline} meeting
**[military needs]{.underline}**. For decades, the military sector has
represented only a very small share of the total sales volume of the
computing and semiconductor industries. The same pattern is repeating
itself currently with AI. This stands [in]{.underline} **[great
contrast]{.underline}** [to]{.underline} **[narrower]{.underline}**
[dual-use technologies, for example aerospace, where the military sector
remains inherently]{.underline} **[important]{.underline}**. With
digital technologies, defence institutions are under much more pressure
to either adapt to civilian industry products and standards or to pay a
significant premium to suppliers to secure military-grade equipment and
software.

[A third challenge]{.underline} to interoperability [lies in how AI is
implemented in **practice**]{.underline}. To set up a bespoke
machine-learning algorithm in a given data environment, best practice in
the software industry is to pursue some variant of **['agile'
development]{.underline}**. This involves a very different
product-development cycle, essentially proceeding [with
multiple]{.underline} **[rapid iterations]{.underline}** [of
an]{.underline} **[imperfect product]{.underline}** that is released in
preliminary versions and later revised---like software products released
in various 'beta versions'---with upgrades developed over time. This
**[contrasts greatly]{.underline}** [with the traditional production of
major military platforms, which puts a]{.underline}
**[premium]{.underline}** [on]{.underline} strict **[quality
control]{.underline}** [and]{.underline} **[compliance]{.underline}**
with requirements [at]{.underline} **[every development
step]{.underline}**---an approach referred to in the software industry
as 'waterfall' development (Christie 2021b, 87). **[Agile]{.underline}**
product [development may pose **challenges**]{.underline}
[to]{.underline} [**interoperability**. Unless very tight standards are
applied, there is a considerable risk of]{.underline}
**[divergences]{.underline}** in how different national institutions go
about solving a particular AI or data analytics problem.

With large traditional military platforms there are long time frames
during which states can take coordination steps, either by purchasing
the same platforms, or by building consensus in terms of requirements
and standards. However, [when a]{.underline} comparatively **[small
team]{.underline}** [works **dynamically**]{.underline} [to generate
an]{.underline} **[algorithmic solution]{.underline}** [to
a]{.underline} **[particular problem]{.underline}** [in]{.underline} a
matter of **[weeks]{.underline}** or months, [traditional coordination
through existing consultation mechanisms may pose]{.underline} **[risks
to the speed advantage inherent to agile development]{.underline}**.
Conversely, once a solution has been developed, its adoption in somewhat
different environments may be challenging for a range of technical
reasons. None of these issues is insurmountable, but they do pose, in a
new light, classical trade-offs between the benefits of inventiveness
and dynamism, on the one hand, and those of imposing constraints through
standards and other harmonising measures to ensure that new products can
be broadly used and shared on the other. In the case of AI, a typical
observation is that there are many excellent prototypes and pilot
projects in numerous defence institutions, but [there are]{.underline}
also **[serious]{.underline}** outstanding **[challenges]{.underline}**
[in terms of **scaling up** to]{.underline}
**[enterprise]{.underline}**-wide [solutions, **let alone Alliance-wide
solutions**]{.underline}.

### 

### Governance Fails\-\--1NC

#### Other states will [inevitably]{.underline} deploy militarized AI and future tech\-\--attempts at [norm-setting]{.underline} just signal [weakness]{.underline} and [cede the race]{.underline} to adversaries. 

Matt **Bartlett 19**, Lecturer in the Faculty of Law at the University
of Auckland, focuses on the gauntlet of legal and policy issues raised
by technology, particularly emerging technologies like AI, blockchain
and cryptocurrency, "The AI Arms Race In 2019",
<https://towardsdatascience.com/the-ai-arms-race-in-2019-fdca07a086a7>

This piece will show just how ineffective such activism has been,
however well-intentioned. [[The **arms race** in **AI** is]{.mark}
**already [underway]{.mark}**]{.underline} --- [[and has been for
**years**]{.underline}]{.mark}. It is now 2019, and [[we]{.underline}
**[cannot]{.underline}**]{.mark} **[waste time [pretend]{.mark}ing
[Pandora's Box hasn't]{.mark} already [been
opened]{.mark}]{.underline}**. [This is the time to take stock
of]{.underline} the latent evidence of [weaponised AI, and consider the
geopolitical incentives]{.underline} that produced this quagmire.

Ready, Set, Gone

[A tour of]{.underline} the [countries driving the AI arms race may as
well start in **Moscow**]{.underline}. [[Putin's
government]{.underline}]{.mark}, hardly one to [fall in line with
existing global
norms](https://www.vox.com/2014/9/3/18088560/ukraine-everything-you-need-to-know),
[[is]{.underline} **[categorically opposed]{.underline}**
[to]{.underline}]{.mark} [the [creation of a]{.mark} **new
[norm]{.mark}**]{.underline} [([against autonomous
weapons]{.underline}]{.mark}). [Moscow has even]{.underline} ---
successfully --- [[lobbied to reduce the number of
days](https://futureoflife.org/2018/11/26/handful-of-countries-including-the-us-and-russia-hamper-discussions-to-ban-killer-robots-at-un/)
states meet just to discuss the issue.]{.underline} [Russia]{.underline}
itself has
[[claimed](https://eandt.theiet.org/content/articles/2017/12/russia-rejects-potential-un-killer-robots-ban-official-statement-says/)
that a limit on autonomous weapon development is
**inappropriate**]{.underline} given "few such weapons have ever been
developed".

Selflessly, Russia is working hard on making a lie of such a claim.
Leaked budgets for AI-specific research and development for 2019--2021
show state investment
([previously](https://www.defenseone.com/technology/2019/01/russia-expect-national-ai-roadmap-midyear/154015/)
\$490m USD) almost
[doubling](https://www.defenseone.com/technology/2019/01/russia-expect-national-ai-roadmap-midyear/154015/)
over the next three years. Russian intent in this area is no secret.
Just ask [General [Gerasimov]{.mark}]{.underline}, a general and [Chief
of the General Staff of the Russian Forces]{.underline}: [[he [is on
record]{.mark}](http://www.militarynews.ru/story.asp?rid=1&nid=476975)
with the state news agency as [saying]{.mark} "robots will be one of the
main features of future wars... [\[Russia\] is seeking to **completely
automate** the battlefield]{.mark}."]{.underline}

For a taste of what to expect in future wars, consider this announcement
from the crown jewel of Russian arms manufacturers: Kalashnikov (maker
of the ubiquitous AK-47). The [arms giant is developing and
launching](https://news.vice.com/en_us/article/vbzq8y/russian-weapons-maker-kalashnikov-developing-killer-ai-robots)
an entire range of autonomous weapons, each with a 'neural network'
enabling the machines to pick out targets and decide autonomously
whether to engage. Another Russian weapons manufacturer, Degtyarev, [has
developed](https://www.forbes.com/sites/noelsharkey/2018/11/28/killer-robots-from-russia-without-love/)
an autonomous 'suicide machine' called the Nerekhta. This drone is built
to stealthily traverse close to a target, and then explode with the
force to destroy fortifications or enemy tanks.

It's important to emphasise here that the selected examples are just the
tip of the Russian iceberg: we have not touched the [autonomous nuclear
submarines](https://en.wikipedia.org/wiki/Status-6_Oceanic_Multipurpose_System),
the '[smart swarm' robot
missiles](https://www.newsweek.com/drones-swarm-autonomous-russia-robots-609399)
or the [Armata T-14 'super
tank'.](https://www.forbes.com/sites/noelsharkey/2018/11/28/killer-robots-from-russia-without-love/)
[The picture is pretty clear]{.underline}: [[Russia]{.mark} has a
**large** and **ambitious** autonomous weapons program in place, and
[sees this program as **central** to its **national security
interests**]{.mark}]{.underline}. [It follows that nobody should be
surprised to see Putin --- already --- on the offensive against the mere
spectre of a global AI arms ban.]{.underline}

More [surprising]{.underline}, [perhaps, is just how aligned the
**Russian** position on autonomous weapons is with that of the **United
States** and]{.underline} **[China]{.underline}**. Indeed, for a pair of
geopolitical powers that struggle mightily to [come to
consensus](https://en.wikipedia.org/wiki/List_of_vetoed_United_Nations_Security_Council_resolutions)
around contentious geopolitical issues, the United States and Russia
have displayed [remarkable cohesion in
opposing](https://www.independent.co.uk/life-style/gadgets-and-tech/news/killer-robots-un-meeting-autonomous-weapons-systems-campaigners-dismayed-a8519511.html)
any prohibitions on autonomous weapons.

Why might this be? No need to reach for the [particular idiosyncrasies
of the Commander in
Chief](https://www.npr.org/2018/07/17/629601233/trumps-helsinki-bow-to-putin-leaves-world-wondering-whats-up);
try a simple number (albeit one with a lot of zeros). The Pentagon [has
committed](https://www.theverge.com/2018/4/12/17229150/pentagon-project-maven-ai-google-war-military)
to a \$9 billion spend on American military AI, explicitly citing the
need to keep up with Russian and Chinese military technology. While the
American budget for AI represents just a fraction of overall defence
spending, much like in Russia, the figure has doubled in recent years.

Unique among the global powers, the US [has already
started](https://www.bloomberg.com/news/articles/2018-05-18/the-u-s-army-is-turning-to-robot-soldiers)
deploying autonomous vehicles in turbulent combat areas, in large
numbers and with significant roles. Autonomous naval vehicles have begun
to patrol the South China Sea --- with larger, more powerful machines
[on their
way](https://www.army-technology.com/features/mq4c-triton-drones/). Most
striking of all, American aerial drones have [rained
death](https://www.thebureauinvestigates.com/projects/drone-war) all
over Afghanistan and Pakistan under the Obama administration. It is
absolutely clear why the United States have opposed all moves towards a
prohibition of autonomous weapons: America wants to win the arms race,
not stop it.

For its part, China has actually indicated [its
support](https://www.lawfareblog.com/chinas-strategic-ambiguity-and-shifting-approach-lethal-autonomous-weapons-systems)
in April last year for a ban on battlefield use of autonomous weapons.
However, discerning readers ought to take the Chinese statement with
several grains of salt: the very same day, [the]{.underline} **[Chinese
air force]{.underline}** [[released
plans](https://mp.weixin.qq.com/s/xfw3hZkCiPJa-gX3GExEcQ) for an
'intelligent-swarm' design for a new autonomous drone]{.underline}. In a
similar vein, even [[in the last year]{.underline} [the **Chinese**
autonomous weapons program]{.underline}]{.mark} [has [**churned out**
success stories]{.mark}]{.underline}. [Some critics
feel](https://thediplomat.com/2018/08/the-trouble-with-chinas-edge-in-the-ai-arms-race/)
that China is taking an unassailable edge in the arms race; somewhat at
odds with Beijing's support for an AI weapons ban.

Elsa Kania for Lawfare
[posited](https://www.lawfareblog.com/chinas-strategic-ambiguity-and-shifting-approach-lethal-autonomous-weapons-systems)
that [the Chinese are pursuing a policy of 'strategic ambiguity' with
military AI]{.underline}: [displaying]{.underline} **[rhetorical
commitment]{.underline}** [to concerned human]{.underline} [rights
groups **without sacrificing any real flexibility**]{.underline}
[to]{.underline} **[develop cutting-edge lethal autonomous
weapons]{.underline}**. After all, [[becoming the global leader in
AI]{.underline}]{.mark} (including arms development) [[is [**literally**
the **official Chinese
plan**](https://www.nytimes.com/2017/07/20/business/china-artificial-intelligence.html)]{.underline}]{.mark};
[and Beijing [tends
not](https://www.hrw.org/world-report/2019/country-chapters/china-and-tibet)
to be too bothered with human rights groups]{.underline} when a
strategic interest is at stake.

In other words, the three biggest military powers in the world have
already:

Identified autonomous weapons as crucial to their military strategy;

Scaled up their resourcing and development of these weapons; and

Characterised the need for more advanced weapons in the context of other
powers' technological development.

We have to call this what it is: a serious [arms
race](http://www.oxfordbibliographies.com/view/document/obo-9780199743292/obo-9780199743292-0002.xml).

A Reckoning for Elon and Friends

In my view, [continued activism to block the development of lethal
autonomous weapons is untenable in light of the evidence
available]{.underline}. Elon Musk and the Future of Life's
well-intentioned
[[efforts](https://futureoflife.org/lethal-autonomous-weapons-pledge/)
to **forestall** an arms race in military AI have
**failed**]{.underline}. [At this stage, [**Russia**, **China**]{.mark}
[and]{.mark}]{.underline} the United States (not to mention [[**[plenty
of smaller
states]{.underline}**](https://www.timesofisrael.com/unmanned-subs-and-sniper-drones-israel-unveils-its-weapons-of-the-future/))
[are]{.underline} **[significantly invested]{.underline}**]{.mark}
[[in]{.mark} lethal [autonomous weapons,]{.mark}]{.underline} [[and view
them as **fundamental** to the **future of**]{.mark} **armed
[conflict]{.mark}**]{.underline}. [We can expect resourcing for military
AI to continue to escalate]{.underline}, and for states to begin to
deploy sophisticated drones in greater numbers.

It is important to note that [[this behaviour]{.underline}]{.mark} from
large states [[is **right in line**]{.underline}
[with]{.underline}]{.mark} **[their [rational
incentives]{.mark}]{.underline}** (rather than, for instance,
[conforming to a bad science fiction
plot](https://en.wikipedia.org/wiki/RoboCop#Plot)). [[It is **not
in**]{.mark} **any of the great [powers' interests]{.mark}** [to
**unilaterally**]{.mark} **support an AI weapons ban**]{.underline}
[and]{.underline} **[[de-escalate]{.mark} weapons
development]{.underline}**. [[If one were to do so,]{.underline}
[the]{.underline} [possibility that **another power
might**]{.underline}]{.mark} [**[take the opportunity]{.underline}** [to
develop an]{.underline}]{.mark} [**unassailable [edge]{.mark}** in
weaponised AI [is]{.mark} **nigh on [inevitable]{.mark}**]{.underline}.
[Battles]{.underline} between autonomous drones [[are likely to be
decided](https://www.researchgate.net/publication/256017649_The_Seabots_are_Coming_Here_Should_They_Be_Treated_as_'Vessels')
by which side has the more **powerful** software and
autonomy]{.underline}. Machines that are able to 'think', react,
manoeuvre and engage on their own accord will prevail over slower
machines, let alone sluggish humans.

#### Emerging tech regulation fails and AFF can't solve.

Greg E. **Marchant 20**, Regents Professor and Lincoln Professor of
Emerging Technologies, Law & Ethics, and Faculty Director, Center for
Law, Science & Innovation, Sandra Day O'Connor College of Law, Arizona
State University, "Governing Emerging Technologies," Vanderbilt Law
Review, Vol. 73(6), 2020, p. 1863-1865

I. [THE WICKED PROBLEM OF EMERGING TECHNOLOGY GOVERNANCE]{.underline}

[**[Emerging tech]{.mark}nologies**---such as synthetic biology, gene
editing, nanotechnology, artificial intelligence, internet of things, 3D
printing, drones, applied neurotechnologies, and blockchain and
cryptocurrencies---**[present]{.mark} a common set of [governance
challenges]{.mark}**]{.underline}.5 Perhaps [[most significant
is]{.mark} the "[pacing]{.mark} problem]{.underline}," where
[[the]{.mark} [pace of]{.mark} technology [development]{.mark} **[far
outstrips]{.mark}** the [capability of **regulatory systems**]{.mark}
[to keep up]{.mark}]{.underline}.6 Powered by growing market demand and
intense business competition, new technologies are being developed,
deployed, and commercialized faster than ever before.7 At the same time,
[traditional [governmental processes]{.mark} of legislation, regulation,
and judicial review [have been **slowed**]{.mark} [by]{.mark} increasing
**[bureaucratic requirements]{.mark}** [and]{.mark} the increasing
**[politicization]{.mark}** of **technological disputes**]{.underline}.8
[The [result]{.mark} of accelerating technology and decelerating
regulatory oversight [is a]{.mark} growing **[governance gap]{.mark}**.
Any new statutes or regulations affecting these new technologies are
likely to be outdated before the ink dries]{.underline}. As technology
governance expert David Rajeski has noted, "\[i\]f you think that any
existing regulatory framework can keep pace with this rate of change,
think again."9 Facing such a bleak prospect, [regulators often sensibly
defer regulation, waiting for a more stable technology plateau that may
or may not ever come]{.underline}.

[A second regulatory challenge of [many]{.mark} emerging technologies is
that **they [present]{.mark} [risks]{.mark} and concerns [outside the
scope of existing regulatory]{.mark} agency
[jurisdictions]{.mark}**]{.underline}.10 [Regulatory agencies, such as
the U.S. Food and Drug Administration, are restricted to regulating the
safety and efficacy of products]{.underline}. But [many applications of
emerging technologies raise broader ethical and social concerns relating
to human enhancement]{.underline}, "playing God," autonomy, dignity,
fairness, equitable access, privacy, and longer-term impacts on
society.11 [These issues are largely outside the safety and efficacy
scope of current agency jurisdictions and [thus]{.mark} often
[escape]{.mark} any regulatory [oversight]{.mark}]{.underline}.

Yet **[[another challenge]{.mark} to the regulation of emerging
technologies [is]{.mark} their [breadth of
application.]{.mark}]{.underline}** [Technologies such **as artificial
intelligence, nanotechnology, and blockchain [span the entire
industry]{.mark} [spectrum]{.mark}, as well as many nonindustrial
activities and sectors**. They are sometimes referred to as "enabling"
or "platform" technologies that, like computers or]{.underline} the
internet, [have the potential to affect virtually every industry
sector]{.underline}.12 There are thousands, if not tens or hundreds of
thousands, of ways these core technologies are used, each with their own
context of risks and benefits. [These broad applications not only
involve many different types of industries and businesses, but also
affect many other types of stakeholders and nongovernmental
organizations with particular interests]{.underline} in specific
applications. [The broad applications of these technologies also [span
many different]{.mark} regulatory [agencies]{.mark}]{.underline}, each
with their own organic statutes with different requirements, criteria,
and goals. [The end result of this multitude of applications, regulated
parties, stakeholders, and regulators is tremendous regulatory diversity
and complexity]{.underline}. Further complicating the regulatory
challenge, [emerging technologies are inherently international in
application, creating the need for some type of international
coordination.]{.underline}13

Finally, **[the [unprecedented uncertainty]{.mark} about emerging
technologies also [impedes]{.mark} effective
[regulation]{.mark}.]{.underline}**14 Beca[use the technologies are so
new and moving forward so quickly, there is enormous uncertainty about
the trajectories, benefits, and risks of these
technologies]{.underline}.15 Given these uncertainties, [it is possible
to paint unrealistically optimistic or pessimistic visions of the
technology]{.underline} at issue, thus [fostering public controversy,
conflict, and unease.16]{.underline}

In summary, **[the governance of emerging technologies is characterized
by complexity, diversity, and uncertainty]{.underline}**. **[These same
characteristics]{.underline}**---complexity, diversity, and
uncertainty---**[are the defining characteristics of a wicked problem.17
As a wicked problem, the [governance]{.mark} of emerging technologies
[is unlikely to be solved by a single]{.mark} or simple
[solution]{.mark}.]{.underline}** **[[Traditional]{.mark} government
[regulation]{.mark} [will not be sufficient]{.mark}, or many times even
appropriate, for emerging technologies]{.underline}**.[18 Rather than
traditional regulation---consisting of enforceable rules unilaterally
imposed by a regulatory agency---emerging technologies will require a
"governance" approach that expands the categories of responsible parties
beyond government to include the private sector, nongovernmental
organizations, and think tanks and also **expands the relevant oversight
mechanism beyond enforceable government regulations**]{.underline}.19
Four alternative governance approaches for emerging technologies are
discussed and evaluated in the next Part.

### Governance Fails\-\--2NC

#### Future tech and militarized AI deployment is [inevitable]{.underline}. Russia and China both view AI weapons as [absolutely critical]{.underline} to their defense strategy and national security in the coming years. They've both [already]{.underline} shot down efforts at developing international norms. There is [zero rational incentive]{.underline} for either of them to stop developing the weapons. That's Bartlett. 

#### [Zero shot]{.underline} at successful future technology arms control. 

\-\--LAWS = lethal autonomous weapons systems

Kyle **Hiebert 22**, Senior Program & Policy Analyst @ Enterprise
Machine Intelligence and Learning Initiative, deputy editor of the
Africa Conflict Monitor, "[[Are Lethal Autonomous Weapons
**Inevitable?**]{.underline}]{.mark} **[[It Appears
So]{.underline}]{.mark}**",
https://www.cigionline.org/articles/are-lethal-autonomous-weapons-inevitable-it-appears-so/

The Evolution of Automated Weapons

[In December 2021]{.underline}, [[the Sixth Rev]{.mark}iew
[Con]{.mark}ference of the UN Convention on Certain Conventional
Weapons]{.underline} (CCW), a 125-member intergovernmental forum that
discusses nascent trends in armed conflict and munitions, [[was [unable
to progress talks on new legal
mechanisms](https://www.aljazeera.com/news/2021/12/18/un-talks-fail-to-open-negotiations-on-killer-robots)]{.mark}
to rein in the development and use of [LAWS]{.mark}]{.underline}. [[The
failure continues]{.underline} **[eight years]{.underline}**
[of]{.underline} **[unsuccessful]{.underline}**]{.mark}
**[[efforts]{.underline}]{.mark}** [[toward]{.mark} either
[regulation]{.mark} or an outright ban]{.underline}. "At the present
rate of progress, [the pace of technological development risks
overtaking our deliberations," warned Switzerland's
representative]{.underline} as the latest conference wrapped up in
Geneva. **[No date is set for the forum's next meeting.]{.underline}**

Semi-autonomous weapons like self-guided bombs, military drones or
Israel's famed Iron Dome missile defence system have existed for
decades. In each case, a human operator determines the target, but a
machine completes the attack. On the other hand, LAWS --- derided by
critics as "slaughterbots" --- empower AI to identify, select and kill
targets absent human oversight and control. The Future of Life
Institute, a think tank based in Cambridge, Massachusetts, that is
focused on threats to humanity posed by AI and which organized the 2017
open letter to the United Nations, makes the distinction by saying, "In
the case of autonomous weapons the decision over who lives and who dies
is made solely by algorithms."

Myriad concepts of LAWS for air, ground, sea and space use have long
been speculated about. The difference now is that some models are ready
to be field tested. At the US Army's latest annual convention in
Washington, DC, in October 2021, attendees were treated to prototypes of
robotic combat dogs that could be built with rifles attached. Australian
robotics maker GaardTech announced in November an agreement with the
Australian army to demonstrate the Jaeger-C uncrewed vehicle some time
this year. Described as a "mobile robotic mine" or "beetle tank," the
bulletproof autonomous four-wheeled combat unit can be outfitted with an
armour-piercing large-calibre machine gun and sniper rifle and carry up
to 100 pounds of explosives for use in suicide attacks.

In The Kill Chain: Defending America in the Future of High-Tech Warfare,
Christian Bose, who served as top adviser to US Senator John McCain and
staff director of the Senate Armed Services Committee, tells of how
China intends to develop fully autonomous swarms of intelligent combat
drones. Recent actions bear this out. In addition to China's rapid
expansion of its own domestic drone industry, last September two
state-owned Chinese companies were linked to a Hong Kong firm that
acquired a 75 percent stake in an Italian company that manufactures
military-grade drones for the North Atlantic Treaty Organization. The
Hong Kong firm reportedly paid 90 times the valuation of the Italian
company to execute the takeover.

Meanwhile, a report prepared for the Pentagon's Joint Artificial
Intelligence Center in 2021 by CNA, a non-profit research and analysis
institute located in Arlington, Virginia, describes how Chinese
technology is enabling Russia's military to integrate autonomous AI into
dozens of its platforms. According to the report, this technology
includes anthropomorphic robots capable of carrying multiple weapons
and, possibly, of driving vehicles. Russian media quoted defence
minister Sergei Shoigu confirming last May that Russia has commenced
with the manufacturing of killer robots, saying, "What has emerged are
not simply experimental, but robots that can be really shown in
science-fiction films as they are capable of fighting on their own."

Yet the world's first true test case of a fully autonomous killer robot
may have already taken place, in Libya in March 2020. According to a
report submitted by a panel of experts to the UN Security Council in
March 2021, drones produced by Turkish state-owned defence conglomerate
STM were allegedly sent to track down a convoy of retreating forces
loyal to renegade military general Khalifa Haftar after they abandoned a
months-long siege of the capital, Tripoli.

Turkey's intervention into Libya to prop up the Tripoli-based Government
of National Accord, the war-torn country's UN-recognized government
faction, has opened up Libya's vast deserts to be used as a giant test
theatre for Turkey's booming military drone industry. Turkish drones
have recently altered the trajectory of civil wars in favour of Turkey's
government clients in both Libya and Ethiopia, and delivered a decisive
victory for Azerbaijan during a violent flare-up with Armenia in late
2020 over the disputed territory of Nagorno-Karabakh. Over the past two
years Ukraine has purchased dozens of Turkish drones in response to
Russia's military buildup on Ukraine's eastern border.

The experts' report claims Haftar's forces "were hunted down and
remotely engaged" by a Turkish Kargu-2 drone and other "loitering
munitions" --- those with the ability to hover over targets for hours
--- that "were programmed to attack targets without requiring data
connectivity between the operator and the munition." In other words, the
machines were apparently capable of identifying, selecting and killing
targets without communication from a human handler.

In many ways, the evolution of military drones is a canary in the coal
mine, bridging eras between semi-autonomous and autonomous weapons and
perhaps foreshadowing the way in which fully independent killer robots
might proliferate in the future. In the 2000s, military drones were a
very expensive and hard-to-operate weapons system possessed almost
exclusively by the United States. Less than two decades later, they have
become a low-cost, widely available technology being manufactured and
exported worldwide --- not only by China, Turkey and the United States,
but by Iran, the United Arab Emirates and others, each motivated by not
only geopolitical interests but the lucrative commercial stakes
involved.

By some estimates, more than 100 countries now have active military
drone programs --- all springing up without any sort of international
regulatory structure in place.

Autonomous weapons systems may be able to assess a target's legitimacy
and make decisions faster, and with more accuracy and objectivity than
fallible human actors could.

More Just War --- or Just More War?

Rapid advances in autonomous weapons technologies and an increasingly
tense global order have brought added urgency to the debate over the
merits and risks of their use.

Proponents include Robert Work, a former US deputy secretary of defence
under the Obama and Trump administrations, who has argued the United
States has a "moral imperative" to pursue autonomous weapons. The chief
benefit of LAWS, Work and others say, is that their adoption would make
warfare more humane by reducing civilian casualties and accidents
through decreasing "target misidentification" that results in what the
US Department of Defense labels "unintended engagements."

Put plainly: Autonomous weapons systems may be able to assess a target's
legitimacy and make decisions faster, and with more accuracy and
objectivity than fallible human actors could, either on a chaotic
battlefield or through the pixelated screen of a remote-control centre
thousands of miles away. The outcome would be a more efficient use of
lethal force that limits collateral damage and saves innocent lives
through a reduction in human error and increased precision of munitions
use.

Machines also cannot feel stress, fatigue, vindictiveness or hate. If
widely adopted, killer robots could, in theory, lessen the opportunistic
sexual violence, looting and vengeful razing of property and farmland
that often occurs in war --- especially in ethnically driven conflicts.
These atrocities tend to create deep-seated traumas and smouldering
intergenerational resentments that linger well after the shooting stops,
destabilizing societies over the long term and inviting more conflict in
the future.

But critics and prohibition advocates feel differently. They say the
final decision over the use of lethal force should always remain in the
hands of a human actor who can then be held accountable for that
decision. Led by the Campaign to Stop Killer Robots, which launched in
2013 and is now comprised of more than 180 member organizations across
66 countries and is endorsed by over two dozen Nobel Peace laureates,
the movement is calling for a pre-emptive, permanent international
treaty banning the development, production and use of fully autonomous
weaponry.

Dozens of countries support a pre-emptive ban as well. This briefly
included Canada, when the mandate letter issued by Prime Minister Justin
Trudeau in 2019 to then foreign affairs minister François-Philippe
Champagne requested he assist international efforts to achieve
prohibition. That directive has since disappeared from the mandates
given to Champagne's successors, Marc Garneau and now Mélanie Joly.

For those calling for a ban, the risks of LAWS outweigh their supposed
benefits by ultimately incentivizing war through eliminating some of its
human cost. The unavoidable casualties that result from armed conflict,
and the political blowback that can produce, has always moderated the
willingness of governments to participate in wars. If this deterrent is
minimalized by non-human combatants over time, it may render military
action more appealing for leaders --- especially for unpopular ones,
given the useful distraction that foreign adventurism can sometimes
inject into domestic politics.

Other risks are that autonomous weapons technology could fall into the
hands of insurgent groups and terrorists. At the peak of its so-called
caliphate in Iraq and Syria, the Islamic State was launching drone
strikes daily. Despotic regimes may impulsively unleash autonomous
weapons on their own populations to quell a civilian uprising. Killer
robots' neural networks could also be susceptible to being hacked by an
adversary and turned against their owners.

Yet, just as the debate intensifies, a realistic assessment of the state
of the killer robots being developed confirms what the Swiss ambassador
to the CCW feared --- technological progress is far outpacing
deliberations over containment. But even if it weren't, amid a
splintering international order, plenty of nation-states are readily
violating humanitarian laws and treaties anyway, while others are
seeking new ways to gain a strategic edge in an increasingly hostile,
multipolar geopolitical environment.

**[[National Interests Undermine Collective
Action]{.underline}]{.mark}**

While Turkey may have been the first to allegedly deploy live [[killer
robots]{.underline}]{.mark}, their wide-ranging [[use is likely to be
driven by **Beijing**]{.underline}, **[Moscow]{.underline}** [and
Washington]{.underline}]{.mark}. [**Chinese** President]{.underline}
[[Xi]{.underline}]{.mark} Jinping [[and]{.mark} Russian
President]{.underline} Vladimir [[Putin]{.underline} [both **openly
loathe the Western**]{.underline}]{.mark}**[-oriented human rights
[doctrines]{.mark}]{.underline}** [[that underpin calls to ban]{.mark}
killer [robots]{.mark}]{.underline}. And despite America's domestic
division and dysfunction, its political class still has a bipartisan
desire for the United States to remain the world's global military
hegemon.

With a GDP just slightly larger than that of the state of Florida,
[[Russia's inability to compete in]{.mark} a **great power
competition**]{.underline} [economically [renders it reliant on]{.mark}
exploiting **[asymmetric]{.mark} power
[imbalances]{.mark}**]{.underline} [wherever possible, [including
through]{.mark} furthering its [**[AI]{.mark} capability** for military
and espionage
purposes](https://www.aljazeera.com/news/2021/11/30/uk-spy-chief-warns-china-russia-racing-to-master-ai)]{.underline}.
Autonomous weapons could be well-suited to secure the resource-rich but
inhospitable terrain of the Arctic, a region where the Kremlin is
actively trying to assert Russia's primacy. The country is also the
[world's second-largest arms
exporter](https://crsreports.congress.gov/product/pdf/R/R46937) behind
the United States, accounting for one-fifth of global arms sales since
2016 --- a key source of government revenue and foreign influence. Its
recent [anti-satellite weapons
test](https://www.bbc.com/news/science-environment-59299101) underscores
the Kremlin's willingness to explore controversial weapons technologies
too, even in the face of international condemnation.

President **[[Xi]{.underline}]{.mark}** Jinping, meanwhile, [has
**[pinned [China's ambitions of remaking the global
order](https://www.theatlantic.com/international/archive/2021/12/china-wants-rule-world-controlling-rules/620890/)]{.mark}**]{.underline}
[in favour of autocracies [on]{.mark} the domination of **[key emerging
technologies]{.mark}.**]{.underline} On track by some estimates to
becoming the [world's biggest economy by
2028](https://www.cnbc.com/2021/02/01/new-chart-shows-china-gdp-could-overtake-us-sooner-as-covid-took-its-toll.html),
[China is [pouring **spectacular amounts**]{.mark} of money and
resources [into]{.mark}]{.underline} everything from
**[[AI]{.underline}]{.mark}**, **[nanotechnology]{.underline}**
[and]{.underline} **[quantum computing]{.underline}** to genetics and
synthetic biology, and has a [stranglehold on the market for rare earth
metals](https://www.scmp.com/news/china/diplomacy/article/3130990/chinas-dominance-rare-earths-supply-growing-concern-west).
After tendering his resignation in September out of frustration, the
Pentagon's ex-software chief, Nicolas Chaillan, declared in an
[interview](https://www.ft.com/content/f939db9a-40af-4bd1-b67d-10492535f8e0)
with the Financial Times a month later that the United States will have
"no competing fighting chance against China in 15 to 20 years."

China is also notably keen on state-sponsored intellectual property
theft to accelerate its innovation cycles. The more that others
demonstrably advance on killer robots, the more that China will attempt
to steal that technology --- and inevitably succeed to a degree. This
could create a self-reinforcing feedback loop that hastens the killer
robot arms race among military powers.

This race of course includes the United States. The New York Times
[reported](https://www.nytimes.com/2005/02/16/technology/new-model-army-soldierrolls-closer-to-battle.html)
back in 2005 that the Pentagon was mulling ways to integrate killer
robots into the US military. And much to the dismay of progressives,
even Democrat-led administrations exhibit no signs whatsoever of winding
down military spending any time soon --- the Biden administration
released a decidedly [hawkish Global Posture
Review](https://theintercept.com/2021/12/02/biden-military-deployment-global-footprint/)
at the end of November just as a massive [US\$770 billion defence
bill](https://www.reuters.com/world/us/majority-us-senate-backs-770-billion-defense-bill-2021-12-15/)
sailed through Congress. The US military has already [begun training
drills to fight enemy
robots](https://www.forbes.com/sites/davidhambling/2021/10/22/us-army-carries-out-first-exercise-fighting-enemy-robots/?sh=21c0313556c0),
while deploying autonomous weapons systems could uphold its capacities
for foreign intervention and power projection overseas, now that
[nation-building projects have fallen out of
fashion](https://www.bbc.com/news/world-asia-57489095).

Most important of all, mass production of killer robots could offset
America's flagging enlistment numbers. The US military requires 150,000
new recruits every year to maintain its desired strength and capability.
And yet Pentagon data from 2017 revealed that more than 24 million of
the then 34 million Americans between the ages of 17 and 24 --- over 70
percent --- would have been [disqualified from serving in the
military](https://www.heritage.org/defense/report/the-looming-national-security-crisis-young-americans-unable-serve-the-military)
if they applied, due to obesity, mental health issues, inadequate
education or a criminal record. Michèle Flournoy, a career defence
official who served in senior roles in both the Clinton and the Obama
administrations, [told](https://www.bbc.com/news/world-59755100) the BBC
in December that "one of the ways to gain some quantitative mass back
and to complicate adversaries' defence planning or attack planning is to
pair human beings and machines."

Other, [**[smaller players]{.underline}** [are nurturing an
affinity]{.underline}]{.mark} [for LAWS [too]{.mark}]{.underline}.
**[[Israel]{.underline}]{.mark}** [assassinated Iran's top nuclear
scientist]{.underline}, Mohsen Fakhrizadeh, outside of Tehran in
November 2020 [using a remote-controlled, [AI-assisted machine
gun](https://www.nytimes.com/2021/09/18/world/middleeast/iran-nuclear-fakhrizadeh-assassination-israel.html)]{.underline}
mounted inside a parked car, [and is [devising more remote ways to
strike back against
Hamas](https://www.businesslive.co.za/bd/opinion/2021-05-20-remote-warfare-will-not-end-age-old-israel-palestine-conflict/)]{.underline}
in the Gaza Strip. [Since 2015, **[South Korea]{.mark}**]{.underline}
[has placed nearly fully [autonomous sentry
guns](https://www.bbc.com/future/article/20150715-killer-robots-the-soldiers-that-never-sleep)
on the edge of its demilitarized zone with North Korea]{.underline},
[selling the domestically built robot turrets to customers throughout
the Middle East]{.underline}. Speaking at a defence expo in 2018, Prime
Minister Narendra [Modi of]{.underline} **[[India]{.underline}]{.mark}**
--- the world's second-largest arms buyer ---
[[told](https://timesofindia.indiatimes.com/india/india-moves-to-develop-ai-based-military-systems/articleshow/64250232.cms)
the audience: "New and emerging technologies like AI and Robotics will
perhaps be the most **important determinants** of **defensive and
offensive capabilities** for **any** defence force in the
future."]{.underline}

#### Pandora's box is [already open]{.underline}. 

Elsa B. **Kania 18**, Senior Fellow with the Technology and National
Security Program at the Center for a New American Security, "The Pursuit
of AI Is More Than an Arms Race",
https://www.defenseone.com/ideas/2018/04/pursuit-ai-more-arms-race/147579/

In many respects, [[this]{.mark} particular [Pandora's box is **already
open**]{.mark}]{.underline}[,]{.mark} [so [calls
for]{.mark}]{.underline} absolute [[bans may prove **too little, too
late**]{.underline}]{.mark}. Increasingly, [states and]{.underline} even
[non-state actors are using]{.underline} commercial, off-the-shelf
[technologies to enable **new military capabilities**]{.underline}; ISIS
[uses](https://www.defensenews.com/digital-show-dailies/modern-day-marine/2017/09/21/in-drones-isis-has-its-own-tactical-air-force/)
cheap commercial drones to gather intelligence and provide close air
support. [The [**rapid advances** in **AI**]{.mark}
**[tech]{.mark}nologies** [continue]{.mark}, and [[new
products]{.mark}](https://spectrum.ieee.org/automaton/robotics/drones/skydio-r1-drone)
and available
[algorithms](https://www.digitaltrends.com/cool-tech/dronet-autonomous-naviagation/)
can [enable]{.mark} the **autonomy** and thus [**scalability** of these
capabilities.]{.mark}]{.underline}

[[It seems **unlikely** that **any major military would**]{.mark} **be
willing to [tie its hands]{.mark}**]{.underline} [[or]{.underline}
**[constrain its pursuit of technologies]{.underline}**]{.mark}
[and]{.underline} **[capabilities]{.underline}** [[that are so
**strategic**]{.underline} [and]{.underline} **[evolving so
rapidly]{.underline}**]{.mark}. [[Beyond]{.mark} the [lack of
trust]{.mark}, attempts to enable **[verification]{.mark}** of
compliance with any future agreements [would]{.mark} also [be
**challenging at best.**]{.mark}]{.underline}

### 

### AT: AI Impact\-\--1NC

#### We'll adapt to AI.

Amy **Zhang 21**, PhD candidate at Cornell studying Operations Research
and Research Assistant at Cornell Tech, "DLI Debate: Does AI Pose an
Existential Threat to Humanity?," Cornell Tech, 5/16/21,
https://www.dli.tech.cornell.edu/post/dli-debate-does-ai-pose-an-existential-threat-to-humanity

First of all, [[AI]{.mark} as a tool [is **not
smart**]{.mark}]{.underline}. It needs you to tell it exactly 1. what is
the specific goal to achieve, 2. a success metric that is meticulously
defined, and 3. information to use as a basis that you prepare and feed
in. Then to what extent can you say that AI does bad things? For
example, if a company is allowed to set maximizing the time spent in an
app as its ultimate goal, is it the algorithm's fault for achieving it?
Or if we task a model to mimic our speech by showing it all of Twitter
to use as example, and it produces language that mirrors some of the
toxicity, can we call the model racist? [What [it]{.mark} really [comes
down to]{.mark} is in **[how]{.mark}** these [**systems** are
**designed**]{.mark}, and whether it is done with the level of
**awareness** and]{.underline} **[sensitivity]{.underline}** [required
in really **thinking through** these **human aspects.**]{.underline}

Indeed[, an important part of this [relies on]{.mark} **checks** and
**balances** put in by the **[government]{.mark}**]{.underline} [and
other **rule-setting agencies.** [And]{.mark} it is **true** that [it
can be **frustrating** to feel like they\'re]{.mark}]{.underline}
**[[not measuring up]{.mark},]{.underline}** [which then could lead to a
**pessimistic outlook**]{.underline} that they never will and this will
never work. [[But]{.mark} there are two important points to consider
here. Number one, [there will be a **lag** in **legislative actions**
with **any**]{.mark} **technological advances**]{.underline} almost [by
definition. A [nascent tech]{.mark}nology first needs **time** to
**emerge**, to **grow**]{.underline}, [and to become **widespread
enough** that it **matters**]{.underline} [to the **general public**.
**Then**]{.underline}, only once it gets past the point where people are
just immersed in the excitement and the benefits - because it does
provide real benefits - [do **problems** become **apparent** and gain
**attraction**.]{.underline} [That's when the **agencies** can go in and
try to **understand them**, which in itself is not easy.]{.underline}
Then a second point to consider is that this is creating a new context,
and any change in contexts is very difficult to grapple with for the
legislative. Keep in mind that even the processes that seem very
established today, have gotten here only after being studied and refined
over a long period of time. One should expect this case to be no
different. [So yes, it will take time, but [that **does not mean** that
we will **never get there.**]{.mark}]{.underline}

In addition, [it is very important to bear in mind that [**society**
itself is **adaptive**]{.mark}.]{.underline} **[Humans are
adaptive]{.underline}**[. [This is **not the first
time**]{.underline}]{.mark} [that **[tech]{.mark}nological
[breakthroughs]{.mark}** have [become a **disruptive force**]{.mark} in
human society.]{.underline} Yes, it\'s true that [such disruptions
**bring out** previously dormant **conflicts**]{.underline}, [in a way
that [can **feel like** a]{.mark}]{.underline}
[**[crisis]{.underline}**. [But]{.underline}]{.mark} [it is also a
**chance** for us to **re-examine** and to **make
changes**]{.underline}. We have done this in history, and we have seen
through history that it\'s by facing up to these challenges that
societies progress[. [We have seen]{.mark} this through [many
revolutions]{.mark}, and **this will be another one**]{.underline}. One
is right to argue that it will be all on a much larger scale, but that
exponential rate of change is part of the nature of progress, and part
of what societies have potential to adapt to. So if anything, the
concern with AI is that it\'s still unable to change itself. This means
that unless we do something about it, past mistakes could be frozen in
place and propagated, and that could be the actual risk to our progress
as societies. That\'s why, again, the burden of responsibility is on us
humans.

### AT: AI Impact\-\--2NC

#### AI will never develop consciousness.

Meg **Young 21**, Postdoctoral Fellow at Cornell Tech\'s Digital Life
Initiative, "DLI Debate: Does AI Pose an Existential Threat to
Humanity?," Cornell Tech, 5/16/21,
https://www.dli.tech.cornell.edu/post/dli-debate-does-ai-pose-an-existential-threat-to-humanity

Returning to what Salome has asserted, [let\'s]{.underline}
**[pause]{.underline}** for a moment [to **take in**
[the]{.mark}]{.underline} [**[argument]{.underline}** [that AI
poses]{.underline}]{.mark} [[an **existential
risk**]{.underline}]{.mark} to humanity. [An **existential threat** is
one that will **destroy life on earth**]{.underline}\-\--to **[literally
wipe it out]{.underline}**. [This argument [warns]{.mark} that [AI will
become **super intelligent**]{.mark}]{.underline},
**[overpower]{.underline}** [its **human creators** to]{.underline}
[pursue its own]{.underline} **[unimaginable ends]{.underline}**, and to
menace life as it takes over the planet. [[But]{.mark} what would need
to be true for that to be possible? AI would need to be **intelligent**
in a **meaningful sense**]{.underline}. Meaning it can reason, form its
own goals, and pursue those goals across contexts. In other words, it
would need to be able to think for itself. The philosopher John Searle
refers to this idea that AI will ever be able to do that as quote, "an
enormous philosophical confusion about the correct interpretation of AI
technology." He points out that [**[consciousness]{.underline}** [is
**essential** to **intelligence**]{.underline}]{.mark}.
[And]{.underline} that [without it, **even** an **advanced system** like
IBM Deep Blue is **not playing chess** in the **same way** a **chess
master**]{.underline} like Garry Kasparov [is]{.underline}. Instead**[,
it is just performing a computation.]{.underline}** [We know that [AI is
**not conscious** and **not at risk of becoming
so**]{.mark}]{.underline}[,]{.mark} [because consciousness is an
**enduring mystery**]{.underline} in philosophy, neuroscience, and
psychology. **[[Basic science]{.underline}]{.mark}** [[is **not able**
to **characterize consciousness**]{.mark}]{.underline} and where it
comes from in vivo, [so [why do we think]{.mark} that [**computer
scientists** will be **able** to **recreate it**]{.mark} **in
silico[?]{.mark}**]{.underline}

**[[Proponents]{.underline}]{.mark}** [of **super-intelligent AI** argue
that the technology is **already** on **course** to **emulate human
intelligence**]{.underline}. [They say]{.underline} that because
computational power is becoming cheaper and faster,
**[eventually]{.underline}** [machine learning systems like neural nets
will function **akin** to a **human brain**]{.underline} [and exceed it
in **unpredictable ways**]{.underline}. [But this argument
**[mis-apprehend]{.mark}s** **[what intelligence
is]{.mark}**]{.underline}[.]{.mark} [[It is]{.mark} much [**more** than
the **ability to solve problems**]{.mark}]{.underline}[.]{.mark} A
driverless car, while much more computationally intensive, is no closer
to being sentient than a calculator is; both are machines purpose-built
to solve problems, and both are equally unlikely to plot to kill
humankind. Instead, increases in computational power are merely bringing
us a better and more convincing illusion that AI is super intelligent.
To people decades ago, Siri and Alexa would have seemed akin to Rosie,
the humanoid robot on The Jetsons. But knowing Siri and Alexa as we do
today, we know they cannot be called "intelligent" in a meaningful sense
at all. So yes, we are on course to get better simulations of
intelligence, but [they\'ll have **none** of the **underlying
capability**]{.underline} [necessary for **consciousness
itself**]{.underline}\--[and as such, they **pose no risk** of
**overthrowing humanity.**]{.underline}

#### No runaway AI

Edward Moore **Geist 15**, MacArthur Nuclear Security Fellow at Stanford
University\'s Center for International Security and Cooperation, Former
Stanton Nuclear Security Fellow at the RAND Corporation, Doctorate in
History from the University of North Carolina, "Is Artificial
Intelligence Really An Existential Threat to Humanity?", Bulletin of the
Atomic Scientists, 8-9,
https://thebulletin.org/2015/08/is-artificial-intelligence-really-an-existential-threat-to-humanity/

Superintelligence: Paths, Dangers, Strategies is an astonishing book
with an alarming thesis: Intelligent machines are "quite possibly the
most important and most daunting challenge humanity has ever faced." In
it, Oxford University philosopher Nick [[Bostrom]{.underline}]{.mark},
who has built his reputation on the study of "existential risk,"
[[argues]{.underline}]{.mark} forcefully [that **[a]{.mark}**rtificial
**[i]{.mark}**ntelligence [might be]{.mark}]{.underline} the most
[[apocalyptic]{.mark} technology]{.underline} of all. With intellectual
powers beyond human comprehension, he prognosticates, self-improving
artificial intelligences could effortlessly enslave or destroy Homo
sapiens if they so wished. While he expresses skepticism that such
machines can be controlled, Bostrom claims that if we program the right
"human-friendly" values into them, they will continue to uphold these
virtues, no matter how powerful the machines become.

[These views have found an eager audience]{.underline}. In August 2014,
PayPal cofounder and electric car magnate Elon Musk tweeted "Worth
reading Superintelligence by Bostrom. We need to be super careful with
AI. Potentially more dangerous than nukes." Bill Gates declared, "I
agree with Elon Musk and some others on this and don't understand why
some people are not concerned." More ominously, legendary astrophysicist
Stephen [Hawking concurred]{.underline}: "I think [the development
of]{.underline} full [artificial intelligence could spell the end of the
human race]{.underline}." Proving his concern went beyond mere rhetoric,
Musk donated \$10 million to the Future of Life Institute "to support
research aimed at keeping AI beneficial for humanity."

Superintelligence is propounding a solution that will not work to a
problem that probably does not exist, but Bostrom and Musk are right
that now is the time to take the ethical and policy implications of
artificial intelligence seriously. [The [extraordinary claim]{.mark}
that machines can become so intelligent as to gain demonic powers
**[requires extraordinary evidence]{.mark}**, particularly
[since]{.mark} artificial intelligence (AI) [researchers]{.mark} have
[**struggled** to create]{.mark} machines that show [much]{.mark}
evidence of [intelligence at all]{.mark}]{.underline}. While these
investigators' ultimate goals have varied since the emergence of the
discipline in the mid-1950s, the fundamental aim of AI has always been
to create machines that demonstrate intelligent behavior, whether to
better understand human cognition or to solve practical problems. Some
AI researchers even tried to create the self-improving reasoning
machines Bostrom fears. [Through decades of bitter
experience]{.underline}, however, [[they learned]{.mark} not only that
creating [intelligence is **more difficult** than]{.mark} they initially
[expected]{.mark}, but also that [it grows **increasingly
harder**]{.mark} the smarter one tries to become. [Bostrom]{.mark}'s
concept of "superintelligence,"]{.underline} which he defines as "any
intellect that greatly exceeds the cognitive performance of humans in
virtually all domains of interest," [[builds upon]{.underline}]{.mark}
similar [**[discredited assumptions]{.mark}** about the nature of
thought]{.underline} that the pioneers of AI held decades ago. A summary
of Bostrom's arguments, contextualized in the history of artificial
intelligence, demonstrates how this is so.

In the 1950s, the founders of the field of artificial intelligence
assumed that the discovery of a few fundamental insights would make
machines smarter than people within a few decades. By the 1980s,
however, they discovered **[[fundamental
limitations]{.underline}]{.mark}** that [[show]{.mark} that there will
**[always]{.mark}** be [**diminishing returns** to additional]{.mark}
processing [power and data]{.mark}]{.underline}. Although these
**[[technical hurdles]{.underline}]{.mark}** pose no barrier to the
creation of human-level AI, they [will likely **[forestall]{.mark}**
the]{.underline} sudden [emergence of [an unstoppable
"superintelligence."]{.mark}]{.underline}

[The [risks of self-improving]{.mark} intelligent [machines are
**grossly exaggerated**]{.mark} and ought not serve as a **distraction**
from the existential risks we already face]{.underline}, especially
given that the limited AI technology we already have is poised to make
threats like those posed by nuclear weapons even more pressing than they
currently are. Disturbingly, little or no technical progress beyond that
demonstrated by self-driving cars is necessary for artificial
intelligence to have potentially devastating, cascading economic,
strategic, and political effects. While policymakers ought not lose
sleep over the technically implausible menace of "superintelligence,"
they have every reason to be worried about emerging AI applications such
as the Defense Advanced Research Projects Agency's submarine-hunting
drones, which threaten to upend longstanding geostrategic assumptions in
the near future. Unfortunately, Superintelligence offers little insight
into how to confront these pressing challenges.

#### It\'s [super far off]{.underline} and won't be threatening

Dr. Oren **Etzioni 16**, Professor of Computer Science at the University
of Washington, CEO of the Allen Institute for Artificial Intelligence,
Ph.D. from Carnegie Mellon University and BA from Harvard University,
"No, the Experts Don't Think Superintelligent AI is a Threat to
Humanity", MIT Technology Review, 9-20,
https://www.technologyreview.com/s/602410/no-the-experts-dont-think-superintelligent-ai-is-a-threat-to-humanity/

[[If you **believe everything you read**, you are]{.mark} probably quite
[worried about]{.mark}]{.underline} the prospect of [a superintelligent,
[killer AI]{.mark}]{.underline}. The Guardian, a British newspaper,
warned recently that "we're like children playing with a bomb," and a
recent Newsweek headline reads, "Artificial Intelligence Is Coming, and
It Could Wipe Us Out."

Numerous such [headlines]{.underline}, fueled by comments from the likes
of Elon Musk and Stephen Hawking, [are strongly influenced
by]{.underline} the work of one man: professor Nick
[Bostrom]{.underline}, author of the philosophical treatise
Superintelligence: Paths, Dangers, and Strategies.

[Bostrom is a]{.underline}n Oxford [philosopher, but **quantitative
assessment of risks** is the province of actuarial science]{.underline}.
He may be dubbed the world's first prominent "actuarial philosopher,"
though the term seems an oxymoron given that philosophy is an arena for
conceptual arguments, and risk assessment is a data-driven statistical
exercise.

So what do the data say? Bostrom aggregates the results of four
different surveys of groups such as participants in a conference called
"Philosophy and Theory of AI," held in 2011 in Thessaloniki, Greece, and
members of the Greek Association for Artificial Intelligence (he does
not provide response rates or the phrasing of questions, and he does not
account for the reliance on data collected in Greece).

His findings are presented as probabilities that human-level AI will be
attained by a certain time:

> By 2022: 10 percent.
>
> By 2040: 50 percent.
>
> By 2075: 90 percent.

This aggregate of four surveys is the main source of data on the advent
of human-level intelligence in over 300 pages of philosophical
arguments, fables, and metaphors.

To get a more accurate assessment of the opinion of leading researchers
in the field, I turned to [the Fellows of the **A**merican
**A**ssociation for **A**rtificial **I**ntelligence]{.underline}, [a
group of researchers who are recognized as having made significant,
sustained contributions to the field]{.underline}.

In early March 2016, AAAI [sent out [a]{.mark}n anonymous
[survey]{.mark}]{.underline} on my behalf, posing the following question
[[to 193 fellows]{.underline}]{.mark}:

"In his book, Nick Bostrom has defined Superintelligence as 'an
intellect that is much smarter than the best human brains in practically
every field, including scientific creativity, general wisdom and social
skills.' **[[When]{.mark} do you think [we will achieve
Superintelligence?]{.mark}]{.underline}**"

Over the next week or so, 80 fellows responded (a 41 percent response
rate), and their responses are summarized below:

![https://cdn.technologyreview.com/i/images/ykuvebi16-1.jpg?sw=600&cx=0&cy=0&cw=1024&ch=689](media/image1.jpeg){width="2.8640004374453194in"
height="1.9252504374453194in"}

In essence, [[according to 92]{.mark}.5 [percent]{.mark} of the
respondents, **superintelligence is [beyond the foreseeable
horizon]{.mark}**]{.underline}. This interpretation is also supported by
written comments shared by the fellows.

Even though the survey was anonymous, 44 fellows chose to identify
themselves, including Geoff Hinton (deep-learning luminary), Ed
Feigenbaum (Stanford, Turing Award winner), Rodney Brooks (leading
roboticist), and Peter Norvig (Google).

The respondents also shared several comments, including the following:

> "[Way, way, way more than 25 years.]{.underline} **[[Centuries most
> likely]{.mark}. But not never]{.underline}**."
>
> "[We're competing with millions of years' evolution of the human
> brain. [We can write single-purpose programs]{.mark} that can compete
> with humans]{.underline}, and sometimes excel, [[but the world is
> **not**]{.mark} **neatly [compartmentalized]{.mark} into
> single-problem questions**]{.underline}."
>
> "Nick [[Bostrom is a]{.mark} professional [**scare monger**.
> His]{.mark} Institute's [role is to find existential
> threats]{.mark}]{.underline} to humanity. [**[He sees them
> everywhere]{.mark}**. I am tempted to refer to him as [the '**Donald
> Trump' of AI**]{.mark}]{.underline}."

Surveys do, of course, have limited scientific value. They are
notoriously sensitive to question phrasing, selection of respondents,
etc. However, it is the one source of data that Bostrom himself turned
to.

Another methodology would be to extrapolate from the current state of AI
to the future. However, this is difficult because we do not have a
quantitative measurement of the current state of human-level
intelligence. We have achieved superintelligence in board games like
chess and Go (see "Google's AI Masters Go a Decade Earlier than
Expected"), and yet our programs failed to score above 60 percent on
eighth grade science tests, as the Allen Institute's research has shown
(see "The Best AI Program Still Flunks an Eighth Grade Science Test"),
or above 48 percent in disambiguating simple sentences (see "Tougher
Turing Test Exposes Chatbots' Stupidity").

[There are many valid concerns about]{.underline} AI, from its impact on
jobs to its uses in autonomous weapons systems and even to the potential
risk of [superintelligence. However, [predictions]{.mark}]{.underline}
that **[[superintelligence is on the foreseeable horizon are not
supported by]{.mark} the available [data]{.mark}]{.underline}**.
Moreover, [[doom-and-gloom predictions]{.underline}]{.mark} often
[[fail]{.mark} to consider the potential benefits of AI]{.underline} in
preventing medical errors, reducing car accidents, and more.

## Military Innovation DA 

### 1NC\-\--DA 

#### Transatlantic AI innovation is surging now. 

Edward Hunter **Christie 22**, Senior Research Fellow at the Finnish
Institute of International Affairs, "Defence Cooperation in Artificial
Intelligence: Bridging the Transatlantic Gap for a Stronger Europe,"
European View, vol. 21, no. 1, SAGE Publications Ltd, 04/01/2022, pp.
13--21

Investment challenges

As noted in the introduction, [there is a significant **gap** between
overall **US** and **European** **defence** spending levels. This
general pattern]{.underline} **[also]{.underline}** [holds for
defence]{.underline} **[r]{.underline}**esearch [and]{.underline}
**[d]{.underline}**evelopment spending. In 2020, EU spending in this
area amounted to €8 billion (EDA 2021). For the US, with caveats as to
comparability, expenditure for 'research, development, test and
evaluation' totalled approximately €90 billion3 in the 2021 fiscal year
(from October 2020 to September 2021), or about 10 times more.

Investment [challenges go]{.underline} **[beyond]{.underline}** issues
of [**scale**. The US]{.underline} also [has]{.underline} **[greater
experience]{.underline}** [in]{.underline} the **[setting
up]{.underline}** [and]{.underline} **[operation]{.underline}**
[of]{.underline} **[structures]{.underline}** [to]{.underline}
**[promote]{.underline}** both [**military and dual-use innovation**.
While the best-known institution is the]{.underline}
**[D]{.underline}**efense **[A]{.underline}**dvanced
**[R]{.underline}**esearch **[P]{.underline}**rojects
**[A]{.underline}**gency, **[other]{.underline}** [US government
structures are also relevant in discussions on fostering innovation in
**AI**]{.underline} [for]{.underline} [**military applications**. A
much-discussed example is **In-Q-Tel**]{.underline}, which was
originally set up as the state venture-capital arm of the Central
Intelligence Agency. To illustrate the influence of the In-Q-Tel
example, one may note that both its current Chief Executive Officer,
Chris Darby, and one of its former Chief Executive Officers, Gilman
Louie, served among the 15 commissioners of the National Security
Commission on Artificial Intelligence.4 This was a temporarily created
expert commission mandated by the US Congress to provide policy
recommendations for a whole-of-government and whole-of-society approach
for US AI policy.5

With In-Q-Tel, the idea is to learn from private-sector practices in the
area of venture-capital investment and repurpose them for state needs
and more patient time horizons. A supported company should pursue
product development strategies aimed at serving both civilian markets
and government needs. In this way, rather than effectively taking over a
commercial company and limiting its growth potential to future
government contracts alone, the government body encourages an
intermediate trajectory made up of mixed revenue streams, in the hope
that this will generate greater returns to scale and higher efficiency
thanks to the disciplining effect of private-sector competition.
Conversely, the advantage of this approach as compared to not
intervening at all is that the commercial company will integrate current
and likely future government needs into its product and
business-development strategy, rather than ignoring them and finding
itself, at a later date, unable to supply the government sector
according to the latter's requirements.

A related issue which falls between what can be achieved with new
investment instruments and new protections that can be assured through
the screening of foreign direct investment is the provision of
investment from trusted private investors to the technology sector.
[Certain technology companies that are not part of the traditional
defence industry may be developing dual-use products]{.underline} that
are [of potential interest to the defence sector while having limited
awareness of national security concerns. This may make them vulnerable
targets for both licit and illicit attempts to **acquire their
technologies**]{.underline} [on the part of **foreign state
actors**]{.underline}. [At the same time, their business development
needs may lead them to seek **investment** from]{.underline} **[any
potential source]{.underline}**, thus [exposing them to potential
**risks**]{.underline}. To respond to this challenge, the US Department
of Defense has launched a scheme called the Trusted Capital Marketplace
(US Department of Defense 2021a).

[Building on these considerations]{.underline}, the
**[NATO]{.underline}** Innovation Unit [has developed two new
instruments for Allied use]{.underline} which were announced to the
public in October 2021 (NATO 2021a; 2021b). [Both]{.underline}
instruments [aim to foster]{.underline} **[tech]{.underline}**nological
**[innovation]{.underline}** [with a deliberate focus on dual-use
applications and on enterprises with mixed (potential) revenue streams.
The first instrument is the Defence Innovation Accelerator for the North
Atlantic (DIANA), which is a NATO instrument, that is, it involves the
participation of all 30 NATO Allies. The second instrument is the NATO
Innovation Fund, which in NATO terminology is a 'multinational'
instrument]{.underline}, namely one [that Allies freely opt
into]{.underline}.

[DIANA will aim to accelerate the]{.underline}
**[adoption]{.underline}** [of dual-use technological solutions through
several interlocking components.]{.underline}6 First, [it will develop a
network of national organisations, in particular test centres and
innovation accelerators]{.underline}. Second, [it will competitively
select private-sector innovators and allow them to use national
organisations in the network to interface with military end users and
military capability-development specialists]{.underline}. Third, [it is
envisaged that DIANA will provide mentorship and education services for
private innovators to familiarise them with the opportunities and
responsibilities inherent to the defence and security
sector]{.underline}. Fourth, [DIANA will develop a database of trusted
financial investors from Allied nations and support matchmaking between
investors and innovators]{.underline}. Fifth and finally, [DIANA will
also provide expert advice on defence and security innovation to all
relevant stakeholders, including private-sector and academic
entities.]{.underline}

[Regarding the NATO Innovation Fund, 17 Allies had **opted into the
Fund**]{.underline} [as of the date of its announcement]{.underline} in
October 2021. [The participating Allies will inject up to €1 billion
into Allied innovation ecosystems over the next 15 years]{.underline}.
[The Fund aims to attract **additional private
investments**]{.underline} [due to the de-risking effect, both financial
and technological, thanks to state co-funding and diligence and
screening efforts. The funds are intended to be used for **long-term
support of 'deep tech' innovative companies**]{.underline}, that is, for
advanced research into AI, quantum and related technologies that may
have both military and civilian applications. [Due diligence and
security screening practices will aim to ensure that both private
investors and fund recipients are **trusted** entities.]{.underline}

#### The AFF saps funding for AI research AND eliminates beneficial dual-use technology. 

**Castro & McLaughlin 19** \-\-- \*Vice President, ITIF, and Director,
Center for Data Innovation. \*\*Research Analyst Information Technology
and Innovation Foundation

Daniel & Michael, 2-4-2019, \"Ten Ways the Precautionary Principle
Undermines Progress in Artificial Intelligence,\" ITIF,
https://itif.org/publications/2019/02/04/ten-ways-precautionary-principle-undermines-progress-artificial-intelligence/

[Many groups have started movements to **ban lethal autonomous
weapons**---autonomous robotics systems that can independently identify
and engage targets based on programmed constraints---due to fears that
they will lead to armed conflict on a scale greater and faster than ever
before.]{.underline} For example, 116 founders of mostly small robotics
and AI companies, including Elon Musk, signed a letter to the United
Nations (UN) in 2017 that urges the body to ban lethal autonomous
weapons.36 In 2018, the UN Secretary-General António Guterres stated
that "machines that have the power and the discretion to take human
lives are politically unacceptable, are morally repugnant, and should be
banned by international law."37 Also in 2018, members of the European
Parliament adopted a resolution asking member states and the European
Council for "the start of international negotiations on a legally
binding instrument prohibiting lethal autonomous weapons systems."38 [If
policymakers enacted such a ban, it would **slow research into AI**, as
historically, at least in the United States, **defense agencies** have
been a **source of significant funding** for **technology advancement**,
such as the Internet]{.underline}. [And much of the research to
**support autonomous weapons** would **yield dual-use technology** that
could be used **for commercial purposes**]{.underline}. [For example, a
fully autonomous tank will likely rely on large portions of the same
algorithms and data used to develop a fully autonomous military
transport vehicle]{.underline}.39 [**These same algorithms would be
relevant** to developing autonomous vehicles **for civilian
use.**]{.underline}

**[Continued AI innovation]{.underline} enables us to out-compete
China.**

**Wheeler**, visiting fellow in Governance Studies at The Brookings
Institution, Chairman of the Federal Communication Commission (FCC) from
2013 to 2017, **'20**

(Tom, "Digital Competition With China Starts With Competition At Home,"
<https://www.brookings.edu/wp-content/uploads/2020/04/FP_20200427_digital_competition_china_wheeler_v3.pdf>)

[[The U]{.underline}]{.mark}nited [[S]{.underline}]{.mark}tates [[and
China]{.underline} [are engaged in]{.underline}]{.mark} a
[**[technology-based conflict]{.underline}** [to
**determine**]{.underline}]{.mark} [**21st-century** international
[economic **leadership**]{.mark}]{.underline}. [China's
approach]{.underline} [is to identify]{.underline} and support the
research and development efforts of a handful of "**[national
champion]{.underline}**" [companies]{.underline}. [The
**[dominant]{.mark} tech [companies]{.mark}**]{.underline} of the U.S.
**[[are de facto embracing this]{.underline}]{.mark}** Chinese
[policy]{.underline} in their effort to maintain domestic marketplace
control. [Rather than embracing a China-like consecration]{.underline}
of a select few companies, [[America's]{.mark} digital
[competition]{.mark}]{.underline} with China **[[should begin with
meaningful competition]{.underline}]{.mark}** at home and the
allAmerican reality that competition drives innovation.

America's dominant tech companies have seized upon the competition with
China as a rationale for why their behavior should not be subject to
regulatory oversight that would, among other things, promote
competition. "[China doesn't regulate its companies]{.underline}" [has
become a go-to policy response]{.underline}. When coupled with "of
course, we support regulation, but it must be responsible regulation,"
it throws up a smokescreen that allows the dominant tech companies to
make the rules governing their marketplace behavior.

[[At the heart of digital competition]{.underline}]{.mark} --- both at
home and abroad --- [[is the capital asset]{.mark} of the 21st
century:]{.underline} **[[data]{.underline}]{.mark}**. [Initiatives such
as **machine learning**]{.underline} [and **artificial
intelligence**]{.underline} are data-dependent, [requiring a large data
input]{.underline} [to enable algorithms to reach a
conclusion]{.underline}. [[China's immense
population]{.underline}]{.mark} of almost 1.5 billion [gives it an
advantage in this regard]{.underline}. By definition, a population that
approaches five times the size of the U.S. population produces more
data. The previously "backward" nature of the Chinese economy has
resulted in another Chinese data advantage: New smartphone-based apps,
created in place of the digital integration that China previously
lacked, produce a richer collection of data. [This bulk and richness of
Chinese data [creates]{.mark}]{.underline} **[[an inherent]{.mark}
digital [advantage]{.mark}]{.underline}** when compared to the United
States.

[[If the United States **will never out-bulk China**]{.underline} [in
the quantity and quality of]{.underline} [data**, it must
out-innovate**]{.underline}]{.mark} **[[China]{.underline}]{.mark}**.
[Here]{.underline}, [the U]{.underline}nited [S]{.underline}tates **[has
an advantage]{.underline}**, [should it choose]{.underline} to take it.
**[The [centralized control]{.mark}]{.underline}** of the Chinese
digital economy **[[is an anti-entrepreneurial
force]{.underline}]{.mark}**. In contrast, [**[innovation]{.underline}**
[is the hallmark of a free]{.underline}]{.mark} [and open
[market]{.mark}.]{.underline} [[But the]{.mark} domestic [market]{.mark}
[must]{.mark}, indeed]{.underline}, **[[be free]{.underline}]{.mark}**,
open, and competitive.

[Currently]{.underline}, [the]{.underline} American [digital marketplace
**is not competitive**]{.underline}. [A handful of
companies]{.underline} **[command]{.underline}** the marketplace by
hoarding the data asset others need to compete. [As innovative
as]{.underline} America's tech [giants may be]{.underline}, [they
represent a **bottleneck**]{.underline} **[that starves independent
innovators]{.underline}** **[of the mother's milk of digital
competition]{.underline}**. [If America is to **out-innovate
China**]{.underline}, [then]{.underline} American
**[innovators]{.underline}** [need access to the **essential data
asset** **required for that innovation**]{.underline}.

[The [nation's response]{.mark} to Chinese competition]{.underline}
[[must not be the adoption of]{.underline}]{.mark} China-like national
**[[champions]{.underline}]{.mark}**, nor the "China doesn't regulate
its companies that way" smokescreen. American [public [policy should
embrace]{.mark}]{.underline} the all-American concept of
**[[competition-driven innovation]{.underline}]{.mark}**. [[This begins
with **breaking the bottleneck**]{.mark} that withholds data from its
**competitive application**]{.underline}. [This **does not necessarily
mean** **breaking up** the dominant companies]{.underline}, but [it does
mean breaking]{.underline} open **[their mercenary lock]{.underline}**
on the **[assets essential for competition-driven
innovation]{.underline}**.

**Maintaining our innovative lead solves nuclear war**

**Kroenig and Gopalaswamy 18** -- Associate Professor of Government and
Foreign Service at Georgetown University and Deputy Director for
Strategy in the Scowcroft Center for Strategy and Security at the
Atlantic Council; Director of the South Asia Center at the Atlantic
Council

Matthew Kroenig and Bharath Gopalaswamy, \"Will disruptive technology
cause nuclear war?,\" Bulletin of the Atomic
Scientists, 11-12-2018, <https://thebulletin.org/2018/11/will-disruptive-technology-cause-nuclear-war/>

Rather, [we should think **more broadly** about how **[new
technology]{.mark}** might affect global politics]{.underline}, and, for
this, [it is helpful to turn to]{.underline} scholarly international
relations theory. The dominant theory of the causes of war in the
academy is [the "bargaining model of war." This theory [identifies
**rapid shifts**]{.mark} in the balance of power [as a **primary cause
of conflict**]{.mark}.]{.underline}

[International politics often presents states with conflicts that they
can settle through **peaceful bargaining**, but when bargaining **breaks
down, war results**. **Shi[fts]{.mark}** [in the balance of power are
**problematic** because they **undermine effective
bargaining**]{.mark}]{.underline}. After all, why agree to a deal today
if your bargaining position will be stronger tomorrow? And, [a clear
understanding of the **military balance of power** can contribute to
**peace**.]{.underline} (Why start a war you are likely to lose?) [But
shifts in the balance of power **muddy understandings** of which states
have the advantage.]{.underline}

You may see where this is going. [New technologies threaten to create
potentially **destabilizing shifts** in the balance of
power.]{.underline}

For decades, [stability in Europe and Asia has been supported by US
military power. In recent years]{.underline}, however, [the balance of
power in Asia has begun to shift, as China has increased its military
capabilities.]{.underline} Already, [[Beijing has become **more
assertive**]{.mark} in the region]{.underline}, claiming contested
territory in the South China Sea. [And the results of Russia's
**military modernization** have been on **full display** in its ongoing
intervention in Ukraine.]{.underline}

Moreover, [[China **may have the lead**]{.mark} over the United States
[in **emerging technologies**]{.mark} [that **could be decisive**
for]{.mark} the future of [military acquisitions]{.mark} and
warfare]{.underline}, [[including]{.underline}]{.mark} 3D
**[printing]{.underline}**, **[[hypersonic]{.underline}]{.mark}**
missiles, **[[quantum]{.underline}]{.mark}** computing,
**[[5G]{.underline}]{.mark}** wireless connectivity, [[and]{.underline}
**[a]{.underline}**rtificial **[i]{.underline}**ntelligence]{.mark}
(AI). And Russian President Vladimir Putin is building new unmanned
vehicles while ominously declaring, "Whoever leads in AI will rule the
world."

[[If China]{.mark} or Russia are able to **[incorporate new
tech]{.mark}nologies** into their militaries **[before the United
States]{.mark}**, then [this could lead to the kind of **rapid
shift**]{.mark} in the balance of power [that]{.mark} **often [causes
war.]{.mark}**]{.underline}

[If Beijing believes emerging technologies provide it with a **newfound,
local military advantage** over the United States]{.underline}, for
example, [it may be **more willing**]{.underline} than previously [to
**initiate conflict over Taiwan**. And if Putin thinks new tech has
**strengthened his hand**, he may]{.underline} be more tempted to
[launch a Ukraine-style **invasion of a NATO member**.]{.underline}

[[Either]{.mark} scenario [could bring]{.mark} these **[nuclear powers
into direct conflict]{.mark}** with the United States, and]{.underline}
once nuclear armed states are at war, [[there is an **inherent risk
of**]{.mark} **nuclear [conflict]{.mark}** [through limited]{.mark}
nuclear [war]{.mark} strategies, nuclear [brinkmanship]{.mark}, or
simple accident or [inadvertent escalation]{.mark}.]{.underline}

This framing of the problem leads to a different set of policy
implications. [The concern is]{.underline} not simply technologies that
threaten to undermine nuclear second-strike capabilities directly, but,
rather, any [technologies]{.underline} that [can result in a meaningful
shift in the broader balance of power]{.underline}. And [the solution
is]{.underline} not to preserve second-strike capabilities, but [to
**preserve prevailing power balances** more broadly.]{.underline}

When it comes to new technology, [this means that [the U]{.mark}nited
[S]{.mark}tates [should seek to **maintain an**]{.mark} **innovation
[edge]{.mark}**]{.underline}. Washington should also work with other
states, including its nuclear-armed rivals, to develop a new set of arms
control and nonproliferation agreements and export controls to deny
these newer and potentially destabilizing technologies to potentially
hostile states.

These are no easy tasks, but [the consequences of Washington **[losing
the race]{.mark}** for technological superiority to its autocratic
challengers just [might mean **nuclear
Armageddon**]{.mark}.]{.underline}

### 

### 2NC\-\--Link

#### Forcing all NATO countries to adhere to uniform ethical guidelines [hamstrings innovation]{.underline} and [the competitiveness of the DIB]{.underline}. 

**Castro & McLaughlin 19** \-\-- \*Vice President, ITIF, and Director,
Center for Data Innovation. \*\*Research Analyst Information Technology
and Innovation Foundation

Daniel & Michael, 2-4-2019, \"Ten Ways the Precautionary Principle
Undermines Progress in Artificial Intelligence,\" ITIF,
https://itif.org/publications/2019/02/04/ten-ways-precautionary-principle-undermines-progress-artificial-intelligence/

1\. **[Slower and More Expensive AI Development]{.underline}**

[Policies based on the precautionary principle both slow and make the
development of AI more expensive]{.underline}. For example, if all fifty
U.S. states had laws such as New York's, which requires autonomous
vehicle firms to perform road testing under the paid supervision of
police, testing such vehicles would be more expensive. Moreover,
proposals to require even non-medical algorithms to undergo pre-market
trials would hurt the development of AI because such trials are
time-consuming and expensive. [Such proposals may also make AI systems
that use machine learning, and thus may change frequently and need more
testing, significantly less viable because such systems could constantly
need to go through a new approval process]{.underline}.96 [Finally,
policies that **increase the cost of developing AI** would likely
**discourage innovation in AI** by creating **a substantial barrier to
entry for startups** that lack sufficient funding to cover the cost of
proving their AI system is safe]{.underline}. For example, the GDPR has
dampened investment in European technology startups and led to a 30
percent decrease in the market share of small online advertising firms
that lack the resources to easily comply with the regulation.97

[**Restrictions on one AI technology** can also **limit ways to develop
another** AI technology. For example, researchers in Germany are using
drones hovering hundreds of meters above highways to record the
movements of vehicles. This data can help develop simulations to test
autonomous vehicles; such simulations are important tools for improving
the safety of autonomous vehicles because otherwise they would need to
travel billions of miles for safety validation]{.underline}.98 While
this novel method of collecting data to validate the safety of
autonomous vehicles may or may not prove valuable, [implementing it in
the United States would be would be difficult to do at scale until the
FAA implements its new rules that allow out-of-sight drone flights and
flights over people]{.underline}.99

**[2. Less Innovation]{.underline}**

[AI will spur innovation so policies that limit the development of AI
will limit innovation.100 For example, proposals to ban or limit the
introduction of autonomous vehicles would also limit the generation of
new businesses, business models, and ways to do deliver services through
the "passenger economy."]{.underline} The passenger economy, a term
coined by Intel and research firm Strategy Analytics, "is the economic
and societal value that will be generated by fully
autonomous...pilotless vehicles."101 The firms envision a world where a
significant portion of vehicle ownership is replaced by fleets of
autonomous vehicles that provide on-demand transportation. Productivity
would also increase as autonomous vehicles free employees to work during
their commutes and autonomous trucks to operate more efficiently. The
firms estimate the value of this economy could be \$7 trillion by
2050.102 Nations that ban autonomous vehicles will not experience the
benefits of such an economy.

**[3. Lower-Quality AI]{.underline}**

[There is often a negative correlation between making an AI system more
explainable and its accuracy.103 As a result, any policies that require
AI to be explainable could **lead to less accurate AI**]{.underline}.
For example, researchers at Mount Sinai Hospital in New York developed
an AI system called Deep Patient that can predict whether a patient is
contracting any of a wide variety of diseases.104 The researchers
trained Deep Patient on the health data from 700,000 patients, using
hundreds of variables, such as test results, which allow it to predict
diseases such as schizophrenia---which doctors struggle to
predict---extremely well.105 Even though its operators can verify its
accuracy by measuring outcomes, such as if a person is developing a
disease, it is difficult for its own developers to know why it made a
particular decision.106

Many sophisticated forms of AI pose a similar problem. [Developing an AI
system capable of explaining itself or justifying its decisions is an
incredibly challenging technical feat, so much so that the U.S. Defense
Advanced Research Projects Agency (DARPA) devoted \$75 million in 2017
to research how AI could achieve it.]{.underline}107 [Some groups are
skeptical that requiring explainability would chill
innovation]{.underline}. They cite DeepMind, a British company owned by
Google parent-company Alphabet, developing an AI system in 2018 that can
analyze eye scans to predict diseases while also providing doctors a map
of the features of disease it sees, such as hemorrhages.108 [However,
the fact that one of the world's leading AI companies could achieve a
form of explainability in a system it worked on for nearly two years is
not evidence that all other operators should or would be able to achieve
explainability for their AI easily]{.underline}.109 To be clear, it is
legitimate for companies, such as IBM, to create internal requirements
for AI explainability.110 [Requiring all firms to meet such a standard,
however, would **create a barrier to adopting AI,** because not all AI
systems are alike and not all businesses have a similar level of
expertise.]{.underline}

Nonetheless, it is important for AI operators to continually assess
their AI system's accuracy to ensure it is generating or predicting the
correct outcomes. The other option is to allow only AI applications that
operators can explain; this would lead to AI systems that consider fewer
variables and that use simpler algorithms to make decisions.  In turn,
this would reduce the effectiveness of AI that can generate significant
impacts such as identifying a terminal illness before a doctor can.

4\. Less AI Adoption

The right to human review illustrates how attempts to mitigate the
impact of AI could also stifle its adoption. One of the reasons firms
use AI is because it increases productivity as it can analyze large
amounts of data significantly faster and cheaper than humans. For
example, LawGeex, a firm that uses AI to automate the review and
approval of contracts, created an AI system that outperforms lawyers in
identifying risks in non-disclosure agreements (NDAs). During a test in
which 20 lawyers and LawGeex's AI were each given five NDAs to review,
the lawyers took an average of 92 minutes to review the contracts and
had a mean accuracy score of 85 percent. LawGeex's AI, however, achieved
94 percent accuracy and only took 26 seconds to review all the
contracts.111

A right to human review would require firms to review significant
decisions made by algorithms. Such a requirement is particularly
problematic because the complexity and amount of data used by some AI
systems to make accurate decisions can make it nearly impossible for
firms to explain exactly why a system made one decision, even though
they may be able to provide a general explanation of how the system
works. Thus, it would take significant time and expertise for a firm to
explain many decisions made by AI, which then makes using AI more
expensive---negating one of its benefits. Firms subject to a right to
human review can make one of three choices.  They can: 1) use
sophisticated AI, but face litigation if they cannot properly explain a
decision, 2) implement simple, and therefore more explainable but less
useful, forms of AI, or 3) leverage no AI at all. The first option is
not viable over the long term, leaving firms with only the latter two
options. And if firms choose either of these options, the economy will
be less productive.112

5\. Less Economic Growth

PricewaterhouseCoopers predicts AI can boost global gross domestic
product by 14 percent by 2030.113 Unfortunately, policies based on the
precautionary principle often discourage the use of AI out of fears that
AI will eliminate jobs. For example, Amy Webb, founder of the Future
Today Institute, which researches emerging technologies, professes, "We
need to address a difficult truth that few are willing to utter aloud:
AI will eventually cause a large number of people to be permanently out
of work\..."114

But policies that discourage the use of AI due to the prevalence of such
fears rob economies of ways to become more productive, something that
all developed nations will desperately need over the course of the next
three decades as populations age and dependency ratios increase. If
productivity growth really eliminates net jobs, then developed nations
should be in depression-like conditions, as productivity over the last
50 years has increased in most nations by over 75 percent.115 The
reality is that productivity leads to cost savings, most of which are
passed on to consumers in the form of lower prices or to workers in the
form of higher wages, both of which spur more spending, which in turn
spurs job creation. Consequently, virtually all economic studies show
that productivity gains lead to more jobs, even if there is short-term
job loss.116 Policies that aim to stem the introduction of AI, and thus
automation, will reduce per-capita income growth.

6\. Fewer Options for Consumers

Biometric laws show how passing legislation to address hypothetical
problems can discourage the use of AI, such that consumers have access
to fewer services or products. For example, Illinois users of Facebook,
Shutterfly, Google, and Snapchat have all sued the companies for
scanning their faces without consent, which is illegal under the state's
Biometric Information Privacy Act.117 Regardless, the companies were
typically sued for relatively innocuous uses of AI, such as for scanning
individuals' faces to tag them in photos or to add alterations to
photos.118

Such threats of legal action do and will lead to fewer services for
consumers. For example, Illinois and Texas' biometric laws led to Google
blocking individuals in those states from using its Arts and Culture
app.119 Millions of individuals have downloaded the app, which scans
users' faces and compares those images to those of paintings in Google's
database to find users' doppelgängers in famous art.120

Similarly, some lawmakers have already passed precautionary legislation
related to autonomous vehicles that limit consumers' options. For
example, Washington, D.C. enacted a law in 2013 that requires a licensed
human driver in the front seat of autonomous vehicles who is prepared to
take control of the vehicle at any moment. This requirement means people
with certain disabilities, who would like the independence that would
come from using autonomous vehicles but do not qualify as a capable
human driver under this law, are unable to use autonomous vehicles, even
if they can safely operate them.121 The requirement might be reasonable
given the current state of the technology, but locks in a standard that
is unhelpful over the long term. Instead of a broad restriction that
requires a capable individual in the driver's seat of autonomous
vehicles, government regulators, such as the National Highway Traffic
Safety Administration (NHTSA) in the United States, should develop and
enforce safety standards that preempt local laws, but allow the
operation of fully autonomous vehicles that meet safety standards.

7\. Higher Prices

By raising the costs of using AI for operators or by banning forms of
AI, policies based on the precautionary principle also keep prices high
for consumers. For example, some policies would require businesses to
get express consent before using facial recognition. Yet, U.S. stores
lose nearly \$50 billion every year due to shoplifting, and facial
recognition could reduce that figure by helping catch repeat
offenders.122 Shoplifting costs consumers because money lost from
shoplifting leads to higher prices---shoplifting cost the average U.S.
family over \$400 in 2009---instead of being put towards increased
investments in customer experience improvements.123

Another way the precautionary principle keeps prices artificially high
for consumers is by limiting the ways firms can offer their services or
products through bans. For example, delivery robots can perform the
"last mile" of a delivery---where transporters move packages from a
central hub to an individual's residence. Today the process is
time-intensive and can be up to 28 percent of a product's transportation
cost.124 As a result, efforts to ban robots on sidewalks, which could
reduce these costs, would rob consumers of faster and cheaper
deliveries.

Likewise, slowing the introduction of autonomous trucks hurts consumers.
There was a shortage of 51,000 truck drivers in the United States in
2017 which grew to 63,000 in 2018.125 Truck driver turnover rates are
also 94 percent, meaning employers in the for-hire trucking market need
to replace the vast majority of employees they hire every year.126 The
situation has already led to delayed deliveries and higher prices for
consumers and may only get worse because there will be 900,000 truck
driver openings in the United States over the next decade due to
retirements.127

8\. Inferior Consumer Experiences

Policies that require firms to get prior consent before using commercial
applications of AI, including facial recognition, can actually delay
improvements in consumer experiences. For example, AI may be able to
reduce the effects of implicit bias---the stereotypes that affect human
actions in an unconscious manner. These stereotypes lead to people of
color getting falsely accused of theft by store employees.128 Indeed,
employees for Nordstrom Rack, Staples, and Finish Line have all wrongly
accused African-Americans of theft in 2018.129 But AI technologies can
improve the consumer experiences of all people, including people of
color, by replacing or complementing human decision-making. Amazon Go,
one of Amazon's cash-register-less stores, uses cameras, sensors, and
computer vision technology to "see" who takes items off shelves, adding
these items to a virtual shopping cart so that checkout is seamless.
Many retailers are moving in this direction, with over 150 companies,
including 7-Eleven and two of China's largest e-commerce businesses,
Alibaba and JD.com, experimenting with using facial recognition and
other biometrics to eliminate the need for cashiers. As a result, store
employees are not looking for potential shoplifters because the
technology automatically charges customers for what they take when they
leave the store.130 After visiting Amazon Go, former CNET senior
associate editor Ashlee Clark Thompson, an African-American journalist,
wrote "No one cared what I was doing. Is this what it feels like to shop
when you\'re not black?"131

9\. Fewer Positive Social Impacts

AI can and already is generating positive social impacts, from mapping
poverty to measuring literacy rates to helping doctors treat deadly
infections.132 It is also helping make society safer, but the
demonization of such AI applications as facial recognition and proposals
to phase in AI could derail its benefits. While privacy advocates are
stoking fears of future mass surveillance, law enforcement is already
using facial recognition for several positive purposes. These purposes
include identifying uncooperative suspects, such as the Capital Gazette
shooter.133 In addition, some airports, such as the Washington Dulles
International Airport, employ the technology to catch individuals using
false documents.134

Law enforcement also uses AI to find victims. For example, the Fort
Worth Police Department uses a combination of AI tools from Marinus
Analytics, which builds AI tools to fight human trafficking, including
facial recognition, to identify victims of human trafficking. With
thousands of escort ads appearing online each day, AI can significantly
reduce the time it would take a detective to go through the ads
manually.135 While no government should use facial recognition to
undermine personal freedoms and rights among its citizens or to unfairly
target certain demographic groups, nations can mitigate negative uses
without creating bans that curtail the use of beneficial ones.

Unfortunately, misguided proposals to curtail negative impacts from AI
can create other negative impacts. For example, phasing in autonomous
trucks to lessen job loss would be detrimental to the environment.
Tractor trailers account for a disproportionate amount of greenhouse gas
emissions, but autonomous trucks can take advantage of platooning, a
form of driving where the trucks drive closer together than humans can
by using vehicle-to-vehicle communication and sensors to automatically
break and accelerate together.136 The trucks following the leader
experience less wind resistance, which improves fuel
efficiency.137 Limiting the number of autonomous trucks on roads,
however, keeps emissions from trucks higher than necessary. In addition,
banning autonomous vehicles in the United States would rob the nation of
a potential \$900 billion in yearly savings from fewer crashes.138

[10. **Reduced** Economic Competitiveness and **National
Security**]{.underline}

[**Nations that slow AI adoption will** metaphorically **tie one hand
behind the backs of their companies competing** in global markets.
Moreover, for nations such as the United States, finishing behind China
in the global race to be the leader in AI not only limits its ability to
influence the development of AI, but also raises **national security
concerns** due to the many **potential national security applications of
AI** and the **reduced competitiveness** of the **defense industrial**
base.139]{.underline}

#### It stifles the positive benefits of AI development. 

**Gürkaynak 18** \-\-- Founding Partner of ELIG Gürkaynak
Attorneys-at-Law, LL.M. from Harvard Law School, İlay Yılmaz, Partner at
ELIG Gürkaynak Attorneys-at-Law, and Güneş Haksever, LLM from Istanbul
Bilgi University, Attorney at IBM Turkey.

Gönenç, "Stifling Artificial Intelligence: Human Perils", Computer Law &
Security Review, Volume 32, Issue 5, 12/12/2018,
https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3285264

[[Although scientists]{.underline}]{.mark} have [[calculated]{.mark} the
**[significant positive]{.mark} welfare [effects]{.mark}**
[of]{.mark}]{.underline} Artificial Intelligence [[(AI)]{.mark}, **fear
mongering** continues to **hinder** AI **development**. [If
**reg**]{.mark}**ulation[s]{.mark}** in this sector **[stifle]{.mark}**
our active imagination, [we risk **wasting**]{.mark} the **[true
potential]{.mark}** of AIs dynamic efficiencies]{.underline}. Not only
would Schumpeter dislike us for spoiling creative destruction, but the
AI thinkers of the future would also rightfully see our efforts as [[the
**'dark age'** of]{.mark} human [advancement]{.mark}]{.underline}. This
article provides a brief philosophical introduction to artificial
intelligence; categorizes artificial intelligence to shed light on what
we have and know now and what we might expect from the prospective
developments; reflects thoughts of worldwide famous thinkers to broaden
our horizons; provides information on the attempts to regulate
artificial intelligence from a legal perspective; and discusses how the
legal approach needs to be to ensure the balance between artificial
intelligence development and human control over them, and to ensure
friendly artificial intelligence.

Our technology, our machines, is part of our humanity. We created them
to extend ourselves, and that is what is unique about human beings. --
Ray Kurzweil1

1\. Introduction

The Chinese cardboard game "Go" is one of the most complex strategy
games humankind invented. Go was considered so important, there are
myths indicating that ancient kings played Go between their armies in
the battlefield to resolve the conflict in peace. Computers prevailed
against humanities best in many zero-sum, perfect-information, partisan,
deterministic strategy games2 before, with the exception of Go, which
was something to be proud of.

The strategy aspect of Go is very complex and emphasizes the importance
of balance on multiple levels and has internal tensions. A game of Go
cannot be won by using brute force: calculating every possible move,
similar to what IBM®'s then state of the art AI, Deep Blue® used to win
over Gary Kasparov. To manoeuvre through the countless possible moves on
the Go board and chose the most efficient path, one requires
capabilities beyond the conventional computing powers; capabilities only
our minds have (or so we thought), such as extremely accurate image and
pattern recognition and insight, all of which we thought granted us
superiority over the artificial minds we created.

In October 2015, a software called "AlphaGo®" became the first computer
to beat a professional human Go player in an un-handicapped game of Go
(Silver and Hassabis, 2016). AlphaGo's victory is probably one of the
most significant demonstrations of the capabilities of an AI. Firstly,
it shows that AIs are beginning to surpass us at things where success is
dependent on strategy as well as calculation. Things we classify as a
"game", from stock exchange to conflicts, from contract negotiations to
hostage situations. Second, AlphaGo developed strategies on its own,
through playing millions of games against itself. These feats sent the
chills down the spines of those who fear that AIs will overpower us in
the future.

We humans accelerate the future with our minds. This is a strength and a
weakness. [[Often]{.underline}]{.mark}, our [**[predictions]{.mark}** of
the future [are **highly inaccurate**. Based on]{.mark} predictions from
a book called ['The World in 2010']{.mark}, published [in]{.mark}
19[**76**, we]{.mark} should have **[be]{.mark}**en living [**above**
and **below**]{.mark} the surfaces of **[three planets]{.mark}** as of
**[five years ago]{.mark}**. Predictions [regarding]{.mark} the future
of **[AI]{.mark}** are **[equally]{.mark} likely** to be **[off
base]{.mark}**]{.underline}.

[To avoid **premature** regulation over AI, we should]{.underline} be
studying and **[search]{.underline}**ing [for the **meaningful point in
time** when a broader anxiety about AI becomes a genuine
concern]{.underline}. The study of a point of ripeness, a 'threshold
ability test,' asks when AI could really bring about concrete
disadvantages that might counter-balance the demonstrated contribution
to economic efficiency and welfare.

[In the absence of]{.underline} such [an **objective
benchmark**]{.underline} marking the point in time when AI becomes a
competitor with the human mind, [[regulators could]{.mark} easily
**[jump the gun]{.mark}** in regulating AI, [which]{.mark} would [lead
to **irreparable harm**]{.mark} in **total welfare** [of]{.mark} human
[societies]{.mark}]{.underline}.

Most of what we consider AI today is really our own intelligence
re-formatted and re-cycled, with the help of computers lacking any skill
of learning or consciousness of being. [Regulation at this stage would
be **perverse**. The economic efficiency **[potential]{.mark}**s of AI
[should be]{.mark} set **[entirely free]{.mark}** at **this point** in
time, [allowing]{.mark} us to **[active]{.mark}**ly [and
**aggressivel**]{.mark}y [research]{.mark} appropriate goals for them
which would **not** result in the **extinction** of
humankind]{.underline}.

[If you think]{.underline} our [future **robot overlords**
will]{.underline} one day [thank us for ignoring]{.underline} the risks
[and **under regulating**, **think again**]{.underline}. On the one
hand, [**[any issues]{.mark}** we may face [from **AI**]{.mark}s
[will]{.mark} likely [result from]{.mark} humanity [**failure**
to]{.mark} **effectively [direct]{.mark}** AIs [to]{.mark} our
**[needs]{.mark}**, **not** because we switched to a defensive AI
regulation regime **too early**]{.underline}. On the other hand, [[at
**some point**]{.mark} of time]{.underline} in the not too distant
future, [[**natural**, **human**]{.mark}**-related** [or
**external**]{.mark} factors may [**threaten** the **fate of the
Earth**, and we]{.mark} may **[need AI to save]{.mark} the planet and
[us]{.mark}**. One **[hope]{.mark}**s that [society has not **pulled
the**]{.mark} **hand [brakes]{.mark}** on the wheels of AI **[too
early]{.mark}**]{.underline}, fearing our own active imagination.

#### Turns the AFF: Military regulations [destroys]{.underline} AI control by driving it [underground]{.underline}, [abroad]{.underline}, or into [higher-risk]{.underline} areas

**Watson 21** \-\-- PhD in Engineering from the University of
Gloucestershire, Degree in AGI Safety Fundamentals from the University
of Cambridge, Senior Scientific Advisor to The Future Society at Harvard
University, Fellow at the British Computing Society and Royal
Statistical Society.

Dr. Nell, "Regulatory Challenges to Catastrophic AI Risk", ExO Insight,
11/24/2021, https://insight.openexo.com/regulatory-challenges-to-ai/

Rick Increase Factors:

Obfuscation: [**Reg**ulation**s** may **drive research underground**
where it is **harder to monitor**, or to **'flag of convenience'
jurisdictions** with **lax restrictions**, by **embedding** dangerous
**tech**nologies with**in** apparently benign **cover operations**
(multipurpose technologies), or by **obfuscating** the **externalized
effects** of a system, such as in the **vehicle emissions**
scandal]{.underline} (Wikipedia).

Arms race: Recent advances in machine learning such as multimodal
abstractions models (aka Transformers, Large Language Models, Foundation
Models) such as GPT-3 and DALL-E illustrate that dumping computing
resources (and the funds for them) in colossal models seems to be a
worthy investment. So far, there is no apparent limit or diminishing
return on model size, and so now state and non-state actors are
scrambling to produce the largest models feasible in order to access
thousands of new capabilities never before possible. An arms race is
afoot. Such [arms races can lead to **rapid** and **unexpected**
take-off in terms of AI capability, and the rush can blindside people to
risks, especially when]{.underline} the [loss]{.underline} of a race
[can mean an **existential threat**]{.underline} to a nation or
organization.

Perverse incentives: Incentives can be powerful forces within
organizations, and financialization, moral panic, or fear of political
danger may cause irrational or incorrigible behavior of personnel within
organizations.

Postmodern Warfare: Inexpensive Drones and other AI-enabled technologies
have tremendous disruptive promise within the realm of warfare,
especially given their asynchronous nature. Control of drone swarms must
be performed using AI technologies, and this may encourage the entire
theatre of war to be increasingly delegating to AI, perhaps including
the interpretation of rules of engagement and grand strategy. (Lsusr,
2021)

Cyber Warfare: Hacking of systems is increasingly being augmented with
machine intelligence (Cisomag, 2021), through GAN-enabled password
crackers (Griffin, 2019) and advanced social engineering tools (Newman,
2021). This is equally the case in the realm of defense, where only
machine intelligence may provide the swift execution required to defend
systems from attack. A lack of international cyberwar regulations, and
poor international policing of organized cybercrimes, may increase the
risk of catastrophic risks to societal systems.

Zersetzung: The human mind is becoming a new theatre of war, through
personalized generative propaganda, which may even extend to gaslighting
attacks on targeted individuals, significantly leading to
destabilization of societies (Williams, 2021). Such technologies are
also plausibly deniable, being difficult to prove who may be
responsible.

[Inflexibility: The German Military after WW1 was **not** allowed to
develop their **artillery** materiel, and so developed powerful
**rocket** **tech**nologies **instead**, as these were **not subject to
regulation**. Similarly, inflexible rules may permit **exploitable
loopholes**. They may also **not be sufficiently adaptive** to allow for
the **implementation** of **new technologies** and even improved
**industry standards**.]{.underline}

Limitation of problem spaces: -- [It may be taboo to allow machine
intelligence to work on sensitive issues or to be exposed to
controversial (if potentially accurate) datasets. This may limit the
ability of AI to make sense of out complex issues, and thereby
**frustrate finding** **solutions** for **crises**]{.underline}.

### 

**[2NC\-\--AT: AI = No War]{.underline}**

**High tech warfare means [defense doesn't apply]{.underline}\-\--AI
escalation leads to [nuclear war]{.underline}**

**Saalman, 18**

Lorea Saalman, EastWest Institute Asia-Pacific Program Vice President,
"\"Fear of false negatives: AI and China\'s nuclear posture\"; Bulletin
of the Atomic Scientists. April 2018.
https://thebulletin.org/2018/04/fear-of-false-negatives-ai-and-chinas-nuclear-posture

New pockets of excellence. In its relations with Russia and the United
States, [China has long contended with nuclear asymmetry]{.underline}.
**[[AI]{.underline}]{.mark}** and autonomy, in contrast,
**[[offer]{.mark} Beijing the [long-term potential to disrupt
Washington's]{.mark} traditional [strengths]{.mark}]{.underline}**.
[They open the door for swarm and]{.underline} other [technologies that
could overwhelm conventional and nuclear platforms]{.underline} that are
larger, more cumbersome, and less agile. While China may be concerned
about potential adversaries tracking its own nuclear platforms and
systems, Beijing is just as likely to avail itself of these relatively
inexpensive methods of disrupting US activities. Also, Chinese
publications indicate that [[Beijing is building
autonomy]{.underline}]{.mark} into its own "bolt-out-of-the-blue"
systems, for example in hypersonic glide vehicles such as the DF-ZF. As
China debates integration of automation via launch-on-warning, [doing so
[with]{.mark} a **[greater]{.mark} range of [AI]{.mark}** and autonomy
in [it]{.mark}s tool kit [could lead to **destabilizing
trends**]{.mark}**.**]{.underline} Again, the most sensational advances
in these enabling technologies do not necessarily carry the greatest
implications for China's military and nuclear force structure. Instead,
[what counts is the level of AI and autonomy introduced into Beijing's
command and control structure.]{.underline}

When it comes to platforms, this author's preliminary review of Chinese
technical writings on AI and autonomy reveals that Beijing's greatest
emphasis, at least where the most flexible systems are concerned, is on
unmanned aerial and underwater vehicles. In China's view, these systems
can be leveraged for a range of activities, including enhanced accuracy
in: battlefield reconnaissance, surveillance, patrolling, electronic
reconnaissance, communications, electronic interference, combat
assessment, radar deception, projectile firearms, laser guidance, target
indication, precision bombing, interception and launch of tactical
missiles and cruise missiles, and anti-armor, anti-radiation, and
anti--naval vessel capabilities; as well as nuclear, chemical, and
biological detection and operations. When the topic turns to leveraging
new means of warfare, Chinese writings discuss the use of swarm systems
(link in Chinese) for a number of purposes, with battlefield
applications focusing on anti-submarine warfare and countering
integrated air defense.

AI and autonomy provide China an opportunity to exploit a new pocket of
excellence, but they are hardly ends in themselves. This is one of
myriad reasons that China has been reluctant to engage in arms control
efforts to constrain the deployment of autonomous systems. Moreover, the
amount of Chinese research already being conducted in this arena,
particularly at the university level, is substantial. Research is
unlikely to diminish any time soon. (Programs on AI and autonomy receive
ample government support through such funds as the Laboratory of
National Defense Technology for Underwater Vehicles, Project for
National Key Laboratory of Underwater Information Processing and
Control, National Key Basic Research and Development Program, China
Aviation Science Foundation, National Science and Technology Major
Project, National 973 Project, National Key Laboratory Fund, National
"863" High-tech Research and Development Program, and Ministry of
Communications Applied Basic Research Project, among a number of
others.)

Expansive programs to turn AI and autonomy into a weaponized reality,
even in challenging or illusory domains such as underwater swarms,
indicate the emphasis this research receives within the hierarchy of
Chinese defense planning. Whether or not China is able to achieve all of
these capabilities, the vast resources and manpower allocated to these
endeavors merit great attention by the United States. The direct
implications of aerial and underwater swarms for larger, more lumbering
US nuclear and conventional platforms remain to be seen. However, if the
US Congress provides funding for the low-yield submarine-launched
ballistic and cruise missiles proposed under the 2018 Nuclear Posture
Review, China could deploy swarms to track and potentially intercept US
dual-capable platforms. In short, whether intentionally or
unintentionally, an escalatory scenario could develop.

The evolution of smaller platforms mobilized in joint formations could
turn China's nuclear asymmetrical disadvantage on its head. Much like
decoys, which can be used as an inexpensive means of confusing and
saturating missile defenses, low-cost swarms of unmanned aerial and
underwater vehicles, along with cyber technologies, could provide a
"guerilla combat--style" advantage against systems that the United
States sees as providing an element of surprise, speed, and precision.
Some of these platforms are already destined for deployment and will
provide China with greater capability to monitor US activities in the
Asia-Pacific region. However, if these platforms are turned toward
actual engagement---in efforts to disrupt or confront lower-yield,
smaller-scale US nuclear or dual-capable platforms---the potential for
miscalculation may grow.

[[If China enhances]{.mark} its development of [cruise missiles and
hypersonic]{.mark} glide platforms [by applying AI]{.mark}]{.underline}
and autonomy, [close-range [encounters off]{.mark} the coast of [Taiwan
and in the]{.mark}]{.underline} East and
**[[S]{.underline}]{.mark}**outh **[[C]{.underline}]{.mark}**hina
**[[S]{.underline}]{.mark}**eas **[could [grow]{.mark} even [more
complicated]{.mark}]{.underline}**. China's ground-launched DH-10
missile is believed to carry a conventional warhead, but indications
have emerged that the air-launched CJ-10 may have both nuclear and
conventional variants. Moreover, China has hedged on what kind of
payload will be carried by hypersonic glide platforms such as the DF-ZF,
which are designed to break through missile defenses. With the release
of the 2018 Nuclear Posture Review and Vladimir Putin's subsequent
declaration that Russia has developed new nuclear weapons, the United
States and Russia have engaged in a game of tit-for-tat. If China
follows suit, [a new set of [destabilizing variables could be
introduced]{.mark} into a region that is already tense and
crowded]{.underline}, with freedom-of-navigation operations carried out
among competing territorial claims.

From asymmetry, advantage. Within this environment, China's integration
of AI and autonomy aligns with its attempts to avoid being surprised by
a false negative. Though the United States and Russia are both trending
toward intentional escalation in their official doctrines, China's
response to this trend indicates a desire to avoid getting dragged into
a nuclear arms race. Nonetheless, [Beijing's **assumptions** about US
preemptory behavior have shaped its efforts to leverage its nuclear
asymmetry into an advantage]{.underline}. [One significant step in this
direction comes through [greater Chinese integration of AI]{.mark} and
autonomy]{.underline}, meant to mitigate the risk of being caught off
guard, whether by a conventional or nuclear system. While some aspects
of this dynamic have stabilizing potential---as is true of enhanced
situational awareness---strong indications suggest that China is engaged
in other pursuits **[that [could lead to miscalc]{.mark}ulation [at
the]{.mark} conventional and [nuclear level]{.mark}]{.underline}**.

**Chinese AI dominance is the death knell of global peace\-\--sparks
great power wars**

**Allison 20 --** Professor of Government, Harvard Kennedy School

Graham Allison, August 2020, \"Is China Beating the U.S. to AI
Supremacy?,\" Belfer Center for Science and International Affairs,
<https://www.belfercenter.org/publication/china-beating-us-ai-supremacy>

An AI Arms Race?

During the Cold War, the stakes in the nuclear arms race with the Soviet
Union were obvious. [In today's **Thucydidean rivalry** between a
**meteorically** rising **China** and a colossal ruling **United
States**]{.underline}, [what are the risks of an escalating AI arms
race?]{.underline}

Like it or not, **[[future war will be AI-driven]{.underline}]{.mark}**.
As Secretary of Defense Mark Esper recently noted at the conference of
the National Security Commission on AI, "[[Advances]{.mark} in AI
[have]{.mark} the [potential to change]{.mark} the character of [warfare
for generations]{.mark} to come. **[Whichever nation harnesses AI first
will have a decisive advantage]{.mark} on the battlefield [for]{.mark}
many, many [years]{.mark}."**]{.underline} [AI's ability to accelerate
decision cycles in conflict will compel militaries to adopt
it.]{.underline} In air-to-air combat, pilots begin with an ooda loop:
observe, orient, decide, act. If A can "get inside B's OODA loop," A
wins---since he can maneuver to escape A's fire and attack where he
calculates B's path will leave him when A's missile arrives. Because AI
can observe, orient, decide and act at multiples of a human pilot, it
will become irresponsible to send a human pilot into battle with an AI
piloted aircraft.51 As former Chairman of the Joint Chiefs of Staff
Joeseph Dunford put it: "**[Whoever has the competitive advantage in
artificial intelligence and can field systems informed by artificial
intelligence, could very well have an overall competitive
advantage]{.underline}**."52

The demonstrated success of AlphaGo, and more recently, AlphaStar, in
defeating all competitors in one of the world's most complex real-time
strategy video games suggests that [in any structured contest between
offense and defense, **[AI will dominate humans]{.mark}.**]{.underline}
[The company, country or team with [the best AI will
win]{.mark}]{.underline}. As an example, consider American football. In
what commentators often discuss as a "chess match," the offense and
defense coordinators know that if the defense guesses correctly whether
the next play will be a pass or a run, most nfl teams' defenses can
successfully stop most opponents' offense. Reading all the variables in
a situation, [AI should be able to tilt the scales [on the
field]{.mark}]{.underline}---or in analogous military competitions on
land, sea, and in the air and space.

[The domain's leader will also be the first to know which of today's
military mainstays AI will upend]{.underline}. Germany discovered the
power of submarines before World War I because it led in their
development. [British admirals did not wake up to their deadly
efficiency until a lone German U-boat in 1914 sank three armored
cruisers on a single morning.]{.underline} **[By then, it was too
late]{.underline}**---the British had already invested their treasure in
building battle fleet that had become largely obsolete. The coordination
of drones and cruise missiles that successfully attacked Saudi Arabia's
most valuable target and cut its oil exports by half is suggestive. Will
[AI-empowered [drone swarms make aircraft carriers]{.mark} equally
[obsolete]{.mark}, all for one one-thousandth of the cost? Will
[AI]{.mark} analysis of data from all sources [pierce]{.mark} the
[invisibility of]{.mark} stealthy systems like [the F-35]{.mark} in
which the United States has invested so substantially? **[The first
country to know will be]{.mark} the one [driving the]{.mark} research
and [development frontier.]{.mark}**]{.underline}

#### Chinese AI dominance increases incentives for China to be assertive in foreign policy

**Chang 18** -- Benjamin Angel Chang is the inaugural Andrew W. Marshall
Fellow at Georgetown University\'s Center for Security and Emerging
Technology (CSET).

Benjamin Angel Chang, December 2018, "Chapter 14. AI and US-China
Relations," in "AI, China, Russia, and the Global Order: Technological,
Political, Global, and Creative Perspectives,"
https://nsiteam.com/social/wp-content/uploads/2019/01/AI-China-Russia-Global-WP_FINAL_forcopying_Edited-EDITED.pdf

Independent of effects on the US-China relationship, [[intensified PRC
use of AI]{.mark} for domestic security [may]{.mark} also [encourage
greater Chinese assertiveness]{.mark}. Again, I highlight two potential
reasons. First, a pacified domestic sphere might free up attention for
expanded external aims]{.underline}. China's relative ability to weather
the 2008 financial crisis significantly motivated its recently more
assertive turn (Chen & Wang, 2011). Whereas many Chinese intellectuals
had previously sought to emulate Western economic development,
[**[viewing]{.mark} the [American stage of development as]{.mark} if [a
higher rung on a universally climbable ladder]{.mark}**, the **[crisis
incubated the view]{.mark} that, [instead, the Chinese model might be a
fine endpoint in and of itself]{.mark}**]{.underline}. Similarly, i[f
the CCP were to feel AI had successfully and permanently allowed it to
address the full panoply of possible sources of broad public unrest,
r**anging from unbalanced growth to Xinjiang to income inequality,** it
w]{.underline}ould likely see this as one of the Party\'s Chang 109
crowning achievements in its leadership of the Chinese people. Chinese
spending on domestic security has exceeded spending on external defense
since 2010, with the gap increasing each year. In 2017, according to the
best open-source estimate available, the former exceeded the latter by
18.6 percent (Zenz, 2018). Were [t]{.underline}he domestic sphere to be
"solved," some of this attention might then be turned outward. [Second,
**[concentrations of power generally]{.mark} tend to [lead to more
belligerence on the international]{.mark}** stage. In particular, by
substituting technology for manpower in carrying out the state\'s
policing functions]{.underline}, an [[AI]{.mark}**-empowered [PRC may
enable ever-smaller groups of elites to retain equivalent amounts
of]{.mark} power**]{.underline}. For de Mesquita et al. (1999, 2003),
[as the size of the coalition required for political survival (the
\"winning coalition\") shrinks, corruption and war may become more
likel]{.underline}y, as [[l**eaders no longer fear being
punished**]{.mark} **by other domestic actors [for selfish arrangements
or military defeats.37]{.mark}**]{.underline}

**[2NC\-\--AT: US Too Far Ahead]{.underline}**

**China's catching up\-\--continued innovation by America is necessary
to outpace them**

**Allison 20 --** Professor of Government, Harvard Kennedy School

Graham Allison, August 2020, \"Is China Beating the U.S. to AI
Supremacy?,\" Belfer Center for Science and International Affairs,
<https://www.belfercenter.org/publication/china-beating-us-ai-supremacy>

China's AI Surge

Though still in their infancy, [[AI tech]{.mark}nologies [will]{.mark}
be [drive]{.mark}rs of future economic growth and [national
security]{.mark}.]{.underline} From facial recognition and fintech to
drones and 5g, **[[China is not just catching up]{.mark}. [In many
cases]{.mark}, [it has]{.mark} already overtaken the United States to
[become the world's]{.mark} undisputed [No.
1]{.mark}]{.underline}**[.]{.mark} [In some arenas]{.underline}, because
of constitutional constraints and different values, [the United States
willfully forfeits the race. In others, **China is simply more
determined to win.**]{.underline}

China's AI surge is so recent that anyone not watching closely has
likely missed it. As late as 2015, when assessing its international
competition, American industry leaders---Google, Microsoft, Facebook and
Amazon---saw Chinese companies in their rearview mirrors alongside
German or French firms in the third tier. But this changed four years
ago---in 2016---when leading AI application company DeepMind fielded a
machine that defeated world champion Lee Sedol in the world's most
complex board game, Go.9 Even after several American companies' machines
had bested the chess masters of the universe10, most Chinese remained
confident that machines could never beat Go champions, since Go is ten
thousand times more complex than chess. Thus, DeepMind's decisive
victory became for China a "Sputnik moment"11---a jolt as dramatic as
the Soviet Union's launch of the first satellite into space that sparked
America's whole-of nation surge in math and science, nasa's creation and
the original "moon shot."

Kai-Fu Lee's book AI Superpowers offers an insightful summary of China's
engagement in the field. It began with President [[Xi]{.mark}
Jinping's]{.underline} personal reaction to the defeat of the world's Go
champion. **[[Declaring that]{.mark} this was a technology in which
[China had to lead]{.mark}]{.underline}**, [he set specific targets for
2020 and 2025 that p[ut China on a path to dominance over AI]{.mark}
technology and related applications by 2030]{.underline}.12 Recognizing
that this would have to be led by entrepreneurial companies rather than
agencies of government[, he designated five companies to become China's
national champions: Baidu, Alibaba, Tencent, iFlytek and
SenseTime]{.underline}.13 **[Twelve months after Xi's directive,
[investments in Chinese AI startups]{.mark} had [topped investments in
American]{.mark} AI [startups]{.mark}]{.underline}**.14 By 2018, [China
filed 2.5 times more patents in AI technologies than the United
States.15 And this year China is graduating three times as many computer
scientists as the United States.]{.underline}

In contrast to nuclear weapons---where governments led in discovery,
development and deployment---[AI and related technologies have been
created and are being advanced by private firms and university
researchers]{.underline}. **[The military establishments in
[Washington]{.mark}]{.underline}** and Beijing **[[are]{.mark}
essentially [playing catch-up, adopting]{.mark} and adapting
[private-sector products.]{.mark}]{.underline}**

Where do these two competitors stand in the AI race today? Consider
leading indicators under six key headings: product market tests,
financial market tests, research publications and patents, results in
international competitions, talent and national operating environments.

[Consumers' choices of products in markets speak for
themselves]{.underline}. In fintech, China stands alone. Tencent's
[WeChat Pay has nine hundred million Chinese users,16 while Apple Pay
only has 22 million in the United States]{.underline}.17 And when it
comes to capability, [WeChat Pay can do much more than Apple
Pay.]{.underline} [Chinese consumers]{.underline} use their app to buy
coffee at Starbucks and new products from Alibaba, pay bills, transfer
money, take out loans, make investments, donate to charity and manage
their bank accounts. In doing so, they [generate a treasure trove of
granular data about individual consumer behavior that AI systems use to
make better assessments of individuals']{.underline} credit-worthiness,
interest in products, capacity to pay for them and other
[behavior]{.underline}. In mobile payments, Chinese spend \$50 for every
dollar Americans spend, in total, \$19 trillion in 2018.18 U.S. mobile
payments have yet to reach \$1 trillion. Credit cards are as
old-fashioned to Chinese millennials as handwritten checks are to their
American counterparts. Mark Zuckerberg has noticed: Facebook's major
moves last year into digital payments,19 including the recent
introduction of Facebook Pay, are copying Tencent, rather than the other
way around.

In facial recognition, the world's most valuable AI startup is Chinese
company SenseTime20---a company whose headquarters Graham visited in
October. (While there, Graham also took a tour of Zhongguancun---China's
version of Silicon Valley---guided by Kai-Fu Lee whose hedge fund is one
of the leading VC investors in Chinese AI startups.) In 2018's
international competition for facial recognition, Chinese teams claimed
the top five places.21 Chinese firms---such as Hikvision and Dahua
Technology, which control a third of the world's security camera
market22; Tiandy, whose cameras need light from only a single star at
night to capture high-definition color images23; and Wuhan Guide
Infared, which specializes in infrared and thermal imaging---are working
hand in glove with their government to perfect facial recognition for
profit and control. In this domain, there is no U.S.-China contest; the
United States has essentially conceded the race because of concerns over
the average individual's privacy, and deep reservations about how this
technology could be deployed. Westerners were alarmed in 2017 when
researchers at Stanford created an AI algorithm that could detect with
shocking accuracy individuals' sexual orientation simply by scanning a
single photo24. It does not take much imagination to consider how less
socially liberal governments would apply this technology. So while San
Francisco recently banned facial recognition technologies, the Party has
given China's top four facial recognition firms access to its database
of over 1.4 billion citizen photos. One well-informed venture capitalist
in this arena estimates that Chinese facial recognition firms have 1
million times more images than their U.S. counterparts.

In speech tech, Chinese are beating American firms in all
languages---including English. The world's top voice recognition startup
is China's iFlytek. Its user base is seven hundred million, almost twice
the 375 million people who speak to Apple's Siri.25 In system
performance competitions, iFlytek regularly beats teams from Google,
Microsoft, Facebook, ibm and mit, all in its second language.26 At
Stanford's international challenge for machine reading comprehension,
Chinese teams won three of the top five spots, including first place.
Baidu developed a human-level speech recognition system a year before
Microsoft did.

Who was the U.S. Army's major supplier of commercial drones until
2017---when the United States prohibited purchases for foreign
suppliers?27 Shenzhen drone maker DJI, which controls 70 percent of the
global market28. Drones would be just miniature hobby helicopters
without elementary AI, which gives them computer vision for targeting
weeds or weapons, and enables them to operate in swarms. As the recent
attack on Saudi Arabia's principal oil facilities demonstrated, the
world has just begun to discover the security consequences of
AI-enhanced drones operating literally below the radar. Of the world's
top five commercial drones brands, 3 are Chinese; 1 American.29

[5g infrastructure will be the backbone that enables AI to reach further
into everyday life, from automated cars to smart glasses.]{.underline}
[China's Huawei is the world's leading supplier of this telecom
equipment. Not only does it own the Chinese market, which will be the
world's largest, but its 28 percent global market share nearly equals
the combined shares of its two top competitors]{.underline}.30 Of the
top four brands that will build 5g infrastructure, two are Chinese and
zero are American. [Chinese firms own twice as many 5g -essential
patents as American firms.]{.underline} While the outcome of the current
U.S. government campaign against Huawei remains uncertain, [the company
is currently delivering 5g systems well ahead of all competitors and is
bringing a 5g phone to market a year ahead of Apple, the company that
invented the iPhone.]{.underline}

[Financial markets reflect these realities]{.underline}. Five years ago,
two of the world's twenty most valuable internet companies were Chinese;
today, nine are. The "Seven Giants of the AI age"---Google, Amazon,
Facebook, Microsoft, Baidu, Alibaba and Tencent---are split on either
side of the Pacific. Of every ten venture capital dollars invested in AI
in 2018, five went to Chinese startups; four to American firms.31 Of the
world's top ten AI startups, half are American and half are Chinese.

**[[Chinese investments]{.mark} in AI research [and development]{.mark}
have [surged to American levels]{.mark}, [and]{.mark} the [results are
beginning to show]{.mark} it.]{.underline}** **[The blunt truth is that
China is laying the intellectual groundwork for a generational advantage
in AI.]{.underline}** According to the Allen Institute for Artificial
Intelligence's authoritative assessment, China would overtake the United
States in 2019 in the most-cited 50 percent of AI papers. It will take
the lead in the most-cited 10 percent this year. And by 2025, the United
States will fall to second in the top 1 percent of papers.32
(Fortunately, in breakthrough papers, China remains behind.) In public
patents for AI technologies, China passed the United States in 2015, and
in 2018 filed 2.5 times more than America.33 In machine learning's
hottest subfield---deep learning---China has six times more patent
publications than the United States. (Raw numbers, however, must be
taken with a grain of salt, since not all patents are equal.)

[China is investing heavily in the necessary hardware as
well.]{.underline} In 2001, China had none of the world's five hundred
fastest supercomputers. Last year, it had 219 (the United States has
116).34And while China's supercomputers previously relied on American
semiconductors, its top machine today was built entirely with
domestically-manufactured processors.

**[2NC\-\--AT: China Wins Now]{.underline}**

**Close, but *not inevitable*\-\--[regulatory environment]{.underline}
and maintaining [comparative advantages]{.underline} in the private
sector are key**

**Allison 20 --** Professor of Government, Harvard Kennedy School

Graham Allison, August 2020, \"Is China Beating the U.S. to AI
Supremacy?,\" Belfer Center for Science and International Affairs,
<https://www.belfercenter.org/publication/china-beating-us-ai-supremacy>

Clues for a Winning Strategy

**[Is AI a race China is destined to win?]{.underline}** With a
population four times the size of the United States, there is no
question that China will have the largest domestic market for AI
applications. With many multiples of the United States in data,
substantially larger numbers of computer scientists and a government for
which there is a first-order priority, [we can understand colleagues who
are pessimistic]{.underline}. Indeed, **[it is our best judgment that on
the current trajectory, [while the U]{.mark}nited [S]{.mark}tates [will
maintain a narrow lead]{.mark} over the next five years, [China will
then catch up]{.mark} and pass us quickly thereafter]{.underline}**.

Nonetheless, we **[believe that [this is an arena]{.mark} in which [the
U]{.mark}nited [S]{.mark}tates [can]{.mark} compete---and
[win]{.mark}]{.underline}**. Congress recently established the "National
Security Commission on Artificial Intelligence," with Eric Schmidt as
its chair, and Bob Work, who served as Deputy Secretary of Defense under
both Obama and Trump, as Vice Chair. Its mission is to develop that
strategy "to ensure America's national security enterprise has the tools
it needs to maintain U.S. global leadership."55 In the hope of being
helpful to that effort, we conclude with five pointers toward a winning
strategy.

First, Americans must wake up to the challenge. [[Recognition that that
the U]{.mark}nited [S]{.mark}tates [faces a serious competitor]{.mark}
in a contest in which the outcome will be decisive for our future [is
necessary to get]{.mark} our [competitive juices
flowing]{.mark}.]{.underline} The Olympics offers an instructive analogy
for thinking about a competitive strategy for AI. It also reminds us
that competition is inherently a good thing. Competition produces
superior performance. Participants in a marathon run faster than they do
when running alone. Indeed, competition is a core American value. Free
markets organize a competitive process that produces better products at
cheaper prices. Science and its applications advance as research teams
compete to better understand the world.56

Second, in this competition, the United States cannot hope to be the
biggest---in that category, China wins by default due to the size of its
population. However, what the United States can be is the smartest. In
the seeking to improve and advance the most advanced of technologies,
the brightest 0.0001 percent of individuals make the difference. The
United States can succeed by recruiting talent from all 7.7 billion
people on Earth and enabling these individuals to realize their full
potential.57 In fact, U.S. companies have now recruited more than half
of the top 100 recognized AI geniuses. In sharp contrast, China is a
closed society---limited essentially to 1.4 billion Chinese speakers.
Just 1000 foreign born individuals became Chinese citizens last year. So
while the United States will not win competitions in which bulk numbers
are the dominant factor, where brilliance, creativity and innovation
matter most, the United States has a decisive advantage.58

Third, platforms matter. [Here [the U]{.mark}nited [S]{.mark}tates
[begins with a huge sustainable]{.mark} competitive [advantage]{.mark}:
[English is the]{.mark} universal [language for]{.mark} science,
business and [the web]{.mark}]{.underline}. Chinese face the choice of
either speaking English, or simply talking to themselves. Not only do
the Chinese, but also the French and others often complain that this is
unfair---and it may be. But it is a fact. To transform Singapore from a
third-world city into one of the world's most successful and prosperous
global trading hubs, Lee Kuan Yew insisted on making English its first
language. (Indeed, at one point in counseling Chinese leaders, he
suggested that China make English its first language.) Today, more than
half of the 7.5 billion people on Earth speak English---and another
billion are seeking to learn.

Fourth, [[American companies have a]{.mark} significant [first mover
advantage]{.mark} in the establishment of the major platforms [in AI,
including operating systems]{.mark}]{.underline} (Android and Apple),
[design of advanced semiconductors]{.underline} (arm), [[and killer
apps]{.underline}]{.mark}---including Instagram, YouTube and Facebook.
Instagram has 1 billion monthly active users; Facebook more than 2.4
billion. While Chinese competitors will certainly attempt to displace
the current leaders in both platforms and applications, [if American
companies are smart enough to continue enlarging their users'
opportunities]{.underline}, improving their experiences, and expanding
the number of people using their platforms and applications, [Chinese
and others who want to speak to the world could have to continue relying
on U.S.-dominated platforms.]{.underline}

## IR K

### Link -- AI -- Tech Thesis 

#### The advent of modernity is marked by the disappearance of humanity -- the global integration of AI is a strategy of [racialized governance]{.underline} via digitalized corporatization that has exceeded sovereignty and become a [Leviathan]{.underline} built on [speed]{.underline} and [acceleration]{.underline} into a dystopic future that marks populations deemed unworthy for [death]{.underline}

**Mbembe 19** -- member of the staff at the Wits Institute for Social
and Economic Research (WISER) at the University of the Witwatersrand,
visiting appointment at the Franklin Humanities Institute at Duke
University PhD in History at the Sorbonne, DEA in Political Science at
the Instituts d\'études politiques, \[Achille, "Bodies as Borders," From
the European South 4, pg. 5-18, DKP\]

My intervention is a set of urgent, fragmentary, and unfinished
reflections on our global present. When I say 'our global present', what
I truly have in mind is the sustainability and durability of our planet.
As a matter of fact, this is an almost existential preoccupation, which
is increasingly expressed in many different voices and shared by various
people all over the world.

Indeed, many are wondering how we should inhabit anew and share as
equitably as possible a planet whose life-support system has been so
severely damaged by human activities and that is in dire need of repair.
[In view of the deep state of fragmentation the planet finds itself in,
they are asking: how should we re-member it, that is, put back together
its different parts, reassemble it and reconstitute it as an integrated
system in which humans and nonhumans, physical, chemical and biological
components, oceans, atmosphere and land-surface are all interlinked in a
grand gesture of mutuality?]{.underline}

[These [questions of]{.mark} inhabitation and interconnection, of
[mutuality]{.mark}, sustainability and durability, of the interlacing of
human history and Earth's history [are far from abstract]{.mark}
concerns.]{.underline} In fact, the ongoing long-term planetary
environmental changes have only further dramatized them, and [there is
little doubt that [they will be at the centre of any debate on the
future of life and]{.mark} the future of [reason]{.mark} in this
century.]{.underline} To properly attend to them forces us to refocus
our attention on three mega processes that have an almost overwhelming
bearing on what humanity and the planet we live on (the only one, so
far, where life is known to exist) might become.

Early 21st-century corporate sovereignty

[The first mega process is the unprecedented **[consolidation of power
and knowledge]{.mark}** (political, financial, and technological)
**[in]{.mark}** the hands of]{.underline} private
[high-tech]{.underline} corporate [entities whose sphere of action is
not one country or one region, but the globe. '**[Corporate
sovereignty']{.mark}** has taken various forms throughout
history.]{.underline} Take, for instance, the English East India Company
and its political dominance in some parts of the Indian subcontinent in
the 18th century. A composite, diffuse and hybrid entity, it exercised
powers customarily associated with formal state institutions. It could
acquire territories and exercise authority over people. It could engage
in wide ranging operations such as tax collection and war making. In
competition with the monarchical and national state, [it **[was a key
part of]{.mark}** the different institutional and constitutional forms
that shape]{.underline}d **[[imperial expansion]{.underline}]{.mark}**
(see Stein 2011).

The conditions that have enabled the expansion of privatized government
in the first half of the 21st century are well known. [Many of these
have to do with the various legal frameworks behind international trade
agreements, foreign investment treaties and other mechanisms that have
turned markets into the single most undisputed forces of our
times.]{.underline} Others have to do with the computational
transformations of financial markets and the possibilities afforded by
media technologies (see Beverungen and Lange 2018). Furthermore, whether
the old distinction between the economic power of corporations and the
political sovereignty of states still holds is more and more open to
debate (read Barkan 2013). Most global corporations aspire to secede
from everybody else while exercising surveillance on everybody else.
Their big dream is to be exempt from taxes and to be free from
accountability; in short, to enjoy the kind of immunity and state of
exceptionality we used to recognize only to truly sovereign powers.

In a recent book about what she terms "surveillance capitalism," Shohana
Zuboff argues that **[[a global architecture of behaviour modification
is under way. Driven by powerful states, high-tech corporations and
military apparatuses, surveillance capitalism
threatens]{.mark}]{.underline}** what she calls [["**human
nature"**]{.mark} in the 21st century, just as industrial capitalism
disfigured the natural world in the 20th.]{.underline} She shows the
extent to which [vast wealth is accumulated in what she terms new
"behavioural futures markets," that is, markets where predictions about
our behaviour are bought and sold, and the production of goods and
services is subordinated to new means of behavioural
modification.]{.underline} Indeed, **[[capital,]{.underline}]{.mark}**
especially finance capital, **[[has become]{.mark} our shared
infrastructure, [our nervous system]{.mark}, the transcendental maw
[that]{.mark} nowadays [maps out our world and its psycho-physical
limits]{.mark}]{.underline}** (Zuboff 2018). Around us, it looks as if
[nothing escapes its control. **[Affects, emotions]{.mark}** and
**[feelings,]{.mark}** manifestations of desire, **[dreams]{.mark}** or
thoughts -- **[no sphere]{.mark}** of contemporary life **[has been left
untouched]{.mark}**]{.underline} by the spread of capital. [Capital now
extends its grasp deep into the underbelly of the world. In its wake, it
leaves vast fields of debris and toxins, waste heaps of
humans]{.underline} ravaged by sores and boils. [Now that everything is
a potential source of capitalization, it has made a world of itself: a
hallucinatory phenomenon of planetary dimensions]{.underline}.

Early 21st -century corporate sovereignty is therefore an unprecedented
form of power, whose main aspiration is to free itself from democratic
oversight. As a result, we might no longer live in an epoch when
sovereignty was exercised by the demos. **[[The demos properly
understood might no longer be the sovereign]{.underline}]{.mark}**.
Finance capital in the guise **[[of a ubiquitous digital
architecture]{.mark} might have definitely [become the new
Leviathan.]{.mark} [We are witnessing t]{.mark}he historical
[bifurcation between liberal democracy and finance capitalism]{.mark},
and the emergence of a new form of sovereignty -- corporate sovereignty
-- which claims for itself the law of immunity and the powers of
exception.]{.underline}**

The computational speed regime

The second mega process I would like to invoke is **[[technological
escalation]{.underline}]{.mark}** and the ways in which it
[**[has]{.mark} totally [redefined]{.mark} the nature of [speed,
unshackled markets and the economy, and]{.mark}**]{.underline} the way
it **[[constantly monitors]{.mark} our [behaviour]{.mark} in an attempt
at [revealing how it could be]{.mark} modified and
[optimized.]{.mark}]{.underline}** As a matter of fact, some of the
fastest expanding markets in the world today are 'markets for future
behaviour'. They rely on better understanding incipient future intent.
This "could be future voting intentions, the intent to commit fraud, the
intent to buy life insurance, or the intent to stream a specific video,"
argues Louise Amoore (2019, 4). These markets also rely on the
extraction and mining of new forms of raw material, mostly consisting of
information and details about individuals' behaviour taken, as Zuboff
writes, from the distant corners of our unconscious. It is raw material
"plumbed from intimate patterns of the self" -- "our personality, our
moods, our emotions, our lies, our vulnerabilities, every level of our
intimacy" (2018, 201). **[[The purpose is not only to heighten the
predictability of our behaviour. It is also to make life itself amenable
to 'datafication'.]{.mark}]{.underline}**

[A key feature of our times is therefore the extent to which [all
societies are organized according to]{.mark} the same principle -- [the
computational]{.mark}.]{.underline} [We are surrounded with ubiquitous
computing, technologies that weave themselves [into the fabric
of]{.mark} our [everyday lives]{.mark},]{.underline} devices, sensors,
things we interact with and [which have become part of our presence in
the world all the time.]{.underline} How the boundary between us and
these devices is enacted is a matter of open debate (Matzner 2019).

But, what is the computational? [**The computational is generally
understood as a technical system whose function is to capture, extract,
and automatically process data that must be identified, selected,
sorted, classified, recombined, codified and activated**.]{.underline}
Yet we shouldn't forget that **[[the computational
is]{.underline}]{.mark}** also **[a force and
[energy]{.mark}]{.underline}** of a special kind, a speed regime with
its own qualities and infrastructures. It is a force and energy [**[that
produces]{.mark}** and serializes **[subjects]{.mark}**, objects,
phenomena; that splits reason from consciousness and memory, codes
**[and stores data that can be used to
manufacture]{.mark}**]{.underline} new types of services and devices
sold for profit. **[Whether operating on bodies, nerves, material,
blood, cellular tissues, the brain or energy, the aim is the same, i.e.
the conversion of all substances into quantities; [the conversion of
organic and vital ends into technical means]{.mark}; the capture of
forces and possibilities and their [annexation by the language of a
machine-brain transformed into an autonomous]{.mark} and automated
[system.]{.mark}]{.underline}**

But [the computational is also the institution through which a common
world, a new common sense and new configurations of power, of perception
and of reality are nowadays brought into being.]{.underline} The
globalization of corporate sovereignty, the extension of capital into
every sphere of life and technological escalation in the form of the
computational are all part of one and the same process.

The dialectics of entanglement and separation

The third mega process is what we should call the dialectics of
entanglement and separation. All over the world, [the combination of
**[fossil capital, soft-power warfare, and the saturation of the
everyday]{.mark}** by digital and computational technologies **[has led
to the acceleration of speed]{.mark}** and the intensification of
connections, creating a new redistribution of the Earth]{.underline} and
of population movements. **[[To be alive,]{.mark} or to remain alive,
[is]{.mark} increasingly [tantamount to]{.mark} being able to move
[speed]{.mark}ily.]{.underline}**

[In the process, the human race has come up against terrestrial
limits.]{.underline} [Such limits are not only the consequence of the
sphericality of the planet. They are also limitations on the expansion
of life as such.]{.underline} **[[As the planet increasingly seems bound
to burn, it is not only the individuated bodies that are imperilled. It
is earthly existence]{.mark}, the fate of everything on earth, the
fluidity of life which is [at stake]{.mark}]{.underline}** (Pyne 1997;
Parisi and Terranova 2000).

Meanwhile, we are, more than ever before at any other time in human
history, not only in close proximity to each other but also exposed to
each other. This close proximity and exposure is experienced less and
less as opportunity and possibility and, more and more, as heightened
risk. But entanglement and exposure to each other are not all that
characterize the now. Wherever we look, the drive is simultaneously and
decisively towards contraction, towards containment, towards enclosure
and various forms of encampment, detention, and incarceration.

[Typical of this **logic of** contraction**, containment,
incarceration** and enclosure is the worldwide erection of all kinds of
walls and fortifications, gates and enclaves. In other words, various
practices of partitioning space, of]{.underline} offshoring and [fencing
off wealth, of splintering territories, of fragmenting spaces, saddling
them with various kinds of borders whose function is to decelerate
movement, to stop it in some instances, for certain classes of
populations, in order to manage risks.]{.underline} Various reasons are
mobilized to account for this renewed infatuation with borders taken as
the best way to manage risks. Security and the preservation of one's
identity are some of these reasons. And as it happens, physica[l **and
virtual [barriers of separation,]{.mark} [digitalisation of
databases]{.mark}, filing systems, the development of [new tracking
devices,]{.mark} sensors, drones, satellites and sentinel robots,
infrared detectors and various other cameras, biometric controls, and
new microchips containing personal details -- everything is put in
place**]{.underline} to transform the very nature of the [**border [in
the name of security]{.mark}**.]{.underline} Borders are increasingly
turned into mobile, portable, omnipresent and ubiquitous realities. The
goal is to better control movement and speed, accelerating it here,
decelerating it there and, in the process, sorting, recategorizing,
reclassifying people with the goal of better selecting anew who is whom,
who should be where and who shouldn't, in the name of security.

As a result, borders are no longer merely lines of demarcation
separating distinct sovereign entities. Increasingly, they are the name
we should use to describe the organised violence that underpins both
contemporary capitalism and our world order in general. But perhaps, to
be exact, we should not speak of borders in general but, instead, of
'borderization', that is, the process by which **[certain spaces are
transformed into uncrossable places for certain classes of
[populations]{.mark}, who thereby [undergo a process of
racialization;]{.mark} places where speed must be disabled [and the
lives of a multitude]{.mark} of people [judged to be undesirable are
meant to be]{.mark}]{.underline}** immobilized if not
[**[shattered]{.underline}**.]{.mark} Whatever the case, the
technological transformation of borders is in full swing. In a sense,
one of the major consequences of the acceleration of technological
innovations has been the creation of a segmented planet of multiple
speed regimes.

A key development, of late, is the extent to which border security
practices have taken a keen interest in the connection between the human
body and identity, as a means to achieve detailed control over movement
and speed. This being the case, the question we must ask is the
following: what precisely is at stake in the extension of the biometric
border into multiple realms of social life and, in particular, the human
body? In other words, what explains the migration from the border
understood as a particular point in space to the border as the moving
body of the undesired masses of populations? The answer is [a new global
partitioning between potentially risky bodies vs. bodies that are
not.]{.underline}

[It is in the nature of risk to be hidden from view. That which is
hidden from view is generally unknown. For it to be known, it must be
visualized.]{.underline} The screening of bodies at border checkpoints
aims at making visible "that which is hidden from view, opening up new
visualizations of the unknown, potentially risky body" (Amoore and Hall
2009, 444). In such a context, biometric technologies are supposed to
fragment the human body in order to recompose it for the purpose of
securitization, of elimination and neutralization of the risk. This
happens because the human body is seen as an indisputable anchor from
which data can be safely harnessed or extracted. As a result, we are
witnessing a gradually extending intertwinement of individual physical
characteristics with information systems -- a process that has served to
deepen faith in data as a means of risk management and faith in the body
as a source of absolute identification. In this sense, biometric
technologies should perhaps be best understood as techniques that govern
both the mobility and enclosure of bodies (see van der Ploeg 2003). They
are perceived as infallible and unchallengeable verifiers of the truth
about a person -- the ultimate guarantors of identity. They are supposed
to produce the identification of a person beyond question, and lend
authenticity and credibility to all of the data that are connected to
that identity. [According to this logic, the world would be safer if
only ambiguity, ambivalence and uncertainty could be controlled. These
technologies are assumed to provide a complete picture of who someone
is, to fix and secure identity as a basis for prediction and
prevention]{.underline}, leaving people to dispute their own identity.

The three mega processes I have briefly sketched are driving the
movement towards what I have called 'planetary entanglement', as well as
its opposite, that is, enclosure, contraction, containment, encampment,
and incarceration. Once again, [they are shaped by the alliance between
military power, the industries that surround it (contractors), and tech
giants.]{.underline} They are also driven by corporate elites
increasingly detached from their countries of origin and who store most
of their capital in tax heavens (see Davis 2019). These elites can no
longer be 'forced to account' through traditional means such as
elections or protests. They defeat citizens' scrutiny via complexity and
secrecy, often under the pretext of national security or via an economic
rationale that puts capital first, before people. This movement is
erratic, uneven. [But everywhere it heightens uncertainty and
insecurity. Everywhere it institutionalizes the risks inherent in the
misfortunes of reality.]{.underline}

Life and mobility

Part of what we are witnessing as a result is a novel imbrication, a
symbiotic merging of life and mobility. To be alive, or to survive, is
more and more co-terminus with the capacity to move. Just as living,
movement, in turn, involves continual doublings, the incessant crossing
of multiple lines and thresholds, multiple transitions across layers.
**[[Life itself is more and more taken as something that can be
calculated and recombined rather than merely
represented]{.underline}]{.mark}**. Furthermore, we are witnessing a
bifurcation between life on the one hand and bodies on the other hand.
[Nowadays, **not every body is thought of as containing life.
[Discounted bodies are believed to contain no life]{.mark} as such.
[They are,]{.mark} strictly speaking, [bodies at the limits of life,
trapped in uninhabitable worlds]{.mark} and inhospitable
places**.]{.underline} The kind of life they bear or contain is not
insured or is uninsurable, folded as it is in extreme and thin
envelopes.

[**[Such bodies]{.mark}** on the precipice **[are the most exposed to
droughts, storms]{.mark}** and **[famines, toxic waste]{.mark}**
and]{.underline} various experiences of [effacement. Their livelihoods
made impossible, **[they]{.mark}** are the most likely to
**[sustain]{.mark}** the most crippling **[wounds]{.mark}**]{.underline}
and injuries. [**[Trapped human subjects]{.mark}**]{.underline} often
[**[without escape,]{.mark}** they bear the brunt of terrestrial life on
a damaged planet]{.underline} (Tsing et al. 2017). At the same time,
they exceed all attempts to contain them. These bodies are not simply in
motion. Interactive and generative, they are movements and events. The
inside of such bodies is not separated from their outward environments.
From the perspective of discounted bodies, to be alive is always and
already to breach boundaries or to be exposed to the risk of the outside
entering the inside (read Litvintseva 2019).

This disentanglement of life from discounted bodies, this redistribution
of life on differential scales of insurability and non-insurability, is
a key dimension of contemporary migration regimes. The latter aim either
at slowing down the dynamics of people's interactions, at creating
distance or at shattering the chains of relations between them, so as to
institute new patterns of separation. Contemporary movement restrictions
are not limited to national boundaries. They are at work on a global
scale. They are deepening the space and time asymmetries between
different categories of humanity while leading to the progressive
ghettoization of entire regions of the world. To a large extent, this is
akin to a universalization of the Israeli model. In this model, the
restriction of movement does not necessarily aim "to confine unwanted
people territorially or to dissociate their movements from those of
citizens, but to inscribe them into temporalities and spatialities that
are disjointed to the point of giving these populations the illusion of
being territorially separated" (Parizot 2018, 38).

Furthermore, at a time when the material components and biological
organization of the body can be reengineered and redesigned, the latter
are more than ever based on the ideas of repressive selection,
reproduction and the rejuvenation of species. Only what can potentially
generate value counts as life. In this context, borders are meant to
concretize the principle of dissimilarity rather than that of affinity.
They are not only obstacles to free movement. They are boundaries
between species and varieties of the human. As such, they play a crucial
role in contemporary modes of production of human difference and
relatedness. Human bodies are increasingly divided between those that
matter and those that do not, those who can move and those who cannot or
should not, or should only move under very strict conditions. Bodies
that should not move are those that are uninsured. [**[They must be
tracked, captured, and dispensed]{.mark}** of. Such bodies are kept
shifting between invisibility, waiting and effacement. They are trapped
in fragmented spaces, stretched time and indefinite waiting]{.underline}
(Peteet 2018). [As for the dream of perfect security, **[it requires not
only complete systematic surveillance, but also a cleansing
policy.]{.mark}**]{.underline} [This dream is symptomatic of the
structural tensions that, for decades, have accompanied our transition
into a new technical system of increased automation -- one that is
increasingly complex yet also increasingly abstract.]{.underline}

One of the major contradictions of the liberal order has always been the
tension between freedom and security. Today, this question seems to have
been cut in two. Security now matters more that freedom. A society of
security is not necessarily a society of freedom. A society of security
is a society dominated by the irrepressible need for adhesion to a
collection of certainties. It is one fearful of the type of
interrogation that delves into the unknown, unearthing the risks that
must surely be contained within. This is why in a society of security,
the priority is, at all cost, to identify what lurks behind each new
arrival -- who is who, who lives where, with whom and since when, who
does what, who comes from where, who is going where, when, how, why, and
so on and so forth. Moreover, who plans to carry out which acts, either
consciously or unconsciously. The aim of a society of security is not to
affirm freedom, but to control and govern the modes of arrival.

The current myth claims that technology constitutes the best tool for
governing these arrivals; that technology alone allows for the
resolution of this problem -- a problem of order, but also of awareness,
of identifiers, of anticipation and predictions. It is feared that [the
dream of a humanity transparent to herself, stripped of mystery, might
prove to be a catastrophic illusion]{.underline}. For the time being,
migrants and refugees are bearing the brunt of it. In the long run, it
is by no means certain that they will be the only ones.

The mega processes highlighted above leave us with foundational
questions that will haunt us for most of this century. The first
foundational question is related to what I called 'borderization', or
the logics of containment, enclosure, and contraction. [Perhaps more
than at any other moment in our recent past, **[we are increasingly
faced with the question of what to do with those whose very
existence]{.mark}** does not seem to be necessary for our reproduction;
those whose mere existence or proximity **[is deemed to represent
a]{.mark}** physical or **[biological threat]{.mark} to** our own
life.]{.underline} Throughout history, and in response to this
foundational question, various paradigms of rules have been designed for
human bodies deemed either in excess, unwanted, illegal, dispensable, or
superfluous. One historical response has consisted in putting in place
spatial exclusionary arrangements. **[[Such was,]{.underline}]{.mark}**
for instance, [**[the case during]{.mark} the early phases of modern
settler or [genocidal colonialism]{.mark} [in]{.mark} relation to Native
American reservations in the United States, [island prisons, penal
colonies]{.mark} such as Australia, [camps and Bantustans]{.mark} in
South Africa**.]{.underline} A late modern example is Gaza, and [Gaza
might well prefigure what is yet to come.]{.underline} Here, [**[control
of]{.mark}** vulnerable, unwanted, surplus or **[racialized people is
exercised through]{.mark}** a combination of tactics,]{.underline} chief
among which is 'modulated blockade'. A blockade prohibits, obstructs,
and limits who and what can enter and leave the Strip. The goal might
not be to cut the Strip off entirely from supply lines, infrastructural
grids or trade routes. It is nevertheless relatively sealed off in a way
that effectively turns it into an imprisoned territory. [Comprehensive
or relative closure is accompanied by]{.underline} periodic **[[military
escalations and]{.underline}]{.mark}** the generalized use of
**[[extra-judicial assassinations.]{.underline}]{.mark}** [Spatial
violence, humanitarian strategies, and a peculiar biopolitics of
punishment all combine to produce, in turn, a peculiar detention space
in which people deemed surplus, unwanted, or illegal are governed
through abdication of any responsibility for their lives and their
welfare.]{.underline}

allBut there is another, early 21st -century example, which consists in
waging new forms of wars, which can be called wars on speed and
mobility. [Wars on mobility are wars whose aim is to turn into dust the
means of existence and survival of vulnerable people taken as
enemies.]{.underline} These kinds of wars of attrition, methodically
calculated and programmed, and implemented with new methods, are wars
against the very ideas of mobility, circulation, and speed, whilst the
age we live in is precisely one of velocity, acceleration, and
increasing abstraction and algorithms. Moreover, [[the targets
of]{.mark} this kind of [warfare are not]{.mark} by any means [singular
bodies, but]{.mark} rather [great swathes of humanity judged
worthless]{.mark} and superfluous.]{.underline}

All of the above belongs to the current practice of remote
borderization, carried out from afar, in the name of freedom and
security. This battle, waged against certain undesirables and reducing
them to mounds of human flesh, is rolled out on a global scale. It is on
the verge of defining the times in which we live. [Wars on mobility are
peculiar wars on bodies. They have to do with two broad questions that
confront us today and will haunt us for most of this century: on the one
hand the question of life futures, that is, of the self-organization of
being and matter; on the other hand, that of the future of
reason.]{.underline}

The future of life and the future of reason

For a long time, the human race has been concerned with how life emerges
and the conditions of its evolution. The key question today is how it
can be reproduced, sustained, made durable, preserved and universally
shared, and under what conditions it ends. Overall, these debates about
how life on Earth can be reproduced and sustained, and under what
conditions it ends, are forced upon us by the epoch itself,
characterized as it is by the impending ecological catastrophe and by
technological escalation.

It is a fact that[, today, unprecedented numbers of human beings are
embedded in increasingly complex technostructures. The latter are
increasingly intervening in the dynamics of the Earth system on a
planetary scale. This has led to the transgression of planetary
boundaries such as those related to anthropogenic climate change,
degenerative land-use change, accelerated biodiversity loss,
perturbation of the global biogeochemical cycles of nitrogen and
phosphorus, and the creation and release of novel entities such as
nanoparticles and genetically engineered organisms]{.underline} (see
Donges et al.).

Furthermore, both metabolically (for example in terms of their energy
needs) and reproductively, technologies are becoming more and more tied
in complex networks of extraction and predation, manufacturing and
innovation. An example is recent developments in the domain of genes and
molecules. As Margarida Mendes shows, the heyday of DNA study has
allowed the cracking and public dissemination of the genetic codes of
humans, plants, and animals. This, in turn, has given way to an
exponential rise of biological patents, as currently nearly 20% of the
human genome is now privately owned, in a context of a market logic that
addresses life as a commodity to be manipulated and replicated under the
volatility of market consumption. Studies after studies have shown for
instance that corporations are intervening directly in the natural
cycles of life and ecosystems through the widespread genetic
modification of key elements in the food chain (see Mendes 2017). As
patented GMO genes are absorbed into our bodies in a proprietary
relationship of biological subjugation, the body itself becomes an
expanded, multiple infrastructure, where intervention can happen at many
different scales. It is therefore correct to argue [that there is a
shifting distribution of powers between the human and the technological,
in the sense that technologies are moving towards 'general intelligence'
and self-replication.]{.underline} They are being granted the powers of
reproduction and independent teleonomic purpose rather than having them
taken awayOver the last decades, we have witnessed the development of
algorithmic forms of intelligence. They have been growing in parallel
with genetic research, and often in its alliance. [[The integration of
algorithms and big data]{.mark} analysis [in the bio]{.mark}logical
[sphere does not only bring with it]{.mark} an increasingly greater
belief in [techno-positivism]{.mark} and modes of statistical thought.
**[It also paves the way for regimes of assessment]{.mark}** of the
natural world, **[and modes of prediction]{.mark}** and analysis **[that
treat life itself as a computable object.]{.mark}**]{.underline}
Concomitantly, algorithms inspired by the natural world, and ideas of
natural selection and evolution are on the rise. Such is the case with
genetic algorithms -- a subset [**[of evolutionary algorithms]{.mark}**
that **[mimic actions inspired in biological operators]{.mark}**, such
as cells, **[seeking to optimize]{.mark}** the **[responses]{.mark}** to
the problems of their environments **[by self-generating]{.mark}**, and
encompassing processes of mutation and **[natural selection.]{.mark}**
The latter are designed to evolve and further adapt to the environment,
in a process of self-generation. **[The belief]{.mark}** today **[is
that everything is]{.mark}** potentially [**computable and
predictable.**]{.mark} In the process, **[what is rejected is the fact
that life itself is]{.mark} an [open]{.mark} system, [non-linear, and
exponentially chaotic.]{.mark}**]{.underline}

These are also times when many are gradually coming to the realization
that reason may well have reached its limits. Or, in any case, it is a
time when reason is on trial -- [[we are]{.underline}]{.mark}, in other
words[, [in a]{.underline}]{.mark} sort of [[Dark
Enlightenment]{.mark}.]{.underline} Reason is a faculty we used to
recognize in humans and in humans alone. In the Western tradition we
have all, willingly or not, become the inheritors of reason, always seen
as the highest of all human faculties, the one that opened the doors to
knowledge, wisdom, virtue and, most importantly, freedom. Although
unequally redistributed among them, it was the prerogative of humans
alone. It distinguished the latter from other living species. Thanks to
their superior capacity to exercise this faculty, humans could claim to
be exceptional. [Today, reason is on trial in two ways. First, [reason
is]{.mark} increasingly replaced and [subsumed by]{.mark} instrumental
rationality, when it is not simply reduced to procedural or [algorithmic
processing]{.mark} of information. In other words, the logic of reason
is morphing from within machines and computers and algorithms. The human
brain is no longer the privileged location of reason. **[The human brain
is being "downloaded" into nano-machines.]{.mark}** An inordinate amount
of power is gradually being ceded to abstractions of all kinds. Old
modes of reasoning are being challenged by new ones that originate
through and within technology in general and digital technologies in
particular, as well as through the top-down models of artificial
intelligence. As a result, **[techne is becoming the quintessential
language of reason.]{.mark}**]{.underline}

Furthermore, **[[instrumental reason]{.underline}]{.mark}**, or reason
in the guise of techne **[[is increasingly
weaponized]{.underline}]{.mark}**. Time itself is becoming enveloped in
the doing of machines. Machines themselves do not simply execute
instructions or programs. They start generating complex behaviour. [The
computational reproduction of reason has made it such that reason is no
longer, or is a bit more than, just the domain of human species. We now
share it with various other agents. **[Reality itself is]{.mark}**
increasingly **[construed via statistics]{.mark},** metadata, modelling,
mathematics.]{.underline}

### Link -- AI Integration

#### The integration of AI via security cooperation constitutes the [unshackling]{.underline} the nation-state from the population at the level of [economic]{.underline} and [military]{.underline} power -- that turns case -- it paves the way for [unchecked]{.underline} racialized necropolitics as a [value]{.underline} that informs politics and replaces human governance with AI that kill with impunity and result in [endless, endemic warfare]{.underline} 

**Grove 20** -- Associate Professor of Political Science and Director of
the Hawai'i Research Center for Future Studies at the University of
Hawai'I at Mānoa, PhD in International Relations at Johns Hopkins
University \[Jairus, "From geopolitics to geotechnics: global futures in
the shadow of automation, cunning machines, and human speciation,"
International Relations 2020, Vol. 34(3) 432 --455, DKP\]

[[The automation of war]{.underline}]{.mark} and the reduction of human
troop sizes has a similar effect. Wars [aided by drones]{.underline} and
as a result significantly smaller numbers of soldier casualties
[continue]{.underline} on for decades [in a kind of sustainable
warfare.]{.underline}28 [The political and material cost of
casualties]{.underline} like the material cost of striking [are being
removed from the political equation [making states less]{.mark} and less
[accountable in]{.mark} the case of social justice and the [pursuit of
violence]{.mark} outside their borders.]{.underline}

[The feedback]{.underline} between these two trends [is]{.underline}
potentially [catastrophic. At the same time that war becomes easier,
governments become less accountable to their people]{.underline}, and
people are deprived of the means to support themselves, it is also the
case that [[people]{.mark} will matter less to their governments as they
[will not possess the labor power to cause pain to the economic
productivity]{.mark}]{.underline} of the country [[by means of striking
nor the capacity to refuse to fight.]{.mark}]{.underline} Zygmunt Bauman
has spoken of disposable populations, a kind of human waste or surplus
where the value of one's existence is meaningless for the state.29
However, we ought to go further down this path by way of Achille
Mbembe's creeping necropolitics.30 [It is not merely that
chronically]{.underline} or even intergenerational [unemployed people
have no value; it is that [the]{.mark}]{.underline} marginalization and
even [[murder of people can now generate value]{.mark}. In what Mbembe
refers to as the 'enclave economies' of war machines:]{.underline}

> [The concentration of activities connected with [the extraction of
> valuable resource]{.mark} around these enclaves has]{.underline}, in
> return, [[turned the enclaves into privileged spaces of war and death.
> War itself is fed by the increased sales of the products
> extracted]{.mark}.]{.underline}31

**[[In]{.mark} these [enclave economies fueled by petroleum]{.mark},
diamonds]{.underline}**, but increasingly things like
**[[lithium]{.underline}]{.mark}** or even **[sand [or water,]{.mark}
the outright [murder]{.mark} of people, [clearing space, generates
value]{.mark}]{.underline}** even in the supposedly post-resource
digital economy.32 However, beyond the instrumental value of security
there is also the [explosion of security services as its own economic
sector rather than as a merely means to secure other economic sectors.
International security corporation]{.underline}s such as Wackenhut
industries, once a private prison service provider in the U.S., [now
generate profits from refugee management]{.underline} in Australia and
Europe.33 The nearly 200 billion dollar private security industry and
\$1917 billion dollar defense sector suggest that **[the [economy of
making death and deprivation]{.mark} is more than merely a
means.]{.underline}** What few normative and [legal limitations exist on
the lethality of these corporations and institutions could disappear.
This [is already taking place]{.mark} in the global South and [amongst
African-Americans and indigenous people]{.mark} around the
planet.]{.underline}

However, [one can foresee]{.underline}, with little imagination, [the
extreme injustices of the contemporary era as a general condition of
global life]{.underline}. What requires imagination on our part is
reaching a turning point where these crimes become themselves normative,
that is, the 'good' the state pursues. Contrary to our sensibilities
such ideologies already exist and are even gaining attention outside the
obscure chat rooms where they began.

Under the heading of 'negative messianism', Mbembe reviews [the growing
movement of the '[Dark Enlightenment',]{.mark} 'a political religion. .
. \[that\] calls for the exit from democratic society and total
corporate and absolute dictatorship'.]{.underline}34 The movement
**[[calls for a global, racial, culling of the population in the name of
'human biodiversity' and expounds the value of using racially inferior
populations for]{.mark} radical [experimentation]{.mark} to jumpstart
technological breakthrough.]{.underline}** [If this sounds]{.underline}
too [implausible]{.underline} even for speculation **[it is worth
considering the spate of recent [terrorist attacks]{.mark} in the U.S.
[by the vanguard]{.mark} of the Dark Enlightenment. The [mass
shooter]{.mark} who killed 20 people [in El Paso]{.mark}]{.underline}**
Texas in August of 2019 **[posted his Dark Enlightenment manifesto
before beginning his rampage]{.underline}**.35 In 2020, **[there have
been multiple attacks by]{.underline}** the so-called
**[[Boogaloos]{.mark} who [have infiltrated the U.S. military and
police]{.mark} forces and seek to spark the Dark Enlightenment by
[escalating]{.mark} the [B]{.mark}lack [L]{.mark}ives [M]{.mark}atter
protests [into a full scale civil war]{.mark}.]{.underline}**36 And then
there is the most famous and vocal theorist of the Dark Enlightenment,
Steve [Bannon,]{.underline} who in addition to being a key architect of
the Donald Trump administration, [works tirelessly to build the Dark
Enlightenment movement amongst the burgeoning far right of
Europe]{.underline}.37 Whether this world view succeeds or actually
becomes normative globally is not really the point. Instead, as is the
mode in the speculation here I propose that **[[in
the]{.mark}]{.underline}** burgeoning **[[Dark Enlightenment]{.mark}
movement [we can see a political community built around necropolitics as
a value rather than a necessary evil.]{.mark}]{.underline}**

It would be too much to draw a direct line from the Dark Enlightenment
to all of the neo-nationalist, neo-authoritarian, and neo-fascist
movements around the planet. However, [the accelerating [global right
wing has been institutionalized at]{.mark} the [highest levels]{.mark}
of power [in]{.mark} liberal democratic nation-states such as [the
U]{.mark}]{.underline}nited [[S]{.underline}]{.mark}tates, [[U.K. and
India,]{.mark} suggesting that liberal institutions cannot subsist on
autopilot. **Neo-authoritarian politics have also moved from shaping
domestic polities to the shaping of the international
order.**]{.underline}38

In such an order, what would liberal democratic states look like? The
[constraints on the genocidal dictatorships of the twentieth century
was]{.underline} of course that [they needed a substantial portion of
their populations.]{.underline} Genocide could only be pursued against
minority populations. State behavior even in the extremes of the Nazi
state among others still required full mobilization and therefore at
some level the necessity of willing obedience even if not quite
legitimacy that could be supplemented through terror.39

[What of the behavior of future states for whom their people are in some
sense an afterthought? At a minimum the basic conceits of survival that
underwrite practices like deterrence or coercion would change
dramatically.]{.underline} The very logic and mechanics of biopolitics
would have to change. Without a necessary or strict relationship to the
nation, would states differ significantly from some kind of corporate
entity? Would the state more closely resemble the ancien regime? What
would become of territoriality? These are the grammatical questions
raised by the dark imagination of an automated future sufficiently
comprehensive to create the material condition whereby a state could
survive without the majority of their population's cooperation.

Can **[[we]{.mark}]{.underline}** not **[already [see]{.mark} the
outlines of such a [future in the decisions of Bolsanaro, Trump, Xi,
Modi, and Duterte, who]{.mark} blithely [write off
millions]{.mark}]{.underline}** of their own citizens **[[in the face of
COVID]{.mark}-19]{.underline}** and the nearly 50 per cent unemployment
rate it has created where the virus has been allowed total freedom of
movement?40 [One need not be conspiratorial to see how quick
authoritarian leaders have been to give up on disease containment once
the data came back regarding the overwhelming racial disparity in COVID
fatalities]{.underline}.41

If we consider the ways in which the shift from coal to oil changed the
character of economic and labor relations with states in the twentieth
century, [the]{.underline} nearly [[50 per cent loss of jobs due to
computerization]{.underline}]{.mark} in the twenty-first century,42
[[combined with a]{.mark} corresponding [decline in the necessity of
humans for military power]{.mark},]{.underline} then these new
conditions [[could change the very nature of what a state
is.]{.underline}]{.mark} The biopolitical raison d'être of the
nation-state which emerges in the nineteenth century and becomes truly
geopolitical in the twentieth century is premised on the mobilization
and securing of a national population.43 The revolutionary states emerge
from and rationalize the hyphen of the nationstate as essential both in
terms of democratic values and military-economic necessity. What will
emerge in the aftermath of such necessities and values is the horizon of
alternative futures we must consider.

Section 3: from Bergsonian machines to cunning machines

"Hello," whispered Montag, fascinated as always with the dead beast, the
living beast. . . Montag touched the muzzle. The Hound growled. . . "It
doesn't like me," said Montag. "What the Hound?" The Captain studied his
cards. "Come off it. It doesn't like or dislike. It just 'functions.'
It's like a lesson in ballistics. It has a trajectory we decide on for
it. It follows through. It targets itself, homes itself, and cuts off.
It's only copper wire, storage batteries, and electricity. . .

--Fahrenheit 451 A Wiener Filter or The Yellow Peril

![Text, letter Description automatically
generated](media/image2.png){width="4.0023709536307965in"
height="1.583992782152231in"}

The equation above is called a Wiener Filter. In mathematical terms,
Norbert Wiener used it with a number of other steps to calculate the
future. Despite the claims in the first section that the future does not
exist, the territory or probable limits of the future do, at least most
of the time. What Wiener was representing mathematically was that even
with little data on which one would normally make a prediction you can
define the space of possibility or in Wiener's terms the distribution of
probabilities even for non-linear or non-existent causal systems. In
practical terms it meant that artillery could be automated to shoot
where planes were going to be rather than where they were when the radar
signal returned. The mathematicians did this by considering and then
modeling the limits of the system being predicted.

It is impossible to predict what an individual pilot will choose to do
but it is possible to describe in mathematical terms what a pilot is
capable of doing and similarly what a plane with a particular maximum
velocity was capable of doing. The predictions made by the Wiener Filter
allowed the artillery guns to fire in a significantly more restricted
area with minimal radar information rather than just blasting away at
the sky in hopes of hitting something. According to Steve Heims, more
predictable systems like the V2 rocket could be successfully targeted
and shot down 99 out 100 times by the Wiener Filter.44 The seemingly
'dumb' artillery could adjust or read their environment and work in
concert adjusting further as information from rudimentary radar systems
or the assemblage of radar, operators, and canons. The artillery was in
the most basic sense becoming aware.

Wiener's 'solution' which made unpredictable systems targetable was
another version of what Claude Shannon very soon after solved for
communication with his theory of information. Shannon developed the
techniques which allow the efficient transmission of information through
imperfect media such as telephone lines by similarly modeling the range
of noise and compensating or repeating signal to exceed it. Rather than
predicting the noise which is impossible because of its chaotic nature
Shannon was able to treat all noise as a system rather than individual
events of noise such that the range of noise could stand in place of the
individual incidents. In both cases, the breakthroughs of Wiener and
Shannon created the world of computers, the internet, automation, and
machine learning we now inhabit. All systems after Wiener and Shannon
could be treated in some sense as information and communication problems
to be solved.45

After his experience in the war and further experiments after, Wiener
began to describe a more general principle of informatics and machine
technology. What he would later call the last science or the science of
everything saw every system, whether physical, chemical, mechanical,
biological, as computable and alterable. Following this insight Wiener
believed humanity was at the cusp of something unprecedented. In 1948,
he declared that a new kind of machine had emerged in the history of
human evolution. Although still rudimentary, cybernetic machines of the
1940s were capable for the first time of simple self-regulation based on
interactions with their external environment. Unlike thermodynamic
machines that sought equilibrium, cybernetic machines could pursue a
goal or objective in the world. Wiener referred to these new machines as
Bergsonian machines, after the French Philosopher Henri Bergson and his
idea of elan vital.46 For Wiener, machines possessed for the first time
the spark of a vital impulse. While these Bergsonian machines have so
far disappointed the expectation of those hoping for and others fearing
human-like artificial intelligence, machinic intelligence, whether
learning algorithms or self-steering and targeting weapons systems, have
exploded into a variable rainforest ecology of new species.

What is important for the purposes of this article is that Wiener was
able to demonstrate that very simple feedback mechanisms could produce
complex emergent results or what 'appeared' like intelligence even if
the machines were not conscious of that intelligence. What I explore
throughout the rest of the section is how [[even small advances in
machine intelligence could produce dramatic changes]{.mark} in what we
think of now as human dependent drones. Already [AI platforms have the
capacity to strategize and win complex games]{.mark} like Go, AI via
drones have the capability to target or execute operations on their own,
robots can 3D print and construct other robots, that is, a simple form
of reproduction. The only thing missing is]{.underline} what in
philosophical terms we call [will or desire.]{.underline} However, the
insight from Wiener is that the difference between rudimentary will and
a command code is insignificant in effect if a feedback exists between
the machine and the external environment which can shape or direct the
now desiring machine. To put it somewhat simply, [we do not need human
general intelligence for robots to change the world and
[geopolitics;]{.mark} the world [could change overnight if mechanical
life emerged]{.mark}]{.underline} or was released into the wild [and was
[as sophisticated,]{.mark} resilient and procreative [as the
cockroach.]{.mark}]{.underline}

**[We are already experiencing the burgeoning capability of cunning
machine.]{.underline}** If one considers to the underlying political and
economic pressure to move away from human combatants not unlike the
globalization of the labor market more broadly, the incentives for
innovations continuing are difficult to deny.47 Even before 9/11 [combat
was becoming too costly in both economic and political terms and
therefore required an alternative in order for empires and smaller
states to stay afloat]{.underline} in lean times. The globally modeled
War on Terrorism brought the crises of military expenditure still
lingering after the Cold War to a head. **[However, the [drive to cut
costs and political liability has not stopped at the
battlefield]{.mark}.]{.underline}** [Attempts to remove humans further
and further from the battlefield follows this inhuman trajectory into
the arena of decision-making and contestation.]{.underline}48 [**[The
reliance on algorithmic warfare creates the opportunity for increasingly
unilateral warmaking]{.underline}**. **[Cunning
machines,]{.underline}**]{.mark} **[not machines of reason but machines
capable of hunting and trapping, [represent the possibility of the
command and control developed for nuclear arsenals]{.mark} with the
micro-scale to pursue and kill of [assassins or special
forces.4]{.mark}9]{.underline}**

**[This process of [automating politics as well as war]{.mark} creates
further incentive for the development of increasingly autonomous
machines and actually [undermines security as it makes the capacity to
wage war cheaper]{.mark} and more accessible around the
planet.]{.underline}** **[[The drive for]{.underline}]{.mark}** more
autonomous machines is heading toward **['[sustainable
warfare']{.mark},]{.underline}** a kind of weird parallel to sustainable
development. Like sustainable development, sustainable warfare really
**[[makes warfare endemic]{.underline}]{.mark}** rather than providing a
real alternative to war making. So war as we know it may be coming to an
end but a permeating martial transformation is just getting started.

As the transformation in domestic policing, military planning, and
combat takes place, the tactical landscape will also mutate, amplifying
the corrosive effects on politics. A security complex indifferent to the
differences between the war and policing, battlefield and lifeworld will
increasingly target Internet exchanges, servers, monitoring, and
listening stations, civilian communication and media infrastructure. [As
populations cease to matter to states]{.underline}, either those
attacking or being attacked, [infrastructure becomes the whole of the
strategic landscape.]{.underline} Also, [as the size of autonomous
machines shrink, the [incentive for hacking or]{.mark} indiscriminate
attacks such as [el]{.mark}ectro[m]{.mark}agnetic [p]{.mark}ulse attacks
[will become more desirable]{.mark} as drone to drone or human to drone
combat will be prohibitively difficult.]{.underline}

After all, how reliably can one expect to track a drone the size of a
dragonfly or as low to the ground as a snake? Thus, we face the
possibility of a confluence of unaccountable decision-making, even the
absence of human decisions at all with the saturation of living spaces
with the dissonance of combat, killing and destruction. **[Rather than
simply automating the 'hunt' for enemies chosen by political processes,
already reliance on things like [signature strikes signal a shift to the
automation of the political decision of who is and is not an enemy in
the first place.]{.mark}]{.underline}** This shift from what Human
Rights Watch has termed 'human on the loop' practices to 'human out of
the loop' practices pushes the posthuman50 character of war further into
the nightmare zone in which everything is an object to be targeted but
never encountered or recognized. An algorithmic cunning replaces enmity
and martial judgment in the recognizable terms.

Furthermore, in a future with a receding human public and that states
are indifferent to moral catastrophe, these changes in machine
capability and autonomy as well as the deployment of such machines would
not be political events. **[[Switches would be flipped by military
planners or software developers along technical rather than ethical or
political lines.]{.underline}]{.mark}** Lewis Mumford referred to this
as the advent of 'post-historic' humanity in which a process that 'began
innocently by eliminating fallible human impulses from science will end
by eliminating human nature from the whole world of reality. In
posthistoric culture life itself is reduced to predictable, mechanically
conditioned and controlled motion, with ever incalculable -- that is,
every creative -- element removed'.51 I would add that [what emerges in
its place is a mechanic creativity allowed to thrive within the
constraints of a limited martial logic.]{.underline} If we continue on
this trajectory **[practicality could replace both strategic and moral
thinking.]{.underline}**52 Further, the fora in which such decisions
will be made (if at all) are likely to be constricted as secrecy
predominates in an environment charged by a dangerous mix of paranoia
and real danger.

#### The expansion of even "friendly AI" builds a bridge to a post-human hellscape, where geopolitics is structured around techno-dystopic racialized violence 

**Grove 20** -- Associate Professor of Political Science and Director of
the Hawai'i Research Center for Future Studies at the University of
Hawai'I at Mānoa, PhD in International Relations at Johns Hopkins
University \[Jairus, "From geopolitics to geotechnics: global futures in
the shadow of automation, cunning machines, and human speciation,"
International Relations 2020, Vol. 34(3) 432 --455, DKP\]

In Cavell's account [the general economy of violence that characterized
the sadism of slavery could return again but differently. Rather than a
great chain of being or the superiority or some races over others, the
very concept of violence as a category distinct from force or change
could be lost.]{.underline} Although extreme, can we not already see
this transformation underway in the extreme forms of instrumentality
that characterize decisions regarding collateral damage, counter-value
targeting, or economized discourse on immigration and refugees?56

[More than a transformation of moral economies, the automation of humans
and the augmentation of humans, represents the possibility of making
physical and habitual what is now normative and discursive.]{.underline}
Resembling Cavell, David Roden proposes what he calls the disconnection
thesis, in which Cavell's nightmare scenario unfolds only among some
humans for whom the sentimentality of bodies, reproduction, and human
connection impede further evolution of the species.57 Whether it is
those who dream of a singularity in which human consciousness becomes
digital or one of the U.S. veterans who have had mood altering computer
chips implanted into their brains, [some humans will increasingly alter
or altered their brain-body networks to alter their cognitive and
perceptive capacities.]{.underline}58

During the summer of 2018 researchers at the University of Washington
and Carnegie Mellon successfully networked three humans via EEGs and
transcranial magnetic stimulation. The three individuals were able to
collaborate to play a simple video game resembling Tetris.59 The
participants were able to communicate and sense each others' thoughts
without the use of language or even being in the same room. Similar
experiments have successfully sent text message from one side of the
country to the other making at least a limited version of brain to brain
communication a reality.

[In the dark light of geopolitics one can imagine what today takes the
form of geographic and class divides in connectivity and medicine taking
the form of different classes and territories of consciousness and
communication. **Given the**]{.underline} already gossamer **[fragility
of international solidarity and trans-border empathy one can further
imagine cyborg cultures quite literally tuning out of the world left
behind.]{.underline}** Roden's disconnection thesis argues that as these
new forms of networks and augmentation develop so too will cultures and
moral awareness diverge.60 For those without the need or desire to use
oral language accelerating the pace of technological change within new
kinds of communities it is not difficult to follow Cavell to the
precipice of his posthuman horror. **[While the biological racial
fictions of colonialism, apartheid, and settler-colonialism still hold
on in the face of overwhelming scientific evidence to the contrary how
much more would real material differences in forms of life accelerate
existing geopolitical violence?]{.underline}**61 **[Even the beginnings
of disconnection could intensify the already renewed fights between
extractive industrial modernity and those indigenous communities
fighting for their ancestral lands and ways of life.]{.underline}** And
what of the swelling numbers of multi-generationally unemployed masses
who will lack the capital to upgrade? **[One can imagine
class]{.underline}** no longer **[being marked by]{.underline}**
linguistic markers or knowledge of wine but **[the physical ability to
interface with white color working spaces.]{.underline}** More and more
companies have already begun microchipping their employees for security
and tracking crossing the threshold of the skin in the process of making
labor.62 The digital divide in labor of who can and cannot telecommute
is already determining the patterns of employment and unemployment in
the first 6 months of COVID-19 shutdowns. The speciation of interfaces
and sensory capabilities could amplify the already growing trend.63

The point of Roden and Cavell's thought experiments are to show that
such a separation would be more than just a return to or intensification
of racial or class divisions. Instead the very embodied character of
moral appreciation, the shared languages and cultures, the perceptive
capacities to experience beauty or tragedy could be altered to the point
that the diffracted species of once human beings would live in a state
more closely resembling that of Homo sapiens 100,000 years ago in which
there were multiple species of upright anthropoids and none of them
could live without the fear of predation by other non-human animals or
each other. The medium of encounter fundamentally altered. However, [in
this]{.underline} speculative history of the [future the divergence
would not have been by happenstance but to lock in interests and
geopolitical advantage. Difference by design.]{.underline}

This may all seem too far-fetched. How could humans lose their most
basic capacity for socio-emotional intercourse? I want to argue that
**[things need not change that dramatically to see the beginnings of
such a divergence.]{.underline}** One can look around a crowded bus
filled with people each glued to their smart phone, tables of families
at restaurants each separated by their individuated devices or an office
filled with screens each telecommuting the pilot to a drone in the field
thousands of miles away to see the beginnings of such a speciation. Or
we could return to the beginnings of international thought, the first
moments of European geopolitics and remember its multispecies beginnings
when just 50 years after the arrival of Christopher Columbus Bartolomé
de las Casas pleaded with the Castille thrown to recognize the soul and
therefore humanity of the 'Indios'. Instead, of course, the
extermination continued which treated the people of the Americas as
'piles of dung in the middle of the road'.64 **[Geopolitics was in some
sense founded on the premise of many human species rather than one human
species.]{.underline}**65 **[The inability for so many to see their
human counterpoint at a moment of encounter in the new world speaks to
the precedent of a truly dark enlightenment. That is, technological and
martial advance without any corresponding moral
awareness.]{.underline}** A new such speciation that included the
inability to even speak to one another much less recognize some common
heritage or shared community of value would make the efforts of Las
Casas and those who continue to fight against the finishing of the
settler-colonial project entirely potentially invisible.

Conclusion: geotechnics and a planetary state of war

when utilized to perform work highly organized collective enterprises, I
shall call it the 'labor machine': when applied to acts of collective
coercion and destruction, it deserves the title, used even today, the
'military machine'. But when all of the components, political and
economic, military, bureaucratic and royal, must be included, I shall
usually refer to the 'megamachine'.

Lewis Mumford66

Mumford's megamachine is instructive. What he is describing is an
ancient past where the political, economic, military, bureaucratic,
royal all converged to form the empires of the Aztecs and Egyptians.
What I have in mind is this same convergence in the future but with a
twist. The 'royal' may come to relate to the economic and political and
the military such that what we understand as politics becomes
indiscernible. [The megamachine of the future presented here could
better be called geotechnics. The global mobilization of people, the
conditions of competition and coercion, who and what was doing the
competing and their relations would be fundamentally
altered.]{.underline} The relations would no longer be linguistic or
even sensory in the way that humans hold experience in common even if
their subjectivizations of that experience, that is the phenomenology of
body of experience, may be singular.

**[In a world of]{.underline}** possible full **[automation, cunning
machines, and posthuman speciation the equality of]{.underline}**
Hobbes' **[state of nature as well as the state of war is no longer
operable.]{.underline}** If these metaphors ever did more than
underwrite one particular logic of international politics they would in
the future be meaningless as the people of the leviathan, **[the metric
by which order or disorder is experienced may no longer exist in the
mortal meat suit so much of political theory rests.]{.underline}** In
some sense the enmity of war in the Hobbesian sense rested on the equal
finitude of every mortal human as well as the general desire to live
something we could agree was a good life free from the ever presence of
murder. As Hobbes was recontextualized to imagine an international
system of states similarly a sense of mortal equality was present.
**[The ability to be killed underwrote the decision to
kill.]{.underline}**

And what of the English school's society of states? If such sociality
persisted amongst neo-authoritarian states without nations what dark
vision of order would that be? [Basic assumption about the international
system even those based on other less dour models than a realist
anarchic system similarly presumes some equality of communication, the
good, or the desire to live in a particular way. The material limits of
homo sapiens, the necessity of water, air, food, family, and sociality
underwrites everything from deterrence to diplomacy.]{.underline} **[A
geotechnical system populated with intelligent things and governed by
nation-less states and further populated by incommensurate branches of
humanity fundamentally alters the limits and therefore the possibilities
of global life and order.]{.underline}** By what rules those relations
would be conceptually governed, that is, how we could describe such a
planetary system would have to reach for ways of thinking well beyond
even the most radical or critical theory of international relations.
**[In some ways efforts to consider what geopolitics looked like at the
peak of the Atlantic slave trade or during the first 100 years of the
conquest of the Americas more closely resemble what could become of a
posthuman planet than the highly rationalized cosmopolitan institutions
of the United Nations.]{.underline}**67

Just as IR is finally accepting that global politics is inhabited by
more than just nation-states that is, non-state actors, we now must also
come to grips with the fact that global politics is no longer populated
solely by humans and could in the future not even be dominated by
humans. [What new forms of intelligence mean for the transformation of
peace and security is murky at best. What is clear is that a theory of
automation as mere means is no longer sufficient to understanding the
vast infrastructure of machines and sensory data collecting systems and
the new collaborations those systems will create for former humans with
which we are already beginning to share our planet. The horizon of such
a technical transformation has to be thought alongside the normative
upheaval and radicalization of global enmity taking place simultaneously
with the transformation of the very mechanics of political and military
action.]{.underline}

To consider a future where the actors, relations, and order of the
planet could be fundamentally reconfigured by the gradual accretion of
robots, algorithms, bodily and political modification poses to us the
possibility of systemic change well beyond whether the world will be
unipolar or multipolar. No one of these trajectories will be total or
play out as described here but all of these trajectories present us with
the real possibility of altering the basic rules of human planetary
existence from a geopolitical condition to one that is increasingly
geotechnical. [Hundred years from now, what new grammar of planetary
relations could be prepared to describe such a world?]{.underline}

### Link -- AI = Whiteness

#### The fantasy of AI is the fantasy of Whiteness -- a futuristic world where white servants serve white masters -- the aff [cements]{.underline} the domination of the future by an Anglo-European worldview of White Supremacy that conflates Whiteness with intelligence 

**Cave and Dai 20** -- \* Leverhulme Centre for the Future of
Intelligence, University of Cambridge, Cambridge, UK, \*\* Leverhulme
Centre for the Future of Intelligence, University of Cambridge,
Cambridge, UK, \[Stephen, Kanta, "The Whiteness of AI," Philosophy &
Technology volume 33, pages685--703 (2020), DKP\]

This paper focuses on the fact that [[AI is]{.mark}]{.underline}
predominantly portrayed as [[white]{.mark}---in colour, ethnicity, or
both.]{.underline} We first illustrate [[the prevalent Whiteness of real
and imagined intelligent machines in four categories: humanoid robots,
chatbots and virtual assistants, stock images of AI, and portrayals of
AI]{.mark}]{.underline} in film and television. [We then offer three
interpretations of the Whiteness of AI, drawing on critical race theory,
particularly the idea of the White racial frame. First, we examine the
extent to which this [Whiteness might simply reflect the predominantly
White milieus from which these artefacts arise.]{.mark} Second, we argue
that to imagine machines that are intelligent, professional, or powerful
is to imagine White machines because the White racial frame ascribes
these attributes predominantly to White people. Third, we argue that [AI
racialised as White allows for a full erasure of people of colour from
the White utopian imaginary]{.mark}. Finally, we examine potential
consequences of the racialisation of AI, arguing it could exacerbate
bias and misdirect concern.]{.underline}

Overall, I construe race, racialization, and racial identities as
on-going sets of political relations that require, through constant
perpetuation via institutions, discourses, practices, desires,
infrastructures, languages, technologies, sciences, economies, dreams,
and cultural artefacts, the barring of nonwhite subjects from the
category of the human as it is performed in the modern west.

Alexander G. Weheliye
(Weheliye [2014](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR63),
2)

[[Technology as an abstract concept functions as a white
mythology.]{.underline}]{.mark}

Joel Dinerstein (Dinerstein 2006, 570)

Introduction

It is a truth little acknowledged that a machine in possession of
intelligence must be white. Typing terms like "robot" or "artificial
intelligence" into a search engine will yield a preponderance of stock
images of white plastic humanoids. Perhaps more notable still, these
machines are not only white in colour, but the more human they are made
to look, the more their features are made ethnically
White.[Footnote1](https://link.springer.com/article/10.1007/s13347-020-00415-6#Fn1) In
this paper, we problematize the often unnoticed and unremarked-upon fact
that intelligent machines are predominantly conceived and portrayed as
White. We argue that this [[Whiteness]{.mark} both illuminates
particularities of what]{.underline} (Anglophone Western) [society hopes
for and fears from these machines, and [situates these affects
within]{.mark} long-standing [ideological structures that relate race
and technology.]{.mark}]{.underline}

[Race and technology are two of the most powerful and important
categories for understanding the world as it has developed since at
least the early modern period.]{.underline} Yet, as a number of scholars
have noted, their profound entanglement remains understudied
(Sinclair [2004](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR55);
de la
Peña [2010](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR18)).
[There are a number of possible reasons for this---and]{.underline}, as
Bruce Sinclair writes, "[[racial prejudice dominates]{.mark} all of
them]{.underline}"
(Sinclair [2004](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR55),
1[). [They include the lack of]{.mark} first- or secondhand [accounts of
the role of people of colour in]{.mark} the [development and use of
tech]{.mark}nology; persistent [stereotypes about tech]{.mark}nology [as
the province]{.mark} and product [of]{.mark} one particular racial
group---[White people; and]{.mark} the persistent tendency of members of
that group, who dominate the academy in the [US and Europe]{.mark}, to
[refuse to see themselves as racialised]{.mark} or race as a matter of
concern at all.]{.underline}

This lack of scholarly attention is surprising because, as Michael Adas
elucidated in 1989, [the idea of [tech]{.mark}nological [superiority was
essential to]{.mark} the logic of [colonialism.]{.mark} Not only was
[superior weaponry]{.mark} and transportation]{.underline} (etc.)
[[necessary for]{.mark} large-scale [conquest and control]{.mark} of
foreign territory, [it was also]{.mark} part of its
[justification:]{.mark} [proof]{.mark} that [White Europeans]{.mark}
were an advanced civilisation with a [right to rule]{.mark} over
other]{.underline}s (Adas 1989). Fortunately, this lack of attention is
increasingly being remedied, and the relationship between race and
technology is beginning to garner the kind of attention that has since
the 1970s been given to gender and technology, following the pioneering
work of Donna Haraway, Sandra Harding, and Evelyn Fox Keller (Haraway
1991; Harding 1986; Keller 1985). This includes attention to this
century's ubiquitous digital technologies. In 2006, Lisa Nakamura asked,
"How do we make cyberculture studies a field that as a matter of course
employs critical race theory and theories of cultural difference...?"
(Nakamura 2006, 35). Since then, a number of significant works have
attempted to do just that, including Safiya Noble's Algorithms of
Oppression and Ruha Benjamin's Race After Technology (Noble 2018;
Benjamin 2019).

This paper aims to contribute to this body of literature on race and
technology by examining how [the ideology [of race shapes]{.mark}
conceptions and portrayals of artificial intelligence
[(AI).]{.mark}]{.underline} Our approach is grounded in the philosophy
of race and critical race theory, particularly the Black feminist
theories of bell hooks, Sylvia Wynter and Alexander G. Weheliye
(hooks [19921997](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR39);
Wynter [2003](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR67);
Weheliye [2014](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR63)),
and work in Whiteness studies, including that of Richard Dyer, Joe R.
Feagin, and Ruth Frankenberg
(Dyer [1997](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR20);
Feagin [2013](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR23);
Frankenberg [1997a](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR26)).
In 2006, Feagin coined [the term "white racial frame" to describe those
aspects of the Anglophone Western worldview that perpetuate a racialised
hierarchy of power and privilege]{.underline}
(Feagin [2006](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR22)).
In his words, ["[the white racial frame includes]{.mark} a broad and
persisting set of racial [stereotypes, prejudices, ideologies]{.mark},
interlinked interpretations and narratives, and visual
images"]{.underline}
(Feagin [2013](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR23),
xi). Although it reached its peak in the age of colonial expansion, this
framing persists: ["Today, as whites move through their lives, they
frequently combine racial stereotypes and biases (a beliefs aspect),
racial metaphors and concepts (a deeper cognitive aspect), racialised
images (the visual aspect), racialised emotions (feelings), interpretive
racial narratives, and inclinations to discriminate within a broad
racial framing"]{.underline}
(Feagin [2013](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR23),
91). In essence, this paper examines how [[representations of AI reflect
this White racial frame.]{.underline}]{.mark}

One of the main aims of critical race theory in general, and Whiteness
studies in particular, is to draw attention to the operation of
Whiteness in Western culture. [[The power of Whiteness's]{.mark} signs
and symbols [lies]{.mark} to a large extent [in]{.mark} their [going
unnoticed]{.mark} and unquestioned, concealed by the myth of
colour-blindness.]{.underline} As scholars such as Jessie Daniels and
Safiya Noble have noted, [this myth of colour-blindness is particularly
prevalent in Silicon Valley and surrounding tech culture, where it
serves to inhibit serious interrogation of racial framing]{.underline}
(Daniels [2013](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR16), [2015](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR17);
Noble [2018](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR48)).
Hence [[the first step f]{.mark}or such an interrogation
[is]{.mark}]{.underline}, in Richard Dyer's term, [to "make strange"
this Whiteness, de-normalising and [drawing attention]{.mark} to
it]{.underline}
(Dyer [1997](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR20),
10). As Steve Garner puts it, [the reason "for deploying whiteness as a
lens is that it strips a normative privileged identity of its cloak of
invisibility"]{.underline}
(Garner [2007](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR31),
5). [This is our primary intention in examining intelligent machines
through the White racial frame.]{.underline}

In the next section of this paper, we first lay out current evidence for
the assertion that conceptions and portrayals of AI---both embodied as
robots and disembodied---are racialised, then evidence that such
machines are predominantly racialised as White. In the third section of
the paper, we offer our readings of this Whiteness. Our methods are
qualitative. As de la Peña writes: ["[Studying
whiteness]{.mark}]{.underline} means working with evidence more
interpretive than tangible; it [[requires imaginative analyses of
language and]{.mark} satisfaction with [identifying]{.mark} possible
[motivations of subjects,]{.mark} rather than definitive trajectories of
innovation, production, and consumption"]{.underline} (de la
Peña [2010](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR18),
926). We offer [three interpretations of the Whiteness of AI. First, the
[normalisation of Whiteness in the Anglophone West
can]{.mark}]{.underline} go some way to
[[explai]{.mark}n]{.underline}ing [[why]{.mark} that sphere's products,
including [representations of AI, are White.]{.mark}]{.underline} But we
argue that this argument alone is insufficient. Second, [we argue that
[to imagine an intelligent]{.mark}]{.underline} (autonomous, agential,
powerful) [[machine is to imagine a White machine]{.mark} [because the
White racial frame ascribes these attributes]{.mark} predominantly [to
White people]{.mark}.]{.underline} Thirdly, [we argue that **[AI
racialised as White allows for a full erasure of people of colour from
the White utopian imaginary.]{.mark} Such machines** are conceived as
tools that **will replace "dirty, dull, or dangerous"
tasks**]{.underline}
(Murphy [2000](https://link.springer.com/article/10.1007/s13347-020-00415-6#ref-CR46),
16), **[including replacing human interactions that are considered
metaphorically dirty: [White robot servants will allow the White master
to live a life of ease unsullied by interaction with people of other
races.]{.mark}]{.underline}**

### Alt -- Paradigm Shifts 

#### The alternative is to vote negative to [refuse]{.underline} the 1AC's prescriptions in favor of paradigm shifting experiments that center de-racialization against white supremist techno-futurity 

**Mbembe 22**, interviewed by TORBJØRN- Achille is a member of the staff
at the Wits Institute for Social and Economic Research (WISER) at the
University of the Witwatersrand, visiting appointment at the Franklin
Humanities Institute at Duke University PhD in History at the Sorbonne,
DEA in Political Science at the Instituts d\'études politiques
\[Achille, "Thoughts on the Planetary: An Interview with Achille
Mbembe," Decolonizing the Neoliberal University -- Law, Psychoanalysis
and the Politics of Student Protest, Interview first Conducted in 2018,
Re-Published in this book and Edited by Jaco Barnard-Naudé, Professor of
Jurisprudence in the Department of Private Law, University of Cape Town,
DKP\]

TORBJØRN: Some would then argue that there are still colonial or
postcolonial structures operating in the neoliberal project. Would you
say that there is then still a genocidal potential?

MBEMBE: Perhaps more than at any other moment in our recent past, we are
increasingly faced with the question of what to do with those whose very
existence does not seem to be necessary for our reproduction; those
whose mere existence or proximity is deemed to represent a physical or
biological threat to our own life.

[Throughout history]{.underline}, and in response to this question,
[various [paradigms of rules have been designed for human bodies
deemed]{.mark} either in [excess,]{.mark} unwanted, illegal,
dispensable, or superfluous. One historical response has consisted in
putting in place spatial exclusionary arrangements. Such
was]{.underline}, for instance, [the case during]{.underline} the early
phases of modern [settler or [genocidal colonialism i]{.mark}n relation
to Native American reservations]{.underline} in the United States,
[[island prisons, penal colonies]{.underline}]{.mark} such as Australia,
[[camps]{.mark} and]{.underline} even [Bantustan]{.underline}s in South
Africa.

[Two late modern examples are [Gaza]{.mark} and the en[caging of]{.mark}
migrant [children]{.mark} in the context of the ongoing planetary war on
mobility.]{.underline} Gaza and the encaging of migrant children might
well prefigure what is yet to come.

In the case of Gaza, control of vulnerable, unwanted, surplus or
racialized people is exercised through a combination of tactics, chief
among which is modulated blockade or molecular strangulation. A blockade
prohibits, obstructs, and limits who and what can enter and leave the
Strip. The goal might not be to cut the Strip off entirely from supply
lines, infrastructural grids or trade routes. The Strip is nevertheless
relatively sealed off and strangulated in a way that effectively turns
it into an imprisoned territory. [Comprehensive or relative [closure is
accompanied by]{.mark} periodic [military escalations and]{.mark} the
generalized use of [extra-judicial assassinations]{.mark}. Spatial
violence]{.underline}, humanitarian strategies, [and a]{.underline}
peculiar [biopolitics of punishment all combine to produce]{.underline},
in turn, [a]{.underline} peculiar [carceral space in which people deemed
surplus, unwanted, or illegal are governed through abdication of any
responsibility for their lives and their welfare.]{.underline}

But as I have intimated, [there is another, early twenty-first century
example, which consists in waging new forms of wars, which can be called
wars on speed and mobility. **[Wars on mobility]{.mark} are wars whose
[aim]{.mark} is [to turn discounted bodies into
borders]{.mark}.**]{.underline} They generally begin by turning into
dust and piles of ruins the milieux as well as means of existence and
survival of vulnerable people thus forced to flee in search of a refuge.
**[These kinds of wars against milieux and ecosystems rendered toxic and
uninhabitable are not accidental. [They are methodically
programmed]{.mark} and conducted. [Such]{.mark}]{.underline}** milieux
and **[[ecosystems are sites of experimentation of new weapons.]{.mark}
[The targets]{.mark} of this kind of warfare [are]{.mark}]{.underline}**
not by any means singular bodies, but rather **[great [swathes of
humanity]{.mark} [judged worthless]{.mark} and
superfluous.]{.underline}**

TORBJØRN: Can you elaborate a bit more on that?

MBEMBE: Let me put it differently. Nowadays [the project is to render as
many people as superfluous as possible. The novelty is the production at
a massive scale of [discounted bodies]{.mark}, a residual humanity [that
is akin to]{.mark} [waste.]{.mark} With our entry into a new climatic
regime, this process will only intensify.]{.underline} As the global
conditions for the production and reproduction of life on Earth keep
changing, [population politics at a planetary level will increasingly
become synonymous with excess and waste management**. In terms of the
[future geopolitics]{.mark} of our world, [populations will be]{.mark}
more and more [treated]{.mark}**]{.underline} not only in the Darwinian
terms of sexual selection, but also **[[within a
utilitarian]{.mark}]{.underline}** and biophysiologico-organic
**[[framework.]{.underline}]{.mark}**

Take a place such as South Africa where a very high percentage of the
total population is unemployed. This is not because there is no "work as
such". This is not because people do not want to work.

In fact, here as elsewhere in Africa and other parts of the global
South, almost everything remains to be done. [The amount of work needed
in order to create a better life for all is incalculable. **But [the
structure of the economy doesn't]{.mark} really [need us all.]{.mark}**
Nor does it need our time. It doesn't really need every single body, all
of our muscles or energies or even the bulk of our social and collective
intelligence**. And this will be more and more the case in the future,
as we move to a phase of human history in which [only that which is
computable counts.]{.mark}**]{.underline} As we speak, **[[many
bodies]{.mark} already [fall beyond the scope of calculation. Unless we
reinvent the terms of what counts and]{.mark}, in the process,
[resignify]{.mark}]{.underline}** what **[value]{.underline}** stands
for **[as well as the [procedures]{.mark} of assigning
value]{.underline}**, of measuring value, of exchanging value, **[things
[won't change.]{.mark}]{.underline}** These are some of the key
questions any decolonization project worthy of its name has to address
if the injunction to decolonize is to be more than a mere ideological
phantasm.

TORBJØRN: Back to the debate on decolonization: There was a heated
debate in Norway, during the summer of 2018, about the decolonization of
academia. How can #RhodesMustFall in South Africa be relevant for
universities worldwide?

MBEMBE: **[[The need for a critical re-appraisal of the relationship
between knowledge, power and institutions]{.underline}]{.mark}** is not
an exclusively South African preoccupation. In South Africa, the term
"decolonization" **[[is]{.mark} one way in which concerns about
["deracialization"]{.mark} are expressed.]{.underline}** The imperative
to "deracialize" is also valid for Europe, for the United States, for
Brazil and for other parts of the world. **[The [emergence of]{.mark}
new varieties of [racism]{.mark} in Europe and elsewhere, the
reassertion of global [white supremacy,]{.mark} of
populism]{.underline}** and retro-nationalism, **[the [weaponization of
difference]{.mark}]{.underline}** and identity **[[are]{.mark} not only
symptoms]{.underline}** of a deep distrust of the world. **[They are
also [fostered by]{.mark} transnational [forces capable of making
that]{.mark} same [world]{.mark}]{.underline}** inhospitable,
**[[uninhabitable]{.mark} and unbreathable]{.underline}** for many of
us.

All of this is of course important. But part of what truly frightens me
is the recolonization of various fields of knowledge by all kinds of
determinisms. **[What frightens me is the active confusion between
knowledge and data, [the reduction of knowledge to information.]{.mark}
It's the idea that the world is a matter of numbers and the task of
knowledge is to handle quantities.]{.underline}** Furthermore, it's the
belief that the best way to generate information is with computers and
that which is not computable does not exist. **[It's the creeping sense
that [the computer is our new brain.]{.mark}]{.underline}**

In such a context, **["[to decolonize" must start from the assumption
that knowledge cannot be reduced to]{.mark} computational
[info]{.mark}rmation [processing.]{.mark} There is therefore a massive
need to recover the ability to think.]{.underline}** And for me,
knowledge is on the verge of being reduced to a reified metaphor. As a
result, [we are witnessing almost everywhere a tremendous impoverishment
of thought.]{.underline}

TORBJØRN: In the Norwegian debate on decolonization, one of the demands
from the young student activists was to have a more global curriculum.
What's your take on that?

MBEMBE: Right now [we are literally assaulted by [forces that want
to]{.mark}]{.underline} retreat from the world and [[rebuild a certain
idea]{.mark} of the nation, [of]{.mark} the
[community]{.mark}]{.underline}[,]{.mark} of identity and difference
[that [is premised on the capacity to determine]{.mark}]{.underline} who
belongs[, [who must be excluded]{.underline}]{.mark} [and shouldn't
belong]{.underline}, who can settle where, why, how and for how long.
**[Such forces are preoccupied with the erection of all kinds of borders
[and how they must be policed. They buy in the dream of a "pure"
community]{.mark}, a community of people who]{.underline}** look the
same **[and act the same.]{.underline}** They are sustained by the
belief that we can go back to the past because the past is, in truth,
our future. **[Let me just call it the dream of
apartheid.]{.underline}**

**[There is [another dream]{.mark}]{.underline}**, maybe not unrelated
to the first. As I have just highlighted, it's the dream of reducing
knowledge to calculation by computers. In fact, it's the dream [**[of
reducing everything to calculation]{.mark} and explaining everything
from within biological and neurological strictures**. [A planetary
library]{.mark}]{.underline}, archive or, for that matter, curriculum is
one [[whose s]{.mark}trategic [project is to understand the
incalculable]{.mark} and the incomputable.]{.underline} It can only be
based on the will to go beyond cognitivism. I am not against calculation
or mathematics. Nor am I against computation. I am simply saying that
[neither calculation]{.underline}, nor mathematics, [nor computation are
sufficient for explaining life. It can't be enough to do correct
math]{.underline}ematics. **[Once we have done correct mathematics, we
still need to determine what this exercise implies for the life of
beings.]{.underline}** Pushed to a certain level, correct mathematics
alone impoverish thought and destroy theory.

Otherwise, we only have one world. We might dream about colonizing Mars
or Venus or other unknown planets in the future, but for the time being
that is not part of our actuality. **[[We only have one
world,]{.underline}]{.mark}** one solar system **[and for this world to
last]{.underline}** as long as possible and for this solar system to not
calcinate life as such, **[we need to become]{.underline}** a bit more
intelligent and **[wiser.]{.underline}** This Earth is our shared roof
and our shared shelter. **[[Sharing]{.mark} this roof]{.underline}** and
shelter **[[is the]{.underline}]{.mark}** great **[[condition
for]{.mark} the sustainability of [life on Earth.]{.mark}]{.underline}**
We have to share it as equitably as possible. And in any case **[our
lives]{.underline}**, here and elsewhere, **[have become so entangled,
that [trying to separate]{.mark} them [will require]{.mark} a
[tremendous]{.mark} amount of [violence.]{.mark}]{.underline}** It will
require a lot of violence to disentangle humanity from itself and from
the rest of the living species. And therefore, especially in the face of
the kinds of ecological challenges we face, **[it is]{.underline}**
absolutely **[important to reinvent forms of life]{.underline}** in
common **[that go beyond the requisite of the nation state, ethnicity,
race, religion, and so on.]{.underline}** A curriculum that takes
seriously such concerns is absolutely necessary.
