# Artificial Intelligence Affirmative {#artificial-intelligence-affirmative .TOC-Heading}

[Artificial Intelligence
[2](#artificial-intelligence)](#artificial-intelligence)

[Introduction: Artificial Intelligence Affirmative
[4](#introduction-artificial-intelligence-affirmative)](#introduction-artificial-intelligence-affirmative)

[Strategic Overview [5](#strategic-overview)](#strategic-overview)

[Being First Affirmative Speaker (1AC)
[6](#being-first-affirmative-speaker-1ac)](#being-first-affirmative-speaker-1ac)

[Being Second Affirmative Speaker (2AC)
[7](#being-second-affirmative-speaker-2ac)](#being-second-affirmative-speaker-2ac)

[Doing Rebuttal Speeches
[8](#doing-rebuttal-speeches)](#doing-rebuttal-speeches)

[Key DEBATE Terms You may encounter
[9](#key-debate-terms-you-may-encounter)](#key-debate-terms-you-may-encounter)

[Debate Terms [9](#debate-terms)](#debate-terms)

[Argument Glossary [10](#argument-glossary)](#argument-glossary)

[1AC - Lethal Autonomous Weapons
[11](#ac---lethal-autonomous-weapons)](#ac---lethal-autonomous-weapons)

[Inherency [11](#inherency)](#inherency)

[Harm [12](#harm)](#harm)

[Plan Text [13](#plan-text)](#plan-text)

[Solvency [14](#solvency)](#solvency)

[Advantages [16](#advantages-1)](#advantages-1)

[Regulation [16](#regulation)](#regulation)

[China [17](#china)](#china)

[Russia [18](#russia)](#russia)

[2AC -- Lethal Autonomous Weapons
[19](#ac-lethal-autonomous-weapons)](#ac-lethal-autonomous-weapons)

[Plan Text, Restated: [19](#plan-text-restated)](#plan-text-restated)

[Case Extensions [20](#case-extensions)](#case-extensions)

[Solvency [20](#solvency-1)](#solvency-1)

[Regulation Adv Extensions
[21](#regulation-adv-extensions)](#regulation-adv-extensions)

[China Advantage Extensions
[22](#china-advantage-extensions)](#china-advantage-extensions)

[Russia Advantage Extensions
[23](#russia-advantage-extensions)](#russia-advantage-extensions)

[Answers To [24](#answers-to)](#answers-to)

[A2 Russia DA [24](#a2-russia-da)](#a2-russia-da)

[A2 Imperialism DA [25](#a2-imperialism-da)](#a2-imperialism-da)

[A2 China DA [26](#a2-china-da)](#a2-china-da)

[AT Underdeveloped Technology
[27](#at-underdeveloped-technology)](#at-underdeveloped-technology)

[Impact - Nuclear War
[28](#impact---nuclear-war)](#impact---nuclear-war)

[Extra Cards [29](#extra-cards)](#extra-cards)

[Neg Answers (for the Neg)
[31](#neg-answers-for-the-neg)](#neg-answers-for-the-neg)

[Impact - Nuclear War
[31](#impact---nuclear-war-1)](#impact---nuclear-war-1)

# Artificial Intelligence

![Graphical user interface, application Description automatically
generated](media/image2.png){width="5.433962160979878in"
height="2.489047462817148in"}

The goal of the affirmative is simple: Suggest a plan of action, show
how it will work, and why it is a good idea. If the affirmative's plan
is a good idea at the end of the round, then you will win. The more you
focus on the plan and why it is a bad idea, the more often you'll win
debates.

  -----------------------------------------------------------------
  Speech Time                          (Minutes)
  ------------------------------------ ----------------------------
  1^st^ Affirmative Constructive (1AC) 8

  2^nd^ Negative Speaker Questions     3
  1^st^ Affirmative Speaker            

  1^st^ Negative Constructive (1NC)    8

  1^st^ Affirmative Speaker Questions  3
  1stNegative Speaker                  

  2^nd^ Affirmative Constructive (2AC) 8

  1^st^ Negative Speaker Questions     3
  2^nd^ Affirmative Speaker            

  2^nd^ Negative Constructive (2NC)    8

  2^nd^ Affirmative Speaker Questions  3
  2^nd^ Negative Speaker               

  1^st^ Negative Rebuttal (1NR)        5

  1^st^ Affirmative Rebuttal (1AR)     5

  2^nd^ Negative Rebuttal (Closing     5
  Statement) (2NR)                     

  2^nd^ Affirmative Rebuttal (Closing  5
  Statement) (2AR)                     
  -----------------------------------------------------------------

**Goals of each speech:**

1.  **1AC:** Build your case: Inherency, The Plan, Solvency, and the
    Advantages.

2.  **2AC/1AR:** Respond to the negative's arguments and add new
    evidence if needed. You need to be winning at least Solvency and an
    Advantage after the 1AR to win the debate.

3.  **2AR:** The second affirmative speaker should give a closing
    argument all about why the plan is a good idea. Answer the second
    negative rebuttal (2NR) and tell the judge why the affirmative team
    should win.

**\**

## Introduction: Artificial Intelligence Affirmative

Every year, the National Debate Association releases a *[yearly
topic]{.underline}* for students to debate. *[The Policy Debate
resolution for 2022-2023 is as follows:]{.underline}*

#### Resolved: The United States federal government should substantially increase its security cooperation with the North Atlantic Treaty Organization in one or more of the following areas: artificial intelligence, biotechnology, cybersecurity. 

Breaking down the text of this topic gives you three topics for to
center cases around: increasing security cooperation with NATO in
**artificial intelligence**, **biotechnology**, and **cybersecurity**.
This affirmative's plan text is as follows:

#### The United States Federal Government should increase security cooperation with the North Atlantic Treaty Organization on artificial intelligence used for military purposes. 

The Artificial Intelligence affirmative, aptly named, focuses on the
[artificial intelligence]{.underline} part of the resolution. By working
with the North Atlantic Treaty Organization to increase security
cooperation specifically on "artificial intelligence used for military
purposes, there are many implications on an international scale. As we
live in a golden age for technology, technology like smart robots are
now reality. However, advancements in tech like AI also changes the way
wars are fought. This AFF focuses on **Lethal Autonomous Weapons**,
military weapons that rely on AI to engage their targets without the
need for human control.

The development of this technology is not as straightforward as its
description. Currently, various nations are developing or have developed
these "killer robots". The notable nations of the bunch include the
U.S., Russia, and China.

The United States is only one of many member nations under NATO, and
each of them has their own progress in A.I. development, particularly
for autonomous weapons. These weapons have the potential to completely
change the international battlefield, and also put their creators at
risk if left unchecked.

#### The affirmative argues that increasing security cooperation in various potential ways (establishing test centers, regulating AI development in industries, and standardizing member nations' use of AI for war purposes) is important to combat a menagerie of potential risks (miscalculation, China/Russia dominaton, NATO miscommunication).

## Strategic Overview

Each Affirmative Case has four components. You must cover each piece to
successfully debate as the affirmative.

- **Inherency:** What is the problem, and why isn't it being fixed now?
  This usually identifies trends or specific barriers to the problem
  being fixed.

- **The Plan:** What is the affirmative going to do about it? This is a
  short description of action and should be written with care.

- **Solvency:** How will the plan work? Does the technology exist yet?
  Will it actually work?

- **Advantages:** What are the benefits of doing the plan, or the
  problems we can avoid by doing it? This is why we should care about
  the plan.

The affirmative has **three** *advantages* to choose from when building
your 1AC/2AC. However, for your first few debate rounds, stick to
**one** *advantage*. Despite your best efforts, you will only have
enough time to read one. It's also good practice, as you'll need to
understand what each of these *advantages* mean as you continue to
develop your debate skills for this topic.

#### [Advantages]{.underline}

**Regulation Advantage:** AI technology is developing exponentially
faster by the day, and with new discoveries is a need to ensure that
this technology is not being misused. This advantage advocates that our
law/policies are in dire need of an update.

**China Advantage:** China is currently catching up to the U.S. in terms
of developing Lethal Autonomous Weapons, especially when it comes to
research and development. This advantage argues that a strong economic
investment in AI development is key to providing a united front against
foreign competitors like China.

**Russia Advantage:** Russia is another primary competitor for AI
development. To prevent escalation and international conflict, this
advantage argues that cooperation with NATO is essential to prevent the
U.S. and its allies from struggling on interoperability, as well as to
deter conflict and escalation with Russia.

**[When putting together your blocks, you'll want to follow the
structure you learned during flowing:]{.underline}**

+----------------------------------------------------------------+
| **[They say → \<Insert argument\>]{.underline}**               |
|                                                                |
| **[That's not true because → \<Restate your argument or read a |
| new card to answer their argument\>]{.underline}**             |
|                                                                |
| **[Prefer our argument because → \<Explain why your argument   |
| is better\>]{.underline}**                                     |
+================================================================+

### Being First Affirmative Speaker (1AC)

**1st Affirmative Speaker:** Your job is to introduce the affirmative
case in the 1AC, and to keep the affirmative case alive during the 1AR.

**Doing the Constructive Speech (1AC)**

The initial part of your case has already been "cut" or planned out for
you. During the First Affirmative Constructive, also known as the first
speech, your primary responsibility to is understand what exactly each
part of the "Lethal Autonomous Weapons" 1AC means. In this speech,
you'll be reading out evidence, which may not seem very important but is
incredibly necessary, as it establishes the debate for later speeches in
the round. The 1AC process goes as such:

1.  Arrange your evidence prior to the round. Make sure that you have
    your 1AC "foundation" as well as chosen one *Advantage* out of the
    three available to you that you'll read.

2.  When the round begins, set your timer and read out the "foundation"
    of your case (Inherency, Harm, Plan Text, Solvency). Reading
    evidence may look daunting at first, but you will learn how to
    interpret this evidence with your debate instructor.

3.  Once you've read the foundation, move on and read out the
    *Advantage* you chose.

4.  You will need to practice your reading speed so that you can finish
    reading out all of the evidence before your 8 minutes are complete.

5.  After finishing the speech or the timer runs out, you will then
    enter **cross-examination** (3 mins), where a negative speaker will
    ask you a series of questions and you will do your best to answer
    them.

The final reading order for the 1AC is as follows:

Inherency → Harm → Plan Text → Solvency → Advantage(s)

You will need to focus on "extending" the following case components into
your 1AR: The plan, solvency, and at least one advantage. All the
evidence you read in your 1AC will now come into play in this speech!

Consider the following questions as the 1AC:

- **[Can you explain summarize your affirmative case in 2-3
  sentences?]{.underline}**

- **[Why is NATO the best option?]{.underline}**

- **[What are the implications of working with NATO?]{.underline}**

- **[What will happen if we don't pass the affirmative
  plan?]{.underline}**

- **[What do each of the *Advantages* mean? Can you explain them in
  detail?]{.underline}**

### Being Second Affirmative Speaker (2AC)

**2nd Affirmative Speaker:** Your job is answer negative attacks in the
2AC, adding any evidence the affirmative might need, then to make a
closing statement explaining why the affirmative team should win in the
2AR. This should focus on why the plan is a good idea and how the
advantages are more important than the disadvantages.

**Doing the Constructive Speech (2AC)**

The initial part of your case has already been "cut" or planned out for
you. During the Second Affirmative Constructive your primary
responsibility to is not only "extend" the arguments made in the 1AC,
but to provide a response to any arguments made by the 1^st^ Negative
Constructive. The first part of the 2AC involves reading "extensions",
or to continue an argument made by the 1^st^ Affirmative Constructive,
as it establishes the debate for later speeches in the round. At this
point in the round, you'll have chosen which *Advantage(s)* you'll be
using, and you will need to read out the extensions for each argument
accordingly. Like the 1AC, the first part of your 2AC involves reading
out evidence. However, it slightly differs in that you'll need to
prepare your speech as the 1NC is being read out. The 2AC process goes
as such:

Evidence read by the 1AC doesn't just go away. You'll need to continue
making these arguments in the 2AC.

1.  Take notes about the 1NC's main arguments as they are being made.

2.  Arrange your evidence prior to the 2AC. Make sure that you have your
    2AC "foundation" extensions, as well as the extensions for any
    *Advantages* read out from the 1AC.

3.  Begin arranging any "Answers To" evidence for any arguments read out
    by the 1NC.

4.  You will need to practice your reading speed so that you can finish
    reading out all of the evidence before your 8 minutes are complete.

5.  After finishing the speech or the timer runs out, you will then
    enter **cross-examination** (3 mins), where a negative speaker will
    ask you a series of questions and you will do your best to answer
    them.

Consider the following questions as the 2AC:

- **[Can you explain summarize your affirmative case in 2-3
  sentences?]{.underline}**

- **[How can your plan solve for the problems you
  outlined?]{.underline}**

- **[What is NATO? How is the US related to the
  organization?]{.underline}**

- **[How can you rearrange the evidence in this file to make it easier
  for you to read?]{.underline}**

- **[Can you explain what each of the cards mean on this
  file?]{.underline}**

### Doing Rebuttal Speeches 

**[[Note: Advantages (an AFF argument) and Disadvantages (a NEG
argument) are two separate arguments.]{.underline}]{.mark}**

The negative team will respond to your arguments using "on case"
responses. They'll also present some of their own. These "off case"
arguments are dangerous, and you must respond to them in order to win
the debate.

There are two types of rebuttal arguments that you'll encounter in this
packet: Analytical arguments, which are arguments that rely on evidence
previously introduced, and arguments supported by new evidence. **Please
note that new evidence is only permitted when used to directly rebut
your opponent's argument. New *arguments* are [not]{.underline} allowed
in the rebuttal speeches.**

In the Novice Packet, there are three "off case" positions and this is
how to answer them:

- **China Disadvantage**: There are two parts to responding to this
  disadvantage, depending on whether or not you've **read out the China
  Advantage during your 1AC/2AC**:

  - **If you read out the China Advantage in 1AC/2AC:** Extend your
    Bateman 2022 evidence and "[impact turn]{.underline}" their
    argument. Explain that the impact of NATO economic collapse is
    actually prevented by the AFF plan. This spills over to NATO as an
    organization. Strengthening US policy on AI (which the AFF plan
    does) actually prevents NATO from experiencing strain as well.

  - In addition, explain that by strengthening NATO (which the plan does
    by working with the U.S.) actually protects the alliance from any
    potential threats made by China.

- **Russia Disadvantage**: Answering this DA has two parts, depending on
  whether or not you've **read out the Russia Advantage during your
  1AC/2AC.**

  - **If you read out the Russia Advantage in 1AC/2AC:** Argue that
    there is "no impact". Russia hasn't actually used lethal autonomous
    weapons (L.A.W.'s) in Ukraine. This is important, because your Allen
    2022 evidence states their definition of what L.A.W.'s is incorrect.

  - Using the same format as the one above, explain that by
    strengthening NATO (which the plan does by working with the U.S.)
    actually protects the alliance from any potential threats made by
    Russia.

- **Imperialism Disadvantage**: This argument is more technical but has
  two parts.

  - Argue that this argument is "not unique" to your affirmative, and
    that advancements in tech is inevitable.

  - And, argue that the U.S. is the "lesser of two evils". Allowing a
    country like Russia to be the imperial power instead actually is
    much more worse.

## Key DEBATE Terms You may encounter

### Debate Terms

**"Passing the affirmative"** -- when the judge votes for the
affirmative, effectively "passing" your case as it were a real policy
bill.

**"Net worse/Net better"** -- an eloquent way to say "overall
worse/overall better".

**Status quo** -- used to describe the current state of affairs, or the
current situation the case is set in.

**Impact** -- the reason a given argument is important. It is used to
explain why an argument is important, and why the judge should vote for
you.

**Extend (verb)** -- to "extend" an argument made in the 1AC to later
speeches.

**Extension (noun)** -- a category of argument that are made past the
1AC. Used to continue an argument made from previous speeches.

**Link** -- a card/evidence that "links" two arguments together. Without
a link to the resolution, you risk being irrelevant to the debate.

**Link turn/Non unique** -- an argument that the opponent's claim is
"non-unique", or not unique to your case. It argues that the opposite of
their "link" is true.

- For instance, if you claimed that pineapples are delicious, and your
  opponent argued that eating pineapples harms farm workers, then you
  could link turn, arguing that there are many negative factors
  affecting farm workers' lives and eating pineapples is not one of
  them.

**Impact turn** -- an argument that the opponent's claim benefits your
argument.

- For instance, if you claimed that pineapples are delicious and your
  opponent claimed that pineapple turns sweet foods sour, then you could
  impact turn their argument, arguing that you love sour foods.

### Argument Glossary

**NATO (noun)** -- also known as the North Atlantic Treaty Organization,
an international alliance of 30 countries, which includes the United
States.

**Artificial Intelligence** (noun) -- computer programs that utilize
machine learning and are able to mimic human intelligence

**Regulation** (noun) -- legal restrictions enforced by an authority

**Lethal autonomous weapons** (noun) -- weaponized systems with the
ability to operate without human oversight

**Interoperability (noun) --** interconnectedness of systems

**Autonomous** (adjective) -- ability of a system (such as a weapons
system) to work with or use the parts or equipment of another system

**Weaponization** (noun) -- to adapt for use as a weapon of war

**Precedent** (noun) -- something done or said that may serve as an
example or rule to authorize or justify a subsequent act of the same or
an analogous kind

**Ethical** (adjective) -- involving or expressing moral approval or
disapproval

**Intrinsic** (adjective) -- belonging to the essential nature or
constitution of a thing

**Technological Edge** (noun) -- reaching an advantage in the technology
sector

**Competitive Advantage** (noun) -- when countries reach an edge over
another country in a specified rivalry (ie military, economy, space
exploration, etc.)

**Diplomacy** (noun) -- the art and practice of conducting negotiations
between nations

**Escalation** (noun) -- causing something to rise, typically tensions
between two states

**Data violations** (adjective) -- a violation of what is considered
legal or ethical surrounding data

**Hegemony** (noun) -- the position of being the strongest and most
powerful and therefore able to control others

**Undermine** (verb) -- to undercut or circumvent

**Coalition** (noun) -- cooperation between states for a shared goal

**Miscalculation** (noun) -- inaccurate assessment

**Standardization** (noun) -- to bring into conformity with a standard
especially in order to assure consistency and regularity

**Mutually Beneficial** (noun) -- when two parties benefit from the same
action or goal

**[\]{.underline}**

# 1AC - Lethal Autonomous Weapons

### Inherency

#### Many foreign militaries have already developed artificial intelligence for war. This takes the form of Lethal Autonomous Weapons, war machines that rely on AI that do not need manual control.

**Michelson, 21** (Brian Michelson, Colonel (Retired) Brian M. Michelson
is a Nonresident Senior Fellow with CEPA's Transatlantic Defense Tech
Initiative., 2-23-2021, accessed on 6-9-2022, CEPA, \"Why NATO Needs
Lethal Autonomous Weapon Standards \| CEPA\",
<https://cepa.org/why-nato-needs-lethal-autonomous-weapon-standards/>)

While there is no agreed-upon international definition of lethal
autonomous weapons systems, [[the U.S]{.mark}. Department of Defense
[defines them as "weapon system\[s\] that, once activated, can select
and engage targets without further intervention]{.mark} by a human
operator."]{.underline} While these are not Schwarzenegger-style
Terminators and still have a degree of human control over them, [[the
technology enabling these systems is maturing rapidly, and military
necessity will]{.mark} increasingly [demand that these systems gain
broader parameters of autonomous action]{.mark}]{.underline}[.]{.mark}
Yet despite the complexity of these systems and the inevitability of
their proliferation, [[NATO does not currently have a common standard
for their use or development]{.underline}]{.mark}. In fact, some NATO
countries even have opposing views of how to handle them. [[In the
emerging field of lethal autonomous weapons]{.mark}, [establishing a
common NATO standard]{.mark} for the development and use of autonomous
weapons [will]{.mark} help [address the gap in capabilities among NATO
member nations]{.mark}. By establishing]{.underline} these [standards,
[nations can ensure that their]{.mark}]{.underline} defense expenditures
on autonomous [[weapons will create systems that
are]{.mark}]{.underline} interoperable, [[able to contribute to NATO's
capability]{.underline}]{.mark}, and can be employed within defensible
ethical guidelines.

#### The status quo's rapid development of AI-based weapons threatens the North Atlantic Treaty Organization, whose countries have fallen behind. The current standard for L.A.W development is outdated, posing a risk to US and NATO security. 

**Michelson, 21** (Brian Michelson, Colonel (Retired) Brian M. Michelson
is a Nonresident Senior Fellow with CEPA's Transatlantic Defense Tech
Initiative., 2-23-2021, accessed on 6-9-2022, CEPA, \"Why NATO Needs
Lethal Autonomous Weapon Standards \| CEPA\",
<https://cepa.org/why-nato-needs-lethal-autonomous-weapon-standards/>)

[[The rapid weaponization of artificial intelligence]{.mark}, "big
data," social media, robotics, and a host of other technologies
[presents a clear competitive challenge to NATO]{.mark}, an alliance
with members that exist on a wide spectrum of military-technological
capabilities]{.underline}. The future effectiveness of NATO will be
driven in large part by how it handles these challenges from hobbling
its ability both to act in unison and to prevail in a contest of wills.
[[While there are numerous]{.mark} potential [technology gaps, one that
will likely only increase is partner nations' ability]{.mark} and
willingness [to employ lethal autonomous weapon
systems]{.mark}]{.underline}. These systems will inevitably grow more
capable, and more necessary, in the coming decade.

### Harm

#### Several countries have already deployed these deadly technologies on the battlefield. Regulation is desperately needed. 

**Trager and Luca 22** (Robert F. Trager and Laura M. Luca, an associate
professor of political science at the University of California, Los
Angeles, and a graduate student in political science at the University
of California, Los Angeles, 5-11-2022, accessed on 6-8-2022, Foreign
Policy, \"Lethal Autonomous Weapons Systems Are Here---and We Need to
Regulate Them\",
<https://foreignpolicy.com/2022/05/11/killer-robots-lethal-autonomous-weapons-systems-ukraine-libya-regulation/>)

[Unlike traditional drones, [these systems have the ability to
navigate]{.mark} on their own, [and]{.mark} some can [select
targets]{.mark}.]{.underline} Although a human controller can still
decide whether or not to strike, such weapons are acquiring ever more
autonomous capabilities. Now that militaries and paramilitaries
worldwide have taken note, these technologies are poised to spread
widely. The world today stands at the very moment before much more
advanced versions of these technologies become ubiquitous. So far, at
least [[Israel, Russia, South Korea, and Turkey have reportedly deployed
weapons with autonomous capabilities]{.underline}]{.mark}---though
whether this mode was active is disputed---[and Australia, Britain,
China, and the United States are investing heavily in developing LAWS
with an ever-expanding range of sizes and capabilities.]{.underline}
Once these technologies have spread widely, they will be difficult to
control. [[The world thus urgently needs a new approach]{.mark} to
LAWS]{.underline}. So far, the international community has done nothing
more than agree that the issue needs to be discussed. But what it really
needs to do is take a page from the nuclear playbook and establish a
nonproliferation regime for LAWS.

### Plan Text

#### The United States Federal Government should increase security cooperation with the North Atlantic Treaty Organization on artificial intelligence used for military purposes.

### Solvency

#### The impact is competitive advantage -- Maintaining US AI technology front guarantees US/NATO lead, and prevents NATO countries from falling behind.

**Franke, 21** (Ulrike Esther Franke, Dr. Ulrike Franke is a senior
policy fellow at the European Council on Foreign Relations (ECFR). She
leads ECFR's Technology and European Power initiative., Jan-1-2021,
accessed on 6-9-2022, Jstor, \"Artificial Divide: How Europe and America
could\",
https://www.jstor.org/stable/pdf/resrep29123.pdf?refreqid=excelsior%3Aa5f05901d2537261e569c592ad151765&ab_segments=&origin=&acceptTC=1)

Transatlantic cooperation on lethal autonomous weapons, or other
combat-related capabilities, does not, therefore, look promising. Europe
and the US will need to choose the appropriate forum for AI cooperation
based on its area of focus. [[Transatlantic cooperation on military AI
might be best located within NATO.]{.mark} [Members]{.mark} of the
alliance [have a long history of working together, and NATO already has
dedicated units]{.mark} whose task is [to ensure that all allies
can]{.mark} cooperate and [transform together]{.mark}.]{.underline}
Given that military interoperability is vital to its functioning, NATO
has no alternative but to address this issue, independent of other
forums' work. [[It would be advisable for NATO]{.mark}, and possibly the
EU and its member states, [to join the newly established, US-led AI
partnership for defence]{.mark}.]{.underline} The current situation --
in which the partnership includes only a few European countries and some
of the United States' other like-minded partners -- is not constructive
from a European viewpoint: Europeans should strive for Europe-wide
harmonisation, not the creation of further differences. For cooperation
on other areas of AI, such as sharing data or supporting research, other
forums, including ad hoc alliances aimed at specific outcomes, may be
the way forward. From a European standpoint, however, it would be
advisable to try to include the EU as much as possible, so that European
positions are not watered down or member states divided among
themselves.

#### Passing the affirmative [sets a precedent]{.underline} on an international scale and steers future AI development in a brighter direction.

**Miller, 21** (Amanda Miller, experienced with a demonstrated history
of working in the US Air Force with a Top Secret/SCI clearance.,
12-13-2021, accessed on 6-8-2022, Air Force Magazine, \"NATO's Plan to
Grow Trust in Military AI - Air Force Magazine\",
https://www.airforcemag.com/natos-plan-to-grow-trust-in-military-ai/)

As a "pervasive technology," AI will "have an impact on everything we
do," said van Weel. Setting aside "the killer robot discussion," van
Weel dismissed the notion of excluding AI from all military uses: "[[The
idea that AI would not be used for defense]{.mark} purposes [is like
saying that the steam engine]{.mark}, when it was invented, [could only
be used for commercial purposes]{.mark}, [or electricity would not be
supplied to the military]{.mark}]{.underline}." But being behind the
private sector in AI development has left governments "in a situation
where regulation comes after the broad use and misuse of technology,"
van Weel said. "[So [we need to]{.mark} be early to the party and make
sure that we [understand new technologies]{.mark}, not to militarize
them---no, but [to understand the security and defense
implications]{.mark}."]{.underline} Van Weel said military uses of AI
should be regulated, but "[[you don't want to over-regulate if you don't
know that you can defend yourself within the regulations that you're
proposing]{.underline}]{.mark}." He provided the example of drone swarms
"that collectively, powered by AI, are able to follow an intrinsic
pattern---for example, our water supply or one of our cities. So how do
we defend against them?

# Advantages

## Regulation

#### At present, NATO currently does not have a coordinated position on AI development. This puts NATO military strength at risk.

**Stanley-Lockman, 21** (Zoe Stanley-Lockman, Zoe Stanley-Lockman is an
Associate Research Fellow in the Military Transformations Programme at
the Institute of Defence and Strategic Studies at the S. Rajaratnam
School of International Studies in Singapore., 5-26-2021, accessed on
6-14-2022, Center for Security and Emerging Technology, \"Responsible
and Ethical Military AI - Center for Security and Emerging Technology\",
<https://cset.georgetown.edu/publication/responsible-and-ethical-military-ai/>)

[At the same time, [significant differences in ethical approaches to
AI]{.mark} in defense could [imperil political cohesion and undermine
coalition success]{.mark}]{.underline}. [Politically, [alignment]{.mark}
on ethics [is important because shared values are at the foundation of
U.S. alliances]{.mark}]{.underline}.3 This also trickles down to the
operational level, where differing views on ethics could mean that
allies field their systems with different legal authorizations and rules
of engagement.4 [[If]{.mark} coalition [partners deem each others'
capabilities to be based on different]{.mark} legal, ethical, and
doctrinal assumptions, [then forces may not be able to]{.mark}
communicate and [operate together]{.mark}]{.underline}.5 Further, if
different ethical bases for capability development mean that some
countries have higher thresholds for what they develop and contribute to
coalition operations, then others may perceive them as not equally
sharing risks to life.6 [As such, [political cohesion]{.mark} and policy
considerations [about ethics could directly influence operational
effectiveness]{.mark}. In other words, failure to align allied
perspectives on AI ethics in defense will inevitably undermine the
ability of allied forces to understand each other and work
together.7\]{.underline}

#### Failing to regulate AI for member states undermines NATO coordination, making miscalculation and accidents more likely if left unchecked.

**Trabucco et al. 21** (Zoe Stanley-Lockman and Lena Trabucco, Zoe
Stanley-Lockman is an Associate Research Fellow in the Military
Transformations Programme at the Institute of Defence and Strategic
Studies at the S. Rajaratnam School of International Studies in
Singapore, Lena Trabucco is a dual degree candidate pursuing a PhD in
political science at Northwestern University, 4-29-2021, accessed on
6-14-2022, Oxford Handbooks Online, \"NATO's Role in Responsible AI
Governance in Military Affairs\",
<https://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69>)\
Even without being attacked, [governability of [AI in a NATO
context]{.mark} also means [understanding how AI-enabled and autonomous
systems developed by the 30 Allies]{.mark}---and other partners---[will
interact with one another]{.mark}]{.underline}. NATO has expressed
interest in governability as a principle of AI "to disengage or
deactivate in case of unintended behavior,"85 which echoes the U.S.
Department of Defense definition of governable AI.86 Disengaging
adversaries is important to maintain de-escalation measures in conflict.
[For NATO, interoperability between systems also relates to governable
AI because allies must also consider how the interactions between the 30
Allies' own AI-enabled and autonomous systems may result in unintended
or emergent behavior]{.underline}.87 [This means [that NATO has a
responsibility to coordinate activities---be they technical exchanges,
standardization efforts, or training]{.mark} and exercises---to build
confidence that the systems perform as humans intend.]{.underline}88
[[Without this coordination, the lack of interoperability]{.mark} of
allied systems [could lead to accidents, and]{.mark} separately, the
potential loss of operational effectiveness also presents
[vulnerabilities for adversaries to exploit]{.mark}]{.underline}.

## China

#### Maintaining NATO AI technology front by investing in mutually beneficial research guarantees US lead and facilitates defense against China, deterring conflict.

**Franke, 21** (Ulrike Esther Franke, Dr. Ulrike Franke is a senior
policy fellow at the European Council on Foreign Relations (ECFR). She
leads ECFR's Technology and European Power initiative., Jan-1-2021,
accessed on 6-9-2022, Jstor, \"Artificial Divide: How Europe and America
could\",
https://www.jstor.org/stable/pdf/resrep29123.pdf?refreqid=excelsior%3Aa5f05901d2537261e569c592ad151765&ab_segments=&origin=&acceptTC=1)

[In the US, [there is growing concern over the possibility that China
might become too strong an AI actor]{.mark}]{.underline}. [The
competition over global leadership between the US and China is
intensifying, with]{.underline} technology in general, and AI in
particular, as battlefields. [The US fears that AI may give China a
competitive edge. Therefore, [countering China's AI ambitions]{.mark} --
as embodied in its attempts to dominate international technology
standards bodies, for example -- [has become an important motive for the
US to seek international cooperation]{.mark}]{.underline}. In this
context, Joe Biden has proposed an "alliance of liberal democracies" to
present an economic and political alternative to China. As noted,
agreeing on shared goals and supporting measures will present some
challenges. [[Beyond]{.underline}]{.mark} the specific themes of
[ethical AI and [slowing Chinese progress in AI]{.mark}]{.underline},
however, [[there are other areas for transatlantic AI
cooperation]{.underline}]{.mark}. Investing in these potentially less
controversial areas may help create new platforms and lay important
groundwork for greater cooperation. [For example, [the transatlantic
allies should facilitate]{.mark} the [exchange of knowledge and best
practices on AI, and invest in mutually beneficial research]{.mark},
such as privacy-preserving machine learning]{.underline}. Some of these
military capabilities -- namely, [[lethal autonomous weapon
systems]{.mark}, or "killer robots" -- [are among the most controversial
uses of AI]{.mark}]{.underline}.

#### Investments in AI are necessary for [technological edge]{.underline} - United States technology development is needed now to bolster AI front. NATO's 2022 AI Strategy proves.

**Konaev and Nurkin, 22** (Margarita Konaev and Tate Nurkin, Margarita
Konaev is a nonresident senior fellow in the Forward Defense practice of
the Atlantic Council's Scowcroft Center for Strategy and Security, Tate
Nurkin is the founder of OTH Intelligence Group and a nonresident senior
fellow with the Scowcroft Center for Strategy and Security at the
Atlantic Counci, 5-25-2022, accessed on 6-8-2022, Atlantic Council,
\"Eye to eye in AI: Developing artificial intelligence for national
security and defense\",
<https://www.atlanticcouncil.org/in-depth-research-reports/report/eye-to-eye-in-ai/>)

That's why [the alliance is publicizing a new plan by which it hopes its
governments will get involved in AI development from the start, both for
security reasons and [to "bridge a gap of distrust"]{.mark} in the
technology.]{.underline} [Over the last several years, [interest and
investment in AI have gained momentum]{.mark}]{.underline}. This is
especially true in the national security and defense community, as
strategists, policymakers, and executives seek decisive advantages amid
rising geostrategic competition and prepare for future operating
environments characterized by complexity, uncertainty, and, most
importantly, speed. [[AI is now at the center of military-technological
competition between the United States and China]{.mark}, and both
countries, [as well as other militaries throughout the world]{.mark},
are already deploying AI-enabled systems with the goal of dominating the
battlefield of the future. [The United States cannot risk falling
behind]{.mark} [China]{.mark}]{.underline}--- not in AI innovation, not
in AI adoption, and not in the full-scale integration of AI across the
national defense enterprise. Urgency is required in addressing the range
of technical and bureaucratic processes, and cultural issues that have,
to date, dampened the pace of AI adoption within the DoD. [[Systemic
change is a slow]{.mark}, arduous [process]{.mark}. But, [delaying this
transition risks the US military falling behind on]{.mark} exploiting
[the advantages AI promises to deliver]{.mark}, from operational speed
to decision dominance.]{.underline} In the meantime, the following
actions could help improve coordination with industry partners to
accelerate the DoD's AI adoption efforts.

## Russia

#### While Russia may be lagging behind now, increasing cooperation in AI prevents any future clash with Russia, fostering diplomacy.

**Laird, 20** (Burgess Laird, Burgess Laird is a Senior International
Defense Researcher with the RAND Corporation and an adjunct instructor
in the M.A. in Global Security Studies at Johns Hopkins University,
06-03-2020, accessed on 6-9-2022, Rand, \"The Risks of Autonomous
Weapons Systems for Crisis Stability and Conflict Escalation in Future
U.S.-Russia Confrontations\",
https://www.rand.org/blog/2020/06/the-risks-of-autonomous-weapons-systems-for-crisis.html)

Nominally at least, [[Russia\'s vision regarding]{.mark} the aims of
exploiting [AI for military purposes are not dissimilar from those of
the U]{.mark}nited [S]{.mark}tates and [China]{.mark}]{.underline}. It
supports research (PDF) in a number of AI application areas; in just the
past three years, the Kremlin has declared its intent to establish six
new national initiatives dedicated to AI research and development,
including the Advanced Research Foundation (ARF), Russia\'s analogue to
the U.S. Defense Department\'s Defense Advanced Research Projects Agency
(DARPA). As recently as April 21, ARF\'s deputy director boasted to RIA
Novosti that as a result of the foundation\'s research, "[[Living
fighters will gradually begin to be replaced by their robotic
\'brothers\' who can act faster, more accurately and more selectively
than people]{.underline}]{.mark}." Despite what Putin\'s bold assertion
might otherwise seem to suggest, Western experts generally agree that
**[[Russian AI development significantly lags behind that of the United
States and China]{.underline}]{.mark}**. However, in stark contrast to
U.S. AWS development efforts, if only marginally less so than China\'s,
Russia places great emphasis on the development of AI for information
warfare aimed, as a recent comprehensive report by my RAND colleagues
documents, at causing political and societal damage to the target state.
As argued below, instead of seeking to gain military operational
advantages by competing to match U.S. AWS developments, Russia is much
more likely to emphasize and invest in two other military capability
areas.

#### Failing to provide a solution to the AI arms race with Russia leads to escalation, with disastrous consequences.

**Piccone 18** (Ted Piccone -- nonresident senior fellow in the Center
for Security, Strategy, and Technology in the Foreign Policy program at
Brookings and the chief engagement officer at the World Justice Project,
law degree from Columbia University, served eight years as a senior
foreign policy advisor in the Clinton administration. \<KEN\> \"How can
international law regulate autonomous weapons?,\" Brookings. April 2018.
<https://www.brookings.edu/blog/order-from-chaos/2018/04/10/how-can-international-law-regulate-autonomous-weapons/>)

The prospect of [[developing fully autonomous weapons is no longer a
matter of science fiction and is already fueling a new global arms
race]{.underline}]{.mark}. [President [Putin famously told Russian
students last September that "whoever becomes the leader in]{.mark} this
sphere \[of [artificial intelligence\] will become the ruler of the
world."]{.mark}]{.underline} China is racing ahead with an announced
pledge to invest \$150 billion in the next few years to ensure it
becomes the world's leading "innovation centre for AI" by 2030.

# 2AC -- Lethal Autonomous Weapons

### Plan Text, Restated:

#### The United States Federal Government should increase security cooperation with the North Atlantic Treaty Organization on artificial intelligence used for military purposes.

## Case Extensions

### Solvency

#### Extend Miller 21 - Our aff plan is incentivized by NATO's current plans to work with US tech organizations. Passing the plan fortifies NATO's defense even further.

**Miller, 21** (Amanda Miller, experienced with a demonstrated history
of working in the US Air Force with a Top Secret/SCI clearance.,
12-13-2021, accessed on 6-8-2022, Air Force Magazine, \"NATO's Plan to
Grow Trust in Military AI - Air Force Magazine\",
https://www.airforcemag.com/natos-plan-to-grow-trust-in-military-ai/)

Well, we can't, frankly, because you need AI in that case in order to be
able to counter AI." To engender confidence in the principles, [NATO has
also proposed a new initiative]{.underline}. "Principles are nice, but
they need to be verifiable as well, and they need to be baked in from
the moment of the first conception of an idea up until the delivery,"
van Weel said. To that end, to verify new AI, [[NATO wants to create
test centers]{.mark}, [co-located with universities]{.mark} throughout
the alliance. This includes "existing test centers with knowledge, where
allies that are thinking about co-developing AI for use in the defense
sector can come in and verify]{.underline}, with protocols, with certain
standards that we're setting, [that this AI is actually
verified]{.underline}," van Weel said. ["[It's not a world standard yet,
but if]{.mark} the 30 nations, [Western democracies, start]{.mark} out
by [shaping industry to adhere by these standards]{.mark}, then I feel
that [we are making an impact]{.mark}, at least in the development of AI
and hopefully also in the larger world setting standards."]{.underline}

### Regulation Adv Extensions

#### Placing regulations encourages standardization across NATO nations, which is beneficial and ensures systems are reliable.

**Christie et al. 21** (Zoe Stanley-Lockman and Edward H. Christie, Zoe
Stanley-Lockman is an Innovation Officer in the Emerging Security
Challenges Division in NATO's International Staff, and focuses
particularly on Artificial Intelligence and Autonomy., Edward Hunter
Christie is the owner and founder of AI Policy Consulting and served as
lead consultant to NATO in the preparation of NATO's AI Strategy.,
10-25-2021, accessed on 6-10-2022, Nato Review, \"NATO Review - An
Artificial Intelligence Strategy for NATO\",
<https://www.nato.int/docu/review/articles/2021/10/25/an-artificial-intelligence-strategy-for-nato/index.html>)

Having agreed to adopt these mutually reinforcing principles, the task
now turns to translating them into principled action. As such, [[NATO's
role in operationalizing]{.mark} these principles will [involve efforts
that]{.mark}]{.underline} similarly [[tackle different aspects of the
technology]{.mark}'s lifecycle]{.underline}. Building the principles of
responsible use into the front end of AI development is important
because, the later they are considered, the harder it may be to ensure
they are upheld. Ensuring a full life-cycle approach also depends on
multi-stakeholder engagement because responsibility is diffused amongst
the policymakers, designers, developers, and testers, as well as
operational end users that engage in AI development and use. For NATO,
this is relevant because [[various entities play an active role in AI
integration]{.mark}, and]{.underline} because [the Alliance can
encourage coherence with national AI developments.]{.underline}
Regulation sends the message and standardizes AI development, while also
preventing it from violation. For NATO, the common commitment to these
principles has practical advantages as well, providing a coherent common
basis for both NATO and Allies to design and develop AI applications
while also supporting interoperability goals. As such, [[NATO can foster
the necessary interlinkages between safety, security]{.mark},
responsible use, [and interoperability]{.mark}]{.underline}. This can be
seen across the principles. For instance, **[[it is important to
ensure]{.mark} that [AI systems are adequately
robust]{.mark}]{.underline}** and reliable for their intended use, not
only so that they can be expected to function in accordance with legal
obligations, but also to mitigate the risks of the system's defects or
limitations being exploited by nefarious actors. Through the adoption of
principles of responsible use, [[NATO and Allies are sending a]{.mark}
deliberately [public message]{.mark}]{.underline} to their domestic
populations, to Allied forces, and to other states, reiterating the
Alliance's enduring values and commitments under international law. More
than just an obligation, this democratic commitment is also a
pre-condition [[for common policy bases among
Allies]{.underline}]{.mark} -- and for partnership with non-traditional
innovators across the Alliance.

#### Extend Trabucco et al. 21: Ensuring AI is developed ethically and responsibly is key to maintaining the alliance's strength and legitimacy.

**Trabucco et al. 21** (Zoe Stanley-Lockman and Lena Trabucco, Zoe
Stanley-Lockman is an Associate Research Fellow in the Military
Transformations Programme at the Institute of Defence and Strategic
Studies at the S. Rajaratnam School of International Studies in
Singapore, Lena Trabucco is a dual degree candidate pursuing a PhD in
political science at Northwestern University, 4-29-2021, accessed on
6-14-2022, Oxford Handbooks Online, \"NATO's Role in Responsible AI
Governance in Military Affairs\",
<https://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780197579329.001.0001/oxfordhb-9780197579329-e-69>)

[[The political dimension of the Alliance rests on]{.mark} the bedrock
of [a shared commitment to]{.mark} the "principles of
[democracy]{.mark}, individual liberty and the rule of law," as
enshrined in the foundational North Atlantic Treaty of
1949]{.underline}.60 [[Shared values are important for NATO operations
because they help constitute their legitimacy]{.underline}]{.mark}. In
addition to the North Atlantic Council exerting civilian oversight over
NATO operations, legitimacy also includes respect for international
legal principles including the core principles of international
humanitarian law, or the laws of armed conflict, distinction,
proportionality, and necessity. Without political oversight and
legitimacy, NATO's military power would be less effective at shaping
norms and promoting stability in the international system. [[The
introduction of AI means that NATO has the moral and strategic
imperative to adopt technologies that confer]{.mark} legitimacy and
[responsible innovation]{.mark}.61 [Acting on a]{.mark} shared
[commitment to democratic values is vital to the]{.mark} political
[cohesion of the NATO Alliance]{.mark}, just as much as it is a
determinant of military effectiveness in a predictable security
environment.]{.underline}

### China Advantage Extensions 

#### Ignoring the plan gives China leeway to catch up. Increased investments in AI prevents US from falling behind to China, which the plan aims to solve.

**Bateman, 2022** (Jon Bateman, Jon Bateman is a senior fellow in the
Cyber Policy Initiative of the Technology and International Affairs
Program at the Carnegie Endowment for International Peace., No Date,
accessed on 6-10-2022, Carnegie Endowment for International Peace,
\"U.S.-China Technological "Decoupling": A Strategy and Policy
Framework\", April 25 2022,
<https://carnegieendowment.org/2022/04/25/u.s.-china-technological-decoupling-strategy-and-policy-framework-pub-86897>)

[[China's]{.mark} foreign influence [efforts have often focused closer
to home]{.mark}, on targets such as Taiwan and Australia]{.underline}.3
Nevertheless, in 2021 the U.S. Intelligence Community assessed that
"Beijing has been intensifying efforts to shape the political
environment in the United States to promote its policy preferences, mold
public discourse, pressure political figures whom Beijing believes
oppose its interests, and muffle criticism of China on such issues as
religious freedom and the suppression of democracy in Hong Kong."4
According to the IC, China "considered but did not deploy influence
efforts intended to change the outcome of the \[2020\] US presidential
election."5 Beijing apparently judged that the risks outweighed the
benefits. [[This calculus may well change in the future]{.mark},
particularly [if U.S.-China relations continue to deteriorate]{.mark}.
Second, [official U.S. policy goals remain dangerously vague and
open-ended]{.mark} across the board.]{.underline} Washington must
publicly clarify its vision for the global tech trade and set more
achievable ambitions for countering techno-authoritarianism, maintaining
a military edge over China, and preventing Chinese espionage, sabotage,
and influence operations. These are all important U.S. interests, but
none would currently justify broad-based technology controls. Even so,
U.S. rhetoric and policy actions continue to suggest the possibility of
a costly and quixotic expansion of China-oriented controls. [[Clearer,
narrower public messaging]{.mark} by U.S. leaders [would help to focus
agencies on]{.mark} those [problems they can realistically address with
restrictive tools and reduce the motivation of China]{.mark} and others
[to seize control]{.mark} of the decoupling process.]{.underline}

[\]{.underline}

### Russia Advantage Extensions

#### Extend Piccone 18 -- A good offense is a best defense, and NATO cooperation ensures that the alliance remains vigilant to potential threats. Russia is weak now, and the plan prevents any risk of Russian threats. 

**Piccone 18** (Ted Piccone -- nonresident senior fellow in the Center
for Security, Strategy, and Technology in the Foreign Policy program at
Brookings and the chief engagement officer at the World Justice Project,
law degree from Columbia University, served eight years as a senior
foreign policy advisor in the Clinton administration. \<KEN\> \"How can
international law regulate autonomous weapons?,\" Brookings. April 2018.
<https://www.brookings.edu/blog/order-from-chaos/2018/04/10/how-can-international-law-regulate-autonomous-weapons/>)

[[The United States]{.mark}, still the largest incubator for AI
technology, [has identified defending its public-private]{.mark}
"National Security Innovation Base (NSIB)" from [intellectual
property]{.mark} theft [as a national security
priority]{.mark}.]{.underline} Others suggest [that [a more measured,
incremental approach under existing rules]{.mark} of international law
should suffice to [ensure humans remain in the decisionmaking loop of
any use of these weapons, from design through deployment and
operation]{.mark}.]{.underline}

# Answers To

## A2 Russia DA

#### No Impact: Russia has not actually used fully autonomous weapons in Ukraine. The plan is key to preventing it from being reality.

**Allen, 22** (Gregory C. Allen, Gregory C. Allen is the director of the
Artificial Intelligence (AI) Governance Project and a senior fellow in
the Strategic Technologies Program at the Center for Strategic and
International Studies (CSIS)., 5-26-2022, accessed on 6-10-2022, Csis,
\"Russia Probably Has Not Used AI-Enabled Weapons in Ukraine, but That
Could Change\",
<https://www.csis.org/analysis/russia-probably-has-not-used-ai-enabled-weapons-ukraine-could-change>)

[[In March, WIRED ran a story with the headline "Russia\'s Killer Drone
in Ukraine Raises Fears About AI in Warfare]{.mark}," with the subtitle,
"The maker of the lethal drone claims that it can identify targets using
artificial intelligence.]{.underline}" The story focused on the KUB-BLA,
a small kamikaze drone aircraft that smashes itself into enemy targets
and detonates an onboard explosive. The KUB-BLA is made by ZALA Aero, a
subsidiary of the Russian weapons manufacturer Kalashnikov (best known
as the maker of the AK-47), which itself is partly owned by Rostec, a
part of Russia's government-owned defense-industrial complex. The WIRED
story understandably attracted a lot of attention, but [[those who only
read the]{.mark}]{.underline} sensational [[headline missed the
article's critical caveat: "It is unclear if the drone may have been
operated in this \[an AI-enabled autonomous\] way in
Ukraine."]{.underline}]{.mark} Other outlets re-reported the WIRED
story, but irresponsibly did so without the caveat. [In sum, [there is
little reason to believe that Russia is using AI-enabled autonomous
weapons in Ukraine]{.mark}, yet]{.underline}. That is the good news. The
bad news is that, if Russia's unlawful war in Ukraine drags on, Russia
has the intent and likely has the means to deploy autonomous weapons,
with or without advanced AI.

#### A good NATO defense prevents Russia offense - NATO is currently leading in AI technology and the plan fortifies NATO's capabilities.

**Wodecki, 22** (Ben Wodecki, BJTC accredited tech journalist and
assistant editor at AI Business, 6-21-2022, accessed on 6-13-2022, AI
Business, \"NATO at risk of losing AI innovation race to Russia, China -
AI Business\", https://aibusiness.com/document.asp?doc_id=777260)

Its recommendations include [[AI standardization]{.underline}]{.mark},
encouraging and improving AI literacy and spurring private sector
innovation. Such undertakings [[would allow NATO allies to better scale
and deploy AI -- and keep pace with rivals]{.underline}]{.mark}. "These
new capabilities will revolutionize NATO's military and strategic
affairs, thus [[strengthening NATO's ability to fulfill its essential
core tasks of collective defense, crisis management and cooperative
security]{.underline}]{.mark}," CEPA's Nicholas Nelson and Nico Luzum
wrote. The pair cited AI projects being undertaken by adversaries,
including China's attempts to develop purported mind-controllable drones
and AI assistants for fighter pilots. But NATO allies have their own
capabilities -- including U.S.-developed autonomous tanks and
British-made systems that provide ground troops with information on the
surrounding terrain. The think tank's study suggests that **[[at
present, NATO is leading the AI race -- but risks losing its competitive
advantage to peer competitors]{.underline}]{.mark}** "competitors [[if
allies fail to]{.underline}]{.mark} leverage the private sector,
[[coordinate implementation and engage with the
public]{.underline}]{.mark}." CEPA suggests that [[NATO allies should
accelerate AI adoption and actively encourage private sector
innovation]{.underline}]{.mark}. "Ultimately, we hope that these
recommendations enable NATO allies to better innovate, scale, deploy,
and integrate AI and autonomy-based technologies to form agile,
system-wide solutions.

## A2 Imperialism DA

#### Non-Unique/Link Turn: Preventing US/NATO imperialism will not prevent other countries' from succeeding them. AI development is inevitable.

**Michelson, 21** (Brian Michelson, Colonel (Retired) Brian M. Michelson
is a Nonresident Senior Fellow with CEPA's Transatlantic Defense Tech
Initiative., 2-23-2021, accessed on 6-9-2022, CEPA, \"Why NATO Needs
Lethal Autonomous Weapon Standards \| CEPA\",
<https://cepa.org/why-nato-needs-lethal-autonomous-weapon-standards/>)

[The rapid [weaponization of artificial
intelligence]{.mark}]{.underline}, "big data," social media, robotics,
and a host of other technologies [[presents a clear competitive
challenge]{.mark} to NATO]{.underline}, an alliance with members that
exist on a wide spectrum of military-technological capabilities. The
future effectiveness of NATO will be driven in large part by how it
handles these challenges from hobbling its ability both to act in unison
and to prevail in a contest of wills. [[While there are numerous]{.mark}
potential technology gaps, [one that will likely only increase
is]{.mark} partner nations' ability]{.underline} and willingness [to
employ [lethal autonomous weapon systems]{.mark}]{.underline}. **[[These
systems will inevitably grow more capable, and more necessary, in the
coming decade]{.mark}.\]{.underline}**

#### And, any hope of breaking out of the NATO's imperialist structures relies on allowing other nations like Russia to take over, which is net worse. Russia-Ukraine war proves.

**Hamid, 22** (Shadi Hamid, Shadi Hamid is a contributing writer at The
Atlantic, a senior fellow at the Brookings Institution, and assistant
research professor of Islamic studies at Fuller Seminary. , 3-6-2022,
accessed on 6-13-2022, No Publication Found, \"Putin Proves There Are
Worse Things Than American Power\",
https://www.theatlantic.com/ideas/archive/2022/03/putin-kremlin-imperialism-ukraine-american-power/624180/)\
Russia's unprovoked attack on a sovereign nation, in Europe no less, has
put matters back in their proper framing. [The question of whether the
United States is a uniquely malevolent force in global politics has been
resolved]{.underline}. [In the span of a few days, [skeptics of American
power have gotten a taste of what a world where America grows weak and
Russia grows strong looks like]{.mark}]{.underline}. Of course, there
are still holdouts who insist on seeing the United States as the
provocateur. In its only public statement on Ukraine, the Democratic
Socialists of America condemned Russia's invasion but also called for
"the U.S. to withdraw from NATO and to end the imperialist expansionism
that set the stage for this conflict." [This is an odd statement
considering that [Russia, rather than the United States, has been the
world's most unabashedly imperialist force for the past three
decades]{.mark}]{.underline}. But many on the anti-imperialist left
aren't really anti-imperialist; they just have an instinctive aversion
to American power. In any number of ways, Russia's aggression has
underscored why Biden was right and why authoritarians---and the
authoritarian idea itself---are such a threat to peace and stability.
[[Russia invaded Ukraine, a democracy, because of the recklessness and
domination of one man]{.mark}, Vladimir Putin.]{.underline} The
countries that have rallied most enthusiastically behind Ukraine have
almost uniformly been democracies, chief among them the United States.
[[America is]{.mark} lousy, disappointing, and [maddeningly hypocritical
in its conduct abroad, but the notion of any moral equivalence between
the United States and Putin's Russia has been rendered
laughable]{.mark}]{.underline}. And if there is such a thing as a better
world, then anti-imperialists may find themselves in the odd position of
hoping and praying for the health and longevity of not just the West but
of Western power.

## A2 China DA

#### Extend Bateman 2022 AND impact turn their disadvantage -- Preventing the aff plan allows China to catch up, leading to the harms both sides outlined.

#### A good NATO defense prevents China offense - NATO is currently leading in AI technology and the plan fortifies NATO's capabilities. 

**Wodecki, 22** (Ben Wodecki, BJTC accredited tech journalist and
assistant editor at AI Business, 6-21-2022, accessed on 6-13-2022, AI
Business, \"NATO at risk of losing AI innovation race to Russia, China -
AI Business\", https://aibusiness.com/document.asp?doc_id=777260)

Its recommendations include [[AI standardization]{.underline}]{.mark},
encouraging and improving AI literacy and spurring private sector
innovation. Such undertakings [would allow [NATO allies to
better]{.mark} scale and deploy AI -- and [keep pace with
rivals]{.mark}]{.underline}. "These new capabilities will revolutionize
NATO's military and strategic affairs, thus [strengthening NATO's
ability to fulfill its essential core tasks of collective defense,
crisis management and cooperative security]{.underline}," CEPA's
Nicholas Nelson and Nico Luzum wrote. The pair cited AI projects being
undertaken by adversaries, including China's attempts to develop
purported mind-controllable drones and AI assistants for fighter pilots.
But NATO allies have their own capabilities -- including U.S.-developed
autonomous tanks and British-made systems that provide ground troops
with information on the surrounding terrain. The think tank's study
suggests that **[[at present, NATO is leading the AI race -- but risks
losing its competitive advantage to peer
competitors]{.underline}]{.mark}** "competitors [[if allies fail
to]{.underline}]{.mark} leverage the private sector, [[coordinate
implementation and]{.mark} engage with the public]{.underline}." CEPA
suggests that [[NATO allies should accelerate AI adoption and actively
encourage private sector innovation]{.underline}]{.mark}. "Ultimately,
we hope that these recommendations enable NATO allies to better
innovate, scale, deploy, and integrate AI and autonomy-based
technologies to form agile, system-wide solutions.

### AT Underdeveloped Technology

#### Industries want to follow ethical principles -- they won't use underdeveloped technologies because of escalation.

**Byrne et al. 22** (Matilda Byrne, Ryan Gariepy, Emilia Javorsky,
Volker Lehmann, and Laura Nolan, 01-1-2022, accessed on 6-14-2022,
Library.fes, \"\", http://library.fes.de/pdf-files/iez/17215.pdf)

[Further [progress toward stigmatization of LAWS will require engaging
with]{.mark}]{.underline} multiple stakeholders, including
[[industry]{.underline}]{.mark}, academia and civil society. However,
inclusion of a broad range of stakeholders should not distract from the
onus of responsibility for action remaining on states. [Expecting the
private sector to establish and maintain voluntary guidelines or codes
of conduct on meaningful human control is unrealistic,]{.underline}
given that [states are the customers]{.underline} of weapons contracts
[and stipulate their expectations to the private sector]{.underline}.
[In fact, [technology companies themselves have stressed the need for
clear guidelines from states to help engineers]{.mark}]{.underline},
designers and technology workers [make moral, ethical, and legal
judgements about the systems they build]{.underline}.11

## Impact - Nuclear War

#### Non-Unique: Increasing investment in AI isn't the only avenue that leads to nuclear war and is not uniquely exacerbated by the AFF.

#### And, cross-apply Miller 21 -- The aff plan ensures AI development [does not go that path]{.underline}. Escalation is unlikely if military tech is controlled.

**Miller, 21** (Amanda Miller, experienced with a demonstrated history
of working in the US Air Force with a Top Secret/SCI clearance.,
12-13-2021, accessed on 6-8-2022, Air Force Magazine, \"NATO's Plan to
Grow Trust in Military AI - Air Force Magazine\",
https://www.airforcemag.com/natos-plan-to-grow-trust-in-military-ai/)

As a "pervasive technology," AI will "have an impact on everything we
do," said van Weel. Setting aside "the killer robot discussion," van
Weel dismissed the notion of excluding AI from all military uses: "[The
idea that AI would not be used for defense]{.underline} purposes [is
like saying that the steam engine]{.underline}, when it was invented,
[could only be used for commercial purposes]{.underline}, or electricity
would not be supplied to the military." But being behind the private
sector in AI development has left governments "in a situation where
regulation comes after the broad use and misuse of technology," van Weel
said. "So [[we need to]{.underline}]{.mark} be early to the party and
[[make sure that we understand new technologies, not to militarize
them]{.underline}]{.mark}---no, [[but to understand the security and
defense implications]{.underline}]{.mark}." Van Weel said military uses
of AI should be regulated, but "[[you don't want to over-regulate if you
don't know that you can defend yourself within the regulations that
you're proposing]{.underline}]{.mark}." He provided the example of drone
swarms "that collectively, powered by AI, are able to follow an
intrinsic pattern---for example, our water supply or one of our cities.
So how do we defend against them?

### Extra Cards

#### Many foreign militaries have already developed artificial intelligence for war. This takes the form of Lethal Autonomous Weapons, war machines that rely on AI that do not need manual control.

**Kessel 19** (Jonah M. Kessel, 12-13-2019, accessed on 6-8-2022, The
New York Times, \"Killer Robots Aren't Regulated. Yet. (Published
2019)\",
<https://www.nytimes.com/2019/12/13/technology/autonomous-weapons-video.html>)

[There are weapons that use artificial intelligence in active use
today,]{.underline} including some [that can]{.underline} search, select
and [engage targets on their own]{.underline}, attributes often
associated with [defining what constitutes a lethal autonomous weapon
system (a.k.a. a killer robot]{.underline}). In his book "Army of None:
Autonomous Weapons and the Future of War," the Army Ranger turned
[policy analyst Paul Scharre explained, "More than 30 nations already
have defensive supervised autonomous weapons]{.underline} for situations
in which the speed of engagement is too fast for humans to respond."
Perhaps [the best known of these weapons is the Israel Aerospace
Industries Harpy]{.underline}, an armed drone that can hang out high in
the skies surveying large areas of land until it detects an enemy radar
signal, at which point it crashes into the source of the radar,
destroying both itself and the target. [The weapon needs no specific
target to be launched, and a human is not necessary to its lethal
decision making]{.underline}. [It has been sold to]{.underline} Chile,
[China, India, South Korea and Turkey]{.underline}, Mr. Scharre said,
[and the Chinese are reported to have reverse-engineered their
own]{.underline} variant. Although current A.I. is relatively brittle,
that isn't stopping militaries from incorporating it into their robots.
In his book, which was published in 2018, Mr. Scharre wrote that [at
least 16 countries had armed drones, adding that more than a dozen
others were working on them.]{.underline}

**Franke, 21** (Ulrike Esther Franke, Dr. Ulrike Franke is a senior
policy fellow at the European Council on Foreign Relations (ECFR). She
leads ECFR's Technology and European Power initiative., Jan-1-2021,
accessed on 6-9-2022, Jstor, \"Artificial Divide: How Europe and America
could\",
https://www.jstor.org/stable/pdf/resrep29123.pdf?refreqid=excelsior%3Aa5f05901d2537261e569c592ad151765&ab_segments=&origin=&acceptTC=1)

Calls for cooperation between the United States and Europe have become
particularly regular and resonant: following last year's US presidential
election, it was reported that the European Commission planned to
propose a "Transatlantic Trade and Technology Council", which would set
joint standards on new technologies. And[, in September 2020, the US set
up a group of like-minded countries "to provide values-based global
leadership in defense for policies and approaches in adopting AI", which
included seven European states]{.underline}, in addition to countries
such as Australia, Canada, and South Korea. [In June 2020, the Global
Partnership on Artificial Intelligence was founded to consider the
responsible development of AI; it counts among its members the US, four
European states, and the European Union.]{.underline}

**Marijan, 22** (Branka Marijan, Branka Marijan is a senior researcher
at Project Ploughshares, where she leads research on the military and
security implication of emerging technologies., 2-14-2022, accessed on
6-9-2022, Centre for International Governance Innovation, \"Beyond
Ukraine: AI and the Next US-Russia Confrontation\",
<https://www.cigionline.org/articles/beyond-ukraine-ai-and-the-next-us-russia-confrontation/>)

The economic outlook for Russia, which remains dependent on exports of
oil and gas for much of its revenues, is grim at least in the
short-term. COVID-19 forced Russia to agree to a deal with OPEC to
significantly cut production and exports, which it initially rejected in
March, and sent oil prices down in what is bound to reduce budget
revenues and cause economic contraction. Russia is now forecast to
experience a GDP contraction of 5.5. percent and an increase in
unemployment from 2.5 million to 8 million workers this year. Moreover,
continued dependence on exports of commodities whose prices Russia
cannot control, depopulation (PDF), and a host of other structural
factors indicates that the economic outlook for Russia will remain bleak
in the longer term, too, in absence of deep reforms. As a result, for
the foreseeable future, Russia\'s federal budget is likely to be
constrained. If for no other reason than that, the Kremlin will be
unlikely to respond to U.S. AWS advancements by substantially increasing
investments in the area, at least in comparison to two other
capabilities it is more likely to prioritize well ahead of AWS as
discussed immediately below. But there is yet another reason. In brief,
such symmetrical responses to capability differences have seldom been
part of Russia\'s playbook in the post--Cold War era. In this respect,
it is too early to identify just where Russia may be heading in terms of
the character of AWS ground, air, or naval capabilities it is likely to
field, let alone to discern any associated operational concepts. The
time doing so is likely to prove time misspent. Instead, Moscow is much
more likely to look to two other capability areas in search of
comparative military operational advantage with respect to the United
States and NATO.

First, [[the Kremlin can be counted upon to continue with its customary
strategy of]{.mark} underscoring and even [increasing its reliance upon
nuclear weapons both for deterrence and possibly even
warfighting]{.mark}]{.underline}, a cost-effective strategy,
comparatively speaking, that Vasily Kashin and Michael Raska
economically refer to as "countering the Third Offset Strategy with the
First Offset Strategy (PDF)." In this regard, Putin\'s unveiling of the
five nuclear "superweapons" in his March 2018 nationally televised
speech to the Russian Federal Assembly can be seen as exhibit one of
this strategy. Still, Moscow\'s continued reliance on nuclear weapons by
no means suggests that it will be willing to cede leadership in emerging
disruptive technologies entirely to the United States.

#### Their Madnick 2022 evidence only concerns the use of nuclear devices and cyberwarfare, not autonomous weapons -- This has no correlation to the affirmative plan whatsoever.

**Madnick, 2022**, (Stuart, Professor of Engineering Systems in the MIT
School of Engineering, and Director of Cybersecurity at MIT Sloan
(CAMS): the Interdisciplinary Consortium for Improving Critical
Infrastructure Cybersecurity.), "What Russia's Ongoing Cyber Attacks in
Ukraine Suggest About the Future of Cyber Warfare". Harvard Business
Review. 03/07.
https://hbr.org/2022/03/what-russias-ongoing-cyberattacks-in-ukraine-suggest-about-the-future-of-cyber-warfare

Between 1946 and 1958, the Bikini Atoll, in the North Pacific Ocean, was
used as a testing ground for 23 new nuclear devices that were detonated
at various spots on, above, or beneath it. The point of the tests was
primarily to understand (and, in many cases, show off) how these new
weapons really worked --- and what they were capable of. [The era of
nuclear testing may now be over, but the age of cyber warfare is just
beginning.]{.underline} And for Russia, the war with Ukraine has been
likely serving as a live testing ground for its next generation of cyber
weapons. Countries and companies watching this latest chapter unfold
should remember this: The online front of the war can --- and has ---
jumped borders.

# Neg Answers (for the Neg)

## Impact - Nuclear War

1)  **Overinvestment in AI can lead to overdependence, leading to
    fatally unintentional consequences such as nuclear war.**

**Kallenborn, 22** (Zachary Kallenborn, Zachary Kallenborn is a research
affiliate with the Unconventional Weapons and Technology Division of the
National Consortium for the Study of Terrorism and Responses to
Terrorism (START), a policy fellow at the Schar School of Policy and
Government, a US Army Training and Doctrine Command "Mad Scientist," and
national security consultant, 2-1-2022, accessed on 6-13-2022, Bulletin
of the Atomic Scientists, \"Giving an AI control of nuclear weapons:
What could possibly go wrong? - Bulletin of the Atomic Scientists\",
<https://thebulletin.org/2022/02/giving-an-ai-control-of-nuclear-weapons-what-could-possibly-go-wrong/>)

How autonomous nuclear weapons could go wrong. [The huge problem with
autonomous nuclear weapons, and really all autonomous weapons, is error.
Machine learning-based artificial intelligences]{.underline}---the
current AI vogue---[rely on large amounts of data to perform a
task]{.underline}. Google's AlphaGo program beat the world's greatest
human go players, experts at the ancient Chinese game that's even more
complex than chess, by playing millions of games against itself to learn
the game. For a constrained game like Go, that worked well. But in the
real world, [data may be biased or incomplete in all sorts of
ways.]{.underline} For example, one hiring algorithm concluded being
named Jared and playing high school lacrosse was the most reliable
indicator of job performance, probably because it picked up on human
biases in the data.

[In a nuclear weapons context,]{.underline} a government may have little
data about adversary military platforms; [existing data may be
structurally biased]{.underline}, by, for example, relying on satellite
imagery; [or data may not account for obvious, expected variations such
as imagery in taken during foggy, rainy, or overcast
weather.\]{.underline}

#### And, wars utilizing autonomous weapons are more likely to escalate due to preemptive attacks.

**Laird, 16** (Burgess Laird, Burgess Laird is a Senior International
Defense Researcher with the RAND Corporation and an adjunct instructor
in the M.A. in Global Security Studies at Johns Hopkins University,
12-8-2016, accessed on 6-9-2022, Rand, \"The Risks of Autonomous Weapons
Systems for Crisis Stability and Conflict Escalation in Future
U.S.-Russia Confrontations\",
https://www.rand.org/blog/2020/06/the-risks-of-autonomous-weapons-systems-for-crisis.html)

First, [a state facing an adversary with AWS capable of making decisions
at machine speeds is likely to fear the threat of sudden and potent
attack, a threat that would compress the amount of time for strategic
decisionmaking]{.underline}. The posturing of AWS during a crisis would
likely create fears that one\'s forces could suffer significant, if not
decisive, strikes. These fears in turn could translate into pressures to
strike first---to preempt---for fear of having to strike second from a
greatly weakened position. Similarly, within conflict, [the fear of
losing at machine speeds would be likely to cause a state to escalate
the intensity of the conflict possibly even to the level of nuclear
use]{.underline}.
