# NEG -- AI -- UTNIF 2022

## NATO Advantage

### Conventional Deterrence Turn -- 1NC

#### European security cooperation is stable, but has shifted to the EDI to deter Russia\-\--plan trades off, undermines conventional deterrence

Michael J. **Mazarr et al 22**, senior political scientist at the RAND
Corporation. \"Security Cooperation in a Strategic Competition\"
Research Report. <http://www.rand.org/t/RRA650-1> //pipk

[Security Cooperation Efforts in Europe Emphasize Reassuring U.S.
Allies]{.underline} **[European partners have consistently received
approximately 26 percent of all U.S. security aid, but there has been a
shift since 2014 in the type of aid these partners have
received]{.underline}**. [Specifically, more attention has been devoted
to **developing conventional capabilities to deter Russian
aggression**]{.underline}. [Eastern European states]{.underline} that
border Russia, particularly Ukraine, received \$1.1 billion from 2014 to
2019.18 Georgia, Latvia, Lithuania, and Estonia also [received some
funding through the **European Deterrence Initiative**.]{.underline}
However, of the billions of dollars designated for the initiative, only
a small portion supports building partner capacity. [The initiative was
designed primarily to support U.S. force presence, infrastructure, and
exercises]{.underline}; as a result, DoD does not formally categorize
European Deterrence Initiative funding as security aid.19

Over our period of study, U[.S. military sales have increased for both
highly capable allies and]{.underline} newer North Atlantic Treaty
Organization ([NATO) partners in Europe]{.underline}. Among the top
weapon purchasers, the United Kingdom, Italy, and Germany are purchasing
advanced aircraft, unmanned aerial systems, and missiles through the FMS
and DCS programs. Poland and Romania are acquiring Patriot air-defense
systems, and Slovakia is purchasing F-16 aircraft through FMS.20

[The focus of U.S. education and training efforts in Europe has also
been on conventional military capabilities funded by FMS]{.underline}.
Germany, the Netherlands, Italy, Romania, and Poland are the top
recipients of these security cooperation activities.21

Furthermore, [U.S.- and NATO-sponsored exercises in Europe are
increasing in number and size. These exercises, which focus on improving
interoperability for conventional operations]{.underline}, include Saber
Guardian (a U.S.-sponsored exercise with 25,000 service members from 22
allied and partner nations) and Trident Juncture (a NATO-sponsored
exercise with 50,000 participants from NATO and partner countries).22
NATO arrangements [afford the United States a high degree of access in
Europe.]{.underline} Of the 51 countries in the EUCOM AOR, 45 have
multilateral SOFAs through NATO or the Partnership for Peace program,
and there are 126 acquisition and cross-servicing agreements that apply
to the region.23 The majority of USAF armament agreements and airmen in
personnel exchanges are with European countries, and most personnel
exchanges through the USAF's Military Personnel Exchange Program are
with the United Kingdom. Countries in EUCOM's AOR received \$27 million
in Overseas Humanitarian, Disaster, and Civic Aid support, divided
across several Eastern European states; Ukraine received \$4 million,
the highest amount.

### Heg Bad -- 1NC

#### [Multipolarity is inevitable]{.underline} -- Trump provided a [strategic opening]{.underline} for [retrenchment]{.underline} and [soft-landing]{.underline} -- the affs cling to hegemony ensures [violent transition wars]{.underline} and [failure of global cooperation]{.underline}. 

**Marchetti '17** (Raffaele Marchetti, \*senior assistant professor in
International Relations at the Department of Political Science and the
School of Government of LUISS, external expert for the European
Commission, "End of the American hegemonic cycle," Feb 14,
https://www.opendemocracy.net/raffaele-marchetti/end-of-american-hegemonic-cycle)//cmr

[Trump]{.underline}'s election [marks the end of]{.underline} the long
phase of [American world hegemony]{.underline}. Despite the electoral
slogan "Make America Great Again" and the great expectations this may
have generated, [his presidency will]{.underline} presumably [be
characterized by an **overall retrenchment**]{.underline}. Many
different interpretations have been provided on the reasons of Trump's
success ranging from populist framing to FBI support. Contrary to the
mainstream debate, I see a more fundamental reason underpinning his
victory: the changed costs/benefits balance in the US role in the world.
The theory of hegemonic stability holds that at some point the hegemon
will start to decline due to the increased costs of the management of
the system which outbalance the benefits the hegemon gains out of it.
[The costs of]{.underline} the [management of the system
have]{.underline} in fact [been accumulating]{.underline} in the last 4
presidencies. During the Bush administrations, [security costs due
to]{.underline} the military operations in [Afghanistan and Iraq
have]{.underline}, among other damage, [impacted negatively on the US
government]{.underline}. Equally, during the Obama presidencies [costs
due to economic stimuli have increased]{.underline} the overall
[debt]{.underline} of the country. As predicted by hegemonic theory, we
finally come to a point in which [the costs became too heavy
for]{.underline} the [citizens]{.underline}, [or]{.underline} rather
[their perception]{.underline} of this becomes [more evident,
so]{.underline} that [they start to]{.underline} protest and
[demand]{.underline} a [change]{.underline}. This was intercepted by
Trump much more than by Clinton, with Trump stepping back to decrease
the costs of international projection. So-called "[imperial
overstretch]{.underline}", formed much earlier, [led Trump's electorate
to seek less international costs]{.underline} (and possibly, but less
likely, more domestic benefits). Hence, the promised withdrawal from a
number of Free Trade Agreements, the discussion of the terms of NATO
participation, cancellation of the environmental deals etc. From this
perspective Trump's election has to do with a much longer trend of
international order rather than the specific time-lapse of the electoral
campaign, a trend of dis-engagement that had already begun during the
Obama administration and will now be more clearly visible with Trump.
The system in which we have been living in the last 70 years was created
in large part by the US leadership. [The UN system, Bretton
Woods]{.underline} Institutions, [NATO, and WTO]{.underline} are all
institutional arrangements that have been strongly promoted by the post
WWII hegemon and that have been preserved in life thanks to continuous
support by the USA. Now all of this is put into question by the
resistance of the newly elected president to engage in and with these
multilateral organizations. [Trump will]{.underline} most likely [have a
more unpredictable]{.underline}, possibly [turbulent
behaviour]{.underline} vis a vis all of these institutions [and this
will lead to their transformation and]{.underline} perhaps for some, to
their [marginalization]{.underline}. Other significant elements in this
jigsaw puzzle have to do with the phenomenon of globalization. It is
because of global transformation in production chains, the relocation of
multinational corporation abroad coupled with the possibility of
(re-)importing goods, and the subsequent loss of jobs that a component
of the middle class has been badly affected by unemployment. But it is
also thanks to globalization that [China is rising fast and
challenging]{.underline} the [US leadership in economic]{.underline},
but also increasingly in [political and military terms]{.underline}. It
is clear by now that [the policy choice for globalization]{.underline}
taken by the US leadership in the '80s (republican) and '90s
(democratic) was beneficial only at the beginning, but later [turned out
to be detrimental to the power position of the US]{.underline}A in the
world economy. It is widely recognised that [India and]{.underline}
especially [China]{.underline} [are]{.underline} the real winners in the
game of globalization, hence [closing the gap with the
west]{.underline}. Russia is an additional element in this calculation.
[This new would-be multipolar system]{.underline}, deprived of the
overall western master plan, is [left to pure bargaining]{.underline},
[pure transactionalism]{.underline} played with ad hoc games, which is
very much in line with Trump's overall attitude to socio-economic
engagement. And yet, [this might have a **de-polarizing
effect**]{.underline}, **[a de-escalating consequence in terms of the
current world tensions]{.underline}** that have grown in the last few
years. Here [I am thinking especially]{.underline} of [the west-Russia
split]{.underline}. [Without a hegemonic power]{.underline} pushing for
a specific world order, **[a more balanced system might
emerge]{.underline}**. We might end up with a Trump presidency that has
polarizing effects domestically and depolarizing effects
internationally. [The line of march is clear]{.underline}: [either **new
competition**]{.underline} [based on multipolar rivalry which
might]{.underline} possibly **[escalate into conflicts]{.underline}**,
[or the opening of **new channels for dialogue**]{.underline}, [might
lead to a foundational phase in which innovative rules of the
international games are written by western and non-western powers
together]{.underline}. **[It will be up to]{.underline}** Trump and the
other **[leaders to steer the way]{.underline}** and to take a decision
on which way to go.

#### Hegemony fuels [global prolif]{.underline} -- withdrawal solves. 

**Mearsheimer and Walt '16** (John J, R. Wendell Harrison Distinguished
Service Professor of Political Science at the University of Chicago, and
Stephen M, Robert and Renée Belfer Professor of International Affairs at
the Harvard Kennedy School, "The Case for Offshore Balancing: A Superior
U.S. Grand Strategy," Foreign Affairs, July/August,
https://www.foreignaffairs.com/articles/united-states/2016-06-13/case-offshore-balancing)//cmr

[Proponents of liberal hegemony]{.underline} also [claim that the United
States must remain committed all over the world to prevent nuclear
prolif]{.underline}eration. If it reduces its role in key regions or
withdraws entirely, the argument runs, countries accustomed to U.S.
protection will have no choice but to protect themselves by obtaining
nuclear weapons. [No grand strategy is likely to prove wholly successful
at preventing proliferation, but offshore balancing would do a better
job than liberal hegemony]{.underline}. After all, [that strategy failed
to stop India and Pakistan]{.underline} from ramping up their nuclear
capabilities[, North Korea]{.underline} from becoming the newest member
of the nuclear club, [and Iran]{.underline} from making major progress
with its nuclear program. [Countries usually seek the bomb because they
**fear being attacked**, and U.S. efforts at regime change **only
heighten such concerns**]{.underline}. [By eschewing regime change and
reducing the United States\' military footprint, offshore balancing
would give potential proliferators **less reason to go
nuclear**]{.underline}. Moreover, [military action cannot prevent a
determined country from eventually obtaining nuclear weapons; it can
only buy time]{.underline}. The recent deal with Iran serves as a
reminder that coordinated **[multilateral pressure]{.underline}** and
tough economic sanctions are [a **better way** to discourage
proliferation than preventive war or regime change.]{.underline}

#### Prolif causes extinction. 

**Kroenig '16** (Matthew; June 2016; Associate Professor in the
Department of Government and School of Foreign Service at Georgetown
University, Senior Fellow in the Brent Scowcroft Center on International
Security at The Atlantic Council; National Bureau of Asian Research, No.
58 "Approaching Critical Mass: Asia\'s Multipolar Nuclear Future,")

[The most important reason to be concerned about nuclear weapons in
Asia]{.underline}, of course, [is the threat that nuclear weapons might
be used]{.underline}. To be sure, [the use of nuclear weapons remains
remote, but **the probability is not zero** and the consequences could
be **catastrophic**]{.underline}. The subject, therefore, deserves
careful scrutiny. [Nuclear use would overturn a **70-year tradition of
nonuse**, could result in **large-scale death** and **destruction**, and
might **set a precedent** that shapes how nuclear weapons are viewed,
proliferated, and postured decades hence. The dangers of escalation may
be **magnified** in a **multipolar nuclear order** in which small
skirmishes present the potential to **quickly draw in multiple powers**,
each with a finger on the nuclear trigger]{.underline}. The following
discussion will explore the logic of crisis escalation and strategic
stability in a multipolar nuclear order.14 First and foremost, [the
existence of multipolar nuclear powers means that crises may **pit
multiple nuclear-armed states against one another**]{.underline}. This
may be the result of formal planning if a state's strategy calls for
fighting multiple nuclear-armed adversaries simultaneously. [A state may
choose such]{.underline} a strategy [if it believes that a war with one
of these states would]{.underline} inevitably [mean war with both.
Alternatively]{.underline}, in [a]{.underline} war between
[state]{.underline} A and state B, state A [may]{.underline} decide to
[conduct a preventive strike]{.underline} on state C for fear that it
would otherwise seek to exploit the aftermath of the war between states
A and B. Given U.S. nuclear strategy in the early Cold War, for example,
it is likely that a nuclear war between the United States and the Soviet
Union would have also resulted in U.S. nuclear attacks against China,
even if China had not been a direct participant in the precipitating
dispute. In addition, [conflicts of interest between nuclear powers may
**inadvertently impinge** on the interests of other nuclear-armed
states, **drawing them into conflict**. There is]{.underline} always a
danger [that one nuclear power could take action against a nuclear rival
and that this action would **unintentionally cross a red line** for a
third nuclear power, triggering a tripartite nuclear
crisis]{.underline}. Linton Brooks and Mira Rapp-Hooper have dubbed this
category of phenomena the "security trilemma."15 For example, if the
United States were to engage in a show of force in an effort to signal
resolve to Russia, such as the flushing of nuclear submarines, this
action could inadvertently trigger a crisis for China. [There is also
the issue of **"catalytic" war**]{.underline}. This may be the first
mechanism by which Cold War strategists feared that multiple nuclear
players could increase the motivations for a nuclear exchange. They
worried that [a third nuclear power]{.underline}, such as China, [might
conduct a nuclear strike on one of the superpowers, leading the wounded
superpower to conclude wrongly that the other]{.underline} superpower
[was responsible and thereby retaliate against an innocent state
presumed to be the aggressor]{.underline}. This outcome was seen as
potentially attractive to the third state as a way of destroying the
superpowers and promoting itself within the global power hierarchy.
Fortunately, this scenario never came to pass during the Cold War. With
modern intelligence, reconnaissance, and early warning capabilities
among the major powers, it is more difficult to imagine such a scenario
today, although [this risk is **still conceivable** among less
technologically developed states]{.underline}. In addition to acting
directly against one another, [nuclear powers could be **drawn into
smaller conflicts** between their allies and **brought face to face in
peak crises**]{.underline}. International relations [theorists discuss
the concept of **"chain ganging"** within alliance relationships, the
dangers of which are **more severe** when the possibility of nuclear
escalation is present]{.underline}.16 Although this was a potential
problem even in a bipolar nuclear order, [the more nuclear weapons
states present, the **greater the likelihood** of multiple nuclear
powers entering a crisis. A similar logic suggests that the more fingers
on the nuclear trigger, the **more likely it is** that nuclear weapons
**will be used**. Multipolar nuclear crises are **not without historical
precedent**]{.underline}.17 Several Cold War crises featured the Soviet
Union against the United States and its European nuclear-armed allies,
Britain and later France. The 1973 Arab-Israeli War involved the United
States, the Soviet Union, and a nuclear-armed Israel. The United States
has been an interested party in regional nuclear disputes, including the
Sino-Soviet border war of 1969 and several crises in the past two
decades on the Indian subcontinent. Indeed, [many of these crises stand
out as among **the most dangerous of the nuclear era**.]{.underline}

#### Heg causes [nuclear miscalc]{.underline} with Russia.

**Zuckerman '16** (June 7, 2016, at 4:21 p.m., Mortimer Zuckerman is the
chairman and editor-in-chief of U.S. News & World Report and the
publisher of the New York Daily News, Cites William Perry -- former sec
of Defense under Clinton,
https://www.usnews.com/opinion/articles/2016-06-07/four-paths-to-nuclear-disaster)//AP

The third current nuclear threat, [the danger of nuclear war **through
miscalculation**]{.underline}, most seriously [with the Russians,
is]{.underline}, Perry warns, complex but [quite credible]{.underline}.
The story begins [at the end of the Cold War]{.underline} when
[prospects seemed promising for a]{.underline} crucial [cooperative
atmosphere with the Russians]{.underline}, perhaps eventually a
pan-European security system. Indeed, because of the considerable
diplomatic effort led by Perry, the Russians had joined their military
forces with NATO\'s operating in Bosnia, a remarkable and hopeful
development. [But the present]{.underline} situation [is marked by
Russia\'s]{.underline} continuing [**aggressive statements**
about]{.underline} their [ongoing dependence on nuclear
weapons]{.underline}, their robust program to modernize those forces
(which seems to mirror U.S. modernization programs) [and]{.underline}
their [aggression in Ukraine and elsewhere in their
neighborhood]{.underline}. It has been an especially bitter development
for Perry, for it started after the Cold War ended. So what happened?
[After the Cold War]{.underline} ended, and under Perry\'s leadership,
[the Partnership for Peace was formed as an interim]{.underline}
organization [which]{.underline} Eastern European nations, including
[Russia, could join as a step to]{.underline} eventual [NATO
membership]{.underline}, the key idea being that the transition would be
gradual. Understandably, there was little patience among the outside
nations in waiting to join. Perry emphasized that [traditional
Russian]{.underline} sensibilities and [concerns]{.underline} about its
[regional security mandated a carefully **staged**]{.underline}, gradual
[**expansion** of the security organization.]{.underline} He was opposed
by Richard Holbrooke, then an assistant secretary in the State
Department, who argued to promptly move to the Eastern European
\"partnership\" members into NATO. After all, what could the Russians
do? Perry asked Clinton to hold a decisive National Security Council
meeting where he could make the case for delay. There Vice President Al
Gore argued for immediate inclusion and Perry lost the day. Clinton
agreed to membership at once for Poland, Hungary and the Czech Republic,
delaying for a while the membership of the Baltic States. Perry nearly
resigned, but decided not to do so in the hopes he could help mitigate
the increasing lack of trust by the Russians who claimed NATO had no
concern for their priorities. But it was not possible; [NATO expansion
turned out to be the]{.underline} first [slip down a]{.underline} slick
[slope leading to]{.underline} the [hostile relations]{.underline} we
have [today]{.underline}. [Russia today]{.underline} genuinely [feels
threatened]{.underline} and concerned [regarding]{.underline} what it
believes is [**U.S. pursuit of military superiority** and]{.underline}
political and [**economic hegemony.** It views our actions as
inconsistent with]{.underline} traditional notions of [strategic
stability]{.underline}. Thus [Russia]{.underline} presently [is an
unlikely partner in]{.underline} the process of [nuclear
disarmament]{.underline}. Perry makes the case that it is in U.S. and
Russian interest to change our present momentum toward a new Cold War
and he emphasizes that this process requires listening carefully to the
concerns of others. [Failing that, the]{.underline} germinating [threat
is evident]{.underline} today: Look, for example, to Russia\'s action in
the Ukraine and the Baltics, where President Vladimir
[Putin]{.underline} has [pursued an **aggressive policy** based on
the]{.underline} stated [belief that his country bears a
**responsibility to protect**]{.underline} ethnic Russians in [those
countries. This policy has]{.underline} already [led to warfare
in]{.underline} the [Ukraine]{.underline}; if it were applied to any of
the Baltic nations, all of which have a substantial number of ethnic
Russians, it could lead to a military conflict between Russian and NATO
troops. Clearly [the greatest danger is]{.underline} an [escalation to
the **use of nuclear weapons**]{.underline}, either [by]{.underline}
foolish design or [miscalculation]{.underline}. The [expressions by the
Russian government of]{.underline} its [dependence on nuclear weapons
make this danger]{.underline} all the [more pressing]{.underline}.
[Neither]{.underline} the [Russian nor NATO leadership]{.underline}
would [want this]{.underline} outcome of course; [but]{.underline} the
[escalation could occur **beyond their control**, especially
with]{.underline} the [Russian emphasis on \"**tactical\" nuclear
weapons**]{.underline} whose management might be [in the hands
of]{.underline} battlefield [military commanders]{.underline}, as it was
during the Cuban Missile Crisis.

### ! D -- 2NC

#### **Their ev fearmongers**

**Valeriano and Maness 15** -- co-authors of Cyber War versus Cyber
Realities, AND \*Senior Lecturer in Social and Political Sciences at the
University of Glasgow, AND \*\*Visiting Fellow of Security and
Resilience Studies at Northeastern University (Brandon and Ryan C., The
Coming Cyberpeace: The Normative Argument Against Cyberwarfare, Foreign
Affairs,
https://www.foreignaffairs.com/articles/2015-05-13/coming-cyberpeace)

The era of cyberconflict is upon us; at least, experts seem to accept
that cyberattacks are the new normal. In fact, however, [evidence
suggests that cyberconflict is not as prevalent as many
believe.]{.underline} Likewise, [the severity of individual cyber events
is not increasing, even if the frequency of overall attacks has
risen.]{.underline} And [an **emerging norm against the use of severe
state-based cybertactics** contradicts fear-mongering news reports about
a coming cyberapocalypse]{.underline}. The few [isolated incidents of
successful state-based cyberattacks do **not a trend**
make]{.underline}. Rather, what we are seeing is cyberespionage and
probes, not cyberwarfare. Meanwhile, [the international consensus has
stabilized around a number of limited acceptable uses of
cybertechnology---one that prohibits any dangerous use of
force.]{.underline} [**Despite fears of a boom in cyberwarfare**, there
have been **no major or dangerous hacks** between
countries.]{.underline} The closest any states have come to such events
occurred when Russia attacked Georgian news outlets and websites in
2008; when Russian forces shut down banking, government, and news
websites in Estonia in 2007; when Iran attacked the Saudi Arabian oil
firm Saudi Aramco with the Shamoon virus in 2012; and when the United
States attempted to sabotage Iran's nuclear power systems from 2007 to
2011 through the Stuxnet worm. [The attack on **Sony from North Korea**
is just the latest overhyped cyberattack to date, as the corporate giant
has recovered its lost revenues from the attack and its networks are
arguably more resilient as a result.]{.underline} [Even these are more
probes into vulnerabilities than full attacks]{.underline}. Russia's
aggressions show that [**Moscow** is willing to use cyberwarfare for
disruption and propaganda, but not to inflict injuries or lasting
infrastructural damage.]{.underline} The Shamoon incident allowed
**[Iran]{.underline}** to punish Saudi Arabia for its alliance with the
United States as Tehran faced increased sanctions; the [attack destroyed
files on Saudi Aramco's computer network but **failed to do any lasting
damage**.]{.underline} The **[Stuxnet]{.underline}** incident also
[failed to create any lasting damage]{.underline}, as Tehran put more
centrifuges online to compensate for virus-based losses and strengthened
holes in their system. Further, [these supposedly successful cases of
cyberattacks are balanced by **many more examples of unsuccessful
ones**. If the future of cyberconflict looks like today, the
international community must **reassess the severity of the
threat.**]{.underline} [Cyberattacks have demonstrated themselves to be
**more smoke than fire**.]{.underline} This is not to suggest that
incidents are on the decline, however. Distributed denial-of-service
attacks and infiltrations increase by the minute---every major
organization is probed constantly, but only for weaknesses or new
infiltration methods for potential use in the future. [Probes and pokes
do not destabilize states or change trends within international
politics. Even common cyber actions have little effect on levels of
cooperation and conflict between states.]{.underline}

#### Actors [self-deter]{.underline} \-\-- cyber is unique because defenders have the [absolute defense]{.underline} of [disconnecting]{.underline}. If attacks get strong enough, the internet itself becomes a bad deal for the defender, which also screws the attacker by denying lower-level cyber coercion and espionage

Jon **Lindsay and** Erik **Gartzke 14**, Jon R. Lindsay is an assistant
research scientist at the University of California Institute on Global
Conflict and Cooperation and an assistant adjunct professor at the
University of California, San Diego School of International Relations
and Pacific Studies, AND Erik Gartzke is Professor and Director of cPASS
at the Department of Political Science @ UCSD, Lindsay, Jon R., and Erik
Gartzke. "Coercion through Cyberspace: The Stability-Instability Paradox
Revisited." The Power to Hurt: Coercion in the Modern World, Oct. 2014.

Perhaps [the simplest form of cross domain response to cyber threats is
to **forgo the use of the cyber domain altogether**]{.underline}. [While
it is hard if not impossible to limit exposure to nuclear
weapons]{.underline} and even a determined conventional assault, **[the
risk of cyber attack can be completely eliminated by disconnection from
digital networks]{.underline}**. [The internet is an artificial
environment and connection to it is voluntary.]{.underline} Individuals,
organizations, and states retain the ability to unplug completely, limit
their online transactions, or erect various barriers to connection.
[Obviously disconnection is not very feasible]{.underline} commercially,
socially, and militarily today, [but this is more of an indicator of
**how positive the benefits of interconnection are**]{.underline}
compared to the perceived risks. [If the **risks were perceived as
extreme**]{.underline}, then firms and [states could **go
back**]{.underline} to making a living as they did before 1991 (when WWW
went public). [This is a **cross-domain threat**]{.underline} [because
it entails **exiting the cyber domain**]{.underline} altogether [to
leverage]{.underline} more traditional economic and **[military
transactions]{.underline}**. The threat of disconnection follows from
the more general logic of international organizations, where contracts
must be self-enforcing.44 [On the internet as in institutions, ties
among egoistic actors under anarchy must be mutually beneficial. **If
the internet is a bad deal for actors, they can throw up boundaries or
exit**]{.underline} cyberspace altogether. [If repeated exposure to
adversarial exploitation causes states to lose more than they gain from
being online, then they can **undermine the attacker's very means for
accessing the victim**]{.underline}. The threat of voluntary
disconnection is especially relevant for repeated interactions, or
repeated exploitation, rather than a one-shot "bolt from the blue" cyber
attack (which is better countered with cross-domain retaliation). The
threat of disconnection is implicit in the voluntary nature of
connection to the internet, and [the potential loss of the ability to
make future attacks **exercises a deterrent effect on attacks in the
present**]{.underline}. [An aggressor who does not want to lose the
cyber]{.underline} adjuncts for [espionage and disruption it has
invested so much in developing will **show restraint**]{.underline} in
their employment. This does not mean that [coercion]{.underline} cannot
take place online, but it [is]{.underline} **[bounded by excess
value]{.underline}**. One implication is that the countries that can be
most coerced on the internet will be those that have the most to lose by
leaving it.

#### There are [diminishing returns]{.underline} on cyber escalation because stronger attacks are more likely to provoke [disconnection]{.underline}. 

Jon **Lindsay and** Erik **Gartzke 14**, Jon R. Lindsay is an assistant
research scientist at the University of California Institute on Global
Conflict and Cooperation and an assistant adjunct professor at the
University of California, San Diego School of International Relations
and Pacific Studies, AND Erik Gartzke is Professor and Director of cPASS
at the Department of Political Science @ UCSD, Lindsay, Jon R., and Erik
Gartzke. "Coercion through Cyberspace: The Stability-Instability Paradox
Revisited." The Power to Hurt: Coercion in the Modern World, Oct. 2014.

[The combination of cross domain deterrence and voluntary connection to
the internet gives rise to a variant of the classic
stability-instability paradox]{.underline}. In Glenn Snyder's original
articulation of the paradox, mutually assured destruction could deter
nuclear war. However, [MAD was not credible for, and might even
encourage, limited conventional war]{.underline}.56 Or as Robert Jervis
puts it, "To the extent that the military balance is stable at the level
of all-out nuclear war, it will become less stable at lower levels of
violence."57 [Cyber capacity is a poor substitute for nuclear weapons,
myths of paralysis notwithstanding, yet there is a similar logic
constraining the distributions of harms which are possible via
information technology]{.underline}. To extend this logic to the cyber
domain, there are a variety of [deterrent mechanisms]{.underline}
contain the most disruptive types of cyber attacks yet fail to contain,
and even [enable, a wide variety of online espionage, subversion,
symbolic protest, and criminal predation. In cyberspace we observe a
rather **stable damage contest**]{.underline} (i.e., no "paralysis" and
limited "disruption") [but a **very unstable
intelligence**]{.underline}-counterintelligence
**[contest]{.underline}** (lots of "espionage" and "fraud" vying with
efforts at "control" and "mobilization"). [Thus the actors that have the
ability to carry out highly destructive cyber attacks (mainly state
actors for now) **lack the motivation to attack;**]{.underline} [by
contrast, these same actors as well as many different actors have both
the ability and motivation to inflict **irritant aggression with little
fear of suffering consequences**]{.underline} By and large, cyber
options fill out the lower end of the conflict spectrum where deterrence
is not as credible or reliable. The very few cases of physically
disruptive cyber attack we do observe---mainly powerful states
conducting covert action or battlefield support operations against
militarily weaker opponents---have notably involved stronger actors who
not only have the capacity to plan and conduct a sophisticated attack
but also have the ability to deter retaliation against their use of
cyber attack. [This cyber variant of the stability-instability paradox
has a slightly different logic, however. In the nuclear realm, **actors
cannot disconnect from the threatened harm**]{.underline}, and this is
what makes the threatened destruction both mutual and assured. When
there are many missiles with many warheads, the chance of intercepting
them on the ground through a disarming counterforce strike or in the air
through ballistic missile defense with any confidence becomes
vanishingly small. **[Not so in cyberspace]{.underline}**, where
connection to the internet or acceptance of connections through it is
voluntary. **[There is "no forced entry in cyberspace"]{.underline}** in
Libicki's phrase, and so [the hundredth cyber attack against a closed
vulnerability is **as ineffective as the first**]{.underline}.
[Attackers thus rely on **deception**]{.underline} to exploit
vulnerabilities and ensure that they stay open. [However, offensive
deception can **fail in the "fog of cyberwar"** and defenders can be
deceptive as well, both of which are more likely against high-reward
targets]{.underline} (where cross domain deterrence also more credible).
[The need to **preserve internet connections**]{.underline} [to
facilitate ongoing and future deception as well as the need to preserve
stealth to avoid the consequences of getting caught imposes **discipline
on attackers**.]{.underline} Actors cannot enjoy the substantial
benefits of interconnection without accepting some risk of exploitation
(hacking to spy) and attack (hacking to disrupt). Thus the successful
"lockout" of the internet, with advantage accruing exclusively to one
political group or another, is not realistic. Moreover, because these
harms share similar techniques, the observed abundance 39 of the former
represents a latent potential for the later. [The latent escalatory
potential of even minor irritants leads to rampant fears of unrestrained
catastrophe, to be sure]{.underline}. Yet this latent potential is
difficult to harness for targeted coercion because the threat is
self-effacing. Declared cyber threats that highlight the vulnerability
to be exploited are readily mitigated. Instead, [the ineradicable threat
of cyber catastrophe]{.underline} (ineradicable as long as the internet
continues to be useful) [creates a general if diffuse deterrent effect
among all parties who value their connection to the
internet]{.underline}. **[No one who wants to make money on the internet
really wants to have a cyberwar, and this includes states as well as
criminals.]{.underline}** Which types of actors are most able to benefit
through internet coercion and which are most vulnerable to coercion?
Large powers like the U.S. are highly dependent on the internet but also
highly skilled at inflicting harm, both through cyber and traditional
military force. Poor powers across the digital divide may have little
vulnerability at all, while medium powers may have vulnerability but
lack a range of forces to deter attacks. This might imply a "curvature"
to the utility of cyber coercion. Big-capable countries are vulnerable
to cyber harm but can deter through other military instruments. Poor
states are not vulnerable. It may be the prosperous small or digitally
developing who are in trouble, since they cannot credibly deter and have
high dependence on the internet. The information revolution is often
thought to be a boon to non-state actors, and indeed it is, but mainly
in the irritant class of cyber operations. Moreover, the increasing
ubiquity and sophistication of information technologies can be expected
to have something of a democratizing effect on intelligence and
counterintelligence techniques whereby firms and citizens will have
access to and be concerned about the types of things that were
historically the purview of obscure state intelligence agencies.
However, it would be a mistake to use the increasing ferment of
low-intensity information contests to infer the shape of higher 40
intensity activity. On the contrary, the traditional logic of war will
continue to dominate the expression of cyber aggression. [Because
threatened internet harms **depend on voluntary connections in the first
place**]{.underline}, [and as many actors have alternative means to
**inflict (cross domain) harm in retaliation**]{.underline}, [the
coercive utility of cyberspace is actually **somewhat
limited**.]{.underline} At the same time an ever increasing variety
irritants and more temperamental adjuncts becomes available for global
political interaction. The "net" result is that [opponents have strong
incentives to impose costs via the internet but also to keep those costs
low enough to preserve interconnection and avoid retaliation. Therefore,
**contests in damage will remain relatively stable**]{.underline} while
contests in intelligence will be increasingly unstable. The human-built
world is becoming more complex, to be sure, but it is not necessarily
more dangerous. **[As long as it is desirable to connect to the internet
tomorrow, there will be only limited harm via the internet
today.]{.underline}**

## Cooperation Advantage

### EU Turn -- 1NC

#### Plan prevents cooperation with EU\-\--proliferates new agencies and makes coordination impossible

Simona R. **Soare 21**, was a Senior Associate Analyst at EUISS from
2019 to end May 2021. Her research focused on United States security
policy, transatlantic security and EU-NATO relations. Prior to joining
EUISS, Simona served as advisor to the Vice-President of the European
Parliament (2015-2019) and as an analyst with the Romanian Ministry of
Defence, working on transatlantic and European security. She has also
been a research associate with the Institut d'Études Européennes (IEE)
at Université Saint Louis-Bruxelles. Simona holds a PhD in Political
Science from the National School for Political and Administrative
Studies in Bucharest where she lectured on international security
(2008-2015). She is the recipient of a U.S. Department of State
fellowship on U.S. Grand Strategy and has published extensively on
American and transatlantic security. \"Innovation as Adaptation: NATO
and Emerging Technologies\" June 11.
<https://www.gmfus.org/news/innovation-adaptation-nato-and-emerging-technologies>
//pipk

Broadening and Regularizing NATO-EU Cooperation

[The Biden administration also provides a window of opportunity to
progress and be ambitious in broadening and regularizing NATO-EU
cooperation in the field of innovation and EDTs.]{.underline} While
political dialogue among their leadership has been steadily increasing
over the past five years, the EU and NATO have consulted on their
respective EDTs agendas only twice. Furthermore, [bureaucratic
procedures and misalignments sometimes frustrate even staff-to-staff
cooperation in this area.]{.underline} The EU and increasingly **[NATO
are proliferating agencies that conduct work on innovation in EDTs,
including in security and defense. This makes it challenging to achieve
internal coherence of activities within one organization, let alone
coordinating agendas between the two]{.underline}**.

As the allies meet with the EU High Representative for Foreign Affairs
and Security Policy Josep Borrell at this month's NATO summit, [the two
organizations need a more ambition agenda for cooperation]{.underline}.
In particular, [the EU and NATO need to consider a joint task force on
fostering defense innovation and EDTs]{.underline}, with renewable
two-year mandates. [This instrument would provide political impetus for
closer cooperation on EDTs, it would give coherence, regularity, and
structure to the efforts of the two sides, and ensure commonality of
purpose and synergy of output.]{.underline} In addition, allies could
consider meeting regularly in EU-NATO digital summit formats. The EU
could take the lead in this regard given its considerable financial
capacity for investing in EDTs and its regulatory powers. EU-NATO
digital summits would allow the transatlantic partners to regularly
review progress, provide strategic guidance on legal, ethical and
adoption challenges related to innovation and EDTs, and enhance their
tech diplomacy by inviting like-minded global partners to attend.

### AI Governance Bad -- 1NC

#### Regulation [destroys]{.underline} AI control by driving it [underground]{.underline}, [abroad]{.underline}, or into [higher-risk]{.underline} areas

Dr. Nell **Watson 21**, PhD in Engineering from the University of
Gloucestershire, Degree in AGI Safety Fundamentals from the University
of Cambridge, Senior Scientific Advisor to The Future Society at Harvard
University, Fellow at the British Computing Society and Royal
Statistical Society, "Regulatory Challenges to Catastrophic AI Risk",
ExO Insight, 11/24/2021,
https://insight.openexo.com/regulatory-challenges-to-ai/

Rick Increase Factors:

Obfuscation: [**Reg**ulation**s** may **drive research underground**
where it is **harder to monitor**, or to **'flag of convenience'
jurisdictions** with **lax restrictions**, by **embedding** dangerous
**tech**nologies with**in** apparently benign **cover operations**
(multipurpose technologies), or by **obfuscating** the **externalized
effects** of a system, such as in the **vehicle emissions**
scandal]{.underline} (Wikipedia).

Arms race: Recent advances in machine learning such as multimodal
abstractions models (aka Transformers, Large Language Models, Foundation
Models) such as GPT-3 and DALL-E illustrate that dumping computing
resources (and the funds for them) in colossal models seems to be a
worthy investment. So far, there is no apparent limit or diminishing
return on model size, and so now state and non-state actors are
scrambling to produce the largest models feasible in order to access
thousands of new capabilities never before possible. An arms race is
afoot. Such [arms races can lead to **rapid** and **unexpected**
take-off in terms of AI capability, and the rush can blindside people to
risks, especially when]{.underline} the [loss]{.underline} of a race
[can mean an **existential threat**]{.underline} to a nation or
organization.

Perverse incentives: Incentives can be powerful forces within
organizations, and financialization, moral panic, or fear of political
danger may cause irrational or incorrigible behavior of personnel within
organizations.

Postmodern Warfare: Inexpensive Drones and other AI-enabled technologies
have tremendous disruptive promise within the realm of warfare,
especially given their asynchronous nature. Control of drone swarms must
be performed using AI technologies, and this may encourage the entire
theatre of war to be increasingly delegating to AI, perhaps including
the interpretation of rules of engagement and grand strategy. (Lsusr,
2021)

Cyber Warfare: Hacking of systems is increasingly being augmented with
machine intelligence (Cisomag, 2021), through GAN-enabled password
crackers (Griffin, 2019) and advanced social engineering tools (Newman,
2021). This is equally the case in the realm of defense, where only
machine intelligence may provide the swift execution required to defend
systems from attack. A lack of international cyberwar regulations, and
poor international policing of organized cybercrimes, may increase the
risk of catastrophic risks to societal systems.

Zersetzung: The human mind is becoming a new theatre of war, through
personalized generative propaganda, which may even extend to gaslighting
attacks on targeted individuals, significantly leading to
destabilization of societies (Williams, 2021). Such technologies are
also plausibly deniable, being difficult to prove who may be
responsible.

[Inflexibility: The German Military after WW1 was **not** allowed to
develop their **artillery** materiel, and so developed powerful
**rocket** **tech**nologies **instead**, as these were **not subject to
regulation**. Similarly, inflexible rules may permit **exploitable
loopholes**. They may also **not be sufficiently adaptive** to allow for
the **implementation** of **new technologies** and even improved
**industry standards**.]{.underline}

Limitation of problem spaces: -- [It may be taboo to allow machine
intelligence to work on sensitive issues or to be exposed to
controversial (if potentially accurate) datasets. This may limit the
ability of AI to make sense of out complex issues, and thereby
**frustrate finding** **solutions** for **crises**]{.underline}.

#### That [causes]{.underline} catastrophic AI since it'll be controlled by [rogues]{.underline} with [no precautions]{.underline} AND without [defensive countermeasures]{.underline}

Robert A. **Freitas 22** Jr., JD from the University of Santa Clara
(Santa Clara, CA), School of Law, Research Fellow at the Institute for
Molecular Manufacturing, Won the 2009 Feynman Prize in Nanotechnology
for Theory, BS in Physics and Psychology from Harvey Mudd College,
"Molecular Manufacturing: Too Dangerous to Allow?", Nanotechnology
Perceptions, Volume 2, Number 1, Republished at The Lifeboat Foundation,
https://lifeboat.com/ex/molecular.manufacturing

[Attempts to block or "relinquish"]{.underline} \[3, 12\] molecular
manufacturing [research will make the world a **more, not less,
dangerous** place]{.underline} \[13\]. [This paradoxical conclusion is
founded on two premises. First, **attempts** to block the research will
**fail**. Second, such attempts will **preferentially** block or slow
the development of **defensive** measures by **responsible**
groups]{.underline}. One of the clear conclusions reached by Freitas
\[4\] was that **[effective countermeasures]{.underline}** against
self-replicating systems [should be **feasible**, but will require
**significant effort** to **develop** and **deploy**]{.underline}.
(Nanotechnology critic Bill Joy, responding to this author, complained
in late 2000 that any nanoshield defense to protect against global
ecophagy "appears to be so outlandishly dangerous that I can't imagine
we would attempt to deploy it." \[12\]) But [**blocking** the
**development** of defensive systems would simply **insure** that
**offensive** systems, once deployed, would **achieve** their intended
objective in the absence of effective countermeasures]{.underline}.
James Hughes \[13\] concurs: ["The **only** safe and feasible approach
to the dangers of **emerging tech**nology is to **build** the social and
scientific **infrastructure** to]{.underline} monitor, regulate and
[**respond** to their threats."]{.underline}

We can reasonably conclude that blocking the development of defensive
systems would be an extraordinarily bad idea. Actively encouraging rapid
development of defensive systems by responsible groups while
simultaneously slowing or hindering development and deployment by less
responsible groups ("nations of concern") would seem to be a more
attractive strategy, and is supported by the Foresight Guidelines
\[10\]. As even nanotechnology critic Bill Joy \[14\] finally admitted
in late 2003: "These technologies won't stop themselves, so we need to
do whatever we can to give the good guys a head start."

While [a 100% effective ban]{.underline} against development might
theoretically be effective at avoiding the potential adverse
consequences, blocking all groups for all time [does **not**
appear]{.underline} to be a **[feasible]{.underline}** goal. The attempt
would strip us of defenses against attack, increasing rather than
decreasing the risks. In addition, [blocking development would insure
that the substantial economic, environmental, and medical
**benefits**]{.underline} \[15\] [of this new technology would not be
available]{.underline}.

Observes Glenn Reynolds \[16\]:

> [To the extent that such efforts \[to ban all development\] succeed,
> the **cure** may be **worse than the disease**. In 1875, Great
> Britain,]{.underline} then the world's sole superpower,
> [was]{.underline} sufficiently [concerned about]{.underline} the
> [dangers of]{.underline} the new technology of [high
> explosives]{.underline} that [it]{.underline} passed an act
> **[bar]{.underline}**ring [all private experimentation in
> explosives]{.underline} and [rocketry. The result was]{.underline}
> that [**German missiles** bombarded London rather than the other way
> around. Similarly, efforts to control **nano**tech]{.underline}nology,
> **[biotech]{.underline}**nology [or **a**]{.underline}rtificial
> **[i]{.underline}**ntelligence [are **more likely** to **drive
> research underground** (often under **covert** government
> sponsorship]{.underline}, regardless of international agreement) [than
> they are to **prevent** research entirely. The research would be
> conducted by **unaccountable** scientists, often in **rogue regimes**,
> and often under **inadequate safety precautions**. Meanwhile,
> **legit**imate research that might cure disease or solve important
> environmental problems would **suffer**]{.underline}.

#### AI regulation [overshoots]{.underline}, destroying [productive]{.underline} applications necessary to prevent [existential catastrophes]{.underline}

Gönenç **Gürkaynak 18**, Founding Partner of ELIG Gürkaynak
Attorneys-at-Law, LL.M. from Harvard Law School, İlay Yılmaz, Partner at
ELIG Gürkaynak Attorneys-at-Law, and Güneş Haksever, LLM from Istanbul
Bilgi University, Attorney at IBM Turkey, "Stifling Artificial
Intelligence: Human Perils", Computer Law & Security Review, Volume 32,
Issue 5, 12/12/2018,
https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3285264

[Although scientists]{.underline} have [calculated the **significant
positive welfare effects** of]{.underline} Artificial Intelligence
[(AI), **fear mongering** continues to **hinder** AI **development**. If
**regulations** in this sector **stifle** our active imagination, we
risk **wasting** the **true potential** of AIs dynamic
efficiencies]{.underline}. Not only would Schumpeter dislike us for
spoiling creative destruction, but the AI thinkers of the future would
also rightfully see our efforts as [the **'dark age'** of human
advancement]{.underline}. This article provides a brief philosophical
introduction to artificial intelligence; categorizes artificial
intelligence to shed light on what we have and know now and what we
might expect from the prospective developments; reflects thoughts of
worldwide famous thinkers to broaden our horizons; provides information
on the attempts to regulate artificial intelligence from a legal
perspective; and discusses how the legal approach needs to be to ensure
the balance between artificial intelligence development and human
control over them, and to ensure friendly artificial intelligence.

Our technology, our machines, is part of our humanity. We created them
to extend ourselves, and that is what is unique about human beings. --
Ray Kurzweil1

1\. Introduction

The Chinese cardboard game "Go" is one of the most complex strategy
games humankind invented. Go was considered so important, there are
myths indicating that ancient kings played Go between their armies in
the battlefield to resolve the conflict in peace. Computers prevailed
against humanities best in many zero-sum, perfect-information, partisan,
deterministic strategy games2 before, with the exception of Go, which
was something to be proud of.

The strategy aspect of Go is very complex and emphasizes the importance
of balance on multiple levels and has internal tensions. A game of Go
cannot be won by using brute force: calculating every possible move,
similar to what IBM®'s then state of the art AI, Deep Blue® used to win
over Gary Kasparov. To manoeuvre through the countless possible moves on
the Go board and chose the most efficient path, one requires
capabilities beyond the conventional computing powers; capabilities only
our minds have (or so we thought), such as extremely accurate image and
pattern recognition and insight, all of which we thought granted us
superiority over the artificial minds we created.

In October 2015, a software called "AlphaGo®" became the first computer
to beat a professional human Go player in an un-handicapped game of Go
(Silver and Hassabis, 2016). AlphaGo's victory is probably one of the
most significant demonstrations of the capabilities of an AI. Firstly,
it shows that AIs are beginning to surpass us at things where success is
dependent on strategy as well as calculation. Things we classify as a
"game", from stock exchange to conflicts, from contract negotiations to
hostage situations. Second, AlphaGo developed strategies on its own,
through playing millions of games against itself. These feats sent the
chills down the spines of those who fear that AIs will overpower us in
the future.

We humans accelerate the future with our minds. This is a strength and a
weakness. [Often]{.underline}, our [**predictions** of the future are
**highly inaccurate**. Based on predictions from a book called 'The
World in 2010', published in 19**76**, we should have **be**en living
**above** and **below** the surfaces of **three planets** as of **five
years ago**. Predictions regarding the future of **AI** are **equally
likely** to be **off base**]{.underline}.

[To avoid **premature** regulation over AI, we should]{.underline} be
studying and **[search]{.underline}**ing [for the **meaningful point in
time** when a broader anxiety about AI becomes a genuine
concern]{.underline}. The study of a point of ripeness, a 'threshold
ability test,' asks when AI could really bring about concrete
disadvantages that might counter-balance the demonstrated contribution
to economic efficiency and welfare.

[In the absence of]{.underline} such [an **objective
benchmark**]{.underline} marking the point in time when AI becomes a
competitor with the human mind, [regulators could easily **jump the
gun** in regulating AI, which would lead to **irreparable harm** in
**total welfare** of human societies]{.underline}.

Most of what we consider AI today is really our own intelligence
re-formatted and re-cycled, with the help of computers lacking any skill
of learning or consciousness of being. [Regulation at this stage would
be **perverse**. The economic efficiency **potential**s of AI should be
set **entirely free** at **this point** in time, allowing us to
**active**ly and **aggressivel**y research appropriate goals for them
which would **not** result in the **extinction** of
humankind]{.underline}.

[If you think]{.underline} our [future **robot overlords**
will]{.underline} one day [thank us for ignoring]{.underline} the risks
[and **under regulating**, **think again**]{.underline}. On the one
hand, [**any issues** we may face from **AI**s will likely result from
humanity **failure** to **effectively direct** AIs to our **needs**,
**not** because we switched to a defensive AI regulation regime **too
early**]{.underline}. On the other hand, [at **some point** of
time]{.underline} in the not too distant future, [**natural**,
**human-related** or **external** factors may **threaten** the **fate of
the Earth**, and we may **need AI to save the planet and us**. One
**hope**s that society has not **pulled the hand brakes** on the wheels
of AI **too early**]{.underline}, fearing our own active imagination.

#### AI controls are [inevitable]{.underline}, but will be [gradual]{.underline} and [incrementally]{.underline} ratchet up over time\-\--they'll [start]{.underline} with [liability]{.underline} and [transparency]{.underline}, then move into [specific applications]{.underline}, solving [downside]{.underline} risk [without]{.underline} imposing [premature]{.underline} and [ineffective]{.underline} regulation 

Chris **Reed 18**, Professor of Electronic Commerce Law at Queen Mary,
University of London, LLM from the University of London, "How Should We
Regulate Artificial Intelligence?", Philosophical Transactions of the
Royal Society B, Volume 376, Issue 2128, 9/13/2018,
https://royalsocietypublishing.org/doi/10.1098/rsta.2017.0360

Using artificial intelligence [(AI)]{.underline} technology to replace
human decision-making [will inevitably create new risks]{.underline}
whose consequences are unforeseeable. [This **naturally** **lead**s to
calls for **regulation**, but]{.underline} I argue that [it is **too
early** to attempt a general system of AI regulation. Instead, we should
work **incrementally**]{.underline} within the existing legal and
regulatory schemes [which allocate]{.underline} responsibility, and
therefore **[liability]{.underline}**, to persons. Where AI clearly
creates risks which current law and regulation cannot deal with
adequately, then new regulation will be needed. But [in **most cases**,
the **current system** can work **effectively** if the producers of AI
technology can provide sufficient **transparency** in explaining how AI
decisions are made. Transparency **ex post** can]{.underline} often [be
achieved through **retrospective** analysis]{.underline} of the
technology\'s operations, [and will be **sufficient**]{.underline} if
the main goal is to compensate victims of incorrect decisions. [**Ex
ante** transparency is more **challenging**, and can
**limit**]{.underline} the [**use** of]{.underline} some [AI
**tech**]{.underline}nologies [such as **neural networks**]{.underline}.
It should only be demanded by regulation where the AI presents risks to
fundamental rights, or where society needs reassuring that the
technology can safely be used. [Masterly **inactivity** in regulation is
**likely** to achieve a **better** long-term solution than a **rush** to
regulate in **ignorance**]{.underline}.

This article is part of a discussion meeting issue 'The growing ubiquity
of algorithms in society: implications, impacts and innovations\'.

1\. Introduction

[It is hardly surprising that there has been a **sudden interest** in
regulating]{.underline} artificial intelligence [(AI). AI
**tech**]{.underline}nology [has moved from the]{.underline} research
**[lab]{.underline}**oratory [to **be**]{.underline}come [part of our
**daily lives** with **remarkable speed**]{.underline}. We have seen the
first fatal accident involving an autonomous vehicle \[1,2\], AI
applications are analysing images to detect potentially cancerous cells
\[3\] and numerous other implementations are in place or in the
pipeline.

The introduction of AI technologies creates societal risks. Although AI
technologies aim to augment or replace human decision-making, leading to
fewer wrong decisions, there is no doubt that AI will still get it wrong
sometimes. And the ways in which AI gets it wrong are likely to be very
different from the ways in which a human would make mistakes. This feels
dangerous to society. We want to know the kinds of risks we are running,
and purely statistical arguments that AI makes us safer are not
convincing to the wider population.

Good regulation would improve our perception of safety, and also our
perception that humans remain in control. It could also mitigate any new
risks which the use of AI creates. But [bad regulation risks
**stifling** the **development** and **implementation** of useful AI
solutions]{.underline}, perhaps even [**without** improving **safety**
and **control**. Thus, we need to understand what
regulation]{.underline} can and **[cannot do]{.underline}** so that we
can shape it appropriately. [It is]{.underline} also [important that
those who produce and use AI technologies are actually able to
**comply** with regulation, and that regulation does not **stifle
worthwhile advances** in the technology]{.underline}. Outside
specifically regulated sectors, [the general approach of
law]{.underline} and regulation [is that innovation is **freely
permitted**, but]{.underline} that [those responsible must
**bear**]{.underline} the **[consequences]{.underline}** if that
innovation causes certain types of harm. [If]{.underline} our
[**existing** law and regulation can **deal with AI** innovation in
**that way**, **no immediate change is needed**]{.underline}. The
argument, if one exists, for requiring all those who adopt an AI
technology to demonstrate that it achieves a higher standard of
performance and reliability than other innovations has not yet been made
out.

2\. The problem

Fundamentally, [the problem]{.underline} which [regulation
must]{.underline} seek to [solve is]{.underline} that of [controlling
undesirable risks]{.underline}. For any truly useful AI technology,
there is likely to be empirical evidence that it is more cost-effective
and, ideally, more accurate at making decisions than the human-based
solution it replaces. But that [evidence will be based on comparison
with the human-based solution, whose deficiencies are currently
tolerated by society. An AI-based solution will have its own
deficiencies]{.underline}, and these will be less acceptable if they
produce wrong answers where a human would have decided correctly.
Regulation ought therefore to focus on any new risks which the AI
solution presents, recognizing that some of these risks will be as yet
unknown.

[Some]{.underline} commentators [are]{.underline} so [alarmed
by]{.underline} the prospect of **[unknown risks]{.underline}** that
they have proposed the establishment of a general regulator for AI
\[4\]. [But, there are]{.underline} three [**strong arguments** against
introducing **new, generally applicable**]{.underline} legal and
[**regulatory obligations** at **this moment**]{.underline}.

[First, any regulatory body needs a **defined field** of operation, and
a set of **overriding principles** on the **basis** of which it will
**devise** and **apply** regulation. Those principles will be based on
mitigating]{.underline} the [risks]{.underline} to society which the
regulated activity creates. [Until the risks of AI are
**known**]{.underline}, at least to some degree, [this is **not
achievable**. Regulation **cannot** control **unknown** risks, and
devising a regulatory mandate on the basis of **speculative** risks
seems **unlikely** to produce **successful results**]{.underline}.

[Second, lawmakers are **generally unsuccessful** at **prospective**
regulation, **particularly** in **tech**nology fields. The **history**
of legislating **prospectively** for the digital technologies is one of
almost **complete failure**]{.underline} \[5\].

Finally, and most importantly, a [regulatory regime]{.underline} which
aimed [to deal with all uses]{.underline} of AI technology [would be
**impossibly wide** in scope.]{.underline} The range of potential
applications is far too diverse, and it would be foolish to apply the
same regulatory regime to autonomous vehicles as to smart refrigerators
which order groceries based on consumption patterns. Probably, there is
no plausible, let alone compelling, reason to regulate smart
refrigerators at all. [A regulatory project of this kind would **risk**
becoming a project to regulate **all aspects** of human
**life**]{.underline}.

[The **better** strategy is to approach the problem **incrementally**.
Some]{.underline} of the [risks]{.underline} likely to be posed by AI
technology [are **already apparent**, and legal or regulatory action can
be **taken now** to deal with them]{.underline}. Others will make
themselves known as the technology becomes more widely used and can be
dealt with in the same way. [At **some point**, it will **be**come
**apparent** whether specific regulation is needed, and if so the
**scope** and **focus** of that regulation will be possible to devise.
But **at present**, we are **some distance away** from that
point]{.underline}.

### 2NC\-\--Good AI\-\--Link

#### It's [impossible]{.underline} to [only]{.underline} regulate 'bad' AI without [stifling]{.underline} the 'good'. Tech is [too far off]{.underline} and [unpredictable]{.underline} AND humans have [no current baseline]{.underline} for [understanding]{.underline}, let alone [assessing]{.underline} or [guiding]{.underline}, productive means. [Premature]{.underline} regulation drives [straight]{.underline} to extinction.

Gönenç **Gürkaynak 18**, Founding Partner of ELIG Gürkaynak
Attorneys-at-Law, LL.M. from Harvard Law School, İlay Yılmaz, Partner at
ELIG Gürkaynak Attorneys-at-Law, and Güneş Haksever, LLM from Istanbul
Bilgi University, Attorney at IBM Turkey, "Stifling Artificial
Intelligence: Human Perils", Computer Law & Security Review, Volume 32,
Issue 5, 12/12/2018,
<https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3285264> \[note --
'ANI' = 'artificial narrow intelligence'\]

3\. Protecting human dominance through regulation or setting tailored
goals to maintain human existence

Having a timeless and robust definition of AI is of paramount importance
when thinking of regulating AI. [One **cannot** regulate a certain
subject without establishing a **robust definition** of what it
regulates]{.underline}. [The ambiguity of]{.underline} the definition of
[AI is]{.underline} mainly [due to the **"I",**]{.underline}
"intelligence" of the AI. [Concepts like "intelligence"]{.underline},
"consciousness", "free will" and "soul" accompanying it [are yet to have
deterministic definitions]{.underline} although the greatest minds of
our planet have tackled them for thousands of years (Burkeman, 2015).21

Neither any of the foregoing definitions of AI, nor many other
definitions in the academia presents adequate definitions that can be
satisfactory when regulation techniques are considered. In addition, the
lack of definition is only one of the problems regulators will face;
they will need to tackle liability gaps, control and transparency
problems (Danaher, 2015).

In light of the foregoing, our primary statement stands firm: [it is
**very early** to begin thinking about regulating AIs]{.underline} or AI
studies, [**particularly** if such **reg**ulation**s** may **hinder
developments** that could prove **essential for human existence**. The
turning point in AI development will]{.underline} probably [be the
development of **ANIs**, which should be **encouraged**]{.underline}
through regulation, [not **restricted**]{.underline}. However, if
humanity fails in establishing adequate safe guards for ANIs, science
fiction may turn into reality. Goertzel and Pitt (2012) call this the
'AGI Sputnik moment'.

3.1. The great AI hype of 2015

Elon Musk's and Stephen Hawking's fears, Bill Gates' cautious approach,
Kurzweil's optimistic take and Bostrom's realistic analysis on the
future that will probably be painted by [AIs point to a]{.underline}
single [**fundamental** and **existential** dilemma: Are we going to be
extinct **because** of AIs or will we **maintain** our existence with
the **help** of AIs?]{.underline}

[The cycle of **extinction**]{.underline} and rise of species [may be
the greatest success of evolution: ensuring the **continuity of life**.
Over 90% of]{.underline} all [species]{.underline} that ever existed on
Earth [went extinct and **humanity's fate** will be **no different**,
unless we come up with methods to achieve **transcendence** over
evolution]{.underline}.22 Urban (2015) also treats this concept with a
less theatrical manner and stresses two major outcomes for a possible
'ASI Sputnik moment'. He states that either the introduction of ASIs
will make immortality possible for our species or it will drive the
human race into extinction.

Evolution has granted us our strongest instinct: survival. Instinctively
we are in a never-ending war with nature, aiming to prolong our
existence. In the abstract, the field of medicine solely exists for this
purpose. Therefore, [**instinctively** we will]{.underline} either [try
to **eliminate** the existential threat]{.underline} [that
ASIs]{.underline} [might pose]{.underline} against us when we face the
threat itself or try [to eliminate a potential threat]{.underline}
[**prematurely** and in so doing **cause our own
extinction**]{.underline}.

3.2. Reshaping perception on law

We may be living in the dawn of the age of artificial intelligence
today. Consequently, the legal landscape surrounding our lives will
require rethinking, as the case was with every big leap in technology.
The industrial revolution brought conveyor belts and mechanical
manufacturing processes operated by workers for longer and longer hours,
which ended in myriad clashes between proletariat and employers. Hence,
we developed labour laws, bringing a humanitarian minimum standard for
the workers that were suffering from extreme working conditions. Similar
legislative efforts followed each time when technologies required us to
adapt new paradigms they introduced, technologies such as electricity,
telegraph, telephone, railroad, automotive, television, and computers
and so on. . . Below we will seek answers to some exemplary questions as
to how AI might reshape our thinking, in terms of certain matters of
current and prospective law.

3.2.1. Liability on damages

There are very few laws or regulations that address the challenges
raised by AIs, and no courts appear to have developed standards so far,
addressing who is legally responsible if an AI causes harm. The
diversity and richness of individuals and firms that participate in the
creation of an AI will make it difficult to identify the persons under
liability. Certain technologies used in the development of an AI may
date back to years before such AI is developed. Further, the developers
of such technology may never have thought that one day, someone might
incorporate their creation into any AI system. In such circumstances, it
would be unfair to hold the developer of such technology responsible for
a possible tort.

National and international laws do not recognize AI as a legal person.
Therefore, current legal systems cannot hold them liable for the damages
they might cause. However, what if an AI was fully autonomous and aware
of its actions, causing harm knowingly and willingly?

This brings us back to the debate on consciousness. A conscious AI
should naturally be liable for its actions. However, how can that be
possible if we keep refraining from coming up with an adequate
definition of what an AI is as far as legal 'beings' are considered?
Should we ascribe legal personhood to them? (Paulius et al., 2015).

3.2.2. Intellectual property

IP law and its application places human initiative at its core. Berne
Convention of 188623 requires an 'author' and an 'artistic work' to
begin talking about intellectual property. While there is no limitation
as to what form a 'work' can assume as long as humans can perceive it,
an author must be a 'human'. A San Francisco court applied and
materialized this concept in 2015 by deciding in a lawsuit by PETA, the
renowned organization defending animal rights, against David John
Slater, a professional photographer, that a macaque money cannot own
copyright to a selfie it took using the photographer's camera (Kravets,
2016). What about AIs though? Can they own copyrights to the artistic
works they create? Should law consider them as 'individuals'?

3.2.3. Copyright and AI

Currently, a handful of AI applications are capable of producing works
that resemble 'art', such as Deep Dream and the Cybernetic Poet.

Google's® researchers developed DeepDream® to create a human-like image
recognition software to identify certain things through mimicking human
cognitive abilities. DeepDream uses Google's artificial neural networks
protocol to discern and process images of things to learn what they look
like, such as a cat.

Google's developers taught DeepDream what a cat looks like by showing
millions of images of cats. Then they put DeepDream's learning and
identifying abilities to test by asking it to identify cats in pictures
with cats and if found amplify them, introducing a feedback loop to work
on. Then the developers introduced a random image to DeepDream and asked
it to enhance the image in such a way as to elicit a particular
interpretation. This method enabled the developers to understand whether
DeepDream understood the essence of the things it learns. As a result,
DeepDream searched in the images provided for all the things the
developers trained it to recognize and when it found the tiniest bit of
reference, it enhanced the relevant reference to make it look like the
thing it found similar. The resulting images were surprisingly close to
works of art. Few predicted this phenomenon, including DeepDream's
developers.24

Ray Kurzweil developed a poem software in mid-80s, a
computer-implemented method of generating a poet personality that reads
poems and generates analysis models to build its personality, and
ultimately writes poems; the 'Cybernetic Poet'. Cybernetic Poet is
"provided with an input file of poems written by a human author or
authors. It analyses these poems and creates a word-sequence model based
on the poems it has just read. It then writes original stanzas of poetry
using the model it has created." (Bridy, 2012)

Now, who owns the copyrights of the artistic works created by these AIs?

As explained, current law cannot vest ownership of the copyrights to an
AI, as it is not 'human'. However, the laws of the United Kingdom make
express provision for copyright in computer-generated works and
introduce the following definition: 'works generated by a computer in
circumstances such that there is no human author'.25 The copyright in
such works under UK law vests in 'the person by whom the arrangements
necessary for the creation of the work are undertaken'. Concordantly,
Irish Law adopts the same principles.26 However, the UK and Irish
approaches to the issue surrounding copyright ownership of
computer-generated works and not the works of an AI. Therefore, they
overlook the possibility of 'non-human' copyright ownership, ruling out
the possibility of an AI that develops its own creative abilities. Who
will have the ownership then?

3.3. Regulate and dominate?

A regulatory oversight and governmental intervention is a need when the
development of AI is considered.27 It is not common to hear a Silicon
Valley entrepreneur who operates on the frontiers technological
advancement, urge governments to directly intervene with a developing
technology in the hope of preventing humanity to do 'something stupid'.
When such thing happened in October 2014, it created a ripple effect and
caused 'The Great AI Panic of 2015' (Sofke, 2015), which eventually led
an institution called 'Future of Life Institute® (FLI)' to issue an open
letter signed by Elon Musk, Stephen Hawking, hundreds of AI researchers
in addition to many individuals representing U.S. government (Russel et
al., 2015). FLI urged expanded research on how to contain AI systems
within the walls of human benefit, including premature regulation.
However, FLI used statements such as 'AI systems must do what we want
them to do', 'We should identify research directions that can maximize
societal benefits' and 'AI super-intelligence will not act with human
wishes and will threaten humanity' while providing a research roadmap
for AI researchers.

While the 'we' hints at a desired ownership over a technology under
development (i.e. AI) and the 'we' implies superiority over 'others' in
determining how a technology will be socially beneficial for humanity.
It also begs the questions, 'Who are you to claim that you have the
capacity to force your desires over the entire human race, and [**who
are you** to **claim** that you can decide what is socially beneficial
for us?' Stating that]{.underline} an [ASI will definitely be against
the humanity's welfare is]{.underline} an [unexpectedly **ignorant**
claim]{.underline}, allegedly coming from some of the greatest minds on
Earth.

We experienced this line of thought when the Internet reached the
masses, disrupting the status quo by lifting the boundaries of
communication and information exchange and blurring the sense of control
over disseminated information and access to such. The idea of an open
interconnected network of networks that is not in anyone's control or
under any jurisdiction challenged lawmakers, policy makers and judiciary
bodies and it still does. We have still been unable to set out universal
rules on Internet (except DNS policies, where all stakeholders over
Internet govern these policies through ICANN, a non-governmental
organization) for almost 60 years. It would be very naïve to think that
we can regulate AI policies, while AI is still in its infancy.

There is almost a consensus within the scientific AI community that
definitive predictions on the future of ASI are impossible at this
stage, simply because we are so far from creating an ASI, let alone
understanding its implications.

3.3.1. Current and prospective regulatory efforts

[Trying to anticipate ASI's desires from where we stand now in terms of
AI development is **very similar to a chimpanzee trying to anticipate
our motives when we crush an onion to remove its skin**. Therefore,
aiming to **establish regulations** to prevent ASIs from obliterating us
is a **hopeless endeavour**]{.underline}. However, this line of thought
may eventually lead regulators to prevent AI research from developing an
AGI, fearing that it will break free from the chains of our capacity and
become an ASI by itself. For example, John FrankWeaver, an attorney
working in the field of AI law, praised the regulators at California
when they intervened with Google's self-driving cars and required test
drivers to be present in these cars. He even claimed that this as a
'wonderfully swift governmental response to autonomous technology and
artificial intelligence' while further supporting four states
(Mississippi, Florida, Nevada and California) for passing restrictive
regulation on autonomous cars that are not even on the market yet
(Weaver, 2014).

3.3.1.1. Legislative efforts for autonomous vehicles. Nevada is the
first U.S. state to enact a legislation authorizing the operation of
autonomous vehicles in 2011 and was then followed by six other states,
with many other states in still pending status with reference to their
respective autonomous vehicle legislations. Tennessee among those who
did enact such legislations stands out with its enabling and refreshing
legislation wherein it prohibits local governments from banning the use
of motor vehicles equipped with autonomous technology (Legislatures,
2016).

Throughout the world, legislators are working to incorporate autonomous
(driverless) vehicles into their legislations to allow this thriving
technology bloom and develop further, which brings hope.

The Convention on Road Traffic,28 of the United Nations, ratified by 73
countries, is in the process of amendment to allow automated vehicles on
roads in many countries. European Road Transport Research Advisory
Council published the roadmap for automated driving for Europe.29 German
Federal Highway Research Institute published a report on the status of
German legal landscape pertaining to vehicle automation technologies,
indicating the areas of improvement on research, legislation and
involvement of government agencies.30 Netherlands, Sweden, Japan and
many other developed countries are actively working on improving the
conditions of economic and legislative environment to enable swift
development and consequently to reap the benefits of being involved in
the forefront of innovative technologies.

While governments are honing in on preparing the legislative grounds for
the operation of autonomous vehicles, academia adopts a wider approach
and handles the concept in a wider manner, and works on determining the
adequate policies for robotics and AI.

3.3.1.2. The RoboLaw project. The main objective of the RoboLaw project
("Regulating Emerging Robotic Technologies in Europe: Robotics facing
Law and Ethics") is to understand the legal and ethical implications of
emerging robotic technologies and to uncover whether existing legal
frameworks are sufficient in light of the rapid expansion of robotics
technologies.31

The project was launched in March 2012 and funded by the European
Commission (Paulius et al., 2015). The project produced the "Guidelines
on Regulating Robotics", which was then presented to the European
Commission, to create the legal framework surrounding the development of
robotic technologies in Europe.

The RoboLaw Project considered industrial robots, domestic robots, care
robots, medical and surgery robots, autonomous vehicles, and
humanoids/animaloids.The report discussed five essential legal areas for
robotics: (i) health, safety, consumer, and environmental regulations;
(ii) liabilities; (iii) intellectual property rights; (iv) privacy; and
data protection and (v) capacity for legal transactions (Anon, 2015).

3.3.1.2.1. Health, Safety, Consumer and Environmental Regulation. The
report identifies that common usage of robotics in hospitals, homes,
commercial areas and our daily lives will require a new wave of
legislations to cope with the prospective health and safety matters.

3.3.1.2.2. Liability. The report argues that imposing substantial
liability on manufacturers, owners or users of robots for damages caused
to third parties may increase safety while inducing wider social
acceptance of robots. However, the report also argues that such approach
on a liability regime may result in the displeasure of tech industry,
consumers and, in the end, the general public, and may slow down the
development of AI and robotics technologies. Therefore suggests a
balanced approach between the interests of manufacturers, users, and
third parties, and between risk regulation and stimulation of
innovation, to encourage research, innovation and experimentation on
these technologies, for increasing welfare in health, transport,
commerce and other areas of business.

3.3.1.2.3. Intellectual Property Rights. RoboLaw Project indicates the
lack of legal provisions that specifically apply to robotics. RoboLaw
Project states that further research would be beneficial to determine
whether the current application of intellectual property rights
sufficiently meets the needs of the robotic industry and society.

3.3.1.2.4. Privacy and Data Protection. The RoboLaw Project suggests
implementation of legal requirements into the robot's software and
interface through the 'privacy by design' approach, such as data
security through data encryption and data access control in order to
comply with the data protection requirements.

3.3.1.2.5. Capacity for Legal Transactions. The report stresses the lack
of legal personality of robots and indicates that robots are seen as
'mere tools' to carry out commands that can, directly or indirectly, be
attributed to human beings. Consequently, this approach requires the
legal responsibility for robot actions to rest with their human
'masters'.

It is possible to attribute legal personality to robots through
legislative effort. Non-humans such as corporations, associations, and
foundations gain their legal personalities through registration. The
registration principle could be extended to robots and AIs (including
requirements how robots can prove their registered identity); the
capability of owning property is less easy to create, although legal
constructions could be devised to accommodate this.

The report concludes with indicating that if these issues concerning
legal personality are resolved at a certain point in time, more
practical requirements and rules pertaining to legal acts will come into
play, such as implementing legal conditions into the machines to make it
possible for them to enter into a contract.

[Lawmakers need to familiarize themselves with the potential
**benefits** of AIs. Strict rules may]{.underline} prevent humans from
the possible damages of AIs. However, these rules will also [**dampen**
possible improvements]{.underline}. Therefore, lawmakers should consider
the balance between protection of humanity and development in
technology.

4\. Conclusion

[When aiming to regulate **currently non-existent** technologies, we
must **avoid** this approach at **all costs**. Putting restrictions on
developing technologies]{.underline} based on our personal presumptions
might indeed help us to avoid extinction at the hands of 'evil robots',
but it [might]{.underline} also **[cause]{.underline}** our
[**extinction** due to **natural reasons**, such as **evolution** by
making it **harder** for the human race to **use technology** to
**adapt**]{.underline}.

Based on the statements of Elon Musk, SteveWozniak, Bill Gates, Bill
Joy, Stephen Hawking and FLI's open letter, it is clear that what [they
all fear]{.underline} is an [**'unfriendly AI'** and]{.underline} what
they all [want]{.underline} is a [**'friendly AI'** in the
**abstract**]{.underline}.

The terms 'friendly' and 'unfriendly' do **[not]{.underline}** refer to
[a **personal trait** of an AI system]{.underline}. These terms refer to
whether the actions of an AI will have a positive or a negative impact
on humanity (Urban, 2015). This is because AIs are computers and they do
not have human values. [We]{.underline} tend to
**[anthropomorphize]{.underline}**32 [AI and attribute them
with]{.underline} our [**moral values** such as **'good and
evil'**]{.underline}, 'moral and immoral' that are formed by our
consciousness. These attributes developed only after thousands of years
of social interaction. AIs will not share these human traits unless we
specifically create them to do so. They operate on a task and goal
oriented manner. To illustrate this point, for instance, there is an
AGI, whose main task is to ensure that trees in a certain pine tree
plantation are under protection from alien spores to keep the tree DNA
as pure as possible. We should not be surprised when such an AGI takes
drastic measures as far as obliterating the entire flying bug population
in the area. [One who]{.underline} is [**unaware** of]{.underline} the
[goals of]{.underline} this [AGI might easily label it as]{.underline}
'evil' and [a 'danger]{.underline} to humanity' as he/she has no
preconception on what the AGI's motives or goals were. [Similarly, a
**chimp**anzee fearing that the **crushing of an onion** is a **sign of
aggression** might **attack** us. Ironically, this view is **very
similar** to the perspective of those who propose **premature**
regulation of AIs]{.underline}.

#### Regs block [innovative start-ups]{.underline} AND make [advanced neural nets]{.underline} infeasible 

Daniel **Castro 19**, Vice President at the Information Technology and
Innovation Foundation (ITIF) and Director of ITIF\'s Center for Data
Innovation, M.S. in Information Security Technology and Management from
Carnegie Mellon University, B.S. in Foreign Service from Georgetown
University, and Michael McLaughlin, "Ten Ways the Precautionary
Principle Undermines Progress in Artificial Intelligence", Information
Technology & Innovation Foundation, 2/4/2019,
https://itif.org/publications/2019/02/04/ten-ways-precautionary-principle-undermines-progress-artificial-intelligence

HOW POLICIES BASED ON THE PRECAUTIONARY PRINCIPLE IMPACT AI

[Policies]{.underline} based on the precautionary principle can [impact
AI]{.underline} in several ways. [They]{.underline} can [make it **more
expensive** to develop]{.underline} AI, [limit the **testing** and
**use** of AI, and even ban certain **applications**]{.underline}.
Clearly nations have the right to impose any regulations they chose
(assuming they do not violate World Trade Organization rules or other
global treaty obligations). But they should not delude themselves into
believing that [**reg**ulatory regime**s**]{.underline} based on the
precautionary principle [will]{.underline} not [limit increased
**productivity**]{.underline}, competitiveness, [and
**innovation**]{.underline}.

To provide a more detailed discussion of the negative effects policies
based on the precautionary principle can have on AI, the following
section analyzes the effects of policies discussed earlier in this
report. In many cases, these policies have multiple negative effects on
AI.

1\. Slower and More Expensive AI Development

[Policies]{.underline} based on the precautionary principle both
[**slow** and make]{.underline} the [development of AI **more
expensive**]{.underline}. For example, if all fifty U.S. states had laws
such as New York's, which requires autonomous vehicle firms to perform
road testing under the paid supervision of police, testing such vehicles
would be more expensive. Moreover, proposals to require even non-medical
algorithms to undergo pre-market trials would hurt the development of AI
because such [trials are **time-consuming** and
**expensive**]{.underline}. Such [proposals]{.underline} may also [make
AI systems that use **m**achine **l**earning, and thus]{.underline} may
[change frequently and need more testing, significantly **less viable**
because such systems could constantly need to go through a new approval
process]{.underline}.96 Finally, [policies that increase]{.underline}
the [cost]{.underline} of developing AI would likely [discourage
innovation]{.underline} in AI [by **creat**ing a substantial **barrier
to entry** for **startups** that **lack sufficient funding** to cover
the cost of proving their AI system is safe]{.underline}. For example,
the GDPR has dampened investment in European technology startups and led
to a 30 percent decrease in the market share of small online advertising
firms that lack the resources to easily comply with the regulation.97

Restrictions on one AI technology can also limit ways to develop another
AI technology. For example, researchers in Germany are using drones
hovering hundreds of meters above highways to record the movements of
vehicles. This data can help develop simulations to test autonomous
vehicles; such simulations are important tools for improving the safety
of autonomous vehicles because otherwise they would need to travel
billions of miles for safety validation.98 While this novel method of
collecting data to validate the safety of autonomous vehicles may or may
not prove valuable, implementing it in the United States would be would
be difficult to do at scale until the FAA implements its new rules that
allow out-of-sight drone flights and flights over people.99

2\. Less Innovation

AI will spur innovation so policies that limit the development of AI
will limit innovation.100 For example, proposals to ban or limit the
introduction of autonomous vehicles would also limit the generation of
new businesses, business models, and ways to do deliver services through
the "passenger economy." The passenger economy, a term coined by Intel
and research firm Strategy Analytics, "is the economic and societal
value that will be generated by fully autonomous...pilotless
vehicles."101 The firms envision a world where a significant portion of
vehicle ownership is replaced by fleets of autonomous vehicles that
provide on-demand transportation. Productivity would also increase as
autonomous vehicles free employees to work during their commutes and
autonomous trucks to operate more efficiently. The firms estimate the
value of this economy could be \$7 trillion by 2050.102 Nations that ban
autonomous vehicles will not experience the benefits of such an economy.

3\. Lower-Quality AI

[There is]{.underline} often [a negative correlation between making an
AI system more **explainable** and its **accuracy**]{.underline}.103 [As
a result, any policies that require AI to be **explainable** could lead
to **less accurate** AI. For example, researchers at Mount
Sinai]{.underline} Hospital in New York [developed]{.underline} an AI
system called [Deep Patient that]{.underline} can [predict]{.underline}
whether a patient is contracting any of a wide variety of
[diseases]{.underline}.104 The researchers trained Deep Patient on the
health data from 700,000 patients, using hundreds of variables, such as
test results, which allow it to predict diseases such as
schizophrenia---which doctors struggle to predict---extremely well.105
[Even though]{.underline} its [operators]{.underline} can [verify its
accuracy]{.underline} by measuring outcomes, such as if a person is
developing a disease, [it is difficult]{.underline} for its own
developers [to know why it made a particular decision]{.underline}.106

Many sophisticated forms of AI pose a similar problem. Developing an AI
system capable of explaining itself or justifying its decisions is an
incredibly challenging technical feat, so much so that the U.S. Defense
Advanced Research Projects Agency (DARPA) devoted \$75 million in 2017
to research how AI could achieve it.107 Some groups are skeptical that
requiring explainability would chill innovation. They cite DeepMind, a
British company owned by Google parent-company Alphabet, developing an
AI system in 2018 that can analyze eye scans to predict diseases while
also providing doctors a map of the features of disease it sees, such as
hemorrhages.108 However, the fact that one of the world's leading AI
companies could achieve a form of explainability in a system it worked
on for nearly two years is not evidence that all other operators should
or would be able to achieve explainability for their AI easily.109 To be
clear, it is legitimate for companies, such as IBM, to create internal
requirements for AI explainability.110 Requiring all firms to meet such
a standard, however, would create a barrier to adopting AI, because not
all AI systems are alike and not all businesses have a similar level of
expertise.

Nonetheless, it is important for AI operators to continually assess
their AI system's accuracy to ensure it is generating or predicting the
correct outcomes. [The other option is to allow **only** AI applications
that operators can **explain**; this would lead to AI systems that
consider **fewer variables** and that use **simpler algorithms** to make
decisions. In turn, this would **reduce**]{.underline} the
[**effectiveness** of AI that can generate **significant
impacts**]{.underline} such as identifying a terminal illness before a
doctor can.

#### It [nukes]{.underline} R&D at the [small business]{.underline} and [individual]{.underline} levels\-\--they're key

Dr. Jeremy **Straub 21**, PhD, Assistant Professor in the North Dakota
State University Department of Computer Science and NDSU Challey
Institute Faculty Fellow, "Would Regulation Prevent AI From Becoming an
Evil Overlord?", Dakota Digital Review, 10/1/2021,
https://dda.ndus.edu/ddreview/would-regulation-prevent-ai-from-becoming-an-evil-overlord/

WHO DOES REGULATION REALLY PROTECT?

[Achieving]{.underline} most of these [benefits will **require** a **lot
more** **r**]{.underline}esearch [and **d**]{.underline}evelopment.
[**Reg**ulation**s** that make it **more expensive** to develop AIs or
prevent certain uses might **delay** or **forestall** those efforts.
This is **particularly** true for **small businesses** and
**individuals**---**key drivers** of new technologies---who are **not**
as **well equipped** to deal with regulation **compliance** as larger
companies]{.underline}.

In fact, the biggest beneficiary of AI regulation may be large companies
that are used to dealing with it, because startups will have a harder
time competing in a regulated environment. Even ambiguity regarding
regulation and what aspects of AI are regulated may be problematic, as
it may cause people to avoid innovation to avoid risking inadvertent
ensnarement by vague regulations and potential penalties.

[Humanity faced]{.underline} a [similar]{.underline} set of [issues in
the early days of the **internet**. But the **U**]{.underline}nited
**[S]{.underline}**tates [actively avoided regulating the internet to
avoid **stunt**ing its **early growth**]{.underline}.\[39\] Elon Musk's
PayPal and numerous other businesses helped build the modern online
world while subject only to regular human-scale rules, like those
preventing theft and fraud. Similarly, no special rules were rolled out
to govern early software businesses, such as Microsoft, in their
burgeoning years, that have gone on to become industry titans.

### Democracy Bad -- 1NC

#### Democratic peace is [statistically]{.underline} disproven\-\--it's conflict [driving]{.underline}

Dr. Daina **Chiba 21**, Associate Professor of Political Science in the
Department of Government and Public Administration at the University of
Macau, Ph.D. in Political Science from Rice University, LL.M in
Jurisprudence and International Relations from Hitotsubashi University,
and Dr. Erik Gartzke, Professor of Political Science at the University
of California, San Diego, PhD in Political Science from the University
of Iowa, "Make Two Democracies and Call Me in the Morning: Endogenous
Regime Type and the Democratic Peace", 2/19/2021,
https://dainachiba.github.io/research/make2dem/Make2Dem.pdf

[The democratic peace]{.underline}---the observation that democracies
are less likely to fight each other than are other pairings of
states---[is one of the most widely acknowledged empirical regularities
in international relations. Prominent scholars have even characterized
the relationship as an empirical law]{.underline} (Levy 1988; Gleditsch
1992). The discovery of a special peace in liberal dyads stimulated
enormous scholarly debate and led to, or reinforced, a number of policy
initiatives by various governments and international organizations.
Although a broad consensus has emerged among researchers regarding the
empirical correlation between joint democracy and peace, disagreement
remains as to its logical foundations. Numerous theories have been
proposed to account for how democracy produces peace, if only dyadically
(e.g., Russett 1993; Rummel 1996; Doyle 1997; Schultz 2001).

[At the **same time**, peace appears likely to foster or maintain
democracy]{.underline} (Thompson 1996; James, Solberg, andWolfson 1999).
A vast swath of research in political science and economics proposes
explanations for the origins of liberal government involving variables
such as economic development (Lipset 1959; Burkhart and Lewis-Beck 1994;
Przeworski et al. 2000; Acemoglu and Robinson 2006; Epstein et al. 2006)
and inequality (Boix 2003), political interests (Downs 1957; Bueno de
Mesquita et al. 2003), power hierarchies (Moore 1966; Lake 2009), third
party inducements (Pevehouse 2005) or impositions (Peceny 1995; Meernik
1996), geography (Gleditsch 2002b), and natural resource endowments
(Ross 2001), to list just a few examples. [Each]{.underline} of these
putative **[cause]{.underline}**s [of democracy is **also** associated
with various explanations for international conflict]{.underline}.
Indeed, some as yet poorly defined set of canonical factors may
contribute both to democracy and to peace, [making it **look** as if the
two variables are **directly related**, **even if possibly they are
not**]{.underline}.

We seek to contribute to this literature, not by proposing yet another
theory to explain how democracy vanquishes war, but by estimating the
causal effect of joint democracy on the probability of militarized
disputes using a quasi-experimental research design. We begin by noting
that [some of the **common causes** of democracy and peace may be
**unobservable**, generating an **endogenous relations**hip between the
two. Theories of democracy and explanations for peace are at a
**formative state**; it is **not possible** to utilize detailed,
validated and widely accepted models of each of these processes to
assess their interaction]{.underline}. Indeed, [to a **remarkable
degree** democracy and peace each remain **poorly understood** and
**weakly accounted** for **empirically**, despite their central roles in
international politics. We address the risk of spurious correlation by
applying an **instrumental variables approach**. Having **taken into
account possible endogeneity** between democracy and peace, we find that
joint democracy does **not** have **a**n **independent** pacifying
effect on interstate conflict. Instead]{.underline}, our [findings show
that democratic countries are **more likely** to attack other
democracies than are non-democracies]{.underline}. Our [results **call
into question** the]{.underline} large body of [theory that]{.underline}
has been proposed to [account for]{.underline} the [**apparent**
pacifism of democratic dyads]{.underline}.

#### Democracy causes Nigerian [state collapse]{.underline} and [civil war]{.underline}

Dr. Moses E. **Ochonu 19**, Cornelius Vanderbilt Chair in History and
Professor of African History at Vanderbilt University, PhD and MA in
African History from the University of Michigan, BA in History from
Bayero University, Graduate Certificate in Conflict Management from
Liscomb University, "Why Liberal Democracy is a Threat to Nigeria's
Stability", Logos: A Journal of Modern Society & Culture, May 2019,
http://logosjournal.com/2019/liberal-democracy-is-a-threat-to-nigerias-stability/

[In]{.underline} 20[**15**, Nigeria]{.underline}, a country of about 190
million, [spent \$625 million to conduct]{.underline} federal and local
[elections. By comparison, India]{.underline}, with a population of 1.2
billion, [spent \$600 million]{.underline} on its 2015 election,
according to figures released by the Electoral Commission of India
(ECI).\[1\]

In 2019, the election budget of Nigeria's Independent Electoral
Commission (INEC) rose to \$670 million. [This represents about **2.5
percent** of Nigeria's]{.underline} \$28.8 billion [budget]{.underline}
for 2019, a portion of which is being financed through borrowing. To put
the electoral spending in context, [more than half of the country
subsists on about a **dollar a day**]{.underline}, and the country
recently acquired the dubious distinction of being named [the **poverty
capital of the world**]{.underline}, with more people living in extreme
poverty there than in any other country.\[2\] [Key infrastructures and
services]{.underline} such as roads, railway, electricity, water supply,
healthcare, and education [are **severely inadequate**, requiring
**urgent investments**]{.underline} and interventions.

[Election-related expenditure is **expected to rise**]{.underline} in
the near future as INEC implements a wider slate of digital technologies
to combat manipulation and improve the integrity of the electoral
process. For comparison, Nigeria typically devotes about 7 percent of
its budget to education. And yet Nigeria continues to maintain a
four-year election cycle, with smaller by-elections occurring in
between. This electoral calendar guarantees that about \$1 billion is
spent on elections every four years. As the electoral price tag has
grown, democratic dividends have plummeted.

Nigeria's predicament is a microcosm of the phenomenon of rising
financial costs of elections in Africa and diminishing returns on
democracy. Across the continent, [the cost of electoral democracy is
**increasing** and **threatens the delivery of social
goods**]{.underline}. As [African countries battle **myriad
socioeconomic challenges**]{.underline}, the question needs to posed: is
it wise for these countries to continue to spend a large percentage of
their revenue every four or five years on a political ritual with fewer
and fewer positive socioeconomic consequences for their populations? Is
this expensive, periodic democratic ritual called election worth its
price?

[It is not only the monetary cost of elections that now threatens to
**defeat their purpose** and **engender disillusionment** and, along
with disillusionment, the **erosion of trust** in the state and its
ability to **produce** and **distribute** public goods. The **social
cost** of]{.underline} periodic [elections has been]{.underline}
arguably [**great**er, **depleting**, with each election cycle, the
**residual stability** of the state and the **credibility** of its
**institutions**]{.underline}.

[Elections conducted in Nigeria]{.underline} since the return of
civilian rule in 1999 [have brought with them]{.underline} anxiety,
tension, death, **[violence]{.underline}**, and dangerous rhetoric
[that]{.underline}, taken together, have [**frayed** the **national
political and social fabric**. Elections have **widened fissures** and
intensified preexisting **primordial cleavages**]{.underline}.

I can recall no electoral cycle since at least 2003 that was not been
accompanied by fears of Nigeria's disintegration or at the very least
the acceleration of its demise. In 2007 and 2011, post-election violence
claimed hundreds of lives in Northern Nigeria as supporters of then
candidate Muhammadu Buhari rioted after his loss. In the 2019
presidential and national assembly elections, at least 46 people were
reported to have died from election-related violence. In the state
assembly and governorship elections two weeks later on March 9, 2019,
another 10 people died across five states in what the Sunday Tribune
newspaper described in its headline as "another bloody election."\[3\]

Two riders below the same Sunday Tribune headline encapsulate the
turbulent character of Nigerian elections. One was "Thugs, vote buyers,
arsonists take over on election day"; the other was "Nigerians condemn
militarization of elections in Rivers, Bayelsa, Kwara, Akwa Ibom,
Benue," a reference to the government's deployment of soldiers and other
military assets to opposition strongholds before and during the
election. The involvement of soldiers and other military personnel in
the election was a brazen violation of Nigeria's Electoral Act, an
action which many observers interpreted as the incumbent
administration's effort to use its might to manipulate the election in
states held by the opposition.

Every election cycle in Nigeria sees massive, fear-induced demographic
mobility as members of different ethnic groups and religions relocate to
areas considered dominated by their kinsmen and co-religionists to await
[the conclusion of elections]{.underline} that [often degenerate into
**communal clashes** especially in the **volatile north** of the
country]{.underline}.

Periodic [national elections have]{.underline} thus [**worsened**
Nigeria's notoriously **frail union** and caused **apathy** and
**discontent**]{.underline}. The Nigerian people, the major stakeholders
in Nigeria's democracy, have grown weary of being periodically
endangered and rendered pawns in an elaborate elite ritual with little
or no consequence for their lives.

Electoral aftermaths have not improved economic conditions or
strengthened the capacity of citizens to hold elected leaders
accountable. Moreover, as I shall discuss shortly, the familiar abstract
freedoms that democracy, lubricated by periodic elections, can confer on
citizens who participate in such exercises, have eluded Nigerians.

The result has been noticeable apathy represented most poignantly by
voter turnout, which declined from a peak of 69.1 percent in 2003 to
46.3 percent in 2015 and to about 35 percent in 2019. In the same 2019
election cycle, turnout declined to less than 20 percent in the
governorship and state assembly elections, with many Nigerians on social
media stating that they had lost faith in the electoral process and that
the official results of the presidential elections two weeks earlier had
shown that their votes would not count towards the declared outcome.

Voter apathy alone is not an indication of democratic disillusionment
but it can portend or indicate something more devastating: diminishing
trust in the state, its institutions, and its processes.

Such a trust deficit exists already and it predated the return of
civilian rule in 1999 after about two decades of military dictatorship.
However, by all theoretical formulations, such a cumulative loss of
confidence in the transactional sociopolitical contract between the
state and citizens should be corrected by the democratic ideals of
voting, representation, and accountability. This has not happened in
Nigeria. In fact, the opposite scenario is visible: a negative
correlation between successive electoral cycles and citizens' trust in
the Nigerian state. Therein lay the paradoxical consequences of
democratic practice in Nigeria.

[If elections are **increasingly** burdensome as they have become in
Nigeria, the corrective potential of democracy]{.underline}, broadly
speaking, [is lost. Citizens]{.underline} consequently [**lose faith**
in the state and resort to **self-help**]{.underline}, including
criminal self-help. [That is how **states collapse**. Nigeria is **not
far off** this possibility]{.underline}.

In Nigeria, recent political realities reveal a blind spot of
pro-democracy advocacy: without the modulating effect of
decentralization, sustained economic growth, a growing, secure middle
class, and a literate, hopeful poor, liberal democracy can do and has
done more damage than good. [Liberal democracy has ironically become
both an incubator and protector of mediocrity, corruption, and bad
governance. The **overarching casualty** has been Nigeria's **very
stability**]{.underline}.

#### Nigerian instability escalates to [global]{.underline} great power war

Charles A. **Ray 21**, Member of the Board of Trustees and Chair of the
Africa Program at the Foreign Policy Research Institute, Former U.S.
Ambassador to the Kingdom of Cambodia and the Republic of Zimbabwe,
"Does Africa Matter to the United States?", Foreign Policy Research
Institute, 1/11/2021,
https://www.fpri.org/article/2021/01/does-africa-matter-to-the-united-states/

[**Africa matters** in terms of **size**, **population**, and rate of
**population growth**. It]{.underline} is the continent currently most
affected by climate change but [is]{.underline} also [a continent that
can have a **devastating impact** on **climate change globally** because
of the importance of the **Congo Basin** rainforest, which is the
second-largest absorber of heat after the Amazon rainforest. The
destruction of this important ecosystem could further accelerate
**global warming**]{.underline}. As residents of the region come into
increasing contact with the animals of the rainforest, [this region
could be the origin of the world's next **viral pandemic**. Violent
extremism and terrorism are increasing in Africa, and while now mostly
localized, the danger has the potential to **spread beyond the
continent**. **Crises**]{.underline}---natural and man-made---cause
massive relocations of populations, both on the continent and abroad,
which [can have **negative economic, social, and political
impacts**]{.underline}.

Why Africa Matters

The African continent is the world's second-largest, with the
second-fastest growth rate after Asia. With 54 sovereign countries, four
territories, and two de facto independent states with little
international recognition, the continent has a current population of 1.3
billion. By 2050, the continent's population is predicted to rise to 2.4
billion. By 2100, [**Nigeria**, Africa's most populous country, will
have a population of **one billion**]{.underline}, and half the world's
population growth will be in Africa by then.

The population of African countries is also overwhelmingly young.
Approximately 40% of Africans are under 15, and, in some countries, over
50% is under 25. By 2050, two of every five children born in the world
will be in Africa, and the continent's population is expected to triple.
These developments have positive and negative potential impacts on the
United States and the rest of the world. Young Africans have, for the
most part, completely skipped the analog age and gone directly digital.
Comfortable with technology, they form a huge potential consumer and
labor market. [If]{.underline}, on the other hand, the [countries of
Africa fail to develop economically]{.underline} and do not create
gainful employment for this young population, then there is the risk
that [they will become a huge potential source of recruits to extremist
and terrorist movements]{.underline}, which currently target
disadvantaged and disenchanted youth.

Lack of economic opportunity, increased urbanization, and climate-fueled
disasters will also contribute to movement of people seeking better
lives, which will impact economies and security not only on the
continent of Africa, but also the economic and security situations
around the world. [Nations, lacking]{.underline} adequate critical
infrastructure, education, and [**job opportunities** are ripe for
**internal unrest** and **radicalization**]{.underline}. In particular,
inadequate health delivery systems, when coupled with natural disasters,
such as droughts or floods that limit food production, cause famine and
mass movements of populations.

The Challenges for U.S. Policy

Prior to World War II, the U.S. policy towards Africa was not as active
as it was toward Europe, Asia, or Latin America. During the Cold War,
Africa policy was primarily viewed from a perspective of super-power
competition. The end of the Cold War and the rise of international
terrorism introduced this as a major component in U.S. Africa policy
along with competition with a rising China and increased Chinese
engagement in Africa.

Before his first official trip to Kenya, U.S. President Barack Obama
said, "Africa had become an idea more than an actual place . . . with
the benefit of distance, we engaged Africa in a selective embrace." This
is probably an apt description of U.S. policy towards African nations
despite the bipartisan nature of that policy. The United States, with
the many domestic and international issues it has to cope with, can ill
afford to continue to ignore Africa. Going forward, U.S. policy must
include a hard-headed look at where Africa fits in policy priorities.

The incoming Biden administration will face a number of important issues
and challenges as it develops its Africa policy. The most pressing
issues are the following:

Climate Change: Climate change is an existential problem that affects
the entire globe, but Africa has probably suffered more from the effects
of climate change than other continents---and the problem will only get
worse with time. In an October 2020 article, World Meteorological
Organization (WMO) Secretary-General Petteri Taalas said,

Climate change is having a growing impact on the African continent,
hitting the most vulnerable hardest, and contributing to food
insecurity, population displacement and stress on water resources. In
recent months we have seen devastating floods, an invasion of desert
locusts and now face the looming specter of drought because of a La Nina
event. The human and economic toll has been aggravated by the COVID-19
pandemic.

Climate change impacts water quality and availability, and millions in
Africa will likely face persistent increased water stress due to these
impacts. A multi-year drought in parts of South Africa, for instance,
threatened total water failure in several small towns and had livestock
farmers facing financial ruin. Another pressing climate-change issue is
the need for protection of the Congo Basin rainforest. This
178-million-hectare rainforest is the world's second largest after the
Amazon and is currently threatened by agricultural activities in
Cameroon, Central African Republic, Democratic Republic of Congo,
Republic of the Congo, Equatorial Guinea, and Gabon. Countries in the
Congo Basin need to address the preservation issue, while also enabling
sustainable agricultural activities to ensure food security for the
region's population. In addition to the impact on global climate caused
by destruction of the rainforest, such destruction also brings human
populations into closer contact with the region's animals, creating the
risk of future animal-to-human transmission of new and possibly more
virulent viruses similar to COVID-19, which will have a global impact.
In a January 2021 CNN report, Dr. Jean-Jacques Muyembe Tamfum, who as a
researcher helped discover the Ebola virus in 1976, warned of possible
new pathogens that could be as infectious as COVID-19 and as virulent as
Ebola.

Rule of Law/Mitigation of Corruption: A key to African development,
given the increasing urbanization, population increases, and
youthfulness of the continent's population, will be an increase in
domestic and international investment to build the industries that can
provide meaningful employment and improved standards of living. In order
for this to be successful, African nations will need to address the
issues of rule of law and corruption. Investors will not risk money if
the business climate comes with a level of political risk that is too
high. Government leaders throughout Africa need to establish legislation
that provides an acceptable level of security for investments and take
action to curb the endemic corruption that currently discourages
investment. Corruption in Africa ranges from wholesale political
corruption on the scale of General Sani Abachi's looting of \$3-5
billion of state money during his five years as Nigeria's military ruler
to the bribes paid by businessmen to police and customs officials. The
"tradition" of having to pay bribes, or "sweeteners," drives away
domestic investment and scares away foreign investment, leaving many
countries mired in poverty.

Violent Extremism and Terrorism: A number of African nations are
currently plagued with rising extremist movements. While primarily a
domestic issue, the mass movement of people fleeing violence and the
disruption of economic activity have the potential to negatively impact
the rest of the world. African nations need regional responses to curb
extremist and terrorist organizations, many of which are supported by
international terrorist organizations, such as ISIS and al Qaeda. In
addition, the underlying conditions that helped to create these
movements must be addressed. [Terrorist groups in Africa range from
relatively large and dangerous groups, such as Boko Haram]{.underline},
a group [in **Nigeria**]{.underline} that has received support from al
Qaeda and that aims to implement sharia law in the country; Al-Shabab,
an al Qaeda affiliate aiming to overthrow the government in Somalia and
to punish neighboring countries for their support of the Somali regime;
and Uganda's Lord's Resistance Army, a fundamentalist Christian group.
Terrorist groups in the fragile political climate of Libya also pose a
threat to sub-Saharan Africa.

**[Great Power Competition]{.underline}**: As the world's second-largest
economy, and with its increasing participation in international
activities, [**China** will continue to be a factor in Africa for the
foreseeable future]{.underline}. This, however, is more a problem for
the nations of Africa than it is for the rest of the world. The West can
compete best by outperforming China in areas of strength by providing
those goods and services that are unquestionably superior, and let
African governments decide how to deal with China and its
often-predatory lending practices and the Chinese tendency to import
Chinese workers for its projects and investments rather than hiring
locals. At the same time, Russia, which did not completely turn away
from Africa at the end of the Cold War as many in the West sometimes
believe, must still be considered a significant factor on the African
landscape. In an effort to compensate for Western sanctions and to
counter U.S. and Western influence, [**Russia** is once again increasing
its presence on the continent]{.underline}. Russian mercenaries, in
exchange for diamond mining rights, have trained military forces in the
Central African Republic, raising concerns about human rights abuses. Of
particular concern is the presence of the Wagner Group, a private
military company associated with Yevgeny Progozhin, a Russian oligarch
with close ties to Vladimir Putin, who was indicted in the United States
for trying to disrupt the 2016 U.S. elections. To date, Russia has, in
addition to seeking basing rights, signed military cooperation
agreements with 28 African nations. Russian activity is a combination of
military and commercial, with Progozhin at the center of both. From 2010
to 2018, Russia nearly tripled its trade with African countries. While
the activities of both Russia and China in Africa are of concern, and
should be closely monitored, neither is of critical importance to U.S.
national security.

With climate change, disease outbreaks, famine, extremism, and
inter-ethnic violence, Africa will still experience crises in the
foreseeable future that will be beyond the capacity of most nations on
the continent to deal with. Climate change is probably the greatest
cause of humanitarian crises in Africa, but mainstream media outside the
continent either fail to notice or under-report them. Some of the
[crises]{.underline}, like Ebola or the next viral infection, [can
**impact** the **rest of the world**]{.underline}. These crises will
cause starvation, mass movement of people, and increase internal and
regional instability. [Africa matters to the **U**]{.underline}nited
**[S]{.underline}**tates [and the **rest of the world**. Its impacts can
be felt **far beyond the continent's borders**]{.underline}, but if
approached as a partner rather than as a patron---with a focus on
assisting African nations to improve governance, build critical
infrastructure, boost domestic economies, and provide essential services
to all---then Africa can be a positive contributor on the global stage.

#### Democracy makes [disease control]{.underline} impossible

Zhifa **Zhou 21**, Associate Professor at the Institute of African
Studies at Zhejiang Normal University and Pan Qu, Postgraduate at the
Institute of African Studies at Zhejiang Normal University, "The Root
Cause of the Failure of American COVID-19 Governance Based on the
Criticism of Liberal Democracy From Error-Tolerant Democracy",
Philosophy Study, Volume 11, Number 7, July 2021,
https://www.davidpublisher.com/Public/uploads/Contribute/60ff9cfb4589c.pdf

Introduction

Whether [liberal **democracy** contributed to]{.underline} the
**[COVID]{.underline}**-19 [governance]{.underline} was a hot topic in
2020 ("Democracy and Rise of Authoritarianism in COVID-19 World", 2020).
At the end of January, 2020, [when **COVID**]{.underline}-19 [witnessed
the lockdown of Wuhan]{.underline} City, [the West]{.underline}
generally [agreed that China lacked **freedom**]{.underline} of speech
and the inertia of a rigid bureaucratic structure, and the national
censorship system kept the whistle blower Dr. Wenliang Li silent, which
led to the disease out of control (Mérieau, 2020). Democracies'
confidence mainly came from Amartya Sen's research on the famine.
[Sen]{.underline} (1999) has [claimed]{.underline} that no substantial
famine has ever occurred in any independent and democratic country with
a relatively free press and there is no exception to this rule. Citizens
in [democracies]{.underline} can [expect governments to be]{.underline}
more [**candid**, transparent, and **responsible**]{.underline} in
dealing with all kinds of crises, which authoritarian countries usually
cannot (Berengaut, 2020; Bollyky & Kickbusch, 2020). So Steve
[Bloomfield]{.underline} (2020) has [regarded that if China had a free
press and transparent government, the pandemic could be brought under
control before the outbreak. In conclusion,]{.underline} freedom plus
[democracy equals the **COVID**]{.underline}-19
**[antidote]{.underline}** according to Western standards, although
Wilson and Wisongye have found that social media rumors can exploit the
right to freedom of speech and erode people's health benefits (New York
Times, 2021; Bollyky & Kickbusch, 2020). [However]{.underline}, since
March, 2020, [with Western democracies]{.underline} seriously [affected
by **COVID**]{.underline}-19, [their superiority of the political system
has begun to **expose** its untrue and **fatal defects**]{.underline}.
Especially when Wuhan began to lift its blockade on April 8, 2020
(People.cn, 2020), [scholars]{.underline} and journalists [began to
question whether democracies had the **ability** to **deal with the
crisis**]{.underline} better than China (Mérieau, 2020). [Liberal
democracy]{.underline} in the United States [has not proved]{.underline}
that it is [more conducive]{.underline} to the COVID-19 governance [than
authoritarianism]{.underline} since 2020. [From a global perspective,
not only do **most democracies fail to contain**]{.underline} the
**[spread]{.underline}** of COVID-19, but almost [**all of the 10 most
affected** countries are **liberal democracies**]{.underline}
(Coronavirus Resource Center, 2021). [Their **policy responses** have a
**poor effect** in reducing the **death toll** in **early stages** of
the crisis, as shown that democratic political institutions may be at a
**disadvantage** in **responding quickly**]{.underline} to COVID-19
(Cepaluni, Dorsch, & Branyiczki, 2020). More surprising is that the
COVID-19 pandemic is so serious in the United States, yet no government
officials have been removed from office because of their inactivity in
fighting against the corona-virus. People doubt whether American
accountability mechanism is still working. However, two impeachments
against President Trump indicate that it seems to function quite well
(Valenta & Valenta, 2017; Herb, Raju, Fox, & Mattingly, 2021). The
direct loss to the United States caused by Russiagate and incitement of
insurrection is far less than the pain caused by the failure of the
COVID-19 governance, but no any official in the United States is
responsible for it. [If it **again** faces infectious diseases
**similar** to **COVID**]{.underline}-19, [will it **repeat** this
**unprecedented tragedy**]{.underline}? Can liberal democracy and the
separation and balance of powers push American president to act more
aggressively? [Error-tolerantism explains that the fundamental reason
for the failure of]{.underline} American [COVID]{.underline}-19
[governance is a **serious misunderstanding** of the concept of
**freedom**]{.underline} (Zhou, 2018; 2019; Zhou, Tan, & Liu, 2020).
Liberalism has witnessed a rare scene: In the context of COVID-19, the
president, governors, magistrates, and the public (Emery, Schwebke, &
Park, 2020; Sullum, 2020; Behrmann, 2020; Kenton, 2020; Strano, 2020)
have severe misunderstanding of freedom [that cost **more
than**]{.underline} American **[600,000 lives]{.underline}**
(Coronavirus Resource Center, 2021).

In response to the above phenomenon, error-tolerantism as the
development of liberalism defines liberty from a new perspective and
shows a stronger explanatory power than liberalism (Zhou et al., 2020).
The right paradigm of error-tolerantism, the right to be wrong (right to
trial and error) as an original right and mutual empowerment theory,
instead of natural rights theory and social contract theory, divides
liberty into the right to liberty in innovative fields, right to be
wrong as an original right, and the right to be right in non-innovative
fields as sub-rights. The lockdown of Wuhan means that Chinese
government has excised the power to be wrong as an original power, but
the West criticized it with the right to liberty at the level of
sub-rights, which is the first error in understanding liberty during
American COVID-19 governance; after Wuhan effectively controlled
COVID-19, its governance has transformed from an innovative field to a
non-innovative one. Then, liberties in non-innovative fields as the
sub-rights level, such as wearing face masks, keeping social distancing,
showing health codes, are formed definitely (Zhou et al., 2020).
However, [**wearing masks** has been regarded as a sign of **political
oppression** rather than a simple hygienic measure by the
**U**]{.underline}nited **[S]{.underline}**tates (Kahanel, 2021). Since
liberalism has a major misunderstanding of the concept of liberty,
[liberal democracy]{.underline} based on the philosophy of liberalism
[should be]{.underline} deeply reflected or even
**[reconstructed]{.underline}**, and it is very reasonable for
error-tolerant democracy constructed based on error-tolerantism [to
explore the defects]{.underline} of liberal democracy [in]{.underline}
American [COVID]{.underline}-19 [governance]{.underline}. Therefore, we
first review scholars' relevant research on American democracy and the
COVID-19 governance, and then based on the theory of error-tolerant
democracy, discuss [the **defects** of]{.underline} liberal
**[democracy]{.underline}** and American political system that [are
**unable to cope** with the **crisis of the century**]{.underline}.

#### Future pandemics are [inevitable]{.underline}\-\--extinction

Dr. Matt **Boyd 21**, Research Director at Adapt Research Ltd, PhD in
Philosophy of Evolution & Cognition from the Victoria University of
Wellington, BA from Massey University, and Nick Wilson, Research
Professor in the Department of Public Health at the University of Otago,
"Optimizing Island Refuges Against global Catastrophic and Existential
Biological Threats: Priorities and Preparations", Risk Analysis: An
International Journal, Wiley Online Library

1 INTRODUCTION

[Our world is vulnerable to global catastrophic risks]{.underline}
(GCRs) [or existential risks]{.underline} (Bostrom, 2019; Ord, 2020).
[**GCRs** are so disastrous because they affect one or more systems
**critical to humanity**, and **spread** to affect the **entire
planet**]{.underline} (Avin et al., 2018). Existential risks threaten to
eliminate humanity or permanently curtail its potential (Ord, 2020).
Some of these [risks are **natural**, for example]{.underline} asteroid
or comet impact, supervolcanic eruption, [naturally occurring
**pandemic**]{.underline}, or various cosmic events (Bostrom & Cirkovic,
2008; Ord, 2020). Many others are the result of human activities, for
example nuclear war, anthropogenic climate change, nonaligned artificial
intelligence, engineered biological threats, geoengineering, or
inescapable totalitarianism (Bostrom & Cirkovic, 2008; Ord, 2020).

There are three phases to an existential catastrophe: origin, scale up,
and reaching every last human (Cotton-Barratt, Daniel, & Sandberg,
2020). Following any near miss, there would be a period where recovery
of humanity\'s long-term potential may or may not be realized (Baum et
al., 2019). [Failure to]{.underline} anticipate or [**mitigate** these
threats risks **undesirable trajectories** for **human
civilization**]{.underline} (Baum et al., 2019).

In addition to the present generation\'s obvious self-interest in
continuing to exist, the perspective of long-termism suggests that
humanity ought to mitigate these risks due to the potential immense
value of future human generations (Beckstead, 2013), a desire to see
aspects of the human project continue across time and perhaps the
universe (Bostrom, 2003; Scheffler, 2013), and the potential cosmic
significance of preserving intelligent life on Earth (Ord, 2020). A
number of philosophical defenses of long-termism have been published
(Beckstead, 2013; Greaves & MacAskill, 2019). Importantly, these
long-term outcomes are largely under human control because most of the
risk is probably anthropogenic (Beard & Torres, 2020; Ord, 2020).

1.1 Mitigating Existential Threats

It is too simplistic to think of existential risks as mere causes that
are followed by a sequence of effects. We should think of risks as the
product of hazards, vulnerabilities, and exposures (Liu, Lauta, & Maas,
2018). [Hazards are the **precipitating cause** of a
**catastrophe**]{.underline}, vulnerabilities are the inability of
critical systems to withstand hazards, and exposures are the features of
human society that turn this system damage into harm to populations
(Beard & Torres, 2020). [Mitigation of existential threats involves
preventing their emergence, **responding** if the threat spreads, and
building **resilience** so the threat does **not** lead to the death of
**every last human** or leave humanity with **permanently curtailed**
prospects]{.underline} (Cotton-Barratt et al., 2020). After a threat has
passed, there may also be a series of limiters that might prevent the
reemergence of a flourishing humanity (Baum et al., 2019). One such
limiting factor could be the loss of technological society and know-how.

In order to achieve immunity from existential threat, humanity will need
a period where it preserves its potential and protects itself from risks
(Ord, 2020). Various methods have been proposed to address
vulnerabilities and hence shift the probability of existential risk.
These suggestions include: improved international focus, governance, and
cooperation such as through the United Nations (Boyd & Wilson, 2020),
imitating existing frameworks such as the Sendai framework for disaster
risk reduction (Avin et al., 2018), achieving the United Nations
Sustainable Development Goals (Cernev & Fenner, 2020), or extreme
surveillance for threats (Bostrom, 2019). Toby Ord lists 38 specific
measures across eight existential threats, and an additional 12 avenues
to explore that address risks in general terms (Ord, 2020).

1.2 Biological Threats

[**Pandemic viruses** with **high case fatality** could potentially
infect a **majority** of the population. Deliberate biological events
(DBEs) have occurred before]{.underline} (Millet & Snyder-Beattie,
2017a), [will **likely occur again**, and could pose a **threat** to
humans as great as **nuclear war**]{.underline} (Kosal, 2020). [New
**tech**]{.underline}nologies [such as **a**]{.underline}rtificial
**[i]{.underline}**ntelligence [could **amplify biothreats** in a number
of ways]{.underline} (O\'Brien & Nelson, 2020). [These risks are
**increased** because the]{.underline} Biological Weapons Convention
[(BWC) has no verification system]{.underline} (Dando, 2016), [and has
been violated in the past]{.underline} (Gronvall, 2018). [It would
**only** take **one** unanticipated or **accidental event** for a
**bioweapon** (or **lab**]{.underline}oratory [accident) to **be**come a
**catastrophic threat**]{.underline}. The U.S. National Academies of
Sciences specifically warns against synthetic biology and xenobiology
(Gomez-Tatay & Hernandez-Andreu, 2019) and it is argued that [a
state-sponsored bioweapon attack is the **greatest current
threat**]{.underline} (Sandberg & Nelson, 2020). See the Supporting
Information for further details on biological threats. Global
preparedness through the One Health approach, global health security
projects, and the need to integrate health and the GCR field (Millet &
Snyder-Beattie, 2017b) are important. But as the COVID-19 pandemic has
shown, there may be important overlooked aspects or misunderstood risks
that could make any suite of general preparation inadequate. Therefore,
last lines of defense may be required, such as refuges.

#### [Existential]{.underline} warming is [inevitable]{.underline} AND causes a [collapse]{.underline} into [extreme]{.underline} authoritarianism\-\--[only]{.underline} transitioning from democracy solves

Dr. Chien-Yi **Lu 21**, PhD and MA in Government from the University of
Texas, Austin, Visiting Scholar at Harvard University, Associate
Research Fellow at the Institute of European and American Studies of
Academia Sinica, Surviving Democracy: Mitigating Climate Change in a
Neoliberalized World, Paperback Edition, 12/13/2021, p. 1-2

The fact [that]{.underline} the [scientific knowledge on the human
contribution to climate change entered human society
through]{.underline} the most advanced [democratic societies **should
have been** a cause for celebration. Given the **congruence** of climate
mitigation and public interests]{.underline}, the problem of [climate
change should have been considered solved decades ago. **Several decades
of inaction** later, however, arguments are proliferating that
**democracy** is **exactly the reason** for **inaction**]{.underline}.

In The Collapse of Western Civilization, historians Naomi Oreskes and
Erik Conway travel to the future to look back and offer a forensic
analysis on the climate-induced Great Collapse of Western Civilization
of 2074 (2014: 63). The future historians' forensic report states that
["\[a\]s the **devastating effects** of the **Great
Collapse**]{.underline} began to [appear]{.underline}, the
nation-[states with democratic governments... were]{.underline} at first
[**unwilling** and then **unable**" to **deal** with the
crisis]{.underline}. These [democratic governments]{.underline} realized
that they [had no "**infrastructure** and **organization**al ability to
**quarantine** and **relocate**]{.underline} people" [as "**food
shortages** and **disease outbreaks** spread and **sea level\[s\]
rose**."]{.underline} In China, [where there was **centralized**
government, the crisis was handled **much more adequately**, leading to
**survival**]{.underline} rates exceeding 80%, a development [that
"**vindicated** the **necessity** of **centralized**
government"]{.underline} (2014: 51--2). The gist of The Collapse of
Western Civilization is not about critiquing democracy per se but a
warning against the [stubborn inaction]{.underline} mandated by market
fundamentalism that [has **hijacked** Western democracies]{.underline}.1
In their previous book, Merchants of Doubt, Oreskes and Conway
documented the way that [climate deniers **sow**]{.underline}ed the
[seeds of doubt about climate]{.underline} change [and]{.underline}
successfully **[stave]{.underline}**d [off implementations of mitigation
measures]{.underline}. For the authors, the anticommunist ideology that
had kept actors vigilant about government encroachment in the
marketplace occupied a central place in climate denial (2014: 69).
Ironically, [this]{.underline} sort of ideology-informed calculation
meant [that preventative action was **blocked**, increasing the risk
that **disruptive climate disasters** would **eventually necessitate the
suspension of democracy** and **legitimating the sort of heavy-handed
authoritarian interventions that the conservatives most
abhorred**]{.underline} (2014: 52; 69).

[An appeal to **suspend democracy for the sake of
survival**]{.underline} can be found in The Climate Change Challenge and
the Failure of Democracy, where Shearman and Smith argue that [liberal
democracy is **incompatible** with the **urgent necessity** to prevent
**catastrophic climate change**]{.underline}. The vested interests of
politicians, corporations, and media lie in continuing with business as
usual and in keeping the public ignorant. Instead of bottom-up reforms
to improve democracy and bring about sensible climate policies,
[Shearman and Smith see a **transformation** in**to** **authoritarian
regimes** as the **only responsible way forward** when faced with the
**extreme ecological stress** of climate change]{.underline}. They point
out that, as Plato foresaw, [those in power in a democracy are seldom
able to **resist the demands of the populace** for long, but as a mass,
the populace is **seldom able to focus** on **complex problems** and to
perceive threats that lie **over the horizon**]{.underline}. Hence,
[those able to see **further**]{.underline}---scientists, experts, and
the knowledgeable--- [should be entrusted with steering the course while
there is **still time** to **avoid disaster**]{.underline}. It is only
under a benign authoritarian rule of the knowledgeable that a saner,
fairer, and more rational means of weighing social goods against evils
can be introduced (Shearman and Smith, 2007).

#### The public is an idiocracy. 'Pressure' cannot be productive.

Dr. Stuart **Parker 20**, Philosopher and Former Teacher who Lectured on
Philosophy and Education at London\'s Institute of Education, South Bank
University, Author of Reflective Teaching in the Postmodern World, "The
Problem With Democracy --- It\'s You", The Article, 10/5/2020,
https://www.thearticle.com/the-problem-with-democracy-its-you

So [why is]{.underline} our [democracy **so unfit** for purpose? Why is
it that we can elect leaders who are **little more** than **self-serving
schemers**, whose **contempt** for the electorate renders them
**incapable** of giving **straight, honest answers** to even the **most
straightforward**, reasonable questions? It's not as if any of these
qualities have been smuggled in under our noses. They are
**paraded**]{.underline} before our eyes every single day. [Nobody
voting for]{.underline} Johnson or [**Trump** could]{.underline} ~~be
blind to the fact~~ [\[ignore\] that they are **serial liars**. And yet
they **voted all the same**. Why?]{.underline}

\*\*\*

Mencken was on to something when suggesting that [the leaders we get,
the leaders we deserve, closely **represent something dark** in the
**inner soul** of the people. There's no easy way to put this --- **the
problem with democracy is the voters**. The voters simply aren't good
enough to support a healthy democracy]{.underline}. They're not up to
the job. Now I know some will think: a snowflake-remainer-lefty-loser
will always blame the voters just as a bad workman always blames his
tools. But these tools are shot.

[Consider this: a poll]{.underline} in 2005 [found that 21 per cent of
Americans believe in **witches** and 9 per cent that spirits can take
control of a person]{.underline}. In 1999, [18 per cent believed the sun
revolves around the earth]{.underline} --- so much for "the science" ---
and in 2000, 31 per cent believed in ghosts, and increase of 20
percentage points since 1978.

By 2019, the year before Trump's re-election attempt, [significant
numbers **believe**d in the **illuminati**, **Big-foot** and a **flat
earth**. Ghost-belief had **risen** to **45 per cent**]{.underline}, as
had the belief in demons. [Belief in **vampires** stood at a
**fangtastic** 13 per cent]{.underline}.

Britain has nothing to be proud of. While 33 per cent of us believe in
ghosts and 18 per cent in demonic possession, a whopping 52 per cent of
us believe that you can magically make a false claim true simply by
writing it on the side of a bus.

In elective dictatorships where small margins have huge consequences
we'd better get used to the fact that (possibly [small) groups with
**stupid ideas** and a **lack of relevant knowledge** and
**skills**]{.underline} can [have a **disproportionate
effect**]{.underline} on the lives of the rest of us.

### War -- Democracy -- 2NC

#### This is true in [all scenarios]{.underline}, including against [other]{.underline} democracies

Dr. Daina **Chiba 21**, Associate Professor of Political Science in the
Department of Government and Public Administration at the University of
Macau, Ph.D. in Political Science from Rice University, LL.M in
Jurisprudence and International Relations from Hitotsubashi University,
and Dr. Erik Gartzke, Professor of Political Science at the University
of California, San Diego, PhD in Political Science from the University
of Iowa, "Make Two Democracies and Call Me in the Morning: Endogenous
Regime Type and the Democratic Peace", 2/19/2021,
https://dainachiba.github.io/research/make2dem/Make2Dem.pdf

[We]{.underline} now [turn to]{.underline} the [results from the outcome
stage, where]{.underline} militarized [conflict]{.underline} initiation
[is regressed on democracy]{.underline} measures and other covariates.
[The **univariate** clog-log model]{.underline} 32 [that **ignores the
endogeneity**]{.underline}, shown in column (1) in Table 1,
[successfully replicates the standard]{.underline}, dyadic [**democratic
peace** finding]{.underline} that democracies are peaceful, though only
toward other democracies. Note that, while individual democracy measures
have either a positive or insignificant coefficient, joint democracy has
a negative coefficient that overwhelms the positive coefficients of
individual democracy measures in the univariate model. As a result, the
univariate model produces a result that, while democracy may increase
conflict against a non-democracy, it decreases conflict against a
democracy.

To illustrate this, we calculate the average treatment effect of joint
democracy for the challenger and for the target based on the univariate
model. These effects are calculated by comparing the predicted
probabilities of conflict initiation when changing the regime type of
self (challenger or target) from non-democracy to democracy, holding
constant the regime type of the other (target or challenger) as
democracy. 33 Gray, hollow circles in Figure 4 show the treatment
effects of challenger's and target's democracy. We can see that both
effects are negative and statistically significant at the 95% confidence
level.

[Once we **correct** the endogeneity, **however**, the data **no longer
support** such conclusions]{.underline}. In column (2) in Table 1, [the
negative coefficient for joint democracy **no longer overwhelms** the
positive coefficient of challenger's democracy. Challenger's democracy
now appears to **increase conflict** even against a **democratic**
target]{.underline}. Red, solid circles in Figure 4 show the average
treatment effects of challenger's and target's democracy, calculated
from the trivariate model. [The effect is **positive** and
**statistically significant** for challenger's democracy]{.underline},
although the effect is indistinguishable from zero for target's
democracy.

[Whether we **correct for endogeneity**]{.underline} thus [makes a
**significant difference** in our estimates of the effect of joint
democracy on conflict]{.underline}. The key to understanding why these
changes occur lies in the estimated correlations between the error terms
for different equations. The estimated error correlation between
equations for conflict and challenger's democracy, 12, is negative and
statistically significant. This suggests that unobservable or
[unmeasured determinants of]{.underline} a country's [democracy make it
less likely for that country to attack another country. A failure to
control for]{.underline} such [factors]{.underline} would [generate a
**negative omitted variable bias**, making it **look** as
if]{.underline} challenger's [democracy has a **pacify**ing effect on
conflict behavior]{.underline}. On the other hand, the estimated error
correlation between conflict and target's democracy equations, 13, is
indistinguishable from zero, suggesting that the endogeneity problem
does not seem to operate for target's regime type.

#### It\'s an [empirical]{.underline} question, [answered]{.underline} by statistical methods\-\--failing to code based on [exogenous]{.underline} variables [corrupts]{.underline} their evidence

Dr. Daina **Chiba 21**, Associate Professor of Political Science in the
Department of Government and Public Administration at the University of
Macau, Ph.D. in Political Science from Rice University, LL.M in
Jurisprudence and International Relations from Hitotsubashi University,
and Dr. Erik Gartzke, Professor of Political Science at the University
of California, San Diego, PhD in Political Science from the University
of Iowa, "Make Two Democracies and Call Me in the Morning: Endogenous
Regime Type and the Democratic Peace", 2/19/2021,
https://dainachiba.github.io/research/make2dem/Make2Dem.pdf

Before we review our approach in detail, it may be useful to explain why
[this type of analysis has **not** been pursued **successfully** in the
past]{.underline} and [what makes our effort **different** from
other]{.underline}, broadly related [projects. We are not the first to
apply an IV framework]{.underline} (more specifically) [or
multi-equation models]{.underline} (more broadly) [to the democratic
peace. However, **previous attempts** suffer from two **major
problems**. First, previous studies have typically used a
**dyad**]{.underline} (country pair) [as the **unit**]{.underline} of
observation in analyzing conflict, [which requires]{.underline} some
**[summary measure(s)]{.underline}** of democracy [for a
pair]{.underline} of countries [rather than the]{.underline} state-level
[**(monadic)** democracy measure]{.underline}. 6 [Use of a dyadic
aggregate to represent regime type creates a **discrepancy** between the
**first stage regression** (predicting democracy at the country level)
and the **outcome stage regression** (predicting conflict at the dyad
level).]{.underline} 7 [We **avoid this** problem by using the
**directed dyad** as the **unit** of observation in predicting conflict,
**distinguishing** between the potential challenger and target in a
dispute. This allows us to connect the first stage
equations]{.underline} (predicting the challenger's and target's regime
types) [and the outcome stage equation **seamlessly**]{.underline}.
Doing so has several benefits: the outcome stage model could directly
include country-level covariates (such as challenger's and target's
democracy) without having to convert them to a dyadic summary.
[This]{.underline} also [allows us to estimate the system of equations
jointly rather than relying on the **"forbidden
regression."**]{.underline} 8

[Second, a more daunting challenge]{.underline} in applying an IV
approach to democratic peace research [is the difficulty of finding a
**plausible instrument** for **regime type**]{.underline} [--- a
variable that is **strongly correlated** with **regime type** but is
**unrelated to war**. This is the challenge that has **plagued**
empirical researchers in many fields. For example, a recent
study]{.underline} of the effect of regime type on economic growth [uses
a **diffusion-based** measure]{.underline} of democracy (i.e., average
value of democracies in a given region) as an instrument for democracy
(Acemoglu et al. 2019). [However]{.underline}, diffusion-based
[instruments]{.underline} such as this [are unlikely to be]{.underline}
a **[valid]{.underline}** instrument, [due to **spatial spill-over**,
**interdependence**, and]{.underline}, most importantly,
**[simultaneity]{.underline}** (Betz, Cook, and Hollenbach 2018).
Recognizing problems with spatial instruments, McDonald (2015) seeks to
exploit the very discrepancy between country-level and dyad-level
designs as the source of identification. His discussion, however, lacks
a clear explanation as to why some determinants of regime type do not
influence conflict. 9

[We turn to a **demographic** variable]{.underline} --- average female
**[fertility rate]{.underline}** in a given country --- [as a source of
**variation in regime type** that is **exogenous** to international
conflict]{.underline}. As we will argue below, [a lower fertility rate
is a **strong driver** of democratization]{.underline}. We will
[also]{.underline} present theoretical arguments and a series of
falsification tests that support the claim that average national
**[fertility]{.underline}** rate [does **not**]{.underline} directly
[influence international **conflict**]{.underline}.

### Transition Wars -- Democracy -- 2NC

#### The [move]{.underline} to democracy [doubles]{.underline} the risk of [quick]{.underline} conflict AND goes [nuclear]{.underline}

Dr. Edward **Mansfield 22**, Hum Rosen Professor of Political Science
and Director of the Christopher H. Browne Center for International
Politics at the University of Pennsylvania, B.A., M.A., and Ph.D. from
the University of Pennsylvania, and Dr. Jack Snyder, Robert and Renee
Belfer Professor of International Relations in the Political Science
Department and the Saltzman Institute of War and Peace Studies at
Columbia University, Ph.D. in Political Science from Columbia
University, BA in Government from Harvard University, Conflict After the
Cold War: Arguments on Causes of War and Peace, Sixth Edition, Ed.
Betts, p. 331-332

DANGERS OF TRANSITION

[The idea that democracies never fight wars]{.underline} against each
other [has become an axiom]{.underline} for many scholars. It is, as one
scholar puts it, "as close as anything we have to an empirical law in
international relations." This "law" is invoked by American statesmen
[to justify]{.underline} a foreign policy that encourages
[democratization abroad]{.underline}. In his 1994 State of the Union
address, President Clinton asserted that no two democracies had ever
gone to war with each other, thus explaining why promoting democracy
abroad was a pillar of his foreign policy.

It is probably true that a world in which more countries were mature,
stable democracies would be safer and preferable for the United States.
[**But** countries do **not** become mature democracies **overnight**.
They usually go through a **rocky transition**, where mass politics
mixes with authoritarian elite politics in a volatile way. **Statistical
ev**idence covering the past two centuries shows that in **this
transitional phase** of democratization, countries become **more
aggressive and war-prone, not less**, and they do **fight wars** with
democratic states. In fact, formerly authoritarian states where
democratic participation is on the rise are **more likely** to fight
wars than are stable democracies or **autocracies**. States that make
the biggest leap]{.underline}, from total autocracy to extensive mass
democracy---like contemporary Russia---[are]{.underline} about [**twice
as likely** to fight wars]{.underline} in the decade [after
democratization as are states that remain **autocracies**]{.underline}.

[This **historical pattern** of **democratization**, **belligerent
nationalism**, and **war** is]{.underline} already
[emerging]{.underline} in some of today's new or partial democracies,
especially some formerly communist states. Two pairs of states---Serbia
and Croatia, and Armenia and Azerbaijan---have found themselves at war
while experimenting with varying degrees of electoral democracy. The
electorate of Russia's partial democracy cast nearly a quarter of its
votes for the party of radical nationalist Vladimir Zhirinovsky. Even
mainstream Russian politicians have adopted an imperial tone in their
dealings with neighboring former Soviet republics, and military force
has been used ruthlessly in Chechnya.

The following evidence should raise questions about the Clinton
administration's policy of promoting peace by promoting democratization.
[The expectation that the spread of democracy will probably contribute
to peace in the **long run**]{.underline}, once new democracies mature,
[provides **little comfort** to those who might face a heightened risk
of war in the **short run**. Pushing **nuclear-armed** great powers like
Russia or China **to**ward democratization is like **spinning a roulette
wheel**: many of the outcomes are undesirable]{.underline}. Of course,
in most cases the initial steps on the road to democratization will not
be produced by any conscious policy of the United States. The roulette
wheel is already spinning for Russia and perhaps will be soon for China.
Washington and the international community need to think not so much
about encouraging or discouraging democratization as about helping to
smooth the transition in ways that minimize its risks.

## Solvency

### Defense -- 1NC

#### Developing trust in AI is impossible\-\--black box problem means true integration is impossible

Erik **Lin-Greenberg 20**, postdoctoral fellow at the University of
Pennsylvania's Perry World House. Texas National Security Review, Vol 3,
Iss 2. Spring. \"Allies and Artificial Intelligence: Obstacles to
Operations and Decision-Making\"
<https://tnsr.org/2020/03/allies-and-artificial-intelligence-obstacles-to-operations-and-decision-making/>
//pipk

[AI can]{.underline} also [strain alliance decision-making by fueling
uncertainty about information and military actions. Unlike human
analysts or military personnel who can be asked to explain and justify
their findings or decisions, AI generally operates in a "black
box."]{.underline} 97 [The neural networks that underpin many
cutting-edge AI systems are opaque and offer little insight into how
they arrive at their conclusions.]{.underline}98 The[se networks rely on
deep learning, a process that passes information from large data sets
through a hierarchy of digital nodes that analyze data inputs and make
predictions using mathematical rules. As data flows through the neural
network, the net makes internal adjustments to refine the quality of
outputs. Researchers are often unable to explain how neural nets make
these internal adjustments. Because of this lack of "explainability,"
users of AI systems may have difficulty understanding failures and
correcting errors.]{.underline}99

[Policymakers have called for the development of more transparent AI
systems, and researchers are working to develop explainable AI tools
that peer inside the AI black box.100 Yet, **many decision-makers remain
uncomfortable with the uncertainty surrounding AI-enabled
systems**]{.underline}. The commander of the U.S. Air Force's Air Combat
Command, for instance, publicly explained that he was not yet willing to
rely on AI programs to analyze the full-motion video collected by
reconnaissance drones. He argued that although systems are improving,
they are still unable to consistently provide accurate analysis.101 So
long as the decisions and analysis of AI systems remain opaque, military
commanders may be reluctant to trust AI-enabled systems. And if used,
[AI may contribute to the fog of war, rather than reduce it, making it
difficult to make decisions using information delivered by AI
technologies]{.underline}.

**[The operational implications associated with uncertainty and lack of
trust in AI would likely be exacerbated in multinational alliance
contexts.]{.underline}** [There is significant cross-national variation
in trust in AI technologies, even among close allies.]{.underline} One
2018 survey, for instance, found that just 13 percent of respondents in
Japan and 17 percent of respondents in South Korea trust artificial
intelligence, compared to 25 percent of respondents in the United
States. Similar [disparities exist between the United States and many of
its NATO allies]{.underline}. In Spain, 34 percent of respondents trust
artificial intelligence, compared to 21 percent in Canada, 40 percent in
Poland, and 43 percent in Turkey.102 [Given this variation, policymakers
and commanders from some states may be more reluctant to use AI-enabled
systems or trust the information they deliver than leaders from other
states during multinational operations]{.underline}.

[Allied decision-makers will also face uncertainty when confronting a
rival's use of AI-enabled technologies. Leaders will be forced to
wrestle with whether to respond to actions carried out by AI-enabled
systems --- like autonomous aircraft or ships --- in the same way as
actions carried out by traditionally manned assets. Existing doctrine
and law are generally silent on these issues, providing no guidance on
the appropriate response]{.underline}. States have drafted domestic
policies to govern their own use of autonomous weapon systems, but these
regulations and international law make no distinction between how states
should react to a rival's AI-enabled military actions versus
"traditional" military actions.103 Yet, decision-makers may believe that
a rival's use of AI technologies demands different responses than those
involving manned platforms.104 What happens if a rival claims that an
attack carried out by an AI-enabled system was the result of a flawed
algorithm? Should air defense forces respond differently to an
adversary's autonomous drones that penetrate friendly airspace than to a
manned aircraft that does the same? Decision-makers may find themselves
with little time to consider these complicated issues, particularly as
AI technology accelerates the speed of a rival's military operations.

#### Data sharing is too hard\-\--integration is impossible

Erik **Lin-Greenberg 20**, postdoctoral fellow at the University of
Pennsylvania's Perry World House. Texas National Security Review, Vol 3,
Iss 2. Spring. \"Allies and Artificial Intelligence: Obstacles to
Operations and Decision-Making\"
<https://tnsr.org/2020/03/allies-and-artificial-intelligence-obstacles-to-operations-and-decision-making/>
//pipk

Data Sharing and Standardization

[As the number of states that employ military AI applications grows, the
ability of allies to operate collectively will depend, in part, on the
sharing of data that fuels AI systems. AI requires massive amounts of
data to train and feed algorithms and models]{.underline}. To identify a
surface-to-air missile site, for instance, an AI image classifier must
learn to differentiate missile sites from other facilities by studying
images of known missile sites. The more data used to train these
systems, the more accurate the system will be.66 Once fielded,
AI-enabled systems like the image classifier must continue to be fed
imagery from reconnaissance aircraft, satellites, or other assets in a
format that allows for target identification. Shared data might be
needed to enhance the accuracy of AI-enabled systems or to increase the
effectiveness of multinational operations. For example, some member
states may be better positioned than others to gather data on a shared
rival, increasing the amount of data available to AI systems.67

[Because of its central role in AI development and operations, the U.S.
military has described data as a "strategic asset," yet sharing data ---
even within the U.S. military --- has posed a significant
challenge]{.underline}.68 Lt. Gen. Jack Shanahan, founding director of
the Department of Defense's Joint Artificial Intelligence Center,
lamented that [data "has stymied most of the \[military\] services when
they dive into AI." Specifically, "they realize how hard it is to get
the right data to the right place, get it cleaned up, and train
algorithms on it.]{.underline}"69 [There are two primary factors that
underlie these challenges]{.underline}. [First, data resides in
thousands of different repositories and often lacks standardized
formatting]{.underline}. Video from the U.S. military's fleet of
reconnaissance aircraft, for instance, is stored on multiple separate
networks and in different data formats. Second, [significant amounts of
data collected by weapons and sensor systems are considered proprietary
by the contractors that design and maintain the equipment. Firms must
first release or "unlock" this data before it can be analyzed or fed
into other systems]{.underline}.70

[Although shared data is needed to develop AI technologies that can
integrate with allied equipment, states face both political and
technical barriers to sharing security sector information. From a
political standpoint, even the closest allies may be hesitant to share
the sensitive data that undergirds military AI systems]{.underline}.
States fear that sharing sensitive data might reveal intelligence
sources and methods, the revelation of which could compromise ongoing
operations or strain political relationships. During the Vietnam War,
for example, the United States was hesitant to share intelligence with
its ally South Vietnam. Officials feared that communist sympathizers in
the ranks of South Vietnam's military and intelligence services would
pass information to North Vietnam and the Vietcong. They were also
concerned that intelligence might highlight that the United States was
planning operations that did not align with South Vietnam's government
priorities.71 States also worry that shared information could be used
for purposes other than initially intended or in ways that are at odds
with the sharing state's interests. Turkey, for instance, may have used
intelligence shared as part of counter-Islamic State operations to
instead target Kurdish forces in northern Syria.72

[To minimize these perceived risks, states often impose restrictions on
information sharing]{.underline}. One of the most common control
measures is sharing only finished intelligence --- products such as
briefings or reports derived from a variety of different intelligence
sources.73 These products provide assessments, but generally omit
technical data --- like details about the information source --- that
could reveal intelligence-gathering procedures and methods. [Although
data sharing is a type of intelligence sharing, developing and operating
AI-enabled systems may require the exchange of more complete raw data in
far larger quantities than traditional intelligence
sharing]{.underline}. Raw data, which includes imagery files and signals
intercepts, can include metadata such as spectral signatures of imagery
or characteristics of electronic emissions that can be used to feed AI
systems.74 [Since this information can expose precise capabilities and
shortcomings of a state's intelligence systems, decision-makers may be
hesitant to share it --- especially in the large quantities needed to
develop and run many AI-enabled systems]{.underline}.

[There are also technical obstacles to data sharing]{.underline}. Just
as the U.S. intelligence community and military stores information in
nonstandardized formats on multiple systems, so too do national security
institutions in other allied states. [Across an alliance, the same type
of data might reside on hundreds of different networks and in different
formats, making it difficult to share data or to develop interoperable
systems.]{.underline} To [use data from other alliance partners, data
must first be located, transferred out of a state's classified computer
network, and reformatted into a standardized, usable form. Given that
the U.S. military has faced significant data management challenges in
its own AI development, we should expect alliances --- with their
greater number of institutional actors and data sources --- to encounter
even greater obstacles to data sharing]{.underline}.

Vulnerabilities: AI and Data

[In addition to barriers to sharing, allies face the possibility that
the data that they do share may be especially vulnerable to adversary
manipulation.]{.underline} Engineers and military leaders worry that
[rivals could hack into data repositories and "poison" data ---
inserting fake data or making existing data deliberately
flawed]{.underline}.75 In one recent academic study, researchers used
data poisoning to cause an algorithm designed to identify street signs
to misclassify stop signs as speed limit signs.76 [In the military
domain, a rival could poison imagery data in order to throw off AI
target recognition systems, leading the system to miss military targets,
classify them as nonmilitary ones, or identify civilian infrastructure
as military facilities. At best, this could require]{.underline}
manpower-[intensive efforts to secure and sanitize data or lead states
to turn back to manual analysis of targets. At worst, this could lead to
the inadvertent targeting of noncombatants]{.underline}.

[While the risk of data poisoning plagues all AI users, alliance
military operations may be particularly susceptible because data inputs
from multiple states are used to train and operate AI-enabled systems
across the alliance. Flawed data inputs from one state can therefore
have cascading effects across an alliance's operations. Rivals will
recognize that different members of an alliance defend their networks
and data with different levels of safeguards. As a result, rivals may
target data stored by states where they have easier
access]{.underline}.77

#### There's not enough AI workers to solve\-\--shortages means innovations won't be effective

Stefano **Costalli 21**, Associate Professor of Political Science in the
Department of Political and Social Sciences, University of Florence,
Italy and Research Fellow of the Michael Nicholson Centre for Conflict
and Cooperation, University of Essex. "NATO Decision-Making in the Age
of Big Data and Artificial Intelligence" Editors: Sonia Lucarelli;
Alessandro Marrone; and Francesco Niccolò Moro. Sonia Lucarelli is
Professor of International Relations and European Security at the
University of Bologna, and member of the Board of Directors of the
Istituto Affari Internazionali (IAI). Alessandro Marrone is Head of the
Defence Programme of IAI and teaches at the Istituto Superiore di Stato
Maggiore Interforze (ISSMI) of the Italian Ministry of Defence.
Francesco N. Moro is Associate Professor of Political Science at the
University of Bologna and Adjunct Professor of International Relations
at the Johns Hopkins University Europe Campus. This publication is the
result of the Conference "NATO Decision-making: promises and perils of
the Big Data age", organized by NATO Allied Command Transformation
(ACT), the University of Bologna and Istituto Affari Internazionali
(IAI) of Rome. <https://www.iai.it/sites/default/files/978195445000.pdf>
//pipk

[**A key requisite for all** organizational **innovations** to occur and
for Big Data analysis to be effective is the development and
incorporation of a **Big Data culture**]{.underline}. [Chief data
officers and senior data-related leadership positions will acquire
crucial importance in the analysis of information and in the actual
decision-making process, but these positions require a special mix of
talent and tools that are **currently scarce** in many large
organizations]{.underline}, especially in the public sector. [The
organizations]{.underline} that are [implementing big data analysis seem
especially in need of 'translators' -- professionals that can ensure
effective communication between the Big Data analysis unit and other
parts of the organization]{.underline}, where workers are not data
scientist and may not be ready to work directly on complex models.
[However, organizations willing to use Big Data are also in need of real
data scientists and analysts, because sophisticated techniques and data
analysis tools eventually rely on talented humans who know how to manage
the tools and interpret data]{.underline}. **[As a result, attracting
new]{.underline}** types of talented young **[workers]{.underline}** and
retaining them creating new career paths and opportunities **[will
represent both an essential organizational innovation and an important
challenge]{.underline}**.

In fact, some members of the WG highlighted that **[it will not even be
easy to find many workers with the appropriate knowledge and skills to
perform the new tasks in old and complex organizations.]{.underline}**
[It is possible to find computer scientists, but]{.underline} sometimes
[these]{.underline} individuals [do not]{.underline} seem to
[fit]{.underline} [well with large organizations whose main core
business has not much to do with computer science]{.underline}. At the
moment, **[it is even more difficult to find translators]{.underline}**,
since in principle these workers should be social scientists with an
expertise in Big Data analysis, but most academic institutions are not
ready to forge these profiles. [For]{.underline} what concerns
**[NATO]{.underline}** and national armed forces, [this educational task
is not even performed by military academies, even though some
experiments are emerging]{.underline}. [The ideal profile would include
technical awareness, quantitative analytical skills, broad vision,
flexibility and open-mindedness -- and this explains why it is not easy
to produce it.]{.underline}
