### 1NC -- AI "Arms Race" Kritik

#### There is no AI "Arms Race" -- global spending is not enough to warrant the Arms Race title -- it is just military modernization

**Scharre 2021 -- Director of the Technology and National Security
Program at the Center for a New American Security** \[Paul,
6/28/21,https://tnsr.org/2021/06/debunking-the-ai-arms-race-theory/,
"Debunking the AI Arms Race Theory", 6/18/22, LND\]

[The scale of military AI spending, at least at present, is nowhere near
large enough to warrant the title of "arms race."]{.underline} Of
course, AI can also be used for weapons. Militaries around the world are
actively working to adopt AI to improve their military capabilities. Yet
[the militarization of AI does not, at present, meet the traditional
definition of an arms race, despite the rhetorical urgency of many
national leaders]{.underline}. Michael D. [Wallace, in his 1979 article
"Arms Races and Escalation," defined an arms race as "involving
simultaneous abnormal rates of growth in the military outlays of two or
more nations]{.underline}" [resulting from "the competitive pressure of
the military itself, and not from domestic forces exogenous to this
rivalry."]{.underline} Wallace further stated that the concept of an
arms race only applied "between nations whose foreign and defense
policies are heavily interdependent" and who have "roughly comparable"
capabilities.[11](https://tnsr.org/2021/06/debunking-the-ai-arms-race-theory/#_ftn11)
AI is being adopted by many countries around the
globe.[12](https://tnsr.org/2021/06/debunking-the-ai-arms-race-theory/#_ftn12)
Arguably at least some of the dyads, such as the United States and
China, meet Wallace's definition in terms of being nations with "roughly
comparable" capabilities, locked in competition, "whose foreign and
defense policies are heavily interdependent[."]{.underline} However[, AI
fails the arms race test in the critical area of spending.]{.underline}
Wallace distinguished arms races from the normal behavior of states to
improve their military forces. [A state that adopts a new technology and
modernizes its military forces is not automatically in an arms race,
under Wallace's definition, even if the modernization is aimed at
competition with another country]{.underline}. [The decisive
facto]{.underline}r in qualifying as an arms race, according to
Wallace[, is the rate of growth in defense spending. Wallace
characterized arms races as resulting in abnormally large growth rates
in defense spending]{.underline}, beyond the historical average of 4 to
5 percent annual growth (in real dollars[). In an arms race, annual
growth rates are above 10 percen]{.underline}t or even as high as 20 to
25
percent.[13](https://tnsr.org/2021/06/debunking-the-ai-arms-race-theory/#_ftn13)
Other scholars define arms races using different quantitative thresholds
--- and some definitions lack clear quantitative thresholds at all ---
but [the existence of rapid increases in defense spending or military
forces above normal levels is a common criterion in the scholarly
literature on arms
races.[14](https://tnsr.org/2021/06/debunking-the-ai-arms-race-theory/#_ftn14)]{.underline}
[Arms races result in situations in which two or more countries are
locked in spiraling defense spending,]{.underline} grabbing ever-greater
shares of national treasure often with little to no net gain in relative
advantage over the other. Classic historical examples include the
Anglo-German naval arms race prior to World War I and the U.S.-Soviet
nuclear arms race during the Cold War. Military AI spending today
clearly does not meet these criteria of abnormally large growth rates in
defense spending. AI defense spending is difficult to calculate due to
the general-purpose nature of AI technology. Unlike ships or ballistic
missiles, AI systems cannot be easily counted. Nevertheless, [even crude
estimates of defense spending show that military AI investments are
nowhere near large enough to constitute an arms ra]{.underline}ce. [An
independent estimate by Bloomberg Government of U.S. defense spending on
AI identified]{.underline} \$5 billion in AI-related research and
development in fiscal year 2020, or [roughly 0.7 percent of the
Department of Defense's over \$700 billion
budget]{.underline}.[15](https://tnsr.org/2021/06/debunking-the-ai-arms-race-theory/#_ftn15)
The scale of military AI spending, at least at present, is nowhere near
large enough to warrant the title of "arms race." (Adding in private
sector spending, which constitutes the bulk of AI investment, would lead
to larger figures but would further belie the claim of an "arms" race
since most private sector AI investment is not in weapons.)

#### The Affirmative reinforces the Security Dilemma they described in the 1AC -- their discourse labelling AI as an "arms race" reinforces the perception of insecurity that they are "losing" a race that doesn't exist. This increases the risk of conflict -- hyperbolic rhetoric escalates rivalries.

**Roff 2019 -- Fellow in the Brookings Foreign Policy Program**
\[Heather, 4/26/19,
<https://www-tandfonline-com.proxy.lib.umich.edu/doi/full/10.1080/00963402.2019.1604836>,
"The Frame problem: The Ai 'Arms Race' isn't one', 6/18/22, LND\]

[Often,[12](https://www-tandfonline-com.proxy.lib.umich.edu/doi/full/10.1080/00963402.2019.1604836) one
hears the phrase "AI arms
race,"[13](https://www-tandfonline-com.proxy.lib.umich.edu/doi/full/10.1080/00963402.2019.1604836)
especially in regard to
competition[14](https://www-tandfonline-com.proxy.lib.umich.edu/doi/full/10.1080/00963402.2019.1604836)
between major powers. Yet an AI arms race seems a particularly
unfortunate and misleading phrase]{.underline}. Since
1957,[15](https://www-tandfonline-com.proxy.lib.umich.edu/doi/full/10.1080/00963402.2019.1604836)
myriad scholars have attempted to understand arms races, including how
one can identify and
measure[16](https://www-tandfonline-com.proxy.lib.umich.edu/doi/full/10.1080/00963402.2019.1604836)
them and what the potential effects of one are. While there have
certainly been academic and policy disputes over the last 62 years,
[there is one important consensus to note about arms races: looking at
one particular dimension of a state's behavior is not sufficient. Arms
races deal with military build ups, arms expenditures, rivalry,
alliances, territorial disputes, economic policies, and more. As yet,
however, there has been no coherent or comprehensive discussion about
the so-called AI arms race]{.underline}. For example[: How is AI by
itself a weapon? Or is the "race" merely military modernization efforts
that include automation, autonomy, or AI enabled military
systems?]{.underline} How would we even begin to find, label and
disaggregate the numbers to claim that there is an arms race between
rivals regarding only AI? Indeed, [the discussion of an AI arms
race]{.underline} [is reminiscent of the hyperbolic and mislabeled
rhetoric surrounding "cyber
bombs]{.underline}"[17](https://www-tandfonline-com.proxy.lib.umich.edu/doi/full/10.1080/00963402.2019.1604836)
in the battle again ISIS. Of course, there are quite spectacular claims
about AI's potential benefits and risks. Russian President Vladimir
Putin[18](https://www-tandfonline-com.proxy.lib.umich.edu/doi/full/10.1080/00963402.2019.1604836)
fanned that fire when he claimed that "whoever becomes the leader in
this space \[AI\] will become the ruler of the world." But talking about
technological competition -- in research, adoption, and deployment -- in
all sectors of multiple economies and in warfare is not really an arms
race. Indeed, [to frame this competition in military terms risks the
adoption of policies or regulations that could escalate rivalry between
states and increase the likelihood of actual conflict]{.underline}.
[More accurately stated, the current situation is one of AI competition,
with variations of technological proliferation and diffusion. In some
cases, countries may want to limit the amount and kinds of specific AI
systems that proliferate to other countries or non-state actors. In
these instances, it will more than likely be particular kinds of
components or platforms that are at issue.]{.underline} The
International Traffic in Arms Regulations (ITAR), the Export
Administration Regulations (EAR), the Wassenaar Arrangement on Export
Controls for Conventional Arms and Dual-Use Goods and Technologies, the
Australia Group, or the Missile Technology Control Regime are but a few
regimes that are meant to deal with such proliferation issues.

#### This turns the case -- the security dilemma pressures states to push out AI before it is safe, which causes it to fail, risking unintentional escalation of conflicts

**Horowitz and Kahn, 2021 -- Senior and Research Fellows at the Council
on Foreign Relations** \[Michael and Lauren, The Washington Quarterly
3-19-2021 "Leading in Artificial Intelligence through Confidence
Building Measures"
[https://www-tandfonline-com.proxy.lib.umich.edu/doi/full/10.1080/0163660X.2021.2018794
acc on
6-21-2022](%20https://www-tandfonline-com.proxy.lib.umich.edu/doi/full/10.1080/0163660X.2021.2018794%20acc%20on%206-21-2022%20)
TM\]

Risks exist for AI uses across society, in civilian and military sectors
alike.7 [Survey research shows that many in AI]{.underline} and machine
learning (ML) [communities worry about whether militaries can be trusted
to develop safe and reliable]{.underline} [AI]{.underline}.8 [Given the
current geopolitical context, there is fear that competitive pressures
to be first in deploying AI systems could overshadow safety and ethics
efforts, incentivizing militaries to take "short cuts" that could
increase the risk of lethal accidents, unintentional
conflict]{.underline} (conflict between states [that results from
miscommunication or accidents]{.underline}), [and inadvertent
escalation]{.underline} (when states commit intentional actions that
unintentionally cause escalation by an adversary). The Risk of Accidents
[First, military applications of AI may not work as intended due to
flaws in the algorithms themselves. Inadequate training data, the
algorithm's complexity, biased data, biased coding, or intentional data
sabotage or poisoning by adversaries can make accidents more
likely]{.underline} when systems are deployed. For example, a
malfunctioning AI-enabled targeting system in a conflict could attack
friends instead of foes, or friends and foes alike. Or an algorithmic
decision aid could derive a flawed estimate of the risk of a particular
operational plan, leading to a use of force that either unnecessarily
fails or succeeds at a greater cost than required. These risks are
amplified when systems are employed outside their design context, which
may be more likely due to competitive dynamics.9 The Risk of
Unintentional Conflict [Second, even if algorithms work as designed,
they could unintentionally make conflict more likely. Uncertainty about
how algorithms will work on the battlefield could create challenges for
signaling adversaries through posture and deployments in a
crisis]{.underline} or within a conflict. Actors might be uncertain
about how A Ienabled systems deployed by an adversary will behave. They
might not believe that AI-enabled autonomous systems are programmed as
described because the black-box nature of algorithms could lead to
increased skepticism of claims made about the systems. Even if a state
is telling the "truth" about a specific system and how it was used,
there might not be a way for a third party or another state to validate
those claims. Mistrust due to great power competition could exacerbate
the situation. [There is still substantial uncertainty about the
reliability of many AI methods, especially deep learning and related
techniques when they generate opaque outputs]{.underline}, meaning there
is not an available chain of logic which explains why the algorithm
recommended or engaged in a particular action.10 Even with sufficient
training data, hedges against biases, and protections from data
poisoning and hacking, [current DoD systems may not be prepared for
testing, evaluation, validation, and verification (TEVV) of algorithmic
systems, particularly AI-enabled autonomous systems that will
continually learn while operating]{.underline}.11 Furthermore, in
operating at machine speed, AI-enabled autonomous systems could cause
adversaries in a conflict to fear losing a war so quickly that they feel
compelled to escalate.12 [For an adversary with nuclear weapons, this
could create pressure for launch postures such as pre-delegation and
launch on warning that increase the chance of nuclear use]{.underline}.

#### Reject their Rhetoric of an "Arms Race" -- changing our discourse is necessary to head off constructed insecurity and escalation

**Roff 2019 -- Fellow in the Brookings Foreign Policy Program**
\[Heather, 4/26/19,
<https://www-tandfonline-com.proxy.lib.umich.edu/doi/full/10.1080/00963402.2019.1604836>,
"The Frame problem: The Ai 'Arms Race' isn't one', 6/18/22, LND\]

[Diffusion, however, is a different animal]{.underline}. Widely
available commercial off the shelf components, a widely available and
open source knowledge base, and wide access to large amounts of data
make limiting the diffusion of AI knowledge almost impossible. There are
necessary ingredients for AI, including access to computing power and
sufficient amounts of data. Some actors possess more of these
ingredients than others, but that advantage does not preclude
individuals, groups, companies, or states from obtaining access to and
knowledge about AI[. As greater emphasis is placed on the economic and
security benefits of using AI systems, AI will become more diffused
because the incentive structure rewards diffusion. Managing the risks of
proliferation]{.underline} and diffusion of a knowledge base [is an
entirely different enterprise than restraining an arms
race.]{.underline} [In the case of artificial intelligence, rather than
looking at what sorts of actions are required for deterrence, what
balances may affect conflict onset or escalation, world leaders should
turn their focus to how to foster responsible competition.]{.underline}
[Mitigating the risks associated with AI is not a single-shot
activity]{.underline}. Certainly there are technological solutions, such
as researching new ways of testing, verifying, and validating systems
that include the technologies that fall under the AI umbrella. There
even may be novel ways of constraining unwanted system behaviors by
generating new architectures or safety controls. [Ultimately, however,
reducing the risks that AI will be abused requires a reframing of the
way in which we think, talk, write about, and deploy AI.]{.underline}
The problems of AI misuse are human problems; they are problems
exhibited by all dual-use technologies, not just AI. Control of
artificial intelligence lies with humans, because they are the moral
agents responsible for the design, development, and deployment of AI.

#### Our alternative turns their impacts -- only rejecting the "Arms Race" discourse allows global AI collaboration, which is essential its development.

**Huang and Scott, 2018 - Chief Executive Officer and Chief Technology
Officer at Malong Technologies** \[Dinglong and Matt July 21 World
Economic Forum "Who will win the AI race? If countries work together,
then the answer could be all of us"
https://www.weforum.org/agenda/2018/06/ai-arms-race-global-collaboration/,
BK\]

As an artificial intelligence company with co-founders from China and
the United States, we get this question a lot. The premise behind it is
straightforward: [many believe that China will soon challenge the
current leader in AI, the United States. An arms race is imminent, or so
the thinking goes, and the smart move is for each national government to
fund its own AI]{.underline} programme to make sure its citizens don't
miss out. We recognize we might be shouting into the wind a little bit,
but [we want to challenge part of that thinking and suggest a way to
look beyond competition among nation-states. The AI community is global.
We do our best work when we work together across
boundaries]{.underline}. It has been like that for a long time. Here are
some quick examples: 1. The seminal paper on deep neural nets was
published in 2009 by Geoff Hinton, a Brit working at the University of
Toronto. One of his co-authors was Li Deng, who is Chinese and was
working at Microsoft Research in Redmond. 2. Andrew Ng, who trained
computers to recognize cats in videos for a research project at Google,
was born in the United Kingdom to parents who were from Hong Kong. He
spent much of his childhood in Singapore before studying in the US. 3.
Another leading light in AI is Yann LeCun, from France, now working for
Facebook and New York University. 4. And Microsoft Research's Rick
Rashid, from Iowa, brought us the first Chinese-English real-time
translation demonstration in Tianjin in 2012 thanks to a team of experts
from China, the US, the UK and Germany. At Malong Technologies, we've
tried to reflect and extend that heritage of global collaboration. We're
co-founded by a Chinese national from Shenzhen and an American from New
York City. We have offices and teams in China, the US, and Japan, and we
have expansion plans that include South America and Europe in the near
term. We are active in the Association of Asia-Pacific Universities, the
Asia-Pacific Economic Cooperation, the G20 Young Entrepreneurs Alliance
and other multinational groups along with our new membership in the
World Economic Forum's 2018 Technology Pioneers. [Being global gives the
AI community dynamism, creativity and accountability]{.underline}. It
imposes broad obligations to present, share and defend our ideas and
techniques against the best in the world. Irrespective of where we're
located, we have to be aware of one another's work. [If anyone tried to
wall themselves off from the rest of the global AI community, keeping
their work to themselves, their own work would slow down, wither and
die. There's a mutual interdependence based on transparency in pursuit
of the best ideas for the field and ultimately, for
humanity]{.underline}. That is what drives progress more than any
competition among nation-states.

### 

### \--Extend No Arms Race

#### "Arms Race" claims are exaggerated -- the AI adoption process is routine continuation of modernization

**Horowitz and Scharre, 2021 - Director of the Emerging Capabilities
Policy Office in the Office of the Under Secretary of Defense for Policy
and  Vice President and Director of Studies at CNAS** \[Michael, Paul,
January 12 2021, "AI and International Stability: Risks and Confidence-
Building Measures",
<https://www.cnas.org/publications/reports/ai-and-international-stability-risks-and-confidence-building-measures>,
Acc 6/18/22. M.A.\]

AI is a general-purpose technology akin to computers or the internal
combustion engine, not a discrete technology like missiles or aircraft.
Thus, while [concerns of an "AI arms race" are overblown,]{.underline}
real risks
exist.[2](https://www.cnas.org/publications/reports/ai-and-international-stability-risks-and-confidence-building-measures#fn2)
[Additionally, despite the rhetoric of many national leaders, military
spending on AI is relatively modest to date]{.underline}. [Rather than a
fervent arms race, militaries' pursuit of AI looks more like routine
adoption of new technologies and a continuation of the multi-decade
trend of adoption of computers, networking, and other information
technologies. Nevertheless, the incorporation of AI into national
security applications and warfare poses genuine risks]{.underline}.
Recognizing the risks is not enough, however. [Addressing them requires
laying out suggestions for practical steps states can take to minimize
risks stemming from military AI
competition.[3](https://www.cnas.org/publications/reports/ai-and-international-stability-risks-and-confidence-building-measures#fn3)
One approach states could take is adopting confidence-building
measures]{.underline} (CBMs): [unilateral]{.underline}, bilateral,
[and]{.underline}/or [multilateral actions that states can take to build
trust and prevent inadvertent military conflict]{.underline}. CBMs
generally involve using transparency, notification, and monitoring to
attempt to mitigate the risk of
conflict.[4](https://www.cnas.org/publications/reports/ai-and-international-stability-risks-and-confidence-building-measures#fn4)
There are challenges involved in CBM adoption due to differences in the
character of international competition today versus during the Cold War,
when CBMs became prominent as a concept. However, considering
possibilities for CBMs and exploring ways to shape the dialogue about AI
could make the adoption of stability-promoting CBMs more likely.

**There is no global sprint or arms race -- "Arms Race" claims
overexaggerate normal military behavior and ignore actual spending.**

**Perry and Scharre, 2020 - Project Coordinator at the Future of Life
Institute and Director of the Technology and National Security Program
at the Center for a New American Security** \[Lucas and Paul; March 16
\"AI Alignment Podcast: On Lethal Autonomous Weapons with Paul
Scharre,\"
<https://futureoflife.org/2020/03/16/on-lethal-autonomous-weapons-with-paul-scharre/?cn-reloaded=1>
Acc 2/2/21 TA\]

Paul Scharre: [If there's an arms race, it's a very strange one because
no one is building the weapons. We see militaries advancing in robotics
and autonomy, but we don't really see sort of this rush to build
autonomous weapons. I struggle to point to any programs]{.underline}
that I'm aware of in militaries [around the globe that are clearly
oriented to build fully autonomous weapons]{.underline}. I think there
are lots of places where much like these incremental advancements of
autonomy in cars, you can see more autonomous features in military
vehicles and drones and robotic systems and missiles. [They're adding
more autonomy. And one might be violently concerned about]{.underline}
where that's going. [But it's just simply not the case that militaries
have declared their intention]{.underline}. We're going to build
autonomous weapons, and here they are, and here's our program to build
them. [I would struggle to use the term arms race]{.underline}. It could
happen, maybe worth a starting line of an arms race. But I don't think
we're in one today by any means. [It's worth]{.underline} also [asking,
when we say arms race, what do we mean and why do we care? This is
again, one of these terms, it's often thrown around. You'll hear about
this, the concept of autonomous weapons or AI, people say we shouldn't
have an arms race. Okay.]{.underline} Why? [Why is an arms race a bad
thing? Militaries normally invest in new technologies to improve their
national defense. That's a normal activity]{.underline}. So if you say
arms race, what do you mean by that? Is it beyond normal activity? And
why would that be problematic? In the political science world, the
specific definitions vary, but generally, an arms race is viewed as an
increase in defense spending overall, or in a particular technology area
above normal levels of modernizing militaries. Now, usually, this is
problematic for a couple of reasons. One could be that it ends up just
in a massive national expenditure, like during the case of the Cold War,
nuclear weapons, that doesn't really yield any military value or
increase anyone's defense or security, it just ends up net flushing a
lot of money down the drain. That's money that could be spent elsewhere
for pre K education or healthcare or something else that might be
societally beneficial instead of building all of these weapons. So
that's one concern. Another one might be that we end up in a world that
the large number of these weapons or the type of their weapons makes it
worse off. Are we really better off in a world where there are 10s of
thousands of nuclear weapons on hair-trigger versus a few thousand
weapons or a few hundred weapons? Well, if we ever have zero, all things
being equal, probably fewer nuclear weapons is better than more of them.
So that's another kind of [concern whether in terms of violence and
destructiveness of war, if a war breakout or the likelihood of war and
the stability of war]{.underline}. [This is]{.underline} an A in [an
area where certainly we're not in any way from a spending standpoint, in
an arms race for autonomous weapons or AI today, when you look at actual
expenditures, they're a small fraction of what militaries are spending
on]{.underline}, if you look at, say AI or autonomous features at large.

#### AI is different from other Arms Races -- it is not exclusively military, which means there is less advantage to moving first

**Horowitz, 2018 -- Professor of Political Science at UPenn** \[Michael,
September "The Algorithms of August: The AI arms race won\'t be like
previous competitions, and both the United States and China could be
left in the dust,"
https://foreignpolicy.com/2018/09/12/will-the-united-states-lose-the-artificial-intelligence-arms-race/
6/18/22 MD\]

[AN [ARTIFICIAL
INTELLIGENCE](https://go-gale-com.proxy.lib.umich.edu/ps/i.do?p=AONE&u=umuser&id=GALE%7CA556838648&v=2.1&it=r) ARMS
RACE IS COMING. It is Unlikely to play out in the way that the
mainstream media suggest, however: as a faceoff between the United
States and China. That\'s because AI differs from the
technologies]{.underline}, such as nuclear
[weapons](https://go-gale-com.proxy.lib.umich.edu/ps/i.do?p=AONE&u=umuser&id=GALE%7CA556838648&v=2.1&it=r)
and battleships, that have been the subject of arms races in the past.
After all, [AI is software\--not hardware. Because AI is a general
purpose
[technology](https://go-gale-com.proxy.lib.umich.edu/ps/i.do?p=AONE&u=umuser&id=GALE%7CA556838648&v=2.1&it=r)]{.underline}\--more
like the combustion engine or electricity than a weapon\--[the
competition to develop it will be broad, and the line between its
civilian and military uses will be blurry.]{.underline} [There will not
be one exclusively military AI arms race. There will instead be many AI
arms races]{.underline}, as countries (and, sometimes, violent nonstate
actors) develop new algorithms or apply private sector algorithms to
help them accomplish particular tasks. In North America, the private
sector invested some \$15 billion to \$23 billion in AI in 2016,
according to a McKinsey Global Institute report. That\'s more than 10
times what the U.S. government spent on unclassified AI programs that
same year. The largest share came from companies such as Google and
Microsoft, as well as a number of smaller private firms, not from
government-funded defense research. This reverses the dynamic from the
Cold
[War](https://go-gale-com.proxy.lib.umich.edu/ps/i.do?p=AONE&u=umuser&id=GALE%7CA556838648&v=2.1&it=r),
when government investments led to private sector innovation and
produced technologies such as GPS and the internet. China says it
already holds more than 20 percent of patents in the field and plans to
build its AI sector to be worth \$150 billion by 2030. But while Beijing
and Washington are the current leaders in this race, they are not the
only competitors. Countries around the world with advanced technology
sectors, from Canada to France to Singapore, also have the potential to
make great strides in AI (or build on lower-level advances made by
others). While this diffusion means that many more countries will have a
stake in the regulation of AI, it also means that many more governments
will have incentives to go it on their own. UNLIKE THE DEVELOPMENT of a
Stealth bomber, which has only military applications, [basic AI research
has both military and civilian uses, which makes it much harder to keep
research secret and thereby sustain a large first-mover
advantage.]{.underline} [The dual-use character of many developments in
AI creates an incentive to promote their release and spread]{.underline}
to the general public. That means companies can co-opt advances made by
market leaders\--especially lower-level advances that do not require
significant computing hardware.

**Autonomous weapons won't cause an Arms Race -- just because countries
develop them doesn't mean that they are in a hostile race.**

**Horowitz, 2019 - Professor of Political Science, University of
Pennsylvania** \[Michael C. May 2"When Speed Kills: Autonomous Weapon
Systems, Deterrence, and Stability" https://ssrn.com/abstract=3348356\]

Arms Races or Proliferation? [It is important to distinguish arms races
from the proliferation of military technologies.]{.underline} The
scientists in the example above compared an LAWS arms race to the spread
of Kalashnikovs, but there was never an arms race in Kalashnikovs --
they just spread rapidly because they were cheap, easy to produce, and
useful.39 Huntington's classic work on arms races distinguishes between
proliferation and arms races. Countries can increase their arms
acquisitions due to an "absolute need" that exists "regardless of the
actions of other states", or for economic reasons.40 Huntington argues
that [many things described as arms races are simply general buildups
due to military necessity]{.underline} (or for economic reasons[),
rather than a specific buildup due to a particular disagreement between
states.]{.underline}41 For example, after their debut in World War I,
countries around the world acquired tanks in the 1920s and 1930s. Tanks
then became a critical part of ground warfare in World War II and
subsequent conventional ground combat operations. Yet few would call the
spread of tanks in the 1920s and 1930s an arms race. It was simply
proliferation that was not possible to stop, as large-caliber guns,
caterpillar tracks, and the combustion engine were available to
countries around the world.42 [To the extent that those concerned about
an arms race in autonomous weapon technologies are actually concerned
with proliferation, some degree of proliferation may be inevitable
simply due to the underlying factors involved in the production of
LAWS]{.underline}. As Horowitz argues, military capabilities diffuse
faster when, on the technology acquisition side, there is underlying
commercial demand and the unit costs are low.43 [Commercial markets are
already driving the integration of artificial intelligence into several
areas of the US and global economies, through deep learning and machine
learning applications]{.underline}.44 From Google search to Macy's
shopping assistance for customers, artificial intelligence is
increasingly embedded in commercial sectors of modern society.45 Narrow
applications of AI could become increasingly integrated into most
economic sectors, with many algorithms, once developed, now available to
many actors.46 Export controls are unlikely to stop basic narrow AI
capabilities from spreading, even if more advanced applications are
beyond the capacity of most companies and governments; government
regulations generally lag emerging technologies. Finally, AI innovation
is occurring around the world, not just in the United States or even the
West. Machine learning capabilities designed for commercial purposes
could also have spillovers with useful applications to the military
realm. This would reverse the Cold War dynamic in the West, where US
civilian economic innovations such as GPS often spun out of military
development programs.47 Artificial intelligence, as described above, is
more an enabler such as the combustion engine than a weapon. It is
therefore different than a platform like stealth technology, which
really only has military purposes.

#### Framing AI as an arms race assumes that AI is only a weapon -- it is beneficial in many other contexts

**Scharre 2021 -- Director of the Technology and National Security
Program at the Center for a New American Security** \[Paul,
6/28/21,https://tnsr.org/2021/06/debunking-the-ai-arms-race-theory/,
"Debunking the AI Arms Race Theory", 6/18/22, LND\]

As Heather Roff has written, the [arms race framing "misrepresents the
competition going on among
countries."]{.underline}[5](https://tnsr.org/2021/06/debunking-the-ai-arms-race-theory/#_ftn5)
To begin with, AI is not a weapon. AI is a general-purpose enabling
technology with myriad applications. It is not like a missile or a tank.
It is more like electricity, the internal combustion engine, or computer
networks.[6](https://tnsr.org/2021/06/debunking-the-ai-arms-race-theory/#_ftn6)
General-purpose technologies like AI have applications across a range of
industries. Wired magazine co-founder Kevin Kelly has argued [that it
"will enliven inert objects, much as electricity did more than a century
ago.]{.underline} Everything that we formerly electrified we will now
cognitize."[7](https://tnsr.org/2021/06/debunking-the-ai-arms-race-theory/#_ftn7)
Nations may very well be in a technology race to adopt AI across a range
of industries[. AI will help to improve economic productivity and, by
extension, economic and military power.]{.underline} During the
industrial revolution, early adopters of industrial technology
significantly increased their national power. From 1830 to 1890, Britain
and Germany, which were both early industrializers, more than doubled
their per capita gross national product while Russia, which lagged in
industrialization, increased its per capita gross national product by a
mere 7 percent over that 60-year
period.[8](https://tnsr.org/2021/06/debunking-the-ai-arms-race-theory/#_ftn8)
These technological advantages led to increased economic and military
power, most notably for Europe relative to the rest of the world. In
1790, Europe (collectively), China, and India (including what is now
Pakistan and Bangladesh) held roughly the same shares of global
manufacturing output, with Europe and India each holding about
one-quarter of global manufacturing output and China holding roughly
one-third. They all had approximately equivalent levels of per capita
industrialization at that time. But the industrial revolution
skyrocketed European economic productivity. By 1900, Europe collectively
controlled 62 percent of global manufacturing output, while China held
only six percent and India less than two percent. These economic
advantages translated into military power. By 1914, Europeans occupied
or controlled over 80 percent of the world's land
surface.[9](https://tnsr.org/2021/06/debunking-the-ai-arms-race-theory/#_ftn9)
[Being ahead of the curve in adopting AI is likely to lead to
significant national advantages. Although AI can increase military
capabilities, the more consequential advantages over the long term may
come from non-military AI applications across society.]{.underline}
Long-term benefits from AI could include increased productivity,
improved healthcare outcomes, economic growth, and other indicators of
national well-being[. Increasing productivity is especially significant
because it has a compounding effect on economic growth. Over the long
term, technological progress is the main driver of economic
growth.]{.underline}

### \--Extend "Arms Race" Discourse Links

#### The Rhetoric of an AI Arms Race sparks a race to the bottom -- states will deploy unsafe weapons to get them out before their competitors

**Scharre, 2019 - Vice President and Director of Studies at CNAS**
\[Paul, May-June, "Killer Apps: The Real Dangers of an AI Arms Race,"
https://omnilogos.com/killer-apps-real-dangers-of-ai-arms-race/6/18/22
MD\]

The nation that leads in the development of artificial intelligence
will, Russian President Vladimir Putin proclaimed in 2017, \"become the
ruler of the world.\" That view has become commonplace in global
capitals. Already, more than a dozen governments have announced national
AI initiatives. In 2017,
[China](https://go-gale-com.proxy.lib.umich.edu/ps/i.do?p=AONE&u=umuser&id=GALE|A585763278&v=2.1&it=r)
set a goal of becoming the global leader in AI by 2030. Earlier this
year, the White House released the American AI Initiative, and the U.S.
Department of Defense rolled out an AI strategy. But [the]{.underline}
emerging [narrative of an \"AI [arms
race](https://go-gale-com.proxy.lib.umich.edu/ps/i.do?p=AONE&u=umuser&id=GALE|A585763278&v=2.1&it=r)\"
reflects a mistaken view of the risks from AI\--and introduces
significant new risks as a result.]{.underline} For each country, [the
real danger is not that it will fall behind]{.underline} [its
competitors in AI]{.underline} [but that the perception of a race will
prompt everyone to rush to deploy unsafe AI systems. In their desire to
win, countries risk endangering themselves just as much as their
opponents.]{.underline} AI promises to bring both enormous benefits, in
everything from health care to transportation, and huge risks. But those
risks aren\'t something out of science fiction; there\'s no need to fear
a robot uprising. The real threat will come from humans. [Right now, AI
systems are powerful but unreliable. Many of them are vulnerable to
sophisticated attacks or fail when used outside the environment in which
they were trained]{.underline}. [Governments want their systems to work
properly, but competition brings pressure to cut corners]{.underline}.
[Even if other countries aren\'t on the brink of major AI breakthroughs,
the perception that they\'re rushing ahead could push others to do the
same.]{.underline} And [if a government deployed an untested AI weapons
system]{.underline} [or relied on a faulty AI system to launch
cyberattacks]{.underline}, [the result could be disaster for everyone
involved.]{.underline} [Policymakers should]{.underline} learn from the
history of computer networks and make security a leading factor in AI
design from the beginning. They should also [ratchet down the rhetoric
about an AI arms race and look for opportunities to cooperate with other
countries to reduce the risks from AI.]{.underline} [A race to the
bottom on AI safety is a race no one would win.]{.underline}

#### "Arms Race" rhetoric creates a self-fulfilling prophecy by causing states to cut corners on AI development and testing

**Scharre, 2019 - Vice President and Director of Studies at CNAS**
\[Paul, May-June, "Killer Apps: The Real Dangers of an AI Arms Race,"
https://omnilogos.com/killer-apps-real-dangers-of-ai-arms-race/6/18/22
MD\]

[When it comes to]{.underline} applying [AI]{.underline} to national
security[, government agencies will have to reconsider their traditional
approaches to testing new systems.]{.underline} Verifying that a system
meets its design specifications isn\'t enough. Testers also need to
ensure that it will continue to function properly in the real world when
an adversary is trying to defeat it. In some cases, they can use
computer simulations to tease out bugs, as manufacturers now do for
autonomous cars. On top of that, the Departments of Defense and Homeland
Security and the intelligence community should create red teams\--groups
that act as attackers to test a system\'s defenses\--to ferret out
vulnerabilities in AI systems so that developers can fix them before the
systems go live. [Government officials should]{.underline} also [tone
down their rhetoric about an AI arms race]{.underline}, [since such talk
could easily become self-fulfilling.]{.underline} At a conference in
2018, [Michael Griffin, the chief Pentagon official for research and
engineering, said,]{.underline} \"[There might be an artificial
intelligence arms race, but we\'re not yet in it]{.underline}.\"
[Militaries are certainly going to adopt AI]{.underline}, [but
Griffin\'s statement was missing any concern for\--or even awareness
of\--the risks that come with it]{.underline}. [Talk of an arms race
encourages adversaries to cut corners on safety. Government officials
should emphasize]{.underline} not only the value of AI but also [the
importance of guaranteeing reliability and security.]{.underline}

### \--Extend Security Dilemma Links

#### US AI deployment is driven by the fear that China will take the lead.

**Scharre, 2019 - Vice President and Director of Studies at CNAS**
\[Paul, May-June, "Killer Apps: The Real Dangers of an AI Arms Race,"
https://omnilogos.com/killer-apps-real-dangers-of-ai-arms-race/6/18/22
MD\]

WHAT AI WILL DO [Whichever country takes the lead on AI will use it to
gain]{.underline} economic and [military advantages over its
competitors.]{.underline} By 2030, AI is projected to add between \$13
trillion and \$15 trillion to the global economy. AI could also
accelerate the rate of scientific discovery. In 2019, an artificial
neural network significantly outperformed existing approaches in
synthetic protein folding, a key task in biological research. [AI
is]{.underline} also [set to revolutionize warfare.]{.underline} It will
likely prove most useful in improving soldiers\' situational awareness
on the battlefield and commanders\' ability to make decisions and
communicate orders. [AI systems can process more information than
humans, and they can do it more quickly, making them valuable
tools]{.underline} for assessing chaotic battles in real time. [On the
battlefield itself, machines can move faster and with greater precision
and coordination than people.]{.underline} In the recent AI-versus-human
StarCraft match, the AI system, AlphaStar, displayed superhuman
abilities in rapidly processing large amounts of information,
coordinating its units, and moving them quickly and precisely. In the
real world, [these advantages will allow AI systems to manage swarms of
robots far more effectively than humans could by controlling them
manually]{.underline}. Humans will retain their advantages in
higher-level strategy, but AI will dominate on the ground.
[Washington\'s rush to develop AI is driven by a fear of falling behind
China]{.underline}, which is already a global powerhouse in AI. The
Chinese technology giants Alibaba, Baidu, and Tencent rank right
alongside Amazon, Google, and Microsoft as leading AI companies. Five of
the ten AI startups with the most funding last year were Chinese. Ten
years ago, China\'s goal of becoming the global leader in AI by 2030
would have seemed fanciful; today, it\'s a real possibility.

#### US deployment of Autonomous Weapons is driven by the perception of "falling behind" in an AI arms race

**Sosanya, 2022 - AI researcher and a policy analyst at the Day One
Project** \[Andrew, Jan 3, Peace Review A Journal of Social Justice
"Autonomous Weapons Are Here to Stay"
<https://www-tandfonline-com.proxy.lib.umich.edu/doi/full/10.1080/10402659.2021.1998856>
TM\]

Great powers cannot afford to be idle in the face of technological
innovation. [Today, clear signs that leading militaries are preparing
for]{.underline} the inevitable warfare of tomorrow exist: [a future
with autonomous weapons]{.underline}. With promising technology that is
still in the research and development (R&D) phase, [states act
cautiously as the future has become doubly uncertain: they cannot
predict their adversaries' intentions]{.underline}, nor can they predict
the usefulness of the weapon. [In the United States, Department of
Defense (DoD) leaders have indicated their willingness to deploy
them]{.underline}. In 2017, Lieutenant General Jack [Shanahan,
the]{.underline} then-[Director of DoD's Joint AI Center, stated that he
"does not want to see a future where our potential adversaries have a
fully AI-enabled force and we do not]{.underline}." The DoD has
upstarted numerous programs in the last decade dedicated to autonomy,
covering robotics, swarms, target recognition, machine learning, and
more. [Shanahan had cited China and Russia's military AI R&D as a reason
for the DoD's increased focus on improving their own militarized
artificial intelligence]{.underline}. [Former Secretary of Defense Bob
Work]{.underline}, who oversaw the 2017 revision of the DoD's autonomous
weapons policy, [corroborated Shanahan's thinking, that the United
States would deploy autonomous weapons if their adversaries do
first]{.underline}.

### \--Extend "Arms Race" Turns Case

#### The global misperception of an "Arms Race" forces states to rush deployment which inevitably leads to accidents. There is no arms race currently 

**Scharre 2021 -- Director of the Technology and National Security
Program at the Center for a New American Security** \[Paul,
6/28/21,https://tnsr.org/2021/06/debunking-the-ai-arms-race-theory/,
"Debunking the AI Arms Race Theory", 6/18/22, LND\]

In 2015, a group of prominent AI and robotics researchers signed an open
letter warning of the dangers of autonomous weapons. ["The key question
for humanity today," they wrote, "is whether to start a global AI arms
race or to prevent it from starting. If any major military power pushes
ahead with AI weapon development, a global arms race is virtually
inevitable]{.underline}."[1](https://tnsr.org/2021/06/debunking-the-ai-arms-race-theory/#_ftn1)
[Today, many nations are working to apply AI for military advantage, and
the term "AI arms race" has become a catchphrase]{.underline} used by
both critics and proponents of AI militarization[. In 2018, then-Under
Secretary of Defense Michael Griffin, calling for the United States to
invest more in AI, stated, "There might be an artificial intelligence
arms race, but we're not yet in
it."]{.underline}[2](https://tnsr.org/2021/06/debunking-the-ai-arms-race-theory/#_ftn2)
In a 2020 Wired article, Will Roper, then chief acquisition officer for
the U.S. Air Force, warned of the risks of falling behind in a "digital
arms race with
China."[3](https://tnsr.org/2021/06/debunking-the-ai-arms-race-theory/#_ftn3)
The so-called AI arms race has become a common feature in news
headlines,[4](https://tnsr.org/2021/06/debunking-the-ai-arms-race-theory/#_ftn4)
but the [arms race framing fails to match reality. While nations are
clearly competing to develop and adopt AI technology for military use,
the character of that competition does not meet the traditional
definition of an arms race. Military AI competition nevertheless does
pose risks. The widespread adoption of military AI could cause warfare
to evolve in a manner that leads to less human control and to warfare
becoming faster, more violent, and more challenging in terms of being
able to manage escalation and bring a war to an end. Additionally,
perceptions of a "race" to field AI systems before competitors do could
cause nations to cut corners on testing, leading to the deployment of
unsafe AI systems that are at risk of accidents that could cause
unintended escalation or destruction.]{.underline} Even if fears of an
"AI arms race" are overblown, military AI competition brings real risks
to which nations should attend. There are concrete steps nations can
take to mitigate some of these dangers.

#### "Arms Race" mentality pressures rapid deployment of weapons -- militaries skip critical testing and evaluation. 

**Horowitz and Scharre 2021 - Director of the Emerging Capabilities
Policy Office in the Office of the Under Secretary of Defense for Policy
and  Vice President and Director of Studies at CNAS** \[Michael, Paul,
January 12 2021, "AI and International Stability: Risks and Confidence-
Building Measures",
<https://www.cnas.org/publications/reports/ai-and-international-stability-risks-and-confidence-building-measures>,
Acc 6/18/22. M.A.\]

An additional challenge stems from security dilemma dynamics.
[Competitive pressures could lead nations to shortcut test and
evaluation (T&E) in a desire to field new AI capabilities ahead of
adversaries]{.underline}. [Similar competitive pressures to beat others
to market appear to have played an exacerbating role in accident risk
relating to AI systems in self-driving cars and commercial airplane
autopilots]{.underline}.[23](https://www.cnas.org/publications/reports/ai-and-international-stability-risks-and-confidence-building-measures#fn23) [Militaries
evaluating]{.underline} an [AI]{.underline} system of uncertain
reliability could, not unjustifiably, [feel pressure to hasten
deployment if they believe others are taking similar
measures.]{.underline} Historically, these pressures are highest
immediately before and during wars, where the risk/reward equation
surrounding new technologies can shift due to the very real lives on the
line. For example, competitive pressures may have spurred the faster
introduction of poison gas in World War
I.[24](https://www.cnas.org/publications/reports/ai-and-international-stability-risks-and-confidence-building-measures#fn24) Similarly,
in World War II, Germany diverted funds from proven technologies into
jet engines, ballistic missiles, and helicopters, even though none of
the technologies proved mature until after the
war.[25](https://www.cnas.org/publications/reports/ai-and-international-stability-risks-and-confidence-building-measures#fn25) This
dynamic risk might spark a self-fulfilling prophecy in which [countries
accelerate deployment of insufficiently tested AI systems out of the
fear that others will deploy
first]{.underline}.[26](https://www.cnas.org/publications/reports/ai-and-international-stability-risks-and-confidence-building-measures#fn26) [The
net effect is not an arms race but a "race to the bottom" on safety,
leading to the deployment of unsafe AI systems and heightening the risk
of accidents and instability]{.underline}.

**The Rhetoric of an AI Arms Race sparks a race to the bottom -- states
will deploy unsafe weapons to get them out before their competitors**

**Scharre, 2019 - Vice President and Director of Studies at CNAS**
\[Paul, May-June, "Killer Apps: The Real Dangers of an AI Arms Race,"
https://omnilogos.com/killer-apps-real-dangers-of-ai-arms-race/6/18/22
MD\]

The nation that leads in the development of artificial intelligence
will, Russian President Vladimir Putin proclaimed in 2017, \"become the
ruler of the world.\" That view has become commonplace in global
capitals. Already, more than a dozen governments have announced national
AI initiatives. In 2017,
[China](https://go-gale-com.proxy.lib.umich.edu/ps/i.do?p=AONE&u=umuser&id=GALE|A585763278&v=2.1&it=r)
set a goal of becoming the global leader in AI by 2030. Earlier this
year, the White House released the American AI Initiative, and the U.S.
Department of Defense rolled out an AI strategy. But [the]{.underline}
emerging [narrative of an \"AI [arms
race](https://go-gale-com.proxy.lib.umich.edu/ps/i.do?p=AONE&u=umuser&id=GALE|A585763278&v=2.1&it=r)\"
reflects a mistaken view of the risks from AI\--and introduces
significant new risks as a result.]{.underline} For each country, [the
real danger is not that it will fall behind]{.underline} its competitors
in AI [but that the perception of a race will prompt everyone to rush to
deploy unsafe AI systems. In their desire to win, countries risk
endangering themselves just as much as their opponents.]{.underline} AI
promises to bring both enormous benefits, in everything from health care
to transportation, and huge risks. But those risks aren\'t something out
of science fiction; there\'s no need to fear a robot uprising. The real
threat will come from humans. Right now, AI systems are powerful but
unreliable. Many of them are vulnerable to sophisticated attacks or fail
when used outside the environment in which they were trained.
[Governments want their systems to work properly, but competition brings
pressure to cut corners]{.underline}. [Even if other countries aren\'t
on the brink of major AI breakthroughs, the perception that they\'re
rushing ahead could push others to do the same.]{.underline} And [if a
government deployed an untested AI weapons system]{.underline} [or
relied on a faulty AI system to launch cyberattacks]{.underline}, [the
result could be disaster for everyone involved.]{.underline}
[Policymakers should]{.underline} learn from the history of computer
networks and make security a leading factor in AI design from the
beginning. They should also [ratchet down the rhetoric about an AI arms
race and look for opportunities to cooperate with other countries to
reduce the risks from AI.]{.underline} [A race to the bottom on AI
safety is a race no one would win.]{.underline}

### \--Extend "Arms Race" Impacts

#### The Arms Race mentality limits our thinking about AI -- it prevents global collaboration, which is critical to get the most out of the technology

**Huang and Scott, 2018 - Chief Executive Officer and Chief Technology
Officer at Malong Technologies** \[Dinglong and Matt July 21 World
Economic Forum "Who will win the AI race? If countries work together,
then the answer could be all of us"
https://www.weforum.org/agenda/2018/06/ai-arms-race-global-collaboration/,
BK\]

Why, then, the fixation? We suggest three reasons, starting with the
most obvious: China's 2017 declaration of support for AI as a national
priority got the world's attention, and other nations have followed
suit. Second, the great places to work for the world's best talent now
include cities in China. We're in Shenzhen, Beijing and Shanghai, and
can observe our peer AI companies also thriving in these cities. Third,
[the amount of seed capital and venture capital investment available in
China]{.underline} to support great companies is robust and according to
some studies, [exceeds that of the US for the first time]{.underline}.
[This need not be something to fear]{.underline}. [The most promising
near-term AI applications are those that are supported by globally
relevant data, and will help people wherever they happen to
live.]{.underline} Take medical technology. Everyone looks the same on
the inside, and everyone can benefit from AI-enabled solutions that lead
to faster, more accurate diagnoses and more effective treatment. Or take
manufacturing and agriculture. AI-driven improvements and efficiencies
will bring benefits where the factories and farms are[. We aren't
arguing for nations to abandon homegrown efforts to support AI research,
investment and entrepreneurship]{.underline}. In fact, we see them as
something to celebrate and encourage. We expect great people, ideas and
companies to continue to show up all over the world, with all the
attendant benefits in terms of job creation and economic growth. There
are indeed amazing things going on not only in the US and China, but
also in Canada and Europe, Korea and Japan. It's genuinely an
international phenomenon. [Problems come when we limit our thinking to
nation-vs-nation competition]{.underline}. It bogs down our progress.
[There cannot be a Chinese AI vs an American AI]{.underline} vs a French
AI, and so on. [Instead, those national efforts must contribute to
global cooperation and collaboration]{.underline} if AI is to advance
and bring benefits to all communities worldwide. Let the companies do
the competing.

#### Engaging in an AI arms race undermines US security and stability, and drains resources from more important causes. 

**Garcia, 2021 - Vice-chair of the International Committee for Robot
Arms Control** \[Denise, May 13, 2021, Nature.com, "Stop the emerging AI
cold war,"
<https://www.nature.com/articles/d41586-021-01244-z#:~:text=Proliferating%20military%20artificial%20intelligence%20will,on%20ethics%20and%20global%20cooperation.&text=Denise%20Garcia%20is%20a%20professor,Committee%20for%20Robot%20Arms%20Control>.,
6/18/22 MD\]

[A race to militarize artificial intelligence is gearing
up.]{.underline} Two years ago, the US Congress created the [National
Security](https://go-gale-com.proxy.lib.umich.edu/ps/i.do?p=ITOF&u=umuser&id=GALE|A661476451&v=2.1&it=r)
Commission on Artificial Intelligence (NSCAI). This March, it
recommended that the [United
States](https://go-gale-com.proxy.lib.umich.edu/ps/i.do?p=ITOF&u=umuser&id=GALE|A661476451&v=2.1&it=r)
must accelerate artificial-intelligence (AI) technologies to preserve
national security and remain competitive with China and Russia. [This
will undermine the United States\' ability to lead emerging global norms
on AI.]{.underline} In April, the European Commission published the
first international legal framework for making AI secure and ethical; in
January, the European Parliament issued guidelines stating that military
AI should not replace human decisions and oversight. By contrast, the
NSCAI recommendations advocate \"the integration of AI-enabled
technologies into every facet of war-fighting\". [Enhancing AI
war-fighting capacity will decrease security in a world where the
biggest threats are instability \-- political, social, economic and
planetary]{.underline}. The NSCAI should heed the research community.
Some 4,500 AI and
[robotics](https://go-gale-com.proxy.lib.umich.edu/ps/i.do?p=ITOF&u=umuser&id=GALE|A661476451&v=2.1&it=r)
researchers have declared that AI should not make the decision to take a
human life \-- aligning with the European Parliament guidelines and the
European Union regulation. [The NSCAI resurrected disastrous ideas from
the cold war and framed its report in terms of winning a competition for
AI-enabled warfare.]{.underline} [During the cold war, the drive to stay
ahead in the technological race led to]{.underline} the accumulation of
70,000 nuclear weapons and today\'s global arsenal of 13,100 warheads.
This brought [extortionate costs: US\$70 billion is spent annually to
maintain nuclear weapons globally.]{.underline} Other threats demand
similar investments: in 2019, climate-induced natural disasters
displaced 25 million people, and decentralized conflicts forced 8.6
million to move. Still more threats affect infrastructure, such as the
ransomware attack on 8 May that shut down a 8,850-kilometre US fuel
pipeline. The NSCAI does not prioritize international cooperation to
create new regulations. Indeed, it speaks against a global ban on
autonomous weapons, saying that other countries cannot be trusted to
comply. But [an AI-militarization race would be profoundly
destabilizing]{.underline}. Unlike nuclear arms, AI is already
ubiquitous in civilian spheres, so the dual-use risks of, say, flying
drones or computer night
[vision](https://go-gale-com.proxy.lib.umich.edu/ps/i.do?p=ITOF&u=umuser&id=GALE|A661476451&v=2.1&it=r)
are much higher. Since 2014, I have been an observer and adviser at
United Nations meetings, and I testified in 2017 as part of the
International Panel on the Regulation of Autonomous Weapons. In my view,
rather than focusing on counting weapons or on particular weapons
systems, policies should specify human intention and human-machine
interaction, obligating countries to maintain human control over
military force. Other agreements could mitigate malicious uses of AI,
such as using facial recognition to oppress citizens or biased data to
guide decisions about employment or incarceration. The world\'s people
need protection from cyberattacks to infrastructure \-- such as those on
US hospitals in 2020 or those that hit national electrical grids. The
NSCAI report calls for international standards for AI-enabled and
autonomous weapons systems, arguing that if these systems are properly
tested and designed, humans can use them to make the decision to kill,
consistent with international humanitarian law. This is misleading:
it\'s difficult to make machine learning\'s \'black box\' nature fully
interpretable, or to ensure that AI systems perform as expected after
deployment. These systems learn from their environment, and the real
world is never as simple as the laboratory. The NSCAI argues that the
United States should seek commitments from Russia and China against
autonomous nuclear weapons, even as it argues against treaties
regulating other autonomous and AI weapons. Instead, the United States
should negotiate decreases in nuclear arsenals and establish standards
to keep humans in meaningful control. The NSCAI is too dismissive by
discounting cooperation. The Chemical Weapons Convention, the Biological
Weapons Convention, the UN Sustainable Development Goals and the 1987
Montreal Protocol are examples of accountability on which all the major
powers worked together. The United States and Russia established the
International Space Station by cooperating closely. Most nations want
governance that controls the use of AI in war. In June 2020, the Global
Partnership on Artificial Intelligence was created by the Group of Seven
industrialized countries (G7) and called for human-centric development
and use of AI. The partnership brings scientific and research
communities together with industry and government to facilitate
international cooperation. This is the path that the United States
should take \-- with scientists, researchers and industry alike. The
relentless pursuit of [militarization does not protect us]{.underline}.
[It diverts resources and attention from nearer existential
threats]{.underline}, such as extreme weather events. With the world
reeling from COVID-19 \-- the shock of the century \-- [now is not the
moment to hasten towards worldwide confrontation]{.underline}. In 2019
alone, climate disasters displaced almost one million people in the
United States. China, too, is extremely vulnerable to global warming.
This common ground could pave the way to cooperation, including stopping
the emerging AI cold war. [This is no time to embark on an exorbitant
and ineffective race]{.underline}.

### \--Extend Reject "Arms Race" Rhetoric

#### Rejecting the Arms Race framing is essential to prevent the Abuse of the technology

**Roff 2019 -- Fellow in the Brookings Foreign Policy Program**
\[Heather, 4/26/19,
<https://www-tandfonline-com.proxy.lib.umich.edu/doi/full/10.1080/00963402.2019.1604836>,
"The Frame problem: The Ai 'Arms Race' isn't one', 6/18/22, LND\]

[There needs to be a change in thinking about AI. Those dealing with AI
must insist on greater clarity about its definition. If policy makers
and other leaders are not clear about what the term means and entails,
they cannot possibly formulate best practices and governance
mechanisms]{.underline}. It would help matters if artificial
intelligence discussions were framed in an "AI +" framework, [because in
many cases, AI is merely a tool included in a system involving other
functions or capabilities. The news media should stop framing the global
artificial intelligence competition as an "arms race." This
misrepresents the competition going on among countries.]{.underline} The
policy community needs a clear-eyed appraisal of AI's capabilities and
limitations. Without that orientation, those who hope to steer research
and development in positive directions will create more problems than
they solve. [Last year, colleagues and I in the "AI Safety" community
published a
paper[1](https://www-tandfonline-com.proxy.lib.umich.edu/doi/full/10.1080/00963402.2019.1604836)
on the potential misuses of artificial intelligence and potential
interventions to lessen the likelihood and impact of
misuse.]{.underline} Because of the dual-use nature of artificial
intelligence, its almost ubiquitous nature, and its potential to create
threats -- either new or in combination with previously existing threats
-- we recommended that policy makers and others involved in AI efforts
begin to respond immediately. In many cases, my coauthors have done just
that. For example, OpenAI -- an organization that hopes to ensure
artificial general intelligence benefits humanity and that includes some
of my co-authors -- recently
refused[2](https://www-tandfonline-com.proxy.lib.umich.edu/doi/full/10.1080/00963402.2019.1604836)
to publish the full model of its GPT-2 algorithm, which can generate
synthetic natural language text -- that is, articles, answers to reading
comprehension questions, and other types of writing -- of "unprecedented
quality." OpenAI realized that GPT-2 could help malicious actors
generate disinformation and abusive content, increasing the likelihood
of fraud based on impersonation. So they released only a smaller version
of the GPT-2 code, dataset, and related information. That decision has
been met with both
derision[3](https://www-tandfonline-com.proxy.lib.umich.edu/doi/full/10.1080/00963402.2019.1604836)
and
applause.[4](https://www-tandfonline-com.proxy.lib.umich.edu/doi/full/10.1080/00963402.2019.1604836)
[Others]{.underline}[5](https://www-tandfonline-com.proxy.lib.umich.edu/doi/full/10.1080/00963402.2019.1604836)
[have]{.underline} also [begun]{.underline}
serious[6](https://www-tandfonline-com.proxy.lib.umich.edu/doi/full/10.1080/00963402.2019.1604836)
and
[rigorous[7](https://www-tandfonline-com.proxy.lib.umich.edu/doi/full/10.1080/00963402.2019.1604836)
work at the policy and technology nexus, pushing for
responsible]{.underline} and
ethical[8](https://www-tandfonline-com.proxy.lib.umich.edu/doi/full/10.1080/00963402.2019.1604836)
[design, development, and deployment of AI technologies.]{.underline}
But there are other development and [policy changes that could help head
off potential abuses of AI]{.underline}. First, there needs to be a
change in thinking about, and framing of, AI. In particular, those
dealing with AI must insist on greater clarity about its definition. If
policy makers and other leaders are not clear about what the term means
and entails, they cannot possibly formulate best practices and
governance mechanisms. Also, it would help matters if artificial
intelligence discussions were framed in an "AI +" framework, because in
many cases, AI is merely a tool included in a system involving other
functions or capabilities -- for example, artificial intelligence might
be a part of a driverless vehicle that involves many technologies.
Finally, [I certainly hope that scholars, practitioners, policy makers,
and especially the news media stop framing the global artificial
intelligence competition as an "arms race." This framing misrepresents
the competition going on among countries. To address the risks of AI,
the policy community needs a clear-eyed appraisal of its capabilities
and limitations]{.underline}. [Without that orientation, those who hope
to steer AI research and development in positive directions will create
more problems than they solve.]{.underline}
