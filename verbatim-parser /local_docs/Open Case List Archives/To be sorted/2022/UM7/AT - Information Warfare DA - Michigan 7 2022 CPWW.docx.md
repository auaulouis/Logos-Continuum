## Aff Answers

### 2AC -- Aff Solves

#### Any information from Russia still leads to [inaction]{.underline}\-\--triggers our impacts and means they [cannot solve]{.underline}

**Grimes 22** (David Robert Grimes, scientist and author of Good
Thinking: Why Flawed Logic Puts Us All at Risk and How Critical Thinking
Can Save the World (The Experiment). His work focuses on health
disinformation and conspiracy theory, and he is an international
advocate for the public understanding of science. He is a recipient of
the Nature/Sense about **Science Maddox Prize**, and a fellow of the
**Committee for Skeptical Inquiry**; [\"Russian Misinformation Seeks to
**Confound, Not Convince**: Rather than take a side, these campaigns
create **decision paralysis** that leads to **inaction\"**]{.underline},
3-28-2022, Scientific American,
https://www.scientificamerican.com/article/russian-misinformation-seeks-to-confound-not-convince/,
DOA: 7-16-2022)//sposten

As war envelops Ukraine, [Russian sources have strived to create a
**miasma** of disinformation about the invasion.]{.underline} Among
ample efforts to distort reality, [the Russian Ministry of Defense
**asserted** recently that **U.S.-backed labs** in Ukraine have been
**developing bioweapons.**]{.underline} Outlandish as this falsehood may
be, Fox's Tucker Carlson gave it credence by arguing that the U.S.
government's response was a "cover-up."

[As the Russia-Ukraine war intensifies, so too will]{.underline} the
flow of [disinformation. This is an **age-old strategy**]{.underline}
Russia has long history of employing, and a playbook that others, most
notably anti-vaccine activists, have borrowed from liberally. Yet,
[rather than focusing effort on convincing people of a falsehood, the
Russian strategy takes a tack reminiscent of a strategy long employed by
the tobacco industry: to sow **so much doubt**]{.underline} about what
is true [that it sends people into **decision paralysis.**]{.underline}
Faced with a cacophony of wild and conflicting claims, [people do
nothing, unsure of what is right.]{.underline}

Despite constituting only a small part of our media diet, disinformation
campaigns, in our digital world, can be devastatingly effective. [We are
intrinsically biased towards information that is **emotionally
visceral.** We afford more weight to content that **frightens** or
outrages us]{.underline}, with the ability to induce anger serving as
the single greatest predictor of whether content goes viral. [This
propels the most visceral, divisive narratives to the **forefront** of
discourse]{.underline}, creating a sound and fury of passionately
debated claims and counter claims. In that atmosphere, [it becomes
**increasingly difficult** to ascertain what to **believe**, and easy to
abandon]{.underline} the task of [discerning the truth.]{.underline}

If we are not to fall victim to such rank dishonesty, [it is crucial now
that we question our sources]{.underline} more [carefully]{.underline}
than ever before.

Indecision and distraction have long been central to Russia's
dezinformatsiya (disinformation) policy, a term Stalin himself is
credited with coining. While an ancient concept, [Russia]{.underline}
had by the imperial age mastered dark obfuscation techniques refined for
the era of mass communication. By the dawn of the Soviet empire, they
realized this potential on an industrial scale, [establishing the
world\'s first office dedicated to disinformation in 1923.]{.underline}
In the 1960s, the KGB covertly sponsored American fringe groups,
amplifying conspiratorial narratives about everything from the
assassination of president John F. Kennedy to water fluoridation.

The goal, as KGB Major General Oleg Kalugin elucidated in 1998, was "not
intelligence collection, but subversion: [active measures to **weaken**
the West, to **drive wedges** in the Western community alliances of all
sorts, particularly **NATO**, to **sow discord** among allies, to
**weaken** the United States **in the eyes** of the people of Europe,
Asia, Africa, Latin America\...."]{.underline}. [Operation
INFEKTION]{.underline}, a mid-1980s clandestine effort to spread the
myth that AIDS was a CIA-designed bioweapon, was but one infamous
exemplar. While utterly fictious, it [resonated with communities ravaged
by HIV and neglected by the callous indifference of the Reagan
administration.]{.underline} Despite Russian intelligence taking
responsibility for this lie in 1992, the legacy of AIDS denialism
persists to this day worldwide.

[During the Cold War]{.underline}, the doctrine of ["active measures"
was the **beating heart** of Soviet intelligence]{.underline}. This
philosophy of political and information warfare had wide remit,
including front groups, media manipulation, counterfeiting, infiltrating
peace groups and even the occasional assassination.

And in our media-saturated era, [Russia has been, by far,
disinformation's **most enthusiastic user.** Take the 2016 U.S.
presidential election and the contentious Brexit
referendum]{.underline}; Russia appears to have influenced both via lies
and distortions.

But disinformation is not solely confined to geopolitics. By summer
2020, the European Commission identified a concerted Russian drive to
propagate COVID disinformation worldwide. From the outset of the
pandemic, [Kremlin-backed]{.underline} troll farms pushed the narrative
that COVID was an engineered bioweapon, peddling the explosive [fiction
that **5G radio frequencies** caused the **virus**]{.underline}---a lie
that resulted in dozens of arson attacks on cell towers worldwide.

There is a dark irony in the observation that conspiracy-minded people
can be weaponized in plots to which they're entirely oblivious. The
enduring popularity of the virus-as-a-bioweapon mantra is a stark
reminder that in the age of social media, such manipulation has become
ever easier and more effective. Perhaps the most odious example of this
is the cynical rise of anti-vaccine propaganda.

The sheer efficacy of vaccination is scientifically incontrovertible,
and after clean water, immunization is the most life-saving intervention
in human history. Despite this, the last decade has witnessed
precipitous drops in vaccine confidence worldwide. The renaissance of
once-virtually-conquered diseases prompted the [WHO]{.underline} to
[declare vaccine hesitancy a **top-10 threat** to public
health]{.underline} in 2019.

Vaccine hesitancy is a spectrum rather than a simple binary, and
[exposure to anti-vaccine conspiracy theories ***nudges*** recipients
towards rejection.]{.underline} But critically, [many who decline
vaccination are **not dyed-in-the-wool** anti-vaccine zealots, but
simply]{.underline} scared by what they have heard, [**unsure** what to
believe.]{.underline} Our tendency towards the illusory truth effect
exacerbates this inertia, as the mere repetition of a fiction is enough
to prime us to accept it, even if we know it to be false on an
intellectual level. [While Russia has often amplified anti-vaccine
conspiracy theories to increase tensions, the anti-vaccine movements
exist independently of these efforts,]{.underline} and are masters at
sowing the seeds of doubt with torrents of conflicting and emotive
claims.

[This illustrates]{.underline} the grim reality [that disinformation has
**no need for consistency** and **zero commitment to objective
reality**; claims are]{.underline} frequently [**contradictory**,
arguing **both sides** of the coin]{.underline} in exaggerated and
divisive ways. [This "Russian firehose" model]{.underline} of propaganda
[is **high-output**, **contradictory** and
**multichannel**]{.underline}. The stream encourages us to sleepwalk
into apathy, distrustful of everything. [This **renders us** supremely
**malleable**, and dangerously **disengaged**.]{.underline}

When it comes to vaccination, concerned parents often opt to stay with
the devil they know, delaying or even rejecting vaccination rather than
sifting through the symphony of conflicting claims to which they're
subjected. Similarly, the outpouring of fictions about Ukraine, its
president, Volodymyr Zelensky, and [the war is designed to **overwhelm
our capacity to analyze**, inducing us to **implicitly accept
uncertainty** over aggressor and aggrieved---a manufactured doubt
benefitting Russia and other nations.]{.underline}

[**Conviction** is **not** the chief **goal** of disinformation;
**instilling doubt is**. This is why anti-vaccine activists have been so
**successful online**, and why **Russian troll-farms** push **ample
resources** into **hawking lies** virtually everywhere. The ubiquity of
these fictions gives them]{.underline} an implicit veneer of
[legitimacy, fueling polarization and distrust.]{.underline}

[This is the strategy Putin **continues to pursue**]{.underline};
already [Russian propaganda has tried to **paint Ukraine** (or NATO /
America) as **aggressors** with **staged disinformation.**]{.underline}
This has been rendered less effective by the Biden administration's
creative approach of releasing intelligence prior to the operation.
Across social media, [Russian front organizations still try to induce
doubt, efforts that **will** only **intensify**]{.underline} as the war
wages on. [**Truth**, the old adage insists, is the first **casualty of
war.**]{.underline}

#### Open-source intel [solves]{.underline}\-\--only a risk of [decreasing misinformation]{.underline} since the [truth]{.underline} is *already there*

**Glover 22** (Claudia Glover; \"Open-source intelligence key to
fighting Russian disinformation during Ukraine war\", 6-7-2022, Tech
Monitor,
https://techmonitor.ai/technology/emerging-technology/open-source-intelligence-ukraine-war,
DOA: 7-16-2022)//sposten

[Open source intelligence can be **vital** in the fight against
disinformation]{.underline}, according to a study released today which
assesses the impact of novel and emerging technologies on the spread of
false information during the Ukraine war. [While open data can be
harnessed positively to fight disinformation, those deploying it must
also be **aware of the risks**, security experts say.]{.underline}

[The report]{.underline}, entitled 'The Information Battlefield:
Disinformation, declassification and deepfakes' [was
released]{.underline} today [to mark the]{.underline} launch of the
Centre for Emerging Technology and Security ([CfETS]{.underline}), [a
new research centre at the Alan Turing Institute for
a]{.underline}rtificial [i]{.underline}ntelligence [which aims to boost
the UK's security by giving policy makers **better information** about
**emerging technologies.**]{.underline}

CfETS will aim to take an 'innovative approach' in a bid to help
'maintain the UK as a leading voice in international security'.

["The launch of this centre comes at a crucial time -- technology is
advancing at an increasingly rapid rate and emerging technologies
present both opportunities and threats to UK national
security,"]{.underline} said Sir Adrian Smith, director of The Alan
Turing Institute. "Our centre will bring together defence and security
expertise from around the world to ensure that policymakers have access
to the highest quality analysis and research. It will provide us with
new opportunities to keep the UK safe."

Open source intelligence and the war in Ukraine

The inaugural report from CfETS looks at the role of [disinformation
used by Russia during the war in Ukraine, and how emerging technologies
have helped and hindered its spread. Russia]{.underline} has
[used]{.underline} well-[established tactics to try and influence both
Russian and Ukrainian citizens, spreading disinfo]{.underline}rmation
[through social media using misleading posts and videos.]{.underline}

Open source intelligence (OSINT), publicly available data which can be
analysed by professionals and citizens alike, has played a significant
role in countering these false statements. "Data about this conflict
have been more accessible to western audiences than ever before,"
explain the authors. "Commercial satellite imagery showed Russia's
military build up around Ukraine's borders in the weeks preceding the
invasion."

They cite the example of Nasa's Fire Information for Resource Management
System, which uses satellite imagery to detect active fires. It showed
in near real-time the location of heat spots indicative of Russian
attacks, at a time when the Russian government was denying the war and
blaming attacks on Ukrainian terrorist groups.

"I think [open source intelligence is one of the biggest **thorns** in
the **Russian side**,"]{.underline} says Alexi Drew, senior analyst in
defence, security and infrastructure at thinktank RAND Europe.
["Particularly in the way that we've adapted to debunking and
pre-emptively engaging with some of the false narratives that Russia has
tried to set loose on the international stage."]{.underline}

This effort has been encouraged by Western intelligence agencies
declassifying and releasing sensitive material into the public domain,
the report says. "By outlining Russia's plans for invasion and revealing
Russia's attempts at falsifying a pretext for action, these
declassifications have helped to counter Russia's disinformation among
Western audiences," it says.

### 2AC -- AT: Europe Free Speech Bad

#### Europe's free speech measures are [good]{.underline}, and the US [has to change]{.underline} its policies\-\--prefer evidence from social media [insiders]{.underline}

**Haugen 22** (Frances Haugen, former Facebook product manager who
focused on combating misinformation and espionage; **[\"Europe Is Making
Social Media Better Without Curtailing Free Speech. The U.S. Should,
Too\"]{.underline}**, 4-28-2022, New York Times,
https://www.nytimes.com/2022/04/28/opinion/social-media-facebook-transparency.html,
DOA: 7-16-2022)//sposten

[Elon Musk's deal to take Twitter private, which has spurred questions
about power, censorship and safety for the future of the platform,
happened just days after the European Union reached a landmark agreement
to make social media less toxic for users.]{.underline} The new [E.U.
standards]{.underline}, and the ethic of transparency on which they are
based, [will]{.underline} for the first time [**pull back the curtain**
on the **algorithms** that choose what we see and when we see it in our
feeds.]{.underline}

In Europe's case, [the]{.underline} dryly named
**[D]{.underline}**igital **[S]{.underline}**ervices
**[A]{.underline}**ct [is the **most significant** piece of social media
legislation in history. It goes to the heart of what I've tried to do as
a whistle-blower who worked inside Facebook: **make social media far
better without impinging on free speech.**]{.underline} Today,
[Facebook's poorly implemented content moderation strategies leave those
most at risk of real-world violence **unprotected** and consistently
succeed at only one thing: angering everyone.]{.underline}

Last October, I came forward with a simple message:
[Facebook]{.underline} knew it [was **cutting corners** to make more
money]{.underline}, and the public was paying the price. In over 20,000
pages of documents that I disclosed to the Securities and Exchange
Commission and to Congress, the public learned what Facebook already
knew --- [its products were **spurring hate and division**]{.underline},
leading teenagers into rabbit holes of self-harm and anorexia, leaving
millions of users without basic safety systems for hate speech or
violence incitement and, at times, were [even used to **sell humans**
across the platform.]{.underline}

Global companies had chosen profit-maximizing strategies at the expense
of the public interest before. We've seen it with pollution in the
chemical industry, environmental damage in natural resource extraction
and predatory mortgages in financial services.

[What distinguishes the bad practices of these other industries from Big
Tech is simple --- there are laws holding them **accountable.** That's
what **government** is **intended** to do in **democratic
capitalism**]{.underline}: use the law to steer the market back into
alignment with the public interest. [When concentrated monopolistic
power privileges the few over the many and distorts how the free market
operates, this kind of correction is **vital.**]{.underline}

How the new European law is carried out will be just as important as
passing it. It is a broad and comprehensive set of rules and standards,
not unlike food safety standards for cleanliness and allergen labeling.
But what is also remarkable about it is that it focuses on oversight of
the design and implementation of systems (like how algorithms behave)
rather than determining what is good or bad speech.

The law requires that Facebook and other large social platforms be
transparent about what content is being amplified and shared virally
across the platform. And it must apply consumer protections to features
that, among other things, spy on users, addict kids or weaken public
safety. With transparency finally required, it will be easier for
European regulators and civil society to verify that companies are
following the rules.

These rules are like systems in the United States that compel
pharmaceutical companies to keep drugs safe and to allow the Food and
Drug Administration to independently verify the results. Most people
aren't aware of them, but we're all glad they are there.

[The new requirement for access to data will allow **independent
research** into the impact of social media products on public health and
welfare.]{.underline} For example, Facebook, Instagram and others will
have to open up the black box of which pages, posts and videos get the
most likes and shares --- shining light on the outcomes of the
algorithms.

This will allow thousands more people, not just those who work at these
companies, to address the complex problems of how information markets
change social outcomes. As an algorithmic specialist and data scientist,
I'm most excited by this. No longer will we depend on taking the
companies' word for it when they say they are trying to fix a safety
problem. Democratic and investor accountability and oversight of big
companies boils down to whether we can accurately diagnose the problems
their products are causing, devise solutions and verify that the
industry is actually following through with them. The era of "just trust
us" is over.

Why did this happen in Europe? Why not right here in America, which
birthed these incredible technologies? Europe knows Facebook's
censorship strategies fail societies where many languages are spoken
because they require censorship systems to be built one language at a
time. Only the strategy of focusing on product safety works equitably in
every language, even less-spoken ones.

[Europe is approving changes Congress has been trying to secure --- with
a slate of bipartisan bills --- for several years.]{.underline} But, in
the United States, Facebook's and Instagram's owner, Meta, invests
heavily in lobbyists and communications specialists in response to
concerns about hate speech, conspiracy theories and misinformation.

[The industry has **falsely framed** the way forward as a choice between
**free speech** and **safety.**]{.underline} Meta claims it would love
for everyone to be safe, but that safety would come at the cost of free
speech. [The documents in my disclosures paint a different picture: Meta
knows that the product choices it's made give the most reach to the most
divisive and extreme ideas, and it knows how to unwind those choices to
prioritize having **human judgment** direct our attention **instead of
just computers.** Ideas include **cracking down on robots** that
**amplify disinformation**, requiring users to **click a link before
resharing it**, or helping more intentionally drive the distribution of
information by having users copy/paste content shared outside friends of
friends. These are **product choices** that can **reduce** hate speech,
harmful content and **misinformation.**]{.underline}

So [why hasn't Facebook fully implemented them? These changes add
friction and **slightly delay** the spread of **content**]{.underline},
which also means slightly slowing down the growth of Facebook's profits.
[Facebook's **laser focus** on **quarterly returns** has stolen an
opportunity to build for long-term success]{.underline}; we're more
likely to be using Facebook 10 years from now if it's safe and enjoyable
to use. [**Arguing** over censorship works only to **further Facebook's
self-interest** --- while also wrapping our friends, neighbors and
legislators into **angry knots** that are impossible to
untie.]{.underline}

### 2AC -- AT: HR Impact

#### Human rights frameworks are extremely [complex]{.underline} and [difficult]{.underline} to [execute]{.underline}

**Vandenhole and Gready 14** (Wouter Vandenhole, Professor, Faculty of
Law, University of Antwerp, Belgium; Paul Gready, Professor, Centre for
Applied Human Rights, University of New York, USA; "Failures and
Successes of Human Rights-Based Approaches to Development: Towards a
Change Perspective," Nordic Journal of Human Rights,
<https://www.researchgate.net/publication/280217460_Failures_and_Successes_of_Human_Rights-Based_Approaches_to_Development_Towards_a_Change_Perspective>,
October 2014)//sposten

III\. HRBADs and Organisational Change Logically preceding a solid
understanding of the complexity of social change is the need to better
understand what it takes [for an organisation to introduce an
HRBAD]{.underline} with a view to bring about social change successfully
in the first place. Both in change theory and organisations theory, it
has been emphasised that [views on change and on how organisations
change are very often based on **implicit assumptions**.]{.underline}
Both sets of [theories also point out the **complexity** of
(organisational) change]{.underline}, and [the existence of many
different and often **competing approaches** or **"schools"**, with some
emphasising **structural constraints**]{.underline} (i.e. constraints
based on durable social structures) [and others **individual
agency**]{.underline}. Both dimensions are important and often operate
in tandem.33 Moreover, a distinction is to be made between formal
structure and actual day-to-day activities, [for the assumption that
organisations function according to **formal blueprints** is **not
supported** by empirical research]{.underline},34 hence [the emphasis
again on the **need** for much **more empirical work**]{.underline}. In
the case example of UNICEF that follows, we look in particular into
internal reflection and planning, and leadership and true believers as
explanatory entry points for the (lack of) organisational change
accompanying the introduction of an HRBAD. [In addition to]{.underline}
these [drivers of change]{.underline}, we shall [pay attention to the
**spoilers** of change, such as lack of **capacity** or staff
**turnover**, and to the **tension** between HRBAD and RBM]{.underline}.
Attempts at [introducing HRBAD by the UN]{.underline} at the country
level by states and by non-governmental organisations seem to [show
similar trends]{.underline} at first sight, though much more research is
needed before firm conclusions can be reached.
