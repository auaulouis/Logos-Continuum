# \*\*\*INFO WARFARE NEG\*\*\*

The information warfare aff and neg was produced by: Drew Chico; Cyrus
Esmailzadeh; Maggie Howerton; Sarah Kwon; Lenox Leverett; Raleigh
Maxwell; Avi Shah; Ahsan Tahirkheli; Cy Turner

# Topicality 

## T-Cybersecurity 

### 1NC\-\--T Cyberattacks

#### Cybersecurity means [protecting]{.underline} and [recovering]{.underline} networks from [cyberattacks.]{.underline}

Alison Grace **Johansen 22, writer for Norton, an American software
company, "What is Cyber Security? What you need to know." Norton,
4/28/22,
https://us.norton.com/internetsecurity-malware-what-is-cybersecurity-what-you-need-to-know.html**<https://us.norton.com/internetsecurity-malware-what-is-cybersecurity-what-you-need-to-know.html//Wompus>

[**[Cyber security is the state or process of protecting and
recovering]{.mark}** networks, devices, and programs]{.underline}
**[[from any type of cyberattack]{.underline}]{.mark}**.

Cyberattacks are an evolving danger to organizations, employees, and
consumers. These attacks may be designed to access or destroy sensitive
data or extort money.  They can, in effect, destroy businesses and
damage your financial and personal lives ---  especially if you're the
victim of identity theft.

Cyberattacks also are on the rise. According to an Identity Theft
Resource Center (ITRC)  2021 annual data breach report, there was a 68
percent increase in reported  U.S. data compromises from 2020 to
2021. Moreover, breaches related to cyberattacks  represented more
attacks than all other forms.

What's your best defense? A strong cyber security system has multiple
layers of  protection that are spread across computers, devices,
networks, and programs. This  guide can help you decide if you need
one of the cyber security plans offered by  companies, and which kind
may be right for you.

However, a strong cyber security system doesn't rely solely on cyber
defense  technology; it also relies on people like you making smart
cyber defense choices. The  good news is that you don't need to be a
cyber security specialist to understand and  practice good cyber defense
tactics. This article can help.

#### Cyberattacks are operations to [destroy]{.underline} and [disrupt]{.underline} the operation of a network\-\--excludes [disinformation schemes]{.underline}

Qinghui **Liu 21**, researcher at Zaozhang University in Shandong,
China, "A comprehensive review study of cyber-attacks and
cyber-security; emerging trends and recent developments." Science
Direct, November 2021,
[https://www.sciencedirect.com/science/article/pii/S2352484721007289#](https://www.sciencedirect.com/science/article/pii/S2352484721007289)!

+-----------------------------------------+------------------------------------------+
| Type of cyber action                    | Nature and characteristics               |
+=========================================+==========================================+
| Cyber-crime                             | Cyber actions taken only by              |
|                                         | non-governmental attackers.              |
+-----------------------------------------+------------------------------------------+
| Cyber-crime                             | The cyber action is carried out by a     |
|                                         | computer system and is merely in         |
|                                         | violation of criminal law.               |
+-----------------------------------------+------------------------------------------+
| **[[Cyber-attack]{.underline}]{.mark}** | [**[The purpose of a                     |
| and cyber-warfare                       | cyber-attack]{.underline}** **[is to     |
|                                         | destroy and disrupt the operation of     |
|                                         | a]{.underline}** ]{.mark}**[computer     |
|                                         | [network.]{.mark}]{.underline}**         |
+-----------------------------------------+------------------------------------------+
| Cyber-attack and cyber-warfare          | The attack must have political or        |
|                                         | security purposes.                       |
+-----------------------------------------+------------------------------------------+
| cyber-warfare                           | The effects of a cyber-attack are the    |
|                                         | same as an armed attack or the cyber act |
|                                         | took place in the context of an armed    |
|                                         | attack.                                  |
|                                         |                                          |
|                                         | ###                                      |
+-----------------------------------------+------------------------------------------+

#### Vote neg for limits and ground\-\--it outweighs precision\-\--including [non-offensive]{.underline} cyber-operations [explode]{.underline} the topic and dodge core generics.

### 2NC\-\--Intent to exclude

#### Cybersecurity refers to [info]{.underline} and [cyber operations]{.underline}\-\--preventing disinformation is [neither.]{.underline}

Eneken **Tikk and** Mike **Kertutten 20**, Executive Producer of the
Cyber Policy Institute, Estonia, and lead of the 1nternat10nal Law
project at CPI and the Erik Castrén Institute, University of Helsinki,
Finland, and Director of Strategy at the Cyber Policy Institute, and
Senior Research Scientist at the Tallinn University of Technology,
Estonia, "Routledge Handbook of International Cybersecurity," published
in 2020 by Routledge

[Since this is a **handbook of [cybersecurity]{.mark}**[,]{.mark} **the
[relationship between]{.mark}** the **concepts [infor]{.mark}mation
operation** **[and cyber]{.mark} operations** deserves special attention
here.]{.underline} The main difference between the concepts is that
[**cyber operations** **are method-driven** whereas **information
operations are purpose-driven.** **Cyber operations [refer to
actions]{.mark} conveyed [in]{.mark}** or via
**[cyberspace]{.mark}**]{.underline}**.** Information operations, on the
other hand, are defined by the objective of affecting decision-making or
opinion. This conceptual relationship has only been explicit in the US
military doctrine since 2013 (United States Joint Staff, 2013, p. I-5).
In the light of this conceptual relationship, [the two concepts
effectively intersect**: information operations are realized by cyber
operations**]{.underline}. An example of the intersection is the alleged
Russian influence on the US presidential elections in 2016, in which
cyber methods were deployed to collect the information needed in the
information operations against Democratic candidate Hillary Clinton.

[Disinformation is often associated with information
operations,]{.underline} with the connection between disinformation and
propaganda being thoroughly discussed in the literature on the latter.
[**[Even if]{.mark}** the common perception of **[propagand]{.mark}a**
often assumes that it [**is based on lies**, **disinfo**]{.mark}rmation
**[is not a]{.mark}** defining **[characteristic]{.mark} of
propaganda**. Indeed, disinformation is often avoided in propaganda in
order to preserve its credibility. **Following the** established
**relationship** between disinformation and propaganda, [**we exclude
disinformation** **as**]{.mark} **a** defining **characteristic of**
[**our definition** of **info**]{.mark}**rmation
[op]{.mark}eration[s]{.mark}**, even if it may be regarded as a method
in the process.]{.underline}

## 2NC

### 2NC\-\--Cyberattacks = Damage or Destroy

#### A cyberattack means to [damage]{.underline} or [destroy]{.underline} a network\-\--not spreading [false information.]{.underline}

**Oxford ND** Oxford Dictionary, "Cyberattack,"
https://www.oxfordlearnersdictionaries.com/us/definition/english/cyberattack#:\~:text=%2F%CB%88sa%C9%AAb%C9%99r%C9%99t%C3%A6k%2F,information%20on%20it%20without%20permission

**[[an attempt]{.mark} by hackers [to damage or destroy a]{.mark}
computer [network or system.]{.mark}]{.underline}**

# Disads

## DOD Tradeoff

### Link\-\--scale up

#### Moderation tech is [impossible]{.underline} to [scale up]{.underline} or requires robust [infrastructure changes.]{.underline}

Valerie **Wirtschafter 21**, senior data analyst in the Artificial
Intelligence and Emerging Technologies Initiative at the Brookings
Institution, 8-25-2021, \"The challenge of detecting misinformation in
podcasting,\"
<https://www.brookings.edu/techstream/the-challenge-of-detecting-misinformation-in-podcasting/>,
cy

[A research agenda]{.underline}

[The potential for misinformation]{.underline} to go largely unchecked
on podcasts is clear. But what is [the scale of this
problem]{.underline}? To explore that question, [I recently examined
more than 8,000 episodes of popular political podcasts. By using machine
learning and natural language processing to match transcriptions of the
podcasts with a fact-checking database of false or misleading political
claims]{.underline}, I found that [more than one-tenth of the episodes
shared]{.underline} potentially [false information]{.underline}.\[1\]
These flagged episodes have collectively received more than 100 million
views, likes, or comments.

This false content spans a wide range of topics in U.S. politics, from
immigration (e.g., the idea that most DACA recipients are "hardened
criminals") to elections (e.g., that "eight Iowa counties have more
adults registered to vote than voting age adults living") to abortion
(e.g., that Democrats "position on abortion is now so extreme that they
don't mind executing babies after birth"). These sharing patterns often
spike around key political events, such as the 2020 election, and have
become more common over time.

The research project is ongoing and will expand to cover both more
podcasts and more types of misinformation, including claims that have
been linked to foreign influence operations. But for now, these early
results indicate that [popular political podcasts are serving as an
important vector]{.underline} for the proliferation of misinformation.

Policy implications

Based on my preliminary research, [the spread of false
material]{.underline} via podcasts represents an underappreciated
problem that [will require infrastructure-level changes distinct from
content moderation policies]{.underline} already in place on social
media platforms. Unlike other forms of media in the iPhone age, podcasts
are more difficult to moderate due to limitations with respect to
audience engagement and the nature of podcast distribution mechanisms.

Consider the role of the consumer in policing content. Like [Facebook or
Twitter, podcast distributors largely rely on the "crowd" to identify
objectionable content,]{.underline} but the process for reporting this
material as a listener is not straightforward. Apple's podcasting app
allows users to report concerns about episodes, but the reporting tool
only provides a limited number of concerns to choose from, none of which
encompass false or misleading content. Where Apple does specify
guidelines about inaccurate or misleading content, these largely relate
to podcast metadata and copyright issues. At present, Spotify provides
no obvious way for users to report issues with specific episodes and
only vaguely delineates content that is prohibited on the platform.

The decisions made by Apple and Spotify ultimately have downstream
effects across the industry. Most of the smaller players in the field
lack the financial resources to carry out extensive content moderation
and look to larger companies like Apple and Spotify to determine what
should be removed. In making it difficult (or all but impossible) for
users to report misinformation, Spotify and Apple effectively remove the
crowd from helping curb the spread of false or misleading content.
Tackling misinformation in podcasts may require reincorporating the
audience in some capacity---from enabling users to comment or leave
reviews on specific episodes to further experimenting with ways to
transform podcasting into a conversation between the creator and the
audience.

[From an infrastructure perspective, the nature of the RSS
feed]{.underline}, which is open-sourced and accessible by design,
[represents a significant hurdle for content moderation]{.underline}.
For example, Apple's podcasting app---one of the most widely used apps
for streaming episodes---[aggregates content across thousands of
approved RSS feeds]{.underline}. Once Apple approves a feed, it does not
control the content added to these feeds. Although Apple can remove the
RSS feed from its platform, some smaller platforms allow any content on
an RSS feed to be played through their services, making it easy for
listeners to access a removed podcast elsewhere. As a result, a content
moderation decision at one platform, like removing a single episode
urging listeners not to get a COVID vaccine, may not affect its
availability via other platforms. [Addressing the moderation of
misleading material instead requires a fundamental rethinking of the
broader]{.underline} podcast [infrastructure.]{.underline}

[This latter infrastructure-level change will be difficult to
implement]{.underline} but is [fundamental to addressing the risks
associated with the spread of misinformation]{.underline}. The spread of
online misinformation has already demonstrated its ability to undermine
deliberative democracies, and podcasts represent an underappreciated
avenue through which such information proliferates. Internationally,
misinformation shared via podcasts may resonate with and be amplified by
foreign actors intent on sowing discord in U.S. politics. As a first
step, it is critical to understand the scope of this problem in order to
identify appropriate policy solutions to address the spread of
misinformation within the unique contours of the podcasting space.

### Link\-\--investigations

#### Misinformation investigations are a [money suck]{.underline}

Victoria **Smith and**, Natalie **Thompson 20**, Security Officer at
Group-IB, research analyst with the U.S. Cyberspace Solarium Commission,
12-7-2020, \"Survey on Countering Influence Operations Highlights Steep
Challenges, Great Opportunities,\"
<https://carnegieendowment.org/2020/12/07/survey-on-countering-influence-operations-highlights-steep-challenges-great-opportunities-pub-83370>,
cy

[LACK OF FUNDING]{.underline}

Almost 40 percent of respondents in the community survey cited [a lack
of funding as the most or second-most important challenge.]{.underline}
In the targeted survey, six respondents also emphasized the
precariousness of funding. The PCIO's research has found that many
organizations working to research or counter influence operations are
nonprofit, heavily reliant on donations and grants. It is therefore not
surprising that funding is a concern, given the growth in new
initiatives in this field and increasing competition for the same
funding.

One [community leader]{.underline} was [concerned that long-term funding
insecurities are having a detrimental impact on output;]{.underline}
without funding security, [decisions about recruitment and training
cannot be made.]{.underline} Another leader was concerned that financial
challenges might incentivize research organizations to compromise their
independence or methodological rigor in an effort to attract resources
and attention. A third respondent suggested that donors want
reassurances of results in return for their money, but [in a field with
so many unknowns, it can be hard to promise results.]{.underline} The
respondent had the impression that some [donors are more drawn to
headline-grabbing claims of successful interference in political
campaigns or persuasive conspiracy theories and that this leaves fewer
resources for research on under-the-radar issues]{.underline} and
long-term investigations that have no guarantee of success. [Another
respondent also noted that investigations tend to be skewed toward
retrospective analysis of known influence operations instead of
prospective experiments. The latter analysis is more expensive and
uncertain but could reveal deeper insights.]{.underline}

### Link\-\--reach calculation

#### Even [calculating]{.underline} reach of misinformation is a [resource drain.]{.underline}

Clare **Wardle** and Nic **Dias 18**, U.S. Director of First Draft,
Joint Doctoral Student in Communication and Political Science
<https://mediawell.ssrc.org/2018/10/30/10-questions-to-ask-before-covering-misinformation/?pdf=49652>,
cy

When should we publish stories about mis- and dis-information? How much
traffic should a piece of mis- and dis-information have before we
address it? In other words, what is the "tipping point," and how do we
measure it? On Twitter, for example, do we check whether a hashtag made
it to a country's top 10 trending topics?

[How do we think about the impact of mis- and
dis-information]{.underline}, particularly on Twitter? Do [we care about
how many people see the content]{.underline}? Or do we care about who
sees the content? In particular, is Twitter important in virtue of the
number of people who use it, or is it important because certain groups,
like news organizations and politicians, use it? How do our answers to
these questions change how we evaluate the impact of information?

[How do we isolate human interactions in a computationally affordable
manner? When we talk about the "reach" of a piece of content, we should
be referring to how many humans saw it. Yet, identifying the number of
humans who saw a piece of information can be difficult and
computationally expensive. What algorithms might be devised to calculate
human reach (at least on Twitter) in a timely and inexpensive
way?]{.underline}

### Link\-\--enforcement

#### [Even if]{.underline} the center's inexpensive, [enforcement]{.underline} isn't.

**DHS 21**, Department of homeland security, "Combatting Targeted
Disinformation Campaigns,"
<https://www.dhs.gov/sites/default/files/publications/phase_ii_-_combatting_targeted_disinformation.pdf>,
cy

An alternative to naming specific domestic threat actors is to alert
information consumers to those threat actors who assume fake persona or
claim to have credentials which they do not have. [The status of the
threat actor plays an important role]{.underline} in influencing the
perceived trustworthiness of that threat actor.20 [Someone who claims to
be an epidemiologist will likely be viewed as more reliable on the topic
of coronaviruses than a person who claims to be a bus
driver.]{.underline}

Information consumers who assume fake personas or claim fake credentials
to deceive others for illegitimate purposes have no moral or legal
standing for protection for their fraud, which is a form of
disinformation. Revealing that credentials are fake can be accomplished
without identifying the threat actor by name or by other information
which can be tied to a specific person.

[Threat actors who spread disinformation often seem to act with
impunity, facing few]{.underline} negative [consequences]{.underline}
for the harm that they cause. In some circles, their [disinformation may
enhance]{.underline} their status and generate [lucrative
opportunities]{.underline} for them due to the attention that they draw.
[Legal actions against threat actors are available, but limited in
number, and invariably costly and time-consuming. In a deeply divided
society, shunning and ostracism no longer have the practical
import]{.underline} they may have had in earlier generations. [The lack
of perceived consequences encourages threat actors to continue their
activities.]{.underline} We acknowledge the challenges in today's
environment and believe that punitive measures are less effective than
measures which provide information about the threat actors upon which
information consumers can make better informed decisions.

# Counterplans 

## DOS/Non-Military

### Solvency\-\--DOS\-\--Information Warfare

#### The DoS [solves]{.underline}\-\--old agencies for [countering disinformation]{.underline} were [reorganized]{.underline} and placed in the [jurisdiction of the DoS]{.underline} and multiple empirics prove.

**USACPD 20**, United States Advisory Commission on Public Diplomacy,
tasked by Congress with \"appraising U.S. Government activities intended
to understand, inform, and influence foreign publics and to increase the
understanding of, and support for, these same activities." "PUBLIC
DIPLOMACY AND THE NEW "OLD" WAR: COUNTERING STATE-SPONSORED
DISINFORMATION"
<https://www.state.gov/wp-content/uploads/2020/09/Public-Diplomacy-and-the-New-Old-War-Countering-State-Sponsored-Disinformation.pdf>
//lenox

As we gathered background information for this report, we noticed a
pattern: [[experts]{.mark} and practitioners alike became quick to [turn
to the past for]{.mark} cues on [how to proceed in the
future]{.mark}]{.underline}. In fact, the discussion of the historical
framework of disinformation as a threat area revealed a common
understanding that the challenge of disinformation is "not new."
[[Several]{.mark} of our interlocutors spoke reverently of the tools of
the Cold War and [cited]{.mark} the [merits of the]{.mark}]{.underline}
United States Information Agency ([[USIA]{.underline}]{.mark}), Voice of
America ([VOA]{.underline}), Radio Free Europe/Radio Liberty
([RFE/RL]{.underline}), [and]{.underline}, most notably, the Active
Measures Working Group ([AMWG]{.underline}) [[as successful instruments
of PD in countering disinformation]{.underline}]{.mark}.2 However, these
experts agreed that they might be over-emphasizing the similarities
between the disinformation threat then and now, while perhaps
unintentionally underestimating the differences. Much of [the [apparatus
that supported]{.mark} Cold War-era [counter disinfo]{.mark}rmation
efforts still [exists today]{.mark}]{.underline}, albeit [[in a]{.mark}
somewhat [disaggregated]{.mark} [form]{.mark}]{.underline}. In 1999,
[[USIA]{.mark} closed down as an independent foreign affairs
agency]{.underline}. Its [information, cultural, and exchange components
[were integrated into the D]{.mark}epartment [o]{.mark}f
[S]{.mark}tate]{.underline} [[as]{.mark}, respectively,
[the]{.mark}]{.underline} Bureau of International Information Programs
([[IIP]{.underline}]{.mark}) [[and]{.underline}]{.mark} the Bureau of
Educational and Cultural Affairs ([[ECA]{.underline}]{.mark}).
Meanwhile, [oversight of USIA\'s regional programs was turned over to
the State Department's geographic bureaus]{.underline}. USIA's
broadcasting components became part of the Broadcasting Board of
Governors (BBG--now the U.S. Agency for Global Media, or USAGM). The
AMWG was formally disbanded in 1992 with no heir apparent; and at the
BBG, the establishment of an independent board of directors removed
direct USG editorial oversight and created a firewall between Congress
and the independent journalism operations within the VOA and RFE/RL.
[[In addition to the structural changes]{.mark} that have occurred since
the integration of USIA]{.underline} functions into the Department of
State, the rapid convergence of connection technologies \-- the
[[internet]{.mark}, mobile and social [networks]{.mark}]{.underline} \--
[[have fundamentally altered the domain in which information competition
occurs]{.underline}]{.mark}. About half of the world's population has
access to one another via the combination of internet and social media
access and mobile phones, which allow for disintermediated peer-to-peer
communication at scale. The global information space is marked by a
constant fight for attention, and viewership is determined by complex
interactions among algorithms, professional media outlets, corporate
brands, and user generated content via apps on mobile devices. As a
consequence, [modern [public diplomacy]{.mark} practitioners [find
themselves in an environment that offers]{.mark} an [overabundance of
info]{.mark}rmation]{.underline}---what Joseph Nye presciently described
as a "paradox of plenty" that leads to a "scarcity of attention."3 [This
shift has irrevocably changed the information environment in which PD
officers operate]{.underline}, and it gives an asymmetric advantage to
those who would attempt to alter, obscure, or destroy the very concept
of objective truth. Initial [[efforts to meet the]{.mark} most recent
iteration of these [challenges began in the 2010s]{.mark}]{.underline},
during a period of what some have described as U.S. government
"overexuberance" about the ability of emerging social media technologies
to advance democratic values. By the time the Arab Spring began to
unfold in 2011, [[new policies]{.mark} were established that [encouraged
State Department officials to]{.mark} establish online profiles and
pages with the intent to [amplify public affairs
messaging]{.mark}]{.underline} through these increasingly influential
mediums. However, constrained by bureaucratic inertia and, perhaps,
overconfident that "traditional" public diplomacy measures transposed to
the online space (i.e., press releases, photos from speaking events and
conferences, etc.) would have the intended effect, innovation on USG
social media platforms largely stopped there. While these official
Department social media accounts now number in the hundreds, most PD
officials agree that for a number of reasons, including but not limited
to the risk aversion that arises from engaging in an often-frenetic
online environment, the overall impact remained relatively muted. With
the intensification of Russian disinformation efforts following
Ukraine's "revolution of dignity" and the subsequent annexation of
Crimea in 2014, [it became increasingly clear that the social media
space had become, in effect, the front line in a new global competition
for influence]{.underline}. Shortly thereafter, the threat of
disinformation expanded far beyond the borders of Eastern Europe to
become the subject of intense focus from Washington, D.C. to the Silicon
Valley. The 2017 National Security Strategy included a section on
Information Statecraft warning about the exploitation of "marketing
techniques."4 Meanwhile, Facebook CEO Mark Zuckerberg described efforts
to combat disinformation on his platform as an "arms race,"5 and Apple
CEO Tim Cook warned that personal data was being "weaponized against us
with military efficiency."6 To paraphrase Peter W. Singer, whose 2019
book LikeWar7 explored this phenomenon in depth, tech executives were
starting to sound more like national security experts, and national
security experts were starting to sound more like tech executives.
Recognizing a Resurgent State-Sponsored Disinformation Threat: 2016-2017
In the early stages of Russia's attacks on Ukraine's integrity in the
global information space, [the [State Department']{.mark}s Bureau of
European and Eurasian Affairs (EUR) [developed a nascent set of
counter-disinfo]{.mark}rmation [tactics]{.mark}]{.underline}. But formal
and far reaching alterations to PD CSD infrastructure originated with
the passage of the May 2016 Countering Foreign Propaganda and
Disinformation Act, which became a part of the 2017 NDAA. The first
legislation tasking an official lead in government-wide counter
disinformation efforts since the Cold War, the NDAA signaled that the
USG once again recognized disinformation as a high-priority threat that
warranted immediate action. The [State Department's [GEC]{.mark},
established by Executive Order in March 2016, [became the prime vehicle
for CSD]{.mark}]{.underline}[. [It was originally envisioned as a
mechanism to counter]{.underline}]{.mark} [violent extremist (CVE)
messaging and "[foreign propaganda]{.mark} and disinformation"
operations]{.underline}.

#### The [DoS]{.underline} has the capabilities to counter Chinese and Russian [disinformation]{.underline} operations \-\-- [GEC]{.underline} proves

Bill **Gertz 22** (Bill Gertz, a national security correspondent for The
Washington Times, studied English literature at Washington College in
Chestertown, Md., and journalism at George Washington University,
4-7-2022, \"State Department works to counter Ukraine disinformation
from China,\" Washington Times,
https://www.washingtontimes.com/news/2022/apr/7/state-department-working-debunk-chinese-disinforma/,
DOA: 6-28-2022//Smarx Ahsan)

[China's propaganda]{.underline} [and]{.underline}
[disinformation]{.underline} [operations]{.underline} [are]{.underline}
actively [promoting pro-Russian narratives]{.underline}
[about]{.underline} the invasion of [Ukraine]{.underline},
[supporting]{.underline} [Moscow]{.underline}'s positions [and blaming
the U.S]{.underline}. for the conflict, [according to the]{.underline}
[State Department]{.underline} center [involved in trying to counter the
operations.]{.underline}

[The department's]{.underline} Global Engagement Center
([GEC]{.underline}) [is leading]{.underline} U.S. [government efforts to
expose]{.underline} [foreign propaganda]{.underline}
[efforts]{.underline}, [including]{.underline} [Chinese]{.underline}
state [media reports]{.underline} [and]{.underline} official
[statements]{.underline} [claiming]{.underline} that [the
Pentagon]{.underline} [is developing biological and chemical weapons in
Ukraine]{.underline}, a spokesman tells The Washington Times.

[The center is]{.underline} "[leading]{.underline} [the]{.underline}
[State Department's]{.underline} [efforts to recognize and
understand]{.underline} \[[Chinese]{.underline}\] [information
manipulation]{.underline} related to Ukraine, and [we are]{.underline}
deeply [engaged]{.underline} [with colleagues across the
department]{.underline} [as well as]{.underline}
[international]{.underline} [and]{.underline} [interagency]{.underline}
[partners to raise awareness of]{.underline} PRC propaganda and
[disinformation]{.underline}," the spokesman said.

In addition to rebutting Chinese state media claims about U.S.
bioweapons research in Ukraine, [the counter-disinformation
operations]{.underline} [aimed to expose Chinese amplification of
Russian propaganda]{.underline} prior to the invasion in late February.

[The laboratories located in Ukraine]{.underline}, [Georgia]{.underline}
[and Armenia]{.underline} [operate safely]{.underline} and securely [and
are not involved in any biological weapons research]{.underline},
[according to]{.underline} Jerry L. [Mothershead]{.underline}, [a
medical doctor]{.underline} directly involved in the program from 2010
to 2016. [The laboratories are part of the Pentagon's Defense Threat
Reduction Agency]{.underline} that ran the Cooperative Biological
Engagement Program to support research on local diseases.

"[The actual amount of pathogens]{.underline} at those central labs that
can actually do any research [wouldn't even fill a broom
closet]{.underline}, and there are rigorous biosafety and biosecurity
controls over them, including destruction if need be," Dr. Mothershead
said.

[Chinese state media]{.underline}, [echoing Russian government
allegations]{.underline}, has [regularly reported the laboratories were
engaged in biological weapons work]{.underline}. The
[disinformation]{.underline} also [has been repeated by]{.underline}
some [U.S. conservative media]{.underline} outlets.

Kerry Gershaneck, a former Pentagon official and author of the book
"Political Warfare," said [China's professions of
neutrality]{.underline} in the war [are]{.underline}
[undercut]{.underline} [by Beijing's]{.underline} [open
sympathy]{.underline} [for]{.underline} Russian President Vladimir
[Putin's]{.underline} [reasons for invading]{.underline}, support [shown
through media warfare]{.underline}, [psychological]{.underline}
[operations]{.underline} [and]{.underline} [cyberattacks]{.underline}.

"[Beijing's]{.underline} [external narratives are designed to undermine
NATO]{.underline}, \[[Ukraine]{.underline}\] [and the U.S]{.underline}.,
[and to support]{.underline} [Moscow's disinformation]{.underline}
[and]{.underline} [propaganda]{.underline} designed [to
confuse]{.underline} [global reaction]{.underline} [to Putin's
aggression]{.underline}," Mr. Gershaneck said. "[Internally,
the]{.underline} Chinese Communist Party ([CCP]{.underline}) [is
exploiting Russia's war to hypernationalize]{.underline} [the Chinese
people]{.underline}."

[U.S. officials say the lab]{.underline}oratory program [is typical of
government programs]{.underline} that continue on autopilot, seemingly
without end, under legislation passed after the collapse of the Soviet
Union that requires continued funding from a percentage of annual
defense spending bills.

Aside from the laboratory propaganda, [Chinese
disinformation]{.underline} efforts [include]{.underline}
[support]{.underline} [for Kremlin]{.underline} [claims]{.underline}
that [Ukraine is a "core interest"]{.underline} [for Moscow
and]{.underline} that the [military operation was a
legitimate]{.underline} [national security interest]{.underline} [of
Russia]{.underline} [in the face of aggression]{.underline} from the
U.S. and its NATO allies.

"[PRC]{.underline} [propaganda]{.underline} [and]{.underline}
[disinformation]{.underline} [efforts have evolved]{.underline} since
then and [Beijing has increased its use of Russian false
narratives]{.underline} and is now also introducing disinformation of
its own to advance the PRC's agenda," the GEC spokesman said.

[A pair of disinformation themes]{.underline}

[The State Department]{.underline} center has [identified]{.underline}
what it says are [two main disinformation themes]{.underline} promoted
in Chinese narratives. The [first is the claim that the U.S. and NATO
ignored]{.underline} [Russian security concerns]{.underline}
[through]{.underline} the [expansion of the alliance]{.underline} in
Eastern Europe near Russia's border. [This narrative]{.underline} also
[advances]{.underline} [the argument that the U.S. is exploiting the
Ukraine conflict to suppress Russia]{.underline}.

[The line of]{.underline} [Chinese disinformation]{.underline} [centers
on]{.underline} what the spokesman said is [the baseless assertion that
the U.S. is working behind the scenes to prolong the war
that]{.underline} has already [killed thousands of people]{.underline}.

For example, [a recent editorial in the]{.underline}
[C]{.underline}hinese [C]{.underline}ommunist
[P]{.underline}arty-controlled People's Daily [claimed]{.underline} that
[U.S.]{.underline} "[lobbyists, military corporations and Capitol
Hill]{.underline}" [held a champagne toast to celebrate the
crisis.]{.underline}

"Obviously, [we condemn]{.underline} such incendiary, [meritless
claims]{.underline}," [the GEC]{.underline} spokesman
[said]{.underline}.

[To counter]{.underline} the [disinformation]{.underline}, [the
GEC]{.underline} [is]{.underline} [helping]{.underline} [promote the
narrative]{.underline} that [the conflict and ensuing humanitarian
crisis in Ukraine]{.underline} [are the]{.underline} direct
[result]{.underline} [of]{.underline} Mr. [Putin's]{.underline}
[unprovoked]{.underline} [military aggression]{.underline}.

"[The State Department]{.underline} [will continue to raise
awareness]{.underline} [among]{.underline} partners and [allies of the
PRC's]{.underline} [propaganda]{.underline} efforts [and call out
Beijing's attempts to shift blame]{.underline} [while it continues to
stand by Moscow]{.underline} [and]{.underline} refuses to acknowledge
[Russian atrocities]{.underline}," the spokesman said.

[Through]{.underline} its [information operations]{.underline}, [the
department will continue focusing]{.underline} its [public
diplomacy]{.underline} and related efforts [to making sure world publics
get accurate information on the Russian aggression]{.underline}.

[China's government]{.underline}, mainly [through]{.underline} its
[Foreign Ministry]{.underline} spokesmen, [insists]{.underline} that
Beijing is strictly neutral toward the conflict. However, [the Russian
point of view on the crisis has been]{.underline} constantly
[promoted]{.underline} [in China's]{.underline} [state
media]{.underline}.

[Chinese narratives]{.underline} [are controlled by the Propaganda
Ministry,]{.underline} [which exercises]{.underline} strict [control
over all media in China]{.underline}, including
[newspapers]{.underline}, [television]{.underline} and newer online
[social media]{.underline}.

[The ministry]{.underline} recently [produced a documentary
film]{.underline} called "[Historical Nihilism and the Soviet
Collapse]{.underline}" that is being [shown to the 95
million]{.underline} [members of the C]{.underline}hinese
[C]{.underline}ommunist [P]{.underline}arty, reportedly
[portraying]{.underline} Mr. [Putin as a hero]{.underline} for seeking
to restore the Soviet Union and restore the image of brutal Soviet
dictator Josef Stalin.

[While the Chinese government seeks to promote]{.underline} the view of
[Chinese neutrality]{.underline} and support for peace, [Chinese
information outlets]{.underline} [internally create the
impression]{.underline} that [Russia is a victim of U.S.
aggression.]{.underline}

[The Chinese domestic propaganda is also promoting the]{.underline}
recently [strengthened]{.underline} close [ties]{.underline} [between
Beijing and Moscow]{.underline} highlighted in the Feb. 4 cooperation
agreement that says [relations between the two states have]{.underline}
"[no limits]{.underline}." [Chinese students are being indoctrinated in
the]{.underline} "[correct]{.underline}" [view of the Ukraine
war]{.underline}, while [state media blame Washington for the
conflict]{.underline}, according to The New York Times, which first
disclosed the documentary.

"The most powerful weapon possessed by the West is, aside from nuclear
weapons, the methods they use in ideological struggle," the documentary
narrator states.

The documentary was labeled for internal party use, but video and a
transcript of the film were circulating within China recently.

[Under]{.underline} President [Xi]{.underline} Jinping, who since coming
to power in 2012 has pushed a return to hardline communist policies,
[Chinese propaganda has asserted the]{.underline} U[.S. is secretly
promoting]{.underline} "[color revolutions]{.underline}" around the
world [aimed at regime change in authoritarian and communist
countries.]{.underline}

Retired Navy Capt. Stu Cvrk said [China is trying to have it both
ways]{.underline} --- [supporting Russia while offering to lead an
effort to resolve the conflict.]{.underline} He noted the Chinese
Foreign Ministry echoing of Russian claims about the U.S. labs in
Ukraine.

"Official [Chinese comments have been propagated throughout independent
media]{.underline} [sympathetic]{.underline} [to the
Russians]{.underline}," Capt. Cvrk said.

[Chinese social media trolls]{.underline} on Twitter and other platforms
also [are engaged in]{.underline} promoting [pro-Russian
propaganda]{.underline}, often [in collaboration]{.underline} [with
Russian]{.underline} online [allies]{.underline}.

"[They backed the Ukraine biowarfare lab fake story]{.underline} to the
max," said Charles Smith, who closely monitors official Chinese social
media activity disseminated by Wumao, or the "50 Cent Army" of Chinese
government-linked propagandists.

Recently, [Chinese government online agents have challenged reports of
Russian military war crimes in executing Ukrainian civilians as fake
news.]{.underline}

[Another]{.underline} social media [propaganda theme]{.underline}
promoted by the Wumao [is the idea that Ukraine's government
is]{.underline} "[nothing but Nazis]{.underline}," Mr. Smith said.

"[The Russian trolls]{.underline} [work closely with the]{.underline}
[PLA-run]{.underline} [Wumao]{.underline} [and]{.underline} often [post
together]{.underline}," Mr. Smith said, using the acronym for the
Chinese military, the People's Liberation Army.

[The State Department]{.underline} did not provide details on the GEC
operations to counter Chinese disinformation. However, in the past the
center [has approached news media outlets and social media companies
with intelligence identifying false narratives]{.underline}.

In many cases, social media companies will shut down known foreign
government disinformation social media accounts in response.

[The G]{.underline}lobal [E]{.underline}ngagement [C]{.underline}enter
website [lists]{.underline} several [examples]{.underline} [of Russian
disinformation]{.underline}, but has no public material on Chinese
propaganda and disinformation operations.

#### The [State Department]{.underline} has the means to counter [authoritarian]{.underline} disinformation

**Bechara and** **Novelo 22** (Diego Ramos Bechara, covering National
Security at the nation's capital as a full-time journalist, Allison
Novelo, journalist at Northwestern University, Medill News Service,
3-15-2022, \"State Department: We\'re fighting spread of propaganda,
disinformation from Russia,\" UPI,
https://www.upi.com/Top_News/US/2022/03/15/senate-hearing-authoritarianism-vladimir-putin/5921647351139/,
DOA: 6-30-2022//Smarx Ahsan)

WASHINGTON, March 15 (UPI) \-- [The State Department]{.underline} is
[conducting]{.underline} \"[extensive]{.underline} [media
outreach]{.underline}\" [to fight the spread of propaganda and
disinformation]{.underline} coming [from Russia]{.underline}, officials
told lawmakers Tuesday.

\"[That includes]{.underline} two [Russian language]{.underline}
[media]{.underline}, like [Meduza]{.underline}, [as well as]{.underline}
two [U.S. government-supported Russian language media like]{.underline}
[DRL]{.underline} [and]{.underline} [Voice of America]{.underline},\"
[State Department]{.underline} official Jennifer Hall Godfrey told
members of the Senate Foreign Relations Committee during a hearing on
[combating authoritarianism]{.underline}.

According to Godfrey, the senior bureau official for public diplomacy
and affairs, [Russian engagement]{.underline} on these platforms
[has]{.underline} \"[doubled]{.underline}\" [since the Kremlin revoked
access to VOA]{.underline} online [and]{.underline}
[despite]{.underline} [continued efforts to]{.underline} \"[shut
down]{.underline}\" these [outlets]{.underline}.

\"[We have a Telegram]{.underline} \[messaging account\] to keep in
contact, [which has]{.underline} [not]{.underline} yet [been found by
the Russian government]{.underline} \-- [these are
indigenous]{.underline} [Russian language platforms]{.underline} [that
we\'re engaged on,]{.underline}\" she said.

\"[We continue to engage through Twitter, Facebook]{.underline}, and
[even though]{.underline} [the Russian government]{.underline} has
[tried to shut down those platforms]{.underline}, [we]{.underline} still
[see Russian citizens accessing them]{.underline}, and [we\'ll continue
to use]{.underline} all [those means to]{.underline}
[continue]{.underline} to [communicate with Russians]{.underline}.\"

Godfrey\'s remarks come after Russian journalist Marina Ovsyannikova was
detained after running onto the set of one of Russia\'s most-watched
news programs, Vremya, holding a sign that read in Russian: \"No war,
stop the war, don\'t believe the propaganda, they are lying to you
here.\"

Sen. Chris Van Hollen, D-Md., called [Russia\'s attempt to spread
disinformation]{.underline} [an iron curtain]{.underline} \--
essentially [hiding the truth from the public]{.underline} \-- and he
praised Ovsyannikova for her protest. According to Van Hollen, [the
majority of Russians believe Russian propaganda]{.underline}.

Lawmakers, [State Department]{.underline} officials and experts
[referred to this incident to highlight how autocratic
regimes]{.underline} are able to [limit the]{.underline}
[spread]{.underline} [of information.]{.underline}

\"[They do so by]{.underline} [kicking out independent
media]{.underline},\" Godfrey said. \"They do so [by telling their own
journalists and citizens what they may or may not say.\"]{.underline}

[Authoritarian governments]{.underline}, such as [Russia and
China]{.underline}, often [leverage]{.underline} [information
and]{.underline} [manipulate]{.underline} [media outlets to attack the
national security of the]{.underline} [U]{.underline}nited
[S]{.underline}tates [and its allies]{.underline}, the senators were
told.

According to Sen. Jeff Merkley, D-Ore., [authoritarian
regimes]{.underline} [have grown in strength]{.underline} over the past
16 years, and he cited a Freedom House report that [only]{.underline}
roughly [38%]{.underline} [of the global population lives in democratic
countries]{.underline}.

Uzra Zeya, the undersecretary for civilian security, democracy and human
rights at the State Department, said the [Biden]{.underline}
administration has [prioritized bolstering]{.underline}
[legitimate]{.underline} [media outlets]{.underline} by [proposing
increasing the amount spent on media freedom by 40%]{.underline} in the
fiscal year 2022 over fiscal year 2020.

To which Sen. Chris Coons, D-Del., who chairs the Senate subcommittee
that oversees foreign aid, said [more bipartisan focus]{.underline} [is
needed to make sure]{.underline} these [requests make it into a final
spending package]{.underline}.

\"We had the chance to visit Poland in particular with a cable channel
that is under a lot of pressure in terms of maintaining a free and open
media,\" said the lawmaker, who traveled last month with two other
Democratic senators to Germany, Poland and Lithuania.

\"You requested a 40% increase. That is not what we were able to deliver
here.\"

After senators finished hearing from the two State Department officials,
two experts offered suggestions for how lawmakers should use policy to
deter authoritarianism. They highlighted Russia, but also cited
Venezuela and the People\'s Republic of China.

Anne [Applebaum]{.underline}, a staff writer at the Atlantic and senior
fellow at the Stavros Niarchos Foundation Agora Institute at Johns
Hopkins University, [suggested]{.underline} [putting an end
to]{.underline} [transnational kleptocracy]{.underline} [and centering
democracy-building]{.underline} [in]{.underline} [foreign]{.underline}
[policy.]{.underline}

However, Applebaum [emphasized]{.underline} [fighting
disinformation]{.underline} \-- be it [in Russia, China or
Venezuela]{.underline}.

\"[Autocrats understand]{.underline} the [importance of controlling
opinion inside their own countries]{.underline} [and]{.underline}
[influencing debates]{.underline} around the world,\" she said.

\"Hundreds of [Russian journalists have fled Moscow]{.underline}: Why
not start a Russian television channel? [We should]{.underline}
[increase funding]{.underline} [for independent media
outlets]{.underline}, [support]{.underline} [grassroots]{.underline}
[efforts to run media campaigns]{.underline}.\"

Committee Chairman Bob Menendez, D-N.J., touted his bipartisan measure
designed to do just that.

\"[We must counter the]{.underline} [dangerous narratives]{.underline},
[which authoritarians spread to manipulate]{.underline}, [to distract
and to cause people to question whether democracy has anything to
offer]{.underline} the modern world,\" Menendez said.

\"This is one of my passions, and I intend to use your testimony as a
foundation for our legislative initiative in this regard,\" he said.

Van Hollen also said using all avenues of communication is vital.

\"[This is the]{.underline} [information equivalent]{.underline} [of an
arms race]{.underline}, and [Russia will continue to put up
blockades]{.underline}, and [we need to use all the latest technology to
try to make sure]{.underline} that [we get information to]{.underline}
the [Russian people]{.underline},\" he said.

#### The DoS can effectively beat Russian [information operations]{.underline} \-\-- [Africa]{.underline} Proves 

**Pecquet 22** (Julian Pecquet, the founder and editor of Foreign Lobby
Report, a US news site that offers comprehensive coverage of foreign
influence operations in Washington and beyond, 5-25-2022 \"US looks to
expose Russian propaganda in Africa,\" Africa Report,
https://www.theafricareport.com/207268/us-looks-to-expose-russian-propaganda-in-africa/,
DOA: 6-30-2022//Smarx Ahsan\-\--Edited for Spelling)

[The State Department\'s]{.underline} [counter-propaganda
arm]{.underline} has [released its first]{.underline}-ever [report
on]{.underline} [Russian disinformation]{.underline} [in Africa
as]{.underline} the Joe [Biden]{.underline} administration [looks to
expose the Kremlin following]{.underline} the invasion of
[Ukraine]{.underline}.

[The Global]{.underline} [Engagement]{.underline} [Centre]{.underline},
which [leads]{.underline} [and]{.underline} [coordinates]{.underline}
[US efforts to]{.underline} "[recognize]{.underline},
[understand]{.underline}, [expose]{.underline}, [and]{.underline}
[counter]{.underline} [foreign propaganda and
disinformation]{.underline}", released a three-page bulletin on Russian
activities on 24 May. The report focuses particularly on Mali and other
Sahel countries where the Kremlin-linked Wagner Group of mercenaries
operates.

"[Russia deploys disinformation across]{.underline} different
[continents]{.underline} for varied objectives, often [working
through]{.underline} tested [proxies to support Kremlin]{.underline}
[foreign]{.underline} [policy]{.underline} [objectives]{.underline}
indirectly, [which provides]{.underline} a level of
[deniability]{.underline}," the report states. "[In]{.underline} some
parts of [Africa]{.underline} -- including, most recently, Mali --
[Kremlin]{.underline}-linked [proxies]{.underline} [exploit]{.underline}
[instability]{.underline} [to gain]{.underline} [influence]{.underline},
particularly [through disinformation and]{.underline} the deployment of
the [Wagner]{.underline} Group [forces]{.underline}."

A spokesperson for the State Department describes [the
report]{.underline} as "[part of the State Department's]{.underline}
overall [public exposure efforts]{.underline} [to counter Russian
disinformation]{.underline}".

"[We are releasing]{.underline} these substantive [products to the
public]{.underline} [to counter]{.underline} [Russia's]{.underline}
[false narratives]{.underline} [and]{.underline}
[propaganda]{.underline} [with reporting that shines the light on
Kremlin lies]{.underline}," the spokesperson tells The Africa Report.
"[This bulletin is our first on Russia's disinformation efforts in
Africa]{.underline}."

[Evolving target]{.underline}

[The]{.underline} [Global]{.underline} [Engagement]{.underline}
[Centre]{.underline} was created under President Barack Obama in March
2016. Its original [mission]{.underline} [was to contest
the]{.underline} "[information battlespace]{.underline}" with the
Islamic State and "break the recruiting efforts of violent extremists
abroad", according to its first coordinator, Michael Lumpkin.

[Disinformation]{.underline} is [one of the Kremlin's]{.underline} most
important and [far-reaching]{.underline} [weapons]{.underline}

[Housed at the]{.underline} [State Department]{.underline}, [the
interagency organization]{.underline} also draws on staff from the
departments of Defence, Treasury, Justice and Homeland Security as well
as the Intelligence Community and the US Agency for International
Development. Its mandate: to [coordinate]{.underline},
[integrate]{.underline}, [and]{.underline} [synchronize]{.underline}
[government-wide]{.underline} [communications]{.underline} [with foreign
audiences to counter]{.underline} [disinformation
campaigns.]{.underline}

Over the years [its mission has evolved]{.underline}, [with Russia
emerging as a core concern]{.underline} over the past couple of years.

Since January 2020, [the center]{.underline} has notably [issued a slew
of reports]{.underline} [on]{.underline} [Russian]{.underline} [chemical
and biological weapons]{.underline} [disinformation]{.underline} [in
Ukraine]{.underline}, [featured the Kremlin's top propagandists and
denounced the Russian state]{.underline}-owned and state-directed media
RT and Sputnik.

"[Disinformation]{.underline} [is one of the Kremlin's most
important]{.underline} and far-reaching [weapons]{.underline}," the
Global Engagement Centre says at the top of its web page.
"[Russia]{.underline} has [operationalized]{.underline} [the concept of
perpetual adversarial competition]{.underline} [in the information
environment]{.underline} by [encouraging the development of a
disinformation and propaganda ecosystem]{.underline}."

[The new report]{.underline} on Africa [comes as]{.underline} the
[Biden]{.underline} administration [has been lobbying African countries
to join the West in denouncing Russia's invasion of
Ukraine]{.underline}. [Washington]{.underline} not only [hopes to see
the continent defend]{.underline} [the]{.underline} rules-based
[international order]{.underline} but [is just as keen to make
sure]{.underline} that [the surge in food]{.underline},
[fuel]{.underline} [and fertilizer]{.underline} prices
[that]{.underline} has [devastated Africa]{.underline} [gets blamed on
Moscow]{.underline} [rather than its own sanctions
campaign.]{.underline}

"[The impact on Africa of this conflict]{.underline}
\[[is]{.underline}\] [a]{.underline} direct [result]{.underline} [of
this war]{.underline}, and [Putin is to blame]{.underline}," Under
Secretary of State for Political Affairs Victoria Nuland tells The
Africa Report in an exclusive interview.

Focus on Wagner

[The new report is]{.underline} almost entirely [devoted to]{.underline}
the [Wagner]{.underline} Group [and]{.underline} its manager and
financier, oligarch and President Vladimir Putin ally Yevgeniy
[Prigozhin]{.underline}.

[The Treasury]{.underline} Department [sanctioned Prigozhin]{.underline}
in 2019 [for]{.underline} his alleged role in [seeking to
influence]{.underline} the [2018]{.underline} [midterm
elections]{.underline} [through his]{.underline} [Russian troll
farm]{.underline}, [the]{.underline} Internet Research Agency
([IRA]{.underline}).

[More sanctions]{.underline} have [followed]{.underline}, most recently
in March when the [Biden]{.underline} administration
[targeted]{.underline} [Prigozhin]{.underline} and his [family as part
of its bid to turn key oligarchs against the Ukraine war]{.underline}.

[The]{.underline} [Global]{.underline} [Engagement]{.underline}
[Centre]{.underline} [says]{.underline} [Wagner's
intervention]{.underline} in Mali [has been marked by]{.underline}
[false narratives]{.underline} since the very beginning.

"[Pitching themselves as able to counter the terrorist
threat]{.underline}, [Wagner]{.underline} Group forces [deployed to
Mali]{.underline} in December 2021 [amid a barrage of targeted
disinformation]{.underline} [to hide its arrival]{.underline} and
activities," the US report says.

[Russia's]{.underline} intensified [application of
disinformation]{.underline} and the use of the Wagner Group [across
Africa]{.underline} has [spread a trail of lies and human rights
abuses]{.underline}

The group is [accused of using a network of Facebook pages to promote
Russia as an]{.underline} "[alternative]{.underline}" [to]{.underline}
France and [the West]{.underline} in Mali while [encouraging the
postponement of local elections]{.underline}. Since then, [the State
Department says]{.underline}, [Russia]{.underline} has [deployed its
propaganda weapons to deflect responsibility]{.underline} for the Wagner
Group's alleged involvement in the massacre of at least 300 civilians in
the village of Mourah in central Mali while concocting a fake video
purporting to show dug up bodies near a former French base outside the
Malian village of Gossi.

Beyond Mali, [the State Department points to takedown notices on Twitter
and Facebook that allegedly exposed IRA efforts to:]{.underline}

- [trick journalists]{.underline} in Nigeria, Cameroon, The Gambia,
  Zimbabwe and the Republic of Congo [into publishing articles on its
  behalf]{.underline};

- [introduce a pro-Russia viewpoint in the Central African
  Republic]{.underline} ([CAR]{.underline})['s]{.underline} [political
  discourse]{.underline}; and

- [promote Russia and denounce French foreign]{.underline}
  [policy]{.underline} [in CAR]{.underline}, [Madagascar]{.underline},
  [Cameroon]{.underline}, [Equatorial Guinea]{.underline},
  [Mozambique]{.underline}, [South Africa and]{.underline} the
  [CAR]{.underline} [diaspora]{.underline} in France.

"[Russia's]{.underline} intensified [application of]{.underline}
[disinformation]{.underline} and the use of the Wagner Group across
Africa [has spread a trail of lies and human rights
abuses]{.underline}," the [State Department]{.underline} bulletin
[says]{.underline}. "[Despite]{.underline} US, EU, and UK
[sanctions]{.underline} and exposure of Prigozhin-linked entities that
spread disinformation, [these actors continue operating in
Africa]{.underline}, [exploiting]{.underline} [turbulent
situations]{.underline} [through]{.underline}
[disinformation]{.underline} [to sway]{.underline} [public
support]{.underline} [for the Russian government to]{.underline}
[expand]{.underline} [its influence]{.underline}."

[Beyond Russia]{.underline}

Idayat Hassan, the director of the Centre for Democracy and Development
in Nigeria, welcomes the Global Engagement Centre's latest report.

"[We need to]{.underline} actually [pay more attention]{.underline}
[to]{.underline} the role [disinformation]{.underline} is actually
playing on the continent, [and how it's]{.underline} actually
[stealing]{.underline} [the]{.underline} [hope]{.underline} [of citizens
and dampening]{.underline} [trust in democracy]{.underline} as well,"
says Hassan, who co-authored the November 2021 article titled Russian
Disinformation Is Taking Hold in Africa.

She worries that [disinformation is increasingly finding its way
offline]{.underline}, not only in newspaper and broadcast reports, but
also [in rallies in places like Mali and CAR where]{.underline} [Russian
flags are]{.underline} now [commonplace]{.underline}. She says not only
are a "[multitude of actors]{.underline}" [engaged in disinformation in
Africa]{.underline} besides Russia, including countries such as
[China]{.underline} [and]{.underline} [Turkey]{.underline}, but also
[local African nations and groups that are taking a page from Moscow's
playbook to launch their own assaults on the truth]{.underline}.

Although Africa's reduced reliance on Western narratives isn't
inherently a bad thing, Hassan worries that [the continent risks
aligning itself with illiberal actors]{.underline}. At the same time,
[the rise of information warfare presents]{.underline} real [risks of
further destabilizing the region]{.underline}.

[What's needed]{.underline}, she says, [is a comprehensive approach that
avoids]{.underline} once again [turning Africa into a
battlefield]{.underline} where great power rivalries play out, this time
[in the information space.]{.underline}

"[The emphasis]{.underline} \[[should be]{.underline}\] [to
ensure]{.underline} that [actions]{.underline} [are]{.underline} taken
in such a manner that it is [not viewed as]{.underline} a [geopolitical
warfare]{.underline}," Hassan says. "I think [we need a]{.underline}
kind of [new global order]{.underline}, [addressing
disinformation]{.underline}... It's [not just]{.underline} about
[Russia]{.underline}. [There is]{.underline} actually [a coalition of
actors]{.underline} [--- from nation-states]{.underline}, to
[businesses]{.underline}, to [individuals]{.underline} --- and
[we]{.underline} just [have to]{.underline} do something to
[address]{.underline} [what the]{.underline} [influence
industry]{.underline} currently [looks like]{.underline}, especially [if
we want to promote]{.underline} [democracy]{.underline} [and
guarantee]{.underline} [human rights]{.underline}."

#### The State Department has the [capabilities]{.underline} to fight [disinformation]{.underline} \-\-- [Bureau of Cyberspace and Digital Policy]{.underline} proves

Nike **Ching 21** (Nike Ching, VOA's State Department Bureau Chief, she
has traveled with four secretaries of state under Democratic and
Republican administrations, 10-27-2021, \"US State Department Creates
Bureau to Tackle Digital Threats,\" VOA,
https://www.voanews.com/a/us-state-department-creates-bureau-to-tackle-digital-threats/6288123.html,
DOA: 6-30-2022//Smarx Ahsan)

WASHINGTON --- [The State Department]{.underline} is [creating
a]{.underline} new [Bureau of Cyberspace]{.underline} [and Digital
Policy]{.underline} [to focus on tackling cybersecurity
challenges]{.underline} at a time of growing threats from opponents[.
There will]{.underline} also [be a new]{.underline} special
[envoy]{.underline} [for]{.underline} critical and [emerging
technology]{.underline}, [who will lead the technology
diplomacy]{.underline} [agenda]{.underline} with U.S. allies.

On Wednesday, Secretary of State Antony Blinken said [the organizational
changes]{.underline} [underscore]{.underline} [the need for a robust
approach for dealing with cyber threats.]{.underline}

\"[We want to make sure]{.underline} [technology works for
democracy]{.underline}, [fighting back against]{.underline}
[disinformation]{.underline}, [standing up for]{.underline} [internet
freedom]{.underline}, [and]{.underline} [reducing]{.underline} the
[misuse]{.underline} [of surveillance]{.underline}
[technology]{.underline},\" Blinken said in a speech on [modernizing
American diplomacy]{.underline}.

Blinken said [the new bureau will be led by an
ambassador-at-large]{.underline}. [The chief U.S. diplomat
is]{.underline} also [seeking a 50% increase in State
Department\'s]{.underline} [information technology budget]{.underline}.

[The announcement comes as hackers backed by]{.underline} foreign
governments, such as [Russia and China]{.underline}, [continue to attack
U.S.]{.underline} [infrastructures]{.underline} [and global technology
systems]{.underline} [to steal sensitive information]{.underline}.

Earlier this year, the Office of the Director of National Intelligence
said that [more countries are relying on cyber operations to steal
information]{.underline}, [influence populations]{.underline} and
[damage industry]{.underline}, but [the U.S. is most concerned about
Russia, China, Iran and North Korea]{.underline}.

The U.S. technology giant [Microsoft]{.underline} [said]{.underline} on
Monday that [the same Russia-backed hackers responsible for
the]{.underline} 2020 [SolarWinds breach]{.underline} of corporate
computer systems [are]{.underline} [continuing]{.underline} [to
attack]{.underline} [global technology systems]{.underline}, this time
[targeting cloud service resellers]{.underline}.

A senior [State Department]{.underline} official told reporters on
Wednesday that Washington [has been clear with Moscow]{.underline} that
[cyber criminals targeting the U.S. is]{.underline} \"[not
acceptable]{.underline}.\" [The United States]{.underline} has [asked
the Russian government to \"take action against that type of criminal
behavior]{.underline}.\"

[Confronting cyberattacks]{.underline} continues to be \"[a high
priority]{.underline}\" [in U.S. relations with Russia,]{.underline} the
senior official said.

[China]{.underline} is also [considered to be]{.underline} one of [the
United States\']{.underline} [main cyber adversaries]{.underline},
having [coordinated teams both inside and outside of the government
conducting cyberespionage]{.underline} [campaigns]{.underline} [that
were large-scale and indiscriminate]{.underline}, according to analysts.

Over the past year, [experts have attributed notable hacks in the
U.]{.underline}S., Europe and Asia to China\'s Ministry of State
Security, [the nation\'s civilian intelligence agency]{.underline},
which has [taken the lead in Beijing\'s cyberespionage]{.underline},
consolidating efforts by the People\'s Liberation Army.

[In addition to expanding the State Department\'s capacity on
cybersecurity]{.underline}, [Blinken]{.underline} also
[unveiled]{.underline} other [steps to modernize]{.underline} American
[diplomacy]{.underline}, including [the launch of a new]{.underline}
\"[policy ideas channel]{.underline}\" that [allows]{.underline}
[American diplomats]{.underline} [to share their policy
ideas]{.underline} [directly]{.underline} with senior leadership,
[building and retaining a diverse workforce]{.underline}, [as well as a
plan to]{.underline} \"[reinvigorate]{.underline} [the]{.underline}
[in-person diplomacy]{.underline} [and]{.underline} [public
engagement.\"]{.underline}

[The organization changes to beef up resources]{.underline} [and
staffers to tackle]{.underline} [international cybersecurity
challenges]{.underline} [came]{.underline} [after]{.underline}
[the]{.underline} [State Department]{.underline} [completed
an]{.underline} [extensive]{.underline} [review]{.underline}
[of]{.underline} cyberspace and [emerging technology]{.underline}.

### Competition\-\--DOS\-\--AT: PDCP 

#### The plan uses the [DOD]{.underline}.

Catherine A. **Theohary 18**, Specialist in National Security Policy,
Cyber and Information Operations, "Information Warfare: Issues for
Congress," Congressional Research Service, crsreport: R45142 version 5
//chico

IW = Information Warfare

[Within]{.underline} the [U.S. gov]{.underline}ernment,
[much]{.underline} of the [current infor]{.underline}mation
[war]{.underline}fare [doctrine and capability resides with the
military]{.underline}, making it the de facto center of gravity. 23
[DOD]{.underline} is also relatively [wellfunded, leading some to posit
that the epicenter for IW]{.underline} activities should be the
Pentagon. Some fear that military leadership of the IW sphere represents
the militarization of cyberspace, or the weaponization of information
that would counter the principles of global internet freedom. Title 10
U.S.C 2241 prohibits DOD from domestic "publicity or propaganda,"
although the terms are undefined. It is unclear how IW/IO relate to this
so-called military propaganda ban.

## EU 

### 1NC\-\--CP\-\--EU 

**[Next OFF is the Counterplan:]{.underline}**

#### **Text: The European Union should,**

#### Finalize the NIS Directive.

#### Coordinate attribution of cyberattacks, adopting a pooling of capabilities on a voluntary basis. 

#### Integrate CyCLONe into the EU cyber ecosystem. 

#### **The Counterplan solves [disinformation]{.underline} -- our evidence assumes Russia conflict**

Arthur **Laudrain 22** (Arthur Laudrain, DPhil candidate in
Cybersecurity at the University of Oxford (Wolfson College), Rotary
Scholar for Global Peace, and Fellow at the European Cyber Conflict
Research Initiative, Arthur de Liedekerke is a Project Manager at
political advisory Rasmussen Global and a non-resident fellow at the
Institute for Security Policy at Kiel University (ISPK), Germany,
3-30-2022, \"Russia's Cyber War: What's Next and What the European Union
Should Do.,\" Council on Foreign Relations,
https://www.cfr.org/blog/russias-cyber-war-whats-next-and-what-european-union-should-do,
DOA: 6-22-2022//Smarx Ahsan)

Contrary to widespread expectations, [the use of cyberweaponry in the
Russian war with Ukraine has]{.underline} so far [been
limited]{.underline}. To date, [the only significant, sophisticated
operations with suspected Russian involvement are the attacks on
communications]{.underline} giant Viasat's [satellite
networks]{.underline}, attempts [to install data-wiping malware on
Ukrainian government systems]{.underline}, [and attacks against
two]{.underline} major [Ukrainian telecommunications firms]{.underline}.

[There are several reasons that can plausibly explain why cyber
operations have remained marginal]{.underline} in the conflict. First,
[the Ukrainians have done a good job at bolstering their digital
defenses]{.underline}, helped in part by their American allies. [There
are also the inherent limitations of cyberattacks]{.underline}: in an
all-out kinetic war, [missiles offer a faster and more effective means
of achieving strategic objectives]{.underline} than lines of code.

Last, but certainly not least, it is worth remembering that [we are in
the early stages of a war that will drag on]{.underline}, potentially
[for months]{.underline}, [leaving]{.underline} plenty of [time for new
Russian cyber operations]{.underline}. Apparent [reluctance to use cyber
capabilities beyond]{.underline} limited operational-level hits or
[disinformation campaigns may well abate as fears of spillover or
retaliatory Western cyber responses diminish]{.underline}.
[The]{.underline} European Union ([EU]{.underline}) [must act
now]{.underline}, [while the intensity of cyber conflict]{.underline}
outside Ukraine [is still relatively low]{.underline}, [to bolster its
defenses and prepare for the specter of wide-ranging, damaging cyber
operations]{.underline} later in the conflict.

[Even if the Russians agree to a truce]{.underline}, cyber and
[disinformation]{.underline} efforts [would be one of the few avenues
available to them to inflict damage on Ukraine]{.underline} in the gray
zone [below the threshold of direct confrontation]{.underline}. [As the
Russian military shifts its objectives]{.underline}, [resources and
bandwidth will be freed up to fight from the rear]{.underline}. A
cornered [Moscow]{.underline}--with few other options left on the
table--[is likely to resort to the cyber domain]{.underline}, as other
pariah states have done, as the ideal vector to circumvent isolation,
s[py on and disrupt Western defense plans, steal technology and
intellectual property it will be cut off from, and heighten its global
nuisance with disinformation operations]{.underline}. [Recent attacks on
a major Ukrainian telecommunications firm, Ukrtelecom, have heightened
fears that Russia's stalling military campaign could cause it to turn to
cyber operations]{.underline} as another means of achieving its aims.

The EU has adopted new frameworks, including its much vaunted Strategic
Compass, which, in the long term, will improve cybersecurity in the
bloc, and potentially reduce the risk of catastrophic Russian
cyberattacks. However, [the EU needs to take more steps in the short
term to shore up cyber defenses and mitigate the threat of Russian cyber
operations.]{.underline}

First, [the EU should get its own house in order]{.underline}.
[The]{.underline} revised Network and Information Security
([NIS]{.underline}) [Directive]{.underline}--better known in Brussels
circles as NIS 2--[should be finalized in the coming months and will aim
to further strengthen the]{.underline} [security of supply
chains]{.underline}, [streamline]{.underline} [incident reporting
obligations]{.underline}, [and introduce more stringent supervisory
measures for a large number of operators of essential services and
enterprises across the EU]{.underline}. While NIS 2 represents a step in
the right direction, [the EU still has some way to go in implementing
harmonized cybersecurity rules]{.underline} across the bloc's own
institutions.

Second, [the EU and its Member States have a role to play in
discouraging and deterring cyberattacks by demonstrating a willingness
to act and impose costs on perpetrators]{.underline}. The first-ever
operational deployment of the EU's Cyber Rapid Response Team to Ukraine,
alongside similar teams from the United States, was a welcome signal in
this respect. [One way to impose further costs would be by pushing for
coordinated attribution of cyberattacks]{.underline} at the EU-level. On
the offensive and deterrent side, [the EU should adopt a pooling of
capabilities on a voluntary basis]{.underline}. Similar programs already
exist among other groups, such as NATO's Sovereign Cyber Effects
Provided Voluntarily by Allies (SCEPVA) program, which the EU could use
as a model for its own programs.

Third, [the EU should ensure it is better prepared by leveraging the
tools it already has at its disposal]{.underline}. [Intelligence sharing
and situational awareness have proven vital before and during the war in
Ukraine, but the future effectiveness of these strategies in deterring
and mitigating cyberattacks will be reliant on Member States willingness
to contribute with timely and actionable intelligence.]{.underline} In
the short term, [the]{.underline} Cyber Crisis Liaison Organisation
Network ([CyCLONe]{.underline}), [a recently created group bringing
together the executives of the EU's twenty seven national cybersecurity
authorities]{.underline}, [should be]{.underline} used to its full
capability and [integrated with the rest of the EU cyber
ecosystem]{.underline}. [CyCLONe]{.underline}, [with their wealth of
operational-level expertise, should be able to brief political
decision-makers in the Council]{.underline} more frequently. On the
military side, [the EU still lacks a fully fleshed-out cooperation
mechanism for military cybersecurity alerts]{.underline}, despite this
being an objective since the 2014 EU Cyber Defence Policy Framework.
[Ensuring cooperation among both civilian and military groups is
vital]{.underline} given the specter of Russian cyberattacks.

[Supporting Ukraine is every democracy's duty]{.underline}. [Russia will
attempt to undermine this support through cyberattacks and other
means]{.underline}. [The EU needs to shore up its cyber defenses at home
to ensure all Members can continue to aid Ukraine]{.underline} in the
future.

## UN

### 1NC\-\--CP\-\--UN

#### The United Nations should create a United Nations General Assembly committee to manage international information networks.

#### The CP solves

Hanci **Lei 19**, is based at Brown University and majored in Economics
and Political Science. He worked at a Think Tank in Washington D.C.,
June 2019, \" Modern information warfare: analysis and policy
recommendations,\" Emerald Publishing,
https://www.emerald.com/insight/content/doi/10.1108/FS-06-2018-0064/full/pdf?title=modern-information-warfare-analysis-and-policy-recommendations
//AShah

\*\*IIN = International Information Networks

\*\*IW = Information Warfare

[Recognizing the rapid evolution of information technologies over the
past few decades, one important [policy that may facilitate the
development of norms around information warfare is the development of a
UN General Assembly]{.mark} (GA) committee [to manage IIN]{.mark}. [The
U]{.mark}nited [N]{.mark}ations [is an institution that has the power to
deal with "peace]{.mark} and security" and "governance" issues; it has
historically been a forum where states can express their views and
establish norms as the find "areas of agreement and solve problems
together"]{.underline} (United Nations, 2018). So, [[there is potential
in using this institution to]{.mark} manage IW.]{.underline} This
committee could have a mission similar to the Disarmament and
International Security Committee, whose mission is to deal with
"disarmament, global challenges and threats to peace that affect the
international community and \[seek\] out solutions to the challenges in
the international security regime" (General Assembly of the United
Nations, 2018). Similarly, an "Information Infrastructure Management
Committee" can [[deal with "safe development of information
infrastructure, global challenges and threats to the security of
information infrastructure, and seek out solutions to the threat of
information warfare]{.underline}.]{.mark}" Such a committee can allow
states discuss potential weaknesses to information infrastructure in an
international forum, thus giving the issue more international
recognition. [[Having more states recognize the threat of IW]{.mark} and
discuss common ways IW manifests itself [will reduce the challenges of
managing perceptions because states would be better able to identify
whether]{.mark} or not [they are under attack]{.mark} by publically
examining past examples of IW [and creating defined international norms
on the issue]{.mark}.]{.underline} Images and narratives could still be
manipulated; however, if methods of manipulation become well known and
identified by the international community, they would become less
effective as states would be better able to identify whether or not they
are subject to such manipulation. [Finally, by publicly identifying
manipulation tactics, the costs of using IW effectively would also be
driven up substantially because the increased demand for rapid
innovation of IW tactics to keep up with the exposure of such tactics
would ensure that only the richest states -- ones that have little
incentive, as discussed earlier, to develop the infrastructure necessary
to be able to launch sustained IW campaigns -- have the resources to use
IW as an effective policy tool. Thus, driving up the cost of IW
mitigates the threat of attacks from illiberal or nonstate
actors.]{.underline}

# Kritiks 

## Capitalism

### Cap K\-\--Link\-\--Info Warfare 

#### Countering disinformation relies on a false, ideological narrative of [media objectivity]{.underline}\-\--that naturalizes [capitalism]{.underline} and the [security state]{.underline} 

Joseph **Bernstein 21** is a senior reporter at BuzzFeed News and a 2021
Nieman Fellow. "Bad News: Selling the story of disinformation," Harper's
Magazine,
<https://harpers.org/archive/2021/09/bad-news-selling-the-story-of-disinformation/>
//chico

An [even more vexing issue for]{.underline} the
[disinfo]{.underline}rmation [field]{.underline}, though,
[is]{.underline} the [supposedly objective stance media researchers and
journalists take toward the info]{.underline}rmation
[ecosystem]{.underline} to which [they]{.underline} themselves [belong.
Somewhat amazingly]{.underline}, [this attempt has taken place alongside
an agonizing and overdue questioning within the media of the harm done
by unexamined professional standards of objectivity.]{.underline} Like
journalism, scholarship, and all other forms of knowledge creation,
[disinformation research reflects the culture, aspirations, and
assumptions of its creators]{.underline}. A quick scan of the
institutions that publish most frequently and influentially about
disinformation: Harvard University, the New York Times, Stanford
University, MIT, NBC, the Atlantic Council, the Council on Foreign
Relations, etc. That the [most prestigious liberal institutions of the
pre-digital age]{.underline} are the [most invested in fighting
disinfo]{.underline}rmation [reveals a lot about what they stand to
lose,]{.underline} [or hope to regain]{.underline}. [Whatever the
brilliance of the individual]{.underline} disinformation
[researchers]{.underline} and reporters, the [nature of the project
inevitably places them in a regrettably defensive position
in]{.underline} the contemporary [debate about media representation,
objectivity, image-making, and public knowledge]{.underline}. [However
well-intentioned]{.underline} these professionals are, they [don't have
special access to the fabric of reality.]{.underline}

This spring, in light of new reporting and a renewed, bipartisan
political effort to investigate the origins of COVID-19, Facebook
announced that it would no longer remove posts that claimed that the
coronavirus was man-made or manufactured. Many disinformation workers,
who spent months calling for social-media companies to ban such claims
on the grounds that they were conspiracy theories, have been awkwardly
silent as scientists have begun to admit that an accidental leak from a
Wuhan lab is an unlikely, but plausible, possibility.

Still, [Big Disinfo can barely contain its desire to hand the power of
disseminating knowledge back to a set of "objective"
gatekeepers.]{.underline} In February, the tech news website Recode
reported on a planned \$[65 million nonpartisan news
initiative]{.underline} called the Project for Good Information. Its
[creator]{.underline}, Tara McGowan, [is a veteran
Dem]{.underline}ocratic [op]{.underline}erative [and]{.underline} the
[CEO of]{.underline} Acronym, a center-left digital-advertising and
voter-mobilization [nonprofit whose PAC is funded by]{.underline}, among
others, Steven [Spielberg]{.underline}, the [LinkedIn
co-founder]{.underline} Reid Hoffman, [and]{.underline} the [venture
capitalist]{.underline} Michael Moritz. The [former Obama campaign
manager]{.underline} David Plouffe, currently a strategist at the Chan
Zuckerberg Initiative, [is an official]{.underline} Acronym [adviser.
Meanwhile]{.underline}, a February [N]{.underline}ew [Y]{.underline}ork
[T]{.underline}imes article humbly [suggested the appointment of a
"reality czar"]{.underline} who [could "become]{.underline} the [tip
of]{.underline} the [spear for]{.underline} the [fed]{.underline}eral
government's [response]{.underline} to the reality crisis."

The [vision of a godlike scientist bestriding the media on behalf of the
U.S. government]{.underline} is almost [a century old]{.underline}.
[After]{.underline} the [First World War]{.underline}, the [academic
study of propaganda was explicitly]{.underline} [progressive and
reformist]{.underline}, [seeking to expose]{.underline} the role of
powerful interests in shaping the news. [Then,]{.underline} in the late
1930s, the [Rockefeller Foundation]{.underline} [began sponsoring
evangelists of a new discipline called communication
research]{.underline}. The psychologists, political scientists, and
consultants behind this movement [touted]{.underline} their
methodological sophistication and absolute [political
neutrality.]{.underline} They hawked Arendt's "psychological premise of
human manipulability" to government officials and businessmen, much as
the early television ad executives had. They [put]{.underline}
[themselves in the service of the state.]{.underline}

The media scholar Jack Bratich has argued that the contemporary
[antidisinformation industry is part of a "war of restoration" fought by
an American political center humbled by]{.underline} the economic and
political [crise]{.underline}s of the past twenty years. [Depoliticized
civil society]{.underline} becomes, per Bratich, "[the terrain for the
restoration of authoritative truth-tellers]{.underline}" like, well,
Harvard, the New York Times, and the Council on Foreign Relations. In
this argument, the [Establishment has turned its methods for
discrediting the information of its geopolitical enemies against its own
citizens.]{.underline} The [Biden]{.underline} Administration's National
Strategy for [Countering Domestic Terrorism]{.underline}---the first of
its kind---[promises to]{.underline} "[counter]{.underline} the
[polarization]{.underline} often [fueled by disinfo]{.underline}rmation,
misinformation, and dangerous conspiracy theories online." The [full
report warned not just of right-wing militias]{.underline} and incels,
[but anticapitalist, environmental, and animal-rights activists
too]{.underline}. This comes as [governments around the world have
started using emergency "fake news" and "disinformation" laws to harass
and arrest dissidents and reporters.]{.underline}

One needn't buy into Bratich's story, however, to understand what tech
[companies]{.underline} and select media organizations all [stand to
gain from the Big Disinfo worldview.]{.underline} The [content
giants]{.underline}---Facebook, Twitter, Google---have
[tried]{.underline} for years [to leverage]{.underline} the credibility
and expertise of certain forms of journalism through [fact-checking and
media-literacy initiatives]{.underline}. In this context, the
[disinfo]{.underline}rmation [project]{.underline} is si[mply an
unofficial partnership between Big Tech, corporate media, elite
universities, and cash-rich foundations]{.underline}. Indeed, over the
past few years, [some journalists]{.underline} have [started to grouse
that their jobs now consist of fact-checking]{.underline} the very [same
social platforms]{.underline} [that are vaporizing their
industry.]{.underline}

[Ironically]{.underline}, to the extent that [this work creates undue
alarm]{.underline} about disinformation, it [support]{.underline}s
[Facebook's sales pitch]{.underline}. [What could be more appealing to
an advertiser]{.underline}, after all, [than a machine that can persuade
anyone of anything]{.underline}? [This understanding benefits
Facebook]{.underline}, which [spreads more bad information, which
creates more alarm.]{.underline} [Legacy outlets with usefully
prestigious brands]{.underline} are taken on board as trusted partners,
to [determine when the levels of contamination in the information
ecosystem]{.underline} (from which [they have magically detached
themselves]{.underline}) [get too high]{.underline}. [For the old media
institutions,]{.underline} it's [a bid for relevance, a form of
self-preservation. For]{.underline} the [tech]{.underline} platforms[,
it's a superficial strategy to avoid deeper questions]{.underline}. A
trusted disinformation field is, in this sense, a very useful thing for
Mark Zuckerberg.

#### Countering disinformation relies on a [false narrative]{.underline} of an "[algorithmic fix]{.underline}"\-\--that masks the [material conditions]{.underline} that [enable violence]{.underline}. 

Joseph **Bernstein 21** is a senior reporter at BuzzFeed News and a 2021
Nieman Fellow. "Bad News: Selling the story of disinformation," Harper's
Magazine,
<https://harpers.org/archive/2021/09/bad-news-selling-the-story-of-disinformation/>
//chico

This finding resonated with earlier research suggesting that
disinformation typically needs the support of political and media elites
to spread widely. That is to say, the persuasiveness of information on
social platforms depends on context. [Propaganda doesn't show up out of
nowhere, and it doesn't all work the same way.]{.underline} Ellul wrote
of the [necessary role of what he called "pre-propaganda":]{.underline}

[Direct propaganda]{.underline}, aimed at modifying opinions and
attitudes, [must be preceded by propaganda that is sociological in
character, slow, general, seeking to create a climate, an atmosphere of
favorable preliminary attitudes]{.underline}. [No direct propaganda can
be effective without pre-propaganda,]{.underline} [which, without direct
or noticeable aggression, is limited to creating ambiguities, reducing
prejudices, and spreading images, apparently without
purpose.]{.underline}

Another way of thinking about [pre-propaganda is]{.underline} as t[he
entire social, cultural, political, and historical context.]{.underline}
In the [U]{.underline}nited [S]{.underline}tates, [that context includes
an idiosyncratic electoral process and a two-party system that has
asymmetrically polarized toward a nativist, rhetorically anti-elite
right wing]{.underline}. It also includes a libertarian social ethic, a
"paranoid style," an "indigenous American berserk," a [deeply
irresponsible national broadcast media, disappearing local
news]{.underline}, an [entertainment industry that glorifies violence, a
bloated military, massive income inequality, a history of brutal and
intractable racism that has time and again shattered class
consciousness, conspiratorial habits of mind, and themes of
world-historical declension and redemption]{.underline}. The [specific
American situation was creating specific kinds of people long before the
advent of tech platforms]{.underline}.

To take the whole environment into view, or as much of it as we can, is
to see [how preposterously insufficient it is to blame these platforms
for the sad extremities of our national life]{.underline}, [up to and
including the riot on January 6.]{.underline} And yet, given the
technological determinism of the disinformation discourse, is it any
surprise that attorneys for some of the Capitol rioters are planning
legal defenses that blame social-media companies?

Only certain types of people respond to certain types of propaganda in
certain situations. The [best reporting on QAnon]{.underline}, for
example, [has taken into account the conspiracy movement's popularity
among white evangelicals.]{.underline} The [best reporting about
vaccine]{.underline} and mask skepticism has [take]{.underline}n into
account the [mosaic of experiences that form the American attitude
toward the expertise of public-health authorities]{.underline}. [There
is nothing magically persuasive about social-media platforms; they are a
new and important part of the picture, but far from the whole
thing.]{.underline} Facebook, however much Mark Zuckerberg and Sheryl
Sandberg might wish us to think so, is not the unmoved mover.

[For anyone who has used Facebook recently]{.underline}, [that should
be]{.underline} [obvious]{.underline}. Facebook [is full of ugly memes
and boring groups, ignorant arguments, sensational clickbait, products
no one wants, and vestigial features no one cares about. And yet the
people most alarmed about Facebook's negative influence are those who
complain the most about how bad a product Facebook is.]{.underline} The
question is: Why do disinformation workers think they are the only ones
who have noticed that Facebook stinks? Why should we suppose the rest of
the world has been hypnotized by it? Why have we been so eager to accept
Silicon Valley's story about how easy we are to manipulate?

Within the knowledge-making professions [there are]{.underline} some
[sympathetic structural explanations]{.underline}. Social scientists get
funding for research projects that might show up in the news. Think
tanks want to study quantifiable policy problems. Journalists strive to
expose powerful hypocrites and create "impact." Indeed, the tech
platforms are so inept and so easily caught violating their own rules
about verboten information that a generation of ambitious reporters has
found an inexhaustible vein of hypocrisy through stories about
disinformation leading to moderation. As a matter of policy, [it's much
easier to focus on an adjustable algorithm than entrenched social
conditions.]{.underline}

Yet [professional incentives only go so far]{.underline} in explaining
why the [disinfor]{.underline}mation [frame has become so
dominant]{.underline}. Ellul [dismissed]{.underline} a "common [view of
propaganda]{.underline} . . . that it is the [work of a few evil men,
seducers of the people]{.underline}." He [compare]{.underline}d this
[simplistic story to midcentury studies of advertising]{.underline}
"[which regard the buyer as victim and prey."]{.underline} Instead, he
wrote, [the propagandist and the propagandee make propaganda
together.]{.underline}

One reason to grant [Silicon Valley's assumptions about our mechanistic
persuadability]{.underline} is that it [prevents us from thinking too
hard about the role we play in taking up and believing the things we
want to believe.]{.underline} It [turns a huge question about the nature
of democracy in the digital age]{.underline}---what if the people
believe crazy things, and now everyone knows it?---[into a technocratic
negotiation between tech companies, media companies, think tanks, and
universities.]{.underline}

But there is a deeper and related reason many critics of Big Tech are so
quick to accept the technologist's story about human persuadability. As
the political scientist Yaron Ezrahi has noted, the [public relies on
scientific and technological demonstrations of political cause and
effect because they sustain our belief in the rationality of democratic
government.]{.underline}

Indeed, it's possible that [the Establishment needs the theater of
social-media persuasion to build a political world that still makes
sense, to explain]{.underline} Brexit and Trump and the [loss of faith
in the decaying institutions of the West]{.underline}. The
[ruptures]{.underline} that [emerged across]{.underline} much of the
[democratic world]{.underline} five years ago [called into question the
basic assumption]{.underline}s of so [many of the participants in this
debat]{.underline}e---the social-media executives, the scholars, the
journalists, the think tankers, the pollsters. A [common
account]{.underline} of social media's persuasive effects [provides a
convenient explanation for how so many people thought so wrongly at more
or less the same time.]{.underline} More than that, [it creates a world
of persuasion that is legible and useful to capital]{.underline}---to
advertisers, political consultants, media companies, and of course, to
the tech platforms themselves. It is a [model of cause and effect in
which the information circulated by a few corporations has the total
power to justify the beliefs and behaviors of the demos]{.underline}. In
a way, [this world is a kind of comfort. Easy to explain, easy to tweak,
and easy to sell, it is a worthy successor to the unified vision of
American life produced by twentieth-century television]{.underline}. It
is not, as Mark Zuckerberg said, "a crazy idea." Especially if we all
believe it.

### Cap K\-\--Link\-\--Greenwashing

#### The "information-ecosystem" metaphor [greenwashes]{.underline} the [environmental impacts]{.underline} from [big data]{.underline} and legitimizes neoliberal narratives of the market existing as a [natural phenomenon]{.underline} rather than an [artificial one]{.underline}. [Reject the plan]{.underline} in favor of [information ethics.]{.underline} 

Timothy B. **Norris et. al 21**, library assistant professor in research
data science Libraries and the Center for Computational Science at the
University of Miami. Has a Ph.D in environmental studies from the
University of California Santa Cruz, Todd Suomela digital pedagogy
specialist at Bucknell University. Has a Ph.D. in communication and
information from the University of Tennessee, "Information in the
ecosystem: Against the "information ecosystem," First Monday,
<https://firstmonday.org/ojs/index.php/fm/article/view/6847/6530>
//chico

5.3. Green\[wash\]ing the information economy

It is difficult to argue that anything ecological is wrong or bad.
[Using the term "information]{.underline} [ecology"]{.underline} (as a
set of relations) may [imply]{.underline} that [information systems form
part of "everything" good.]{.underline} Lucas, et al. (2012) made a
strong argument that the purpose of using [the information ecology
metaphor]{.underline} (as a set of relations) is to [bring individuals
back into the solution]{.underline}. The authors focus on human-centric
design with less visible technologies. Their [arguments are politically
conservative for the 'liberation' of information from
regulation]{.underline}; the [information ecology]{.underline} (as a set
of relations) [will be self-regulating]{.underline}, [based in
free-market neoliberalism]{.underline}, [and generate profit
opportunities for businesses.]{.underline}

The description of the early development of ecological thought in the
first part of this paper showed how closely the [discourse of markets
and environment could be aligned to a discussion of
ecology.]{.underline} The [early mirroring between the economy and
ecosystem was supplanted by later ideas incorporating complex systems,
cooperation, and autopoesis]{.underline}. In their view of ecosystems,
Lucas, et al. (2012) harkened back to the some of the earliest uses of
the term "ecosystem" a usage that many ecologists have now dismissed.
[Perhaps]{.underline} Lucas, et al. [used]{.underline} the word
[ecology,]{.underline} [instead of economy]{.underline},
[because]{.underline} they knew that with the word economy, [the
artificiality of the system would be revealed to readers and the
inevitable naturalization of the system]{.underline} that they described
[would be that much more difficult.]{.underline}

The [danger of using]{.underline} the [language of information
ecosystems and ecologies is that very real environmental impacts of
information economies will be less visible]{.underline}. As an example,
the "cloud" is anything but a cloud. It is literally tons of digital
storage devices (spinning metal disks) residing in air-conditioned
complexes with thick steel walls and concrete encasings, consuming
enormous amounts of energy \[32\]. [All the equipment on]{.underline}
which [our information technologies depend draw significant quantities
of natural resources from the environment]{.underline} (metal, plastic,
energy, and rare earth minerals), eventually [becoming part of a waste
stream returning to the environment]{.underline}. In many parts of the
world, [extraction and recycling are unregulated industries with
negative environmental and social impacts]{.underline} \[33\]. The cloud
relies on these very material industries. How long will it be until
negative environmental outcomes of high-flow liberated data will become
apparent?

The [information ethic]{.underline} in this critique [is based upon
explicitly acknowledging that information]{.underline} [systems are
human creations]{.underline}, [not natural phenomena]{.underline}. It
[follows the same argument that the free market is a myth]{.underline};
better said, [the so-called "invisible hand"]{.underline} of Adam Smith
[is subordinate to institutions created by humans]{.underline} \[34\].
This [does not deny the possibility of creating greener and friendlier
information systems]{.underline}; [instead it creates opportunities to
emphasize the human role in these processes.]{.underline}

## Security 

### Link\-\--Hybrid War 

#### The AFF presents the [paradox]{.underline} of [liberal security]{.underline}\-\--hybrid warfare is [not an anomaly]{.underline} but rather the [true nature]{.underline} of war, making the AFF a product of [endless securitization]{.underline} and [turning cooperation]{.underline}. The alternative is an [interrogation of war]{.underline}, laying bare the indistinguishability of [politics and warfare]{.underline}.

Maria **Malksoo 18**, Researcher at the International Centre for Defence
Studies, Tallinn, Estonia and a Lecturer at the Institute of Government
and Politics, University of Tartu, Estonia. Her main research interests
include critical security studies, political anthropology and European
memory politics. "Countering Hybrid Warfare as Ontological Security
Management: The Emerging Practices of the EU and NATO" *European
Security 27(3)*, pp. 374-392
<https://doi.org/10.1080/09662839.2018.1497984> //lenox

NATO "[[Hybrid warfare]{.underline}" [has emerged
as]{.underline}]{.mark} [yet [another "resilience
test]{.mark}]{.underline}" (Stoltenberg 2015a) [for the Alliance in its
post-Cold War existential search]{.underline} for a new purpose and
mission. Moreover, the [hybrid [insecurity]{.mark} predicament
[enables]{.mark} the [allies to bring together]{.mark} the renewed
[focus on NATO's traditional mission]{.mark}]{.underline} (i.e.
endorsing collective defence in order to counter the main geopolitical
contestant of the North Atlantic Alliance in Europe) and the Alliance's
post-Cold War out-of-area military expeditions. While "tak\[ing\] on two
different forms of strategic challenges simultaneously" -- that is, "the
Russian hybrid warfare approach" and that of "other non-state actors
like ISIS to the south" -- remains NATO's "greatest challenge", the
[common idea behind these "[hybrid strategies]{.mark}" [endorses the
relevance of "a comprehensive approach]{.mark} across the DIMEFIL
spectrum]{.underline}" (i.e. diplomatic/political, information,
military, economic, financial, intelligence, legal) for NATO (Breedlove
2015, p. xxv; cf. Bell 2012, pp. 225-226). The "[beauty of the hybrid
warfare concept" is accordingly seen to lie in its ability to
"provide\[\] tools for a comparative strategic perspective of NATO's
southern and eastern flanks]{.underline}, while allowing for a
differentiated response" (Johnson 2015, p. 276). NATO's motto in the
face of these twofold challenges is called to be "adopt, adapt, adept":
the new strategies adopted to deal with the hybrid threats to NATO's
East and South need to be accompanied by NATO's adaptation of "its
structure and readiness to become adept at handling the new challenges
it faces" (Calha 2015, p. 9). [Countering hybrid threats posed by Russia
and the Islamic radicals]{.underline} threatening the territories,
populations, interests, and values of the Alliance thus [[enables NATO
to endorse its]{.mark} continuing [relevance by constructing a strong
narrative]{.mark} and maintaining its OS as the core security guarantor
for its members]{.underline} (cf. Flockhart 2012, pp. 78-79). The
softer, partnership geared, or so-called "Jane" narrative of the
early-post Cold War NATO is clearly giving way 23 to a more familiar,
hard security-focused "Tarzan" self-vision and public representation
(see further Flockhart 2011). Calling the kettle black is the least of
NATO's worries: Russia's use of "proxy soldiers, unmarked Special
Forces, intimidation and propaganda, all to lay a thick fog of
confusion; to obscure its true purpose in Ukraine; and to attempt
deniability" is explicitly dissected in outlining NATO's emerging
counter-strategy to hybrid engagements of the sort (Stoltenberg 2015a).
Yet, just the traditional set of NATO's capabilities is clearly deemed
to be insufficient in the face of, inter alia, "sophisticated
disinformation and radicalization campaigns" (Stoltenberg 2015b), this
more forceful and traditional antagonist-driven agenda reflects NATO's
long-pursued comprehensive approach -- that is, "a combination of
military and non-military means to stabilize countries" (that others use
to "destabilize") (Stoltenberg 2015a). "[[Hybrid" is accordingly coined
as "the dark reflection" of NATO]{.mark}'s comprehensive
approach]{.underline}, and accordingly, early warning and situation
awareness, good governance and the resilience of societies become
equally essential parts of deterrence and defence against hybrid threats
(Stoltenberg 2015a). [This necessitates "renewed attention to strategic
communications" and public outreach and education "to build up public
awareness and resilience]{.underline}" and "strengthen the role of an
informed civil society in every member state" (Calha 2015, p. 10).13
NATO declared its readiness to address the specific challenges posed by
"hybrid warfare threats" in the Wales Summit Declaration of 5 September
2014 as a forceful response to the conflict in Ukraine. While NATO's
traditional toolbox of collective defence is hardly perfectly geared for
"insidious and ambiguous threats" (Johnson 2015, p. 270; Calha 2015, p.
4), countering hybrid warfare emerges as a continuing relevance and
resilience test for the Alliance. [NATO's institutional responses to
"hybrid threats" have been further detailed]{.underline} in its
Readiness Action Plan, a roadmap for building capability packages, a
[comprehensive concept for creating an enhanced NATO response force, in
a classified strategy for hybrid warfare and a cyber security action
plan]{.underline}. Altogether, the [[ambiguity]{.mark} and gradient
nature [of hybrid tactics directly challenge the ontological
underpinnings of NATO]{.mark}'s core mission and strength as hybrid
activities might "progress incrementally towards a threatening situation
while remaining under NATO's Article 5 threshold]{.underline}" (Calha
2015, p. 4). The [detection and [definition of a threat]{.mark} hence
[becomes]{.mark} significantly [less
straightforward]{.mark}]{.underline}[, [pointing at the need to
renegotiate the scope]{.underline}]{.mark} [and substance [of NATO's
collective defence]{.mark} clause]{.underline} (i.e. Article 5 of the
Washington Treaty) in light of the contemporary hybrid engagements.
Conclusion This article has brought the notion of OS to bear on the thus
far heavily policy-oriented hybrid warfare literature. As hybrid threats
epitomize ontological insecurity, [[NATO]{.mark} and the EU's
[synergistic discourse]{.mark} and emerging practice [on countering the
hybrid menace]{.mark} [emerges as an attempt at the
institutionalization]{.mark} of their organizational
OS-seeking]{.underline}. [Tackling the hybrid challenges of the day in
apparent unison further provides NATO and the EU a silver lining of a
tightened cooperation]{.underline} between the two organizations.
Further research could map the complex interactions between the
OS-seeking strategies of these distinct intergovernmental institutions
and their member states/societies with regard to countering hybrid
warfare. It would be interesting to investigate, for example, how the
[traditional [lines of division within the]{.mark} European
[community]{.mark} along the more Russia-friendly and Russia-wary
countries might [tap into the institutional dynamics of hybrid threat
management]{.mark} of the EU and NATO]{.underline}. Moreover, the
[[newly established special sub-institutions]{.mark} to confront hybrid
threats within the EU along with the organizationally unaffiliated
Centre of Excellence could themselves develop their own 25
identities]{.underline}, OS drives and placating routines, [potentially
[generating organizational fragmentation and inter-agency
tensions]{.mark} instead of bolstering the OS of the Union as a
whole]{.underline} (cf. Steele 2017). With regard to the ethical
drawbacks of effective hybrid threat management, such [[endeavour points
at]{.mark} the problematic prospect of [compromising the]{.mark} already
fuzzy [distinction between politics and war]{.mark}]{.underline} -- [as
according to the hybrid warfare paradigm, [all politics becomes reduced
to the potential build-up phase for]{.mark} a full-blown
[confrontation]{.mark}]{.underline}. In that sense, hybrid warfare is
close to the criteria of "minimal wars, which consist in merely
threatening the enemy with negotiations held in reserve" (Clausewitz
1976, 604, emphasis in the original). The alleged "[[minimality]{.mark}"
of such a way of warfare nonetheless has considerable potential to
[induce]{.mark} broad and [deep securitisation]{.mark} of various public
policy processes in the Western societies]{.underline} and their
supranational organizations in question. [Hybrid warfare and the
emerging institutionalization of its [countering practices highlight the
paradox of defending]{.mark} democratic [security]{.mark}
communities]{.underline}, [[as the efficacy]{.mark} of such defence
[might]{.mark} in fact [be detrimental to some of the core organising
principles]{.mark} of democracy]{.underline}. [An [alternative
approach]{.mark}]{.underline} [[would be to argue that hybrid
warfare]{.mark}, and the countering practices it is generating, [have
simply brought the nature of the modern power]{.mark} out into the
open]{.underline}. As Foucault maintains in his Society Must Be
Defended, liberal "[[civil peace" must be understood as a secret form of
war]{.underline}]{.mark}, for "[[war is the]{.mark} principle and
[motor]{.mark} of the exercise [of political power]{.mark}]{.underline}"
in general (Foucault 2003, p. 18). Viewed from such a perspective,
[hybrid warfare and its emerging management practices by the EU and NATO
enable us to see what politics is allegedly all about
anyway]{.underline} -- "the continuation of war by other means"
(Foucault 2003, p. 15). For the EU and NATO, [hybrid [warfare
embodies]{.mark} not just [the unsettling of the politics/war
distinction but raises the fundamental question about the practical
distinguishability of their]{.mark} physical and ontological
[security]{.mark} in the first place]{.underline}.

# ADV\-\--Russia

## Squo Solves

### 1NC\-\--Squo Solves Russia 

#### Existing pushback [solves]{.underline} information warfare\-\--Ukraine has made people more [aware]{.underline} of disinformation campaigns

Philip **Seib 22**, professor of Journalism and Public Diplomacy at USC,
5/9/22,"Why Russia is losing the information war,"
https://uscpublicdiplomacy.org/blog/why-russia-losing-information-war/mh

Poor Vladimir Putin. Sitting at his long table by himself, confronting
failure. The Russian military machine, weighed down by its antiquated
hardware and obsolete tactics, can barely hold its own against Ukraine.
The Russian economy is on life support. The archenemy, NATO, is poised
to expand further, adding Finland and Sweden to its ranks. The Kremlin
is not a happy place.

[Putin's information war is also **not going well**]{.underline}. Just a
decade ago, things were very different. Russia had embraced information
warfare as a low-risk tool to undermine adversaries. Gen. Valery
Gerasimov, chief of the general staff of Russia's armed forces, wrote in
2013: "The very 'rules of war' have changed. The role of nonmilitary
means of achieving political and strategic goals has grown, and, in many
cases, they have exceeded the power of force of weapons in their
effectiveness."

[For the Kremlin, information warfare is a key facet of Russia's version
of public diplomacy]{.underline}. With little (if any) allegiance to
truth, Russia's messaging to global publics accentuates
self-justification as it pursues dangerous adventurism.

In line with this, in 2014 Russia unleashed a flood of propaganda about
its need to rescue the supposedly oppressed Russian minorities in
eastern Ukraine, and followed with a de facto invasion. In 2016,
Russia's information efforts directed at the American electorate proved
effective, as the Kremlin's internet trolls helped put Donald Trump in
the White House. These successes crowned years of Russian information
skirmishing directed at the Baltic States and other former Soviet
properties that Putin wanted to reclaim.

[Given Russia's apparent preeminence in information warfare, taking
control of Ukraine seemed well within the Kremlin's grasp. This year, as
its troops massed along the Russia-Ukraine border, **Russia's
information attacks were relentless**, claiming that Ukraine was riddled
with corruption, was run by Nazis, and was not really a nation. Once
again, with this messaging as a foundation, Russia rolled into
Ukraine.]{.underline}

[Despite its past successes, **Russia's information strategy did not
work this time**. The reason, in a word: pushback.]{.underline}

Resistance to past Russian information efforts was usually too little,
too late. Especially in the United States in 2016, the breadth and
effectiveness of the Russian campaign was not fully recognized until
after the election, and little was done in timely fashion to respond to
Kremlin influence.

[In 2022 that has changed, and counterattacks against Russian
information efforts have taken place on many fronts. Western journalists
now recognize that they have a responsibility to address Russian lies
with timely reporting, and to find ways to circumvent barriers to
delivery of that reporting.]{.underline} [Although the Russian
government tries to keep its citizens from seeing unfriendly news
content, the ever-expanding universe of information technology provides
workarounds.]{.underline} For example, the Telegram messaging service
offers channels that can be used by Russians to peruse content from
global news media. Also, [millions of Russians work around
censorship]{.underline} by downloading a virtual private network (VPN)
that allows them to access online information that is banned by their
government.

[Western governments' information agencies are also assertively
responding to Russia]{.underline}. [The United States Agency for Global
Media (USAGM) has undertaken a massive effort to create an information
"ring around Russia" that delivers programming designed not only for
Russians, but is also directed to publics in countries such as Belarus,
Moldova, Kazakhstan, and other neighbors of Russia]{.underline}. Since
the February invasion began, the agency has also introduced a new
Ukrainian- and Russian-language satellite channel that reaches all of
Ukraine and parts of Russia. While the Kremlin silences independent
media voices within Russia, demand for content from abroad grows. During
the first three weeks after Russia's invasion, USAGM verified more than
one billion video views of its Russian-language programs across social
media platforms. The agency reports that interviews with grieving
Russian mothers whose sons were killed in combat are among the most
widely viewed.

[Ukraine itself is doing a remarkable job of presenting its story to the
world.]{.underline} President Volodymyr Zelenskyy is ubiquitous. Whether
he is walking through Kyiv or addressing the United Nations, Zelenskyy
forcefully calls upon the world to assist his country. He has become a
media superstar, admired as the Ukrainian David standing up to the
Russian Goliath. Besides Zelenskyy, Ukrainian officials and individual
citizens flood social media with words and images about their resistance
to the invader. This content is often heartbreaking, as it vividly
illustrates the human costs of war, but for now it keeps Ukraine at the
forefront of debate about the geopolitical future.

In response, the Kremlin relies on connecting with presumably
sympathetic Russian-speaking minorities in Ukraine and elsewhere. It
also broadcasts anti-American messaging about Ukraine to parts of the
world where suspicion of the United States runs high. [But in the
contest for Western public opinion, Russia is finding itself
overmatched.]{.underline}

### 2NC\-\--Squo Solves Russia 

#### The US is [ramping up]{.underline} information warfare against Russia \-\-- [plot exposing]{.underline} proves

Max **Boot 22** (Max Boot, Jeane J. Kirkpatrick Senior Fellow for
National Security Studies, 2-10-2022, \"Why the U.S. Ramped Up Its
Information War With Russia,\" Council on Foreign Relations,
https://www.cfr.org/in-brief/why-us-ramped-its-information-war-russia,
DOA: 6-24-2022//Smarx Ahsan)

For years, [American officials have lamented that the United States
fights with one arm tied behind its back when it comes to]{.underline}
waging [information war]{.underline}---i.e., the battle for "hearts and
minds." [Adversaries including the]{.underline} self-declared [Islamic
State and the Kremlin]{.underline} are free to [spread lies and
conspiracy theories]{.underline}, while t[he U.S. government generally
feels compelled to hew to the truth in its public
pronouncements]{.underline} (even as it often tries to conceal
scandalous misconduct). U[.S. adversaries find it easy to beam
propaganda]{.underline} into the United States---often [under false
pretenses via social media]{.underline}---but [it is harder for
independent information to penetrate into more tightly controlled media
spaces in countries such as China, North Korea, and Russia]{.underline}.

Now, [as the crisis over Ukraine escalates]{.underline}, the Joe
[Biden]{.underline} administration seems to have [developed an effective
technique for waging information war]{.underline}. Rather than allowing
President Vladimir Putin's government to freely disseminate ludicrous
conspiracy theories about anti-Russia plots involving the West and
Ukraine, [the administration has chosen to fight back by releasing
intelligence reports about Russia's attempts to create a justification
for an invasion of Ukraine]{.underline}.

[Plots and Fake Attacks]{.underline}

[On January 23]{.underline}, [the British government]{.underline},
acting [in cooperation with the U]{.underline}nited
[S]{.underline}tates, [announced]{.underline} details of [a]{.underline}
purported [Russian plot to install a pro-Moscow regime in
Kyiv]{.underline}. [It]{.underline} even [went so far as to name a
pro-Russia former member of the Ukrainian parliament]{.underline} as
[Putin's]{.underline} preferred [puppet]{.underline}.

[On February 3]{.underline}, the [Biden]{.underline} administration
[released information about a Russian scheme to film a fake attack on
Russian territory]{.underline} or [on Russian speakers in eastern
Ukraine to manufacture a justification for]{.underline} an
[invasion]{.underline}. The [administration said Russia]{.underline} had
[already recruited people who would be involved in the fake
attack]{.underline}. Pentagon spokesperson John Kirby said [the plan was
to result in]{.underline} "[a]{.underline} very graphic [propaganda
video]{.underline}, which would include corpses and actors who would be
depicting mourners and images of destroyed locations, as well as
military equipment at the hands of Ukraine or the West, even to the
point where some of this equipment would be made to look like it was
Western-supplied."

[The U]{.underline}nited [S]{.underline}tates has also [released copious
details about Russian troop movements on Ukraine's border]{.underline},
along [with assessments that a Russian invasion is likely]{.underline}.
The [administration]{.underline} has even [shared information about
reported dissension within the ranks of the Russian
military]{.underline} [over a possible attack on Ukraine]{.underline}.

A senior U.S. official, speaking on condition of anonymity, explained
the administration's strategy to the Wall Street Journal: "[We've seen
\[Russia\] run false-flag operations and use the confusion to launch
military action]{.underline} many times in recent history. [Exposing
these plots]{.underline} [makes it that much harder for Russia to
execute them]{.underline}."

[A Legacy of Provocations]{.underline}

[Journalists are]{.underline} naturally [skeptical]{.underline} [of the
U.S. intelligence]{.underline}, given the U.S. government's history
making claims that did not pan out---most notoriously about the presence
of weapons of mass destruction in Iraq, which was used to justify the
U.S. invasion in 2003. But [there is indeed a long history of Russia
using so-called false-flag operations to justify
aggression.]{.underline} In 1939, the [Soviet Union shelled its own
troops near its border with Finland to justify an invasion of that
country]{.underline}. In 1968, [KGB agents in]{.underline} what was then
[Czechoslovakia concocted threats against the Soviet Union and even
claimed to have found a "Made in USA" arms cache to justify a Red Army
crackdown on the Prague Spring reform movement]{.underline}.

In 1999, [Russian intelligence operatives are believed to have bombed
Russian apartment buildings to justify an invasion of
Chechnya]{.underline}. And the [Russian invasions of
Georgia]{.underline} in 2008 [and Ukraine]{.underline} in 2014
[were]{.underline} both [accompanied by copious
disinformation]{.underline}, [including]{.underline} the use of ["little
green men"]{.underline} (i.e., [soldiers in green uniforms devoid of
Russian army insignia]{.underline}) [to disguise the role of Russian
military forces]{.underline}. The [Kremlin even blamed the CIA for
shooting down a Malaysian airliner]{.underline} over Ukraine in
2014---[an act]{.underline} actually [carried out by Russia-backed
separatists using a Russian air defense system]{.underline}.

[A New Era of Info Ops]{.underline}

In the past, [the United States was caught flat-footed by Russian
information operations]{.underline}. [Exposing Russian plots in real
time appears to be an effective response]{.underline}, even though doing
so raises concerns about exposing the U.S. intelligence community's
"sources and methods," and journalists question whether the U.S.
government's claims can be trusted.

At the very least, [the U.S. reports throw sand into the gears of the
Russian military machine and force the Russian government to wonder
where Western intelligence agencies are getting their
information]{.underline}, which [could]{.underline} possibly [lead to a
search for traitors within its own ranks]{.underline}. The
[reports]{.underline} also [neutralize Russian propaganda and allow the
United States to try to control the narrative]{.underline} rather than
ceding to Putin and his propagandists.

[Given the growing importance of information operations in modern
warfare, that is no small achievement]{.underline}. [It has already paid
off in considerable Western unity in the face of Russian threats to
Ukraine]{.underline}. Whether the U.S. actions will deter a Russian
invasion of Ukraine, however, is still unclear.

## AT: IL

### IL\-\--Russian Info Ops Fail 

#### No impact to information wars and it [solves itself]{.underline}\-\--propaganda tactics [empirically]{.underline} collapse the attacking states.

**CRI 21**, publishes novel research at the leading edges of global risk
mitigation, governance design and culture. Their content explores the
key challenges and existential threats facing humanity, and the
underlying problems with current approaches for addressing them, "It\'s
a MAD Information War",
<https://consilienceproject.org/its-a-mad-information-war/> //lenox

While the [2016 U.S. election was a watershed in computational
propaganda, the same phenomenon has basically swept the
planet]{.underline}, beginning as early as 2010. Ukraine, Estonia,
China, Iran, Mexico, the UK, and the U.S. have all had major politically
significant incidents of computational
propaganda.[\[12\]](https://consilienceproject.org/its-a-mad-information-war/#fn-12) Research
on computational propaganda is underway at various academic centers and
think tanks, including at the Oxford Internet Institute, the Stanford
Internet Observatory, and the Digital Forensics Lab of the Atlantic
Council. The focus has been largely on the techniques, organizations,
and forensic approaches, revealing a dangerous new frontier of digitally
enhanced irregular warfare. We posit that [this frontier leads toward
mutually assured destruction, like all frontiers of arms races in
weapons technologies]{.underline}.\
In one sense, [mutually assured destruction in the context of
information war is simple]{.underline}. It has been known from the
earliest days of military strategy: [you can be blinded by your own
smokescreen, and even more so when your enemy is using one
too]{.underline}. The [use of powerful information manipulation tactics
to coerce the enemy requires the creation of organizations that
specialize in making and using such tools of war]{.underline}. History
suggests that [it can be hard to achieve trust and collaboration in
governments that maintain large and complex propaganda
operations]{.underline}. [Stalin's demise in Russia can be at least
partially attributed to this lack of trust]{.underline}. Stalin spent
his last days in a bunker, paranoid and suffering the consequences of
creating an almost completely manipulated information environment.
Accounts show that during the Cold War, both [the CIA and KGB used
deceptive techniques to convince their own government agencies of the
success of their campaigns]{.underline} (i.e. the agencies propagandized
their own colleagues to ensure continued support for their work).
[Societies that depend on the politicized control of information end up
shrouding both political leaders and the masses in mere simulations of
reality]{.underline}.[\[13\]](https://consilienceproject.org/its-a-mad-information-war/#fn-13)

We have reached a point at which a difference in magnitude has become a
difference in kind.

The [idea that any group of leaders is immune to the cognitive and
emotional distortions they inflict upon the masses is
misleading]{.underline}. While a [small political elite]{.underline}
might know more than most other members of their society, they [are
nevertheless limited epistemically by their position as problem-solvers
who are segregated from actual free and open streams of
information]{.underline}. [They cannot readily trust high-ranking
officials in their own intelligence and military, who themselves are
employed in the practice of information manipulation]{.underline} and
are interested in keeping their jobs and reputations. They also cannot
rely on well-educated and expert members of the general population, who
in fact have been lifetime subjects of information manipulation. [Nor
can they rely on input from foreign nations, who are systematically
trying to control what information is available to their
adversaries]{.underline}, and how it is framed. Over time, [a downward
spiral of distrust and confusion degrades decision-making and
problem-solving capacities until the social system
collapses]{.underline}, as occurred eventually with the Soviet
Union.[\[14\]](https://consilienceproject.org/its-a-mad-information-war/#fn-14)\
[Politically motivated information asymmetries produce only short-term
gains]{.underline}. [Social systems of this kind are undone by the
long-term consequences of the damage inflicted on public
sensemaking]{.underline}. The dangers of what is possible when
centralizing and politicizing the control of information have long been
noted by those arguing in support of open societies. However, under the
conditions created by advances in digital technologies, [problems of
information war have become more complex]{.underline}.

#### Russian Information Warfare campaigns are ineffective

Jeff **Schogol 22**, senior Pentagon reporter with Task & Purpose. He
reports on both the Defense Department as well as individual services,
covering a variety of topics that include personnel, policy, military
justice, deployments, and technology, May 2022, \" Russia actually isn't
as good at information warfare as everyone thought,\" Task & Purpose,
https://taskandpurpose.com/analysis/russia-propaganda-war-ukraine/
//AShah

[Prior to kicking off its mega-sized Charlie Foxtrot in Ukraine, the
Russians were widely regarded as masters of deception and
propaganda.]{.underline}

Whether it was Russian troops masquerading as "little green men" in
Crimea in 2014 or the successful hacking of former Secretary of State
Hillary Clinton's 2016 presidential campaign, [the Kremlin set the gold
standard for subterfuge]{.underline}. As Russian President Vladimir
Putin was poised to send his forces into Ukraine in February, the State
Department warned that Russia's invasion could be preceded by an
elaborately staged "false flag" operation as a pretext for war, just as
the Nazis had done in 1939 when they claimed Poland had attacked
Germany.

But far from being the juggernaut of neo-Soviet disinformation that the
West had expected, [Russia's information operations about the war in
Ukraine have largely sucked]{.underline}. Just prior to the invasion,
Russia claimed that a Ukrainian roadside bomb had killed three people
inside separatist-held eastern Ukraine, yet the skull of one of the
charred bodies that the Russians paraded in front of sympathetic media
showed signs that it had undergone an autopsy procedure, meaning the
person was dead before being placed at the scene of the alleged attack.

Since then, Russia has claimed that the reason its troops were forced to
abandon their advance on Ukraine's capital of Kyiv was that Russia never
wanted the city anyway, and the initial attacks were just part of an
elaborate ruse meant to distract Ukrainian forces from Russia's real
military objectives in the Donets Basin. (As comebacks go, this is one
step above: 'Fine, I didn't want to be your date to the stupid prom in
the first place!')

More recently, Russia's government has unconvincingly claimed that the
Ukrainians did not sink the cruiser Moskva, once the flagship Russia's
Black Sea Fleet; and Russian propaganda has accidentally used pictures
of criminals Bonnie Parker and Clyde Barrow as well as a Marine in World
War II to honor the Soviet Union's victory over the Nazis in the Great
Patriotic War.

[One reason why Russian information operations are flailing is "they
don't have a lot of material to work with]{.underline}," said Marek
Posard, an expert on disinformation with the RAND Corporation, a
nonprofit research organization.

"[There's only so much you can do when X number of your generals are
being killed in theater,"]{.underline} Posard told Task & Purpose. (In
this case, the Ukrainians claim to have killed 12 Russian general
officers.)

The United States and other Western nations tend to do better at
information warfare when they tell the truth, and right now [the facts
are not in Russia's favor, because the invasion of Ukraine has revealed
how the Russian military is not as professional as many thought it
was.]{.underline}

"The military operations in Ukraine clearly are not going well for the
Russians," Posard said. "You can't hide the fact that civilian
casualties are high. You can't hide the fact that the Russians are
shelling targets that they should not be shelling. You can't hide the
fact that there are Russian soldiers lying dead and there's tanks on the
side of the road that have been blown up."

[However, the Russians have often made mistakes and used flimsy claims
as part of their propaganda efforts because their goal is to flood the
airwaves with as much disinformation as possible, said Olga Lautman, an
expert on Russia and Ukraine.]{.underline}

Back in 2014, Russian media claimed without any evidence whatsoever that
the Ukrainian military had crucified a 3-year-old boy in the city of
Slovyansk, said Lautman, a senior fellow with the Center for European
Policy Analysis, a nonprofit research institutin.

While the story was discredited in western media, [Russian information
operations are not supposed to make sense, she said. Instead, these
operations are intended to create confusion.]{.underline}

"It's just meant to put out so much propaganda and so many different
points to make the person throw their hands up and just say, 'I don't
know what the truth is,'" Lautman told Task & Purpose.

[In fact, sometimes the Russians will cook up completely contradictory
narratives in which some propaganda claims discredit other propaganda
assertions, Lautman said.]{.underline}

"It is not meant to direct you in any which way," Lautman said. "It is
not meant for a critical thinker. It is more meant to pollute the
information space with so much disinformation that the person can't get
to the truth."

Separately, the Russians also launch very targeted propaganda campaigns
against specific people or on certain issues, and those efforts tend to
be more thought out, she said. For example, the Russians are currently
putting a lot of time and effort into claims that the Ukrainian
government is kidnapping journalists to silence them.

Since Russia attacked Ukraine in late February, though, [its information
operations have been weaker than in the past because foreign media have
been on the ground to discredit Russian propaganda,]{.underline} Lautman
said. The New York Times recently exposed Russia's lies about the
massacre of Ukrainian civilians in the Kyiv suburb of Bucha.

As long as the media coverage continues, [Russia's propaganda campaign
will remain weak,]{.underline} Lautman said. "When it wanes, then you
will see Russia's disinformation operations being a lot more successful
because they'll be able to get their message across," she said.

#### Russia's failing [miserably]{.underline} at spreading misinformation about Ukraine\-\--if they can't do it at home, they [definitely can't]{.underline} do it at the international level

Bermet **Talant 22**, freelance journalist from Oxford, 3/1/22, "Russia
is losing the information war,"
https://www.lowyinstitute.org/the-interpreter/russia-losing-information-war/mh

Zelensky's defiance and candor have sparked admiration at home and
abroad. A month ago, 53 per cent of Ukrainians thought he wasn't capable
of defending the country in the event of the Russian invasion. Now, his
people call him a true leader they are proud of.

This [frank and direct communication is a stark contrast to Russian
President Vladimir Putin's pre-recorded rambling diatribes, and the
silence around the war enforced in the Russian media, as the Kremlin,
once again, tries to obscure the scale of its involvement in
Ukraine.]{.underline}

In 2014, Russia annexed Crimea without resistance by getting its
invading soldiers to strip off their military insignia. Although later
it acknowledged its troops had indeed been involved, this simple sleight
of hand allowed it to control the narrative.

Russia subsequently effectively obscured its direct role in the conflict
in Ukraine's east, portraying it as a civil war and bona fide
pro-independence insurgency. Kremlin propaganda successfully spread the
false belief (still widespread among some) that Ukraine is run by
neo-Nazis and has committed a "genocide against Russian speakers".

[Since Putin's invasion, however, Ukraine has dictated the
story.]{.underline}

[Putin's justification of the invasion as a "liberation of the Ukrainian
people from a nationalist regime" and the "defense of Russia from the
NATO threat" has fallen on deaf ears  -- even, possibly, at
home.]{.underline} [More Russians are speaking out against the war and
taking to the streets to protest.]{.underline} Sanctions and
international support for Ukraine keep coming, turning Russia into a
diplomatic and economic pariah.

[Although diplomatic efforts to prevent the war failed, the decision of
the United States and the United Kingdom governments to release
intelligence reports about Russia's invasion plans in real-time was
unprecedented and forced Putin to catch-up, rather than set the
narrative as in the past.]{.underline}

Ukraine is relying on years of first-hand experience in countering
Russian propaganda narratives.

Now, the Ukrainian government continues a transparent and proactive
communications strategy, largely through the effective use of social
media. Throughout the day, official accounts rapidly distribute news
from the battlefield, warn of airstrikes, and instruct citizens on how
to help the defense efforts. Four major oligarch-owned media groups have
teamed up with the parliamentary channel to broadcast the same program
in unison, amplifying a single narrative. Political differences and
criticism over domestic policy have faded, and the trust of the
Ukrainian people for their leadership and army is palpable.

[By contrast, Russian state media are portraying the war as simply a
limited operation in the east, and are not covering the reality of
Russian military strikes on cities across Ukraine, including Kyiv. A
minority of independent media outlets in Russia that report on the
existence of a full-scale war, citing Ukrainian official sources, have
received orders to remove "false information" from the state watchdog
under the threat of being blocked.]{.underline}

[Amid secrecy and censorship in Russia, Ukraine has taken control of the
narrative by releasing reports on losses on both sides, videos of
captured Russian soldiers, and footage of destruction from Russian
airstrikes.]{.underline} Although Ukraine's approach has not been immune
to hyperbole and selective presentation of facts, it is incomparable
with Russia's attempts to create a distorted parallel reality.

Ukraine, of course, is relying on years of first-hand experience in
countering Russian propaganda narratives. Since 2015, Russian media
outlets and social networks have been banned in the country. And,
despite criticism, the National Security Council has in the last year
closed four pro-Russian television channels owned by Ukrainian
politicians. [Civil society has relentlessly promoted Ukraine's account
of its history against Putin's falsified version.]{.underline}

[Ukraine's edge in the ongoing information war also due in part to the
West's own experiences with Russian hybrid warfare. Since 2014, the
Kremlin has meddled in US elections, conducted cyberattacks, and made a
number of assassination attempts of dissidents abroad.]{.underline} The
Russian use of troll farms is well known by now, and Kremlin-funded
multilingual broadcaster RT is widely recognised as a propaganda outlet
(and now suspended by a local broadcast partner in Australia).

[Social media use is widespread, and there has been a boom in
open-source research]{.underline} following the downing by
Russian-backed forces of Malaysian Airlines flight MH17 in eastern
Ukraine in July 2014.

The movements of Russian troops have been documented in high resolution
by satellites. Online sleuths have quickly debunked claims made by
Russian and separatist media on Kyiv's supposed plans of attack. A video
of a purported sabotage attempt at the behest of Ukraine turned out to
be fake, and announcements by separatist leaders of emergency
evacuations of civilians were exposed to have been recorded in advance
of explosions that were blamed on Ukraine. [Facebook and Google have
banned Russian state media from running ads on their platform. Moreover,
Anonymous hacker group has declared a cyberwar on Russia taking down its
government websites and state media.]{.underline}

Fierce fighting continues on the streets of many Ukrainian cities. [But
it's clear that this time the Kremlin likely won't be able to sow
confusion, conceal its crimes, or cloud the international
response.\]{.underline}

### IL\-\--Russian Info Ops Inevitable 

#### Russia is [relentless]{.underline}. The plan is a [drop in the bucket.]{.underline} 

Terry L. **Thompson 20**, lecturer in cyber policy at the Johns Hopkins
University and University of Maryland, Baltimore County, "[No Silver
Bullet]{.underline}: Fighting Russian Disinformation Requires Multiple
Actions," Georgetown Journal of International Affairs, vol 21, no 1, pp.
182, <https://muse.jhu.edu/article/766401> //chico

These [efforts by]{.underline} the [U]{.underline}nited
[S]{.underline}tates, EU, [and NATO provide an improved
deterrent]{.underline} against Russian disinformation. But the [Russian
effort to sow discord and mistrust is relentless.]{.underline} Inspired
by President Vladimir [Putin\'s desire to turn Americans against one
another and armed]{.underline} [with increasingly sophisticated cyber
operators]{.underline} in the Russian military, [Russian
disinfo]{.underline}rmation [has become a powerful twenty-first-century
information weapon that will not be easily defeated.]{.underline} (22)
[Russian tactics are constantly evolving]{.underline}, and [rapid
advances in a]{.underline}rtificial [i]{.underline}ntelligence [and
deep-fake]{.underline} videos [will make detecting
disinfo]{.underline}rmation and other active measures [increasingly
difficult]{.underline} in 2020 and beyond.

### IL\-\--No Escalation 

#### Russia [can't]{.underline} use info warfare effectively\-\--[won't escalate]{.underline}

Bill **Bray 22**, author on defensive actions, 1/4/22, "The Information
Warfare Myth,"
<https://www.realcleardefense.com/articles/2022/01/04/the_information_warfare_myth_810446.html>
//mh

[Russia's troop buildup on the Ukrainian border may culminate in a
full-scale invasion. Or it **may be meant to coerce NATO to negotiate**
and concede to some of Vladimir Putin's demands regarding Ukraine's
future. But one thing it surely demonstrates is that the efficacy of
information warfare to achieve political and security objectives is
greatly overstated.]{.underline} The U.S. military and national security
community should take note.

[One could be forgiven for concluding Vladimir Putin's Russia is the
world's grand practitioner of information warfare. It's a conclusion
Putin ostensibly promotes, if, for no other reason, because it conjures
an image of power that may be **more illusion than
reality.**]{.underline}

The potential destructive effects of cyberattacks are serious, and it is
no overreaction on the part of Western intelligence and military
services to take that threat seriously. But even cyberattacks, at least
as thus far practiced, seem far more bark than bite when evaluating what
they achieve beyond imposing some costs on the target nation.

[Western democracies should take heart at how Ukraine has stood firm
against a ruthless and pervasive Russian information warfare
campaign]{.underline}. In 2014, following the Maidan protests in Kyiv
that ultimately ousted Ukraine\'s pro-Russian President Viktor
Yanukovich, Russia intensified a broad information warfare campaign
against Ukraine. [This campaign aimed to undermine Ukrainian popular
support for the nation's pro-European leadership. Or, if that did not
work well, to at least sow discord and confusion to a point in which
Ukrainians eventually would become apathetic about their government's
decision to defy Moscow.]{.underline}

[Russia has been employing all the information warfare tools it can
muster for nearly eight years, including cyberattacks, disinformation,
and pro-Russian influence campaigns. Yet all evidence indicates the
Kremlin has failed through information warfare alone to keep most of
Ukraine in Russia's political, economic, and cultural
orbit]{.underline}. This contrasts with the parts of Ukraine Russia
physically seized (the Crimea) or is engaging in a proxy war using local
insurgents (the Donbas).

Contrary to the Russian narrative, Ukrainians were never as anti-Russian
as Moscow claims. For example, in 2010, the Kyiv International Institute
of Sociology recorded that 93 percent of Ukrainians surveyed in all
regions had a favorable attitude toward Russia, with 22 percent of the
population believing the two states should reunite. Yet in 2016, only 17
percent of Ukrainians reported having a favorable attitude toward
Russia. More recent polling confirms Ukrainian public opinion remains at
historic lows.

On the question of NATO accession, in 2010, shortly after Yanukovich was
elected, in part to improve relations with Russia, only 28 percent of
Ukrainians supported NATO accession. A June 2017 poll by the Democracy
Initiatives Foundation showed Ukrainian support for joining NATO at 69
percent. Polling in 2021 showed that number remaining above 60 percent.
[Finally, Russian meddling in Ukraine's information space has galvanized
Ukrainian distrust of Russian media, prompting the ban of Russian social
media sites and media outlets in the country.]{.underline}

[Not only has Moscow's information war against Ukraine proved to be
remarkably anemic, but it may ultimately be
counterproductive]{.underline}. Russia already has conducted
cyberattacks against the Ukrainian financial industry and power grid,
and Moscow will undoubtedly continue such attacks. [It is doubtful,
however, that more cyberattacks and a broader, more intense information
warfare campaign (if that is even possible) can turn the tide and help
Russia achieve lasting political objectives in Ukraine]{.underline}.
Moscow has likely come to this realization, hence the threat of physical
aggression.

U.S. military information warfare [advocates have, for years now, tended
toward the hyperbolic in predicting its significance. Information
warfare is not insignificant, particularly cyber warfare, but it thus
far has a dismal record at achieving foreign policy or military
warfighting objectives.]{.underline} What, exactly, did the United
States achieve through information warfare methods in Iraq and
Afghanistan? Perhaps information warfare, particularly cyber and
electronic warfare, will play a more decisive role against a
technologically sophisticated adversary.

### IL\-\--AT: Baltics\-\--Squo Solves

#### SQUO solves Russia disinformation in the Baltics - they have instituted new programs to track disinformation campaigns

Alexandra **Sarlo 17, is currently a PhD candidate in Political Sciences
at University of Pennsylvania. Alexandra specializes in Comparative
Politics. She also holds an MA from Georgetown University in Russian and
East European Studies and a BA in Russian from Cornell University, July
2017, \"**Fighting Disinformation in the Baltic States,\" Foreign Policy
Research Institute,
https://www.fpri.org/article/2017/07/fighting-disinformation-baltic-states/
//AShah

[The main techniques [Baltic states have]{.mark} used to [counter
disinformation from Russian media sources]{.mark} involve fining or
suspending channels that display overt biases.]{.underline} For example,
Latvia fined PBK three times in 2014 for showing fake or biased
broadcasts from Russian news. The radio station Autoradio Rezekne was
also fined once. PBK was fined again in 2015. These fines, while highly
publicized, were less than \$5,000 each, and the fine for the radio
station was equivalent to \$885. [[Latvia]{.mark} also [temporarily
suspended]{.mark} the [Russian television station]{.mark} RTR Planeta in
2014 for alleged incitement to war, which violates Latvian media law.
Latvia has provided a space for the work of independent Russian news
site Meduza, founded by journalists fired from Russian news site
Lenta.ru over their coverage of the war in Ukraine. [Lithuania has also
fought back against Russian disinformation]{.mark}, repeatedly
suspending RTR Planeta.]{.underline}

Estonia found itself facing an extremely hostile information environment
as early as 2007. At that time, Estonian government institutions,
newspapers, banks, and other companies were subjected to weeks of
cyber-attacks after the removal of the Bronze Soldier, a Soviet war
memorial, from central Tallinn. In 2015, [[Estonia began broadcasting a
new Russian-language]{.mark} [channel]{.mark}, ETV+, [to provide an
alternative for the Russian-speaking population]{.mark}.]{.underline}
However, the new station has been hampered by regulations that require
live programming to be translated directly into Estonian. It has been
more popular with Estonian-speakers than with the Russian-speaking
minority, who have access to a wide range of better-resourced channels
directly from Russia that are under no such regulation.

[[International efforts are]{.mark} also [targeting Russian
disinformation in the Baltics]{.mark}]{.underline}. [The [NATO]{.mark}
Stratcom Centre of Excellence]{.underline}, based in Riga, [[seeks
to]{.mark} [strengthen strategic communications within the
Alliance]{.mark}, in part by studying Russia's strategic information
campaign in the Baltic and Nordic countries.]{.underline} This effort
includes examining how contentious historical events---especially
pro-Russian narratives surrounding World War II and the Soviet takeover
of the Baltic states---are interpreted in Russian media. [[It]{.mark}
also [monitors issues like online robot trolling]{.mark} and devises
methods to repel hostile influence. Aside from the Baltic states,
Germany, Italy, Poland, and the United Kingdom are all involved in the
center.]{.underline}

#### NATO is [already]{.underline} increasing its presence in the Baltics -- that's [sufficient to deter]{.underline} Russia

William **Gallo 22**, foreign policy and international affair
correspondent, 3/23/22, "After Russia's Ukraine Invasion, Baltics Push
for Permanent NATO Presence,"
<https://www.voanews.com/a/after-russia-s-ukraine-invasion-baltics-push-for-permanent-nato-presence-/6497246.html/mh>

The small Baltic countries, whose militaries have long been dwarfed by
that of neighboring Russia, are renewing their push for NATO to
establish a larger and more permanent presence on their territory
following the Russian invasion of Ukraine.

[Estonia, Latvia, and Lithuania --- with a combined population of only
about six million people --- have long been seen as some **of NATO's
most vulnerable nations**. The countries joined the Western military
alliance in 2004 but are connected to the rest of European NATO
countries by only a narrow corridor, which lies between the heavily
armed Russian exclave of Kaliningrad and Russia-allied
Belarus.]{.underline}

[The Baltics, former Soviet states, have watched with concern as Moscow
tries to reassert influence across Eastern Europe. However, they have
also been encouraged as **Western countries fortify the NATO alliance in
response to Russia's invasion** of Ukraine]{.underline}.

[NATO had no forces in the eastern part of the alliance until 2014, when
it decided to deploy four multinational battlegroups on a rotational
basis to the Baltics and Poland in response to Russia's annexation of
Crimea. The **NATO presence was further strengthened** this year after
Russia attacked Ukraine. In total, the **Baltics now host about 7,700
foreign NATO troops** --- **nearly twice as many** compared to earlier
this year.]{.underline}

### IL\-\--AT: Baltics\-\--No Invasion

#### New European NATO army [checks]{.underline} Russian expansionism AND [any]{.underline} possible Baltic [invasion]{.underline} 

Andre **Damon 22**, Writer and editor for the World Socialist Web Site
specializing in geopolitics and economics, 6/27/22, "NATO announces plan
for massive European land army,"
<https://www.wsws.org/en/articles/2022/06/28/sosw-j28.html> //mh

In what NATO Secretary-General Jens Stoltenberg called the "biggest
overhaul of our collective deterrence and defense since the Cold War,"
[the US-led NATO alliance has announced plans to build a massive
standing land army in Europe, numbering in the hundreds of
thousands.]{.underline}

[Stoltenberg said NATO would increase its "high readiness forces"
sevenfold, from 40,000 to 300,000, deploying tens of thousands of
additional troops, as well as countless tanks and aircraft, directly to
Russia's border.]{.underline}

The move will entail a massive diversion of social resources to NATO's
ongoing war with Russia and planned war with China, draining treasuries
throughout Europe and North America and fueling demands for the
elimination of social services, the slashing of wages, and the gutting
of workers' pensions.

[Stoltenberg said the creation of this massive fighting force was a
response to the "new era of strategic competition" with Russia and
China.]{.underline}

[He called the plan "a fundamental shift in NATO's deterrence and
defense," embracing not only the war with Russia, but "the challenges
that Beijing poses to our security, interests and values."]{.underline}

[As a part of this massive expansion of its fighting force, NATO will
increase the numbers of troops stationed in Latvia, Lithuania and
Estonia to the "brigade" level, meaning approximately 3,000 to 5,000
troops.]{.underline}

The Financial Times reported, based on an interview with Stoltenberg,
that the plan will "[include new structures in which Western NATO
allies, such as the US, UK and France, would pledge their ships,
warplanes and a total of more than 300,000 troops to be ready to deploy
to specific territories on the alliance's eastern flank, with graded
response times starting from the opening hours of any
attack]{.underline}."

[Instead of troops deployed to the Baltics serving as a "tripwire," the
new plan would envision NATO fighting a war against Russia directly on
the borders of these countries on NATO's eastern
battlefront.]{.underline}

Stoltenberg boasted that "2022 will be the eighth consecutive year of
increases across European Allies and Canada," adding that NATO's target
of two percent of economic output going to military spending will be
"considered a floor, not a ceiling."

#### No Russia invasion AND the Baltics are ready for it

Richard **Milne 22**, Nordic and Baltic Bureau Chief and European
correspondent, 3/8/22, "War in Ukraine: will the Baltics become the 'new
West Berlin'?,"
https://www.ft.com/content/d711c884-653d-4336-a490-b9075e5ce82f/mh

[The three Baltic states have been trampled over by everyone from the
Russians and Soviets to the Germans, Swedes and even Ottomans in the
past few centuries. But, even as the world wonders whether they will be
next on Russian president Vladimir Putin's invasion list after Ukraine,
there is a counterintuitive sense in Estonia, Latvia and Lithuania that
they are as **safe as they ever have been**.]{.underline}

["If you look at the past 800 to 900 years of history, an argument could
be made that we have **never been so secure**. Because we have so many
very powerful allies, we're an independent country with our own standing
army, a free and open and flourishing trade and investment environment,"
says Krisjanis Karins, Latvia's prime minister.]{.underline}

[This confidence is largely due to the **backing of the US and Nato**,
which are jointly rushing to reinforce and reassure those countries on
the frontline between the military alliance's eastern flank and
Russia.]{.underline}

In a stand-off between the west and Russia that many are calling a
second cold war, the Baltic states are increasingly viewed as this
generation's West Berlin. A part of Nato territory that may be all but
impossible to defend in itself, but which western officials underscore
to Moscow will be heavily avenged in the case of any attack.

Antony Blinken, the US secretary of state, reiterated this on Tuesday
after a whistle-stop tour of all three Baltic countries. [He told an
audience in Estonia that the US and the military alliance would
"**defend every inch of Nato territory**".]{.underline}

In more than a dozen interviews with senior Baltic officials, including
all three presidents and numerous ministers, [all suggest there is **no
immediate threat** to their region but that **they are ready** for
whatever Russia might throw at them, as they have been for
decades.]{.underline} There are still security weaknesses that they hope
Nato can help to plug. But for both the military alliance and the EU
there is a clear sense that the Baltics are on the front line against
Russia's revanchism.

#### No shot Russia will invade the Baltics - there\'s no intent

**LRT 22**, is the Lithuanian National Radio and Television, a publicly
owned media group by the Lithuanian people, February 2022, \"No signs of
Russia planning attack on Baltics -- NATO committee chair,\"
https://www.lrt.lt/en/news-in-english/19/1608809/no-signs-of-russia-planning-attack-on-baltics-nato-committee-chair
//AShah

[[NATO has not seen]{.mark} any [signs that Russia might be planning to
attack the Baltic states]{.mark}, according to Admiral Rob Bauer,
chairman of the NATO Military Committee.]{.underline}

He told reporters in Vilnius that, in the military sense, the
[[Russia\'s ongoing military buildup in Belarus could be viewed as a
"combination of capabilities]{.mark}"]{.underline}.

"If you look at the posture of the Russian troops in Belarus, then yes,
you have to consider militarily, whether it is a threat to the Baltic
states and, more particular, to Lithuania now. But then, of course, you
have to look at the intent as well: is there indication that the
Russians or Belarus have an intention to hurt the Baltic states, and
particularly Lithuania?" he said on Monday. "[[Up until now, we don\'t
see an intent, we don\'t expect an attack on NATO soil by Russia --
either directly or via Belarus.]{.underline}]{.mark}"

Bauer says some 30,000 Russian troops are now in Belarus.

[[It 'would be silly' to threaten Lithuania.]{.underline}]{.mark}

The NATO representative\'s view was echoed by Lithuania\'s Chief of
Defence Valdemaras Rupšys.

"\[Russia\'s military buildup\] is changing the security situation, and
also accordingly the readiness of NATO and our national military
capabilities, but there\'s no direct threat tactically or operationally
at this stage," the army chief said.

"[Simply because NATO forces are deployed in Lithuania, [it would be
irresponsible]{.mark} and I would even say silly to threaten us. That
would fundamentally change the situation not in the region, but in the
world in general,]{.underline}" Rupšys added.

### IL\-\--AT: Baltics\-\--Presence Bad 

#### Increased NATO presence in the Baltics [causes]{.underline} Russia war\-\--they're [already wary]{.underline} because of Lithuania's ban on transit

Holly **Ellyatt 22**, reporter and journalist on European economics and
politics, 6/23/22, "Moscow and NATO could be about to clash over
Russia's European exclave Kaliningrad,"
<https://www.cnbc.com/2022/06/22/russia-and-nato-member-lithuania-are-clashing-over-kaliningrad.html/>
//mh

[A new front in tensions between Russia and NATO has opened up after one
of the Western military alliance's members, Lithuania, banned the
transit of some goods coming from Russia to its exclave Kaliningrad on
the Baltic Sea]{.underline}.

[Russia has vowed to retaliate over what it described as the "hostile
actions" of Lithuania, warning of "serious" consequences, while NATO
members have reiterated their support for the country.]{.underline}

Here's a brief guide to what's going on, and why it matters as the
Russia-Ukraine conflict rumbles on in the background.

What's happened?

[Lithuania said last week that it would ban the transit of some
EU-sanctioned goods coming from Russia across its territory to the
Russian exclave of Kaliningrad.]{.underline}

[The government said the blockade would apply to all EU-sanctioned goods
coming from the mainland via rail, effectively blocking the transit of
metals, coal, construction materials and high-technology products to the
Russian sea port.]{.underline}

Kaliningrad

Lithuania said that its decision was taken after consultation with the
European Commission, the EU's executive arm, and that it's enforcing
sanctions on Russia that were imposed following the unprovoked invasion
of Ukraine on Feb. 24.

[Russia responded to Lithuania, a former Soviet republic, by calling the
move an "unprecedented" and "hostile" act, with its Foreign Ministry
issuing a statement Tuesday in which it said "if in the near future
cargo transit between the Kaliningrad region and the rest of the
territory of the Russian Federation through Lithuania is not restored in
full, then Russia reserves the right to take actions to protect its
national interests."]{.underline}

### IL\-\--AT: Euro Populism 

#### There is [no universal]{.underline} response to populism\-\--anything but case-by-case response by the EU [fails]{.underline}

Philip **Manow 21**, Professor of Comparative Political Economy at the
University of Bremen, 12/15/21, "The political economy of populism in
Europe",
https://www.chathamhouse.org/sites/default/files/2021-12/2021-12-15-political-economy-populism-europe-manow.pdf/mh

Beyond illuminating the driving forces of the populist backlash in
Europe, the above typology helps us understand how policymakers could
respond to it. [During the past five years, centrist policymakers have
increasingly focused on how to 'defeat' populism, which they have
**tended to see in simplistic terms**. But the heterogeneity of
populism, as discussed in this paper, means **there is no one solution**
that can be applied everywhere -- even in Europe. Rather, **in each
country's case** an effective solution will necessarily reflect the type
of political economy involved.]{.underline}

This has particular implications for EU-level policymaking. Both trade
and migration policy have become highly Europeanized, usually in ways
that have removed barriers to the movement of goods, services and people
across borders. This trend has often exacerbated the social and economic
pressures that inspire different populist forces, while removing the
opportunity for national policymakers to deal with these pressures.
[This means that any solutions will by definition need to involve EU
institutions. Yet the heterogeneity of populism means that **any
one-size-fits-all policies** emanating from Brussels could **reinforce,
rather than solve, the conflicts** discussed in this paper.]{.underline}

A reversal of the openness to trade and movement driving voter
discontent is both unlikely (given the entrenchment of economic
integration in the EU) and undesirable (given the moral implications of
erecting inhumane barriers to migration). Instead, the EU should aim to
either (a) put in place sufficiently strong compensatory mechanisms to
accommodate voter concerns about issues such as immigration and welfare
competition; or (b) ensure that member states are able to do this
effectively themselves in their respective domestic contexts. [Effective
policies could include increasing investment -- whether through national
governments or EU-level investment facilities -- in local services in
areas affected by migration; or increasing the space within the EU's
fiscal rules for governments to compensate people or communities
affected by the economic impacts of globalization. Whatever these
measures look like, they **need to be mindful of local context** and of
the **specific political economy of populism** in each member
state.]{.underline}

#### European polarization is [non-existent]{.underline}\-\--doesn't spill up to anything larger than [harmless]{.underline} rivalries

Simon **Kuper 22**, journalist for the Financial Times, 1/20/22, "Why
America is dangerously polarised --- and Europe is not,"
https://www.ft.com/content/5655ab7c-1152-414e-bd22-67acd06c5c51/mh

Contrast two leaders. Donald Trump's approval ratings barely budged
during his presidency, and his supporters dismissed every scandal as
"fake news". [But when Boris Johnson turned out to have doubled as a
party host during lockdown, **his supporters fled**: his net
favourability rating went from +29 per cent in April 2020 to -52 per
cent last week, according to pollsters YouGov.]{.underline}

Here, in microcosm, is the uniqueness of American polarisation. People
often discuss polarisation as a global problem, but in fact, [in most
western European and even Latin American democracies, rival camps
**aren't deeply entrenched** or always **entirely
serious**]{.underline}.

Western polarisation peaked between 2016 and 2018, with the victories of
Brexit, Trump and Brazil's Jair Bolsonaro, the violent clashes over
Catalan independence, and the entry of the anti-system Five Star and
nativist League into Italy's government.

Today the US remains dangerously polarised --- more like Turkey or India
than western Europe. Among Republicans in particular, ethnic, religious
and ideological identities are often perfectly aligned. Many believe God
supports their party. Egged on by Trump, they fear their tribe is under
existential threat. In a survey by George Washington University, most
Republicans said, "the traditional American way of life is disappearing
so fast we may have to use force to save it". They have enough firearms.

The US is also handicapped by its constitution, which among other things
has made the Supreme Court --- arguably the country's mightiest
political institution, given congressional gridlock --- a
past-winner-takes-all prize. (Poland has a similar problem.) The step
back from democracy is short in the US, since southern states impeded
many black people from voting until the late 1960s.

[But **western Europe is tamer**. Divides are deep, but most of its
citizens just aren't very interested in political issues and cannot stay
angry about them for years on end. Europe's history is about
**forgetting past polarisation**, or else Finland would still be
brooding over its 1918 civil war and the heads of Protestants would be
hanging from the gates of French towns.]{.underline}

[Today's British depolarisation is a case in point.]{.underline} Most
Leavers celebrated victory in the Brexit referendum less as a revolution
than as a sort of football match: "You lost, get over it!" They don't
believe God wants Brexit. Nor do Leavers lie awake at night afraid that
Remainer hordes will slaughter them in their beds. Indeed, these labels
are peeling off as Brexit loses salience and drifts into impenetrable
negotiations over something called Article 16. [Last year, Britons
conducted **more Google searches for** Aston Villa **Football** Club
**than for Brexit**.]{.underline}

[Helpfully too, most elected leaders other than Trump **seek to reduce
tension**. Democracy is a conflict-management system that usually tends
towards tedium]{.underline}. Chile's new leader, Gabriel Boric, promises
to be "president of all Chileans". In Spain, prime minister Pedro
Sánchez has lowered temperatures over Catalan independence by pardoning
nine jailed separatist leaders. In Barcelona recently, I noticed far
fewer Catalan flags than before hanging from apartment balconies.

Sánchez had another motive for his pardons. He wanted Catalan parties to
back his other policies. The need to build coalitions is a force for
unity in many European democracies. In Italy, the League and Five Star
now sit in Mario Draghi's technocratic government. Some polarising
parties such as Eric Zemmour's in France or Vox in Spain still try to
identify society's faultlines and then sit on top of them, but they
attract few followers --- many of whom understand that there's no risk
of these outfits ever taking power, and just want a bit of excitement.
Mathieu Lefevre, director of the anti-polarisation NGO More in Common,
warns that there's more danger of certain societies sliding into apathy
than of electing extremists.

[One thing holding European societies together is that most people still
get their news from **state broadcasters**. In Britain, nearly 100 per
cent of adults use the BBC every month. People moan about BBC news, but
most of them trust it. When scandals broke around Johnson, hardly
anybody said it was all just "fake news".]{.underline} Even in Brazil,
many of Bolsonaro's supporters see him clearly: his poll ratings
collapsed after he mishandled Covid-19. Anti-system politicians outside
the US generally pay a price for misrule.

#### Populism is meaningless

Yasmeen **Serhan 20**, Yasmeen Serhan is a staff writer at The Atlantic.
She joined the magazine in 2016 as an editorial fellow in Washington,
D.C. In 2017, Yasmeen moved to the U.K. to join The Atlantic's newly
established London bureau as a reporter covering British and European
politics. She currently writes about populism and nationalism for The
Atlantic, March 2020, \"Populism Is Meaningless,\"
https://www.theatlantic.com/international/archive/2020/03/what-is-populism/607600/
//AShah

This view has led to a number of other misconceptions: [One is that any
politician who invokes the will of "the people" must necessarily be a
populist]{.underline}. If that were the case, [every politician could be
labeled a populist]{.underline}, because "everybody talks about people
in a democracy," Daphne Halikiopoulou, an associate comparative-politics
professor at the University of Reading, told me. Another [misconception
is that populism and xenophobic nationalism,
or [nativism](https://www.theatlantic.com/international/archive/2017/04/what-is-nativist-trump/521355/),
are inherently linke]{.underline}d. In reality, [neither ideology is
reliant on the other to exist]{.underline}. "Both prioritize a
particular 'in' group over an 'out' group," Halikiopoulou said, but
[populists tend to prioritize "ordinary people," whereas nativists
prioritize those of a certain ethnic background.]{.underline}

A final misconception is that the populist label is appropriate for any
politician who deviates from the mainstream---an idea that has been
recently applied to noteworthy figures on the left, such as the outgoing
British Labour Party leader Jeremy Corbyn and the U.S. presidential
candidate Bernie Sanders. Though both men exhibit some populist
tendencies---both, for example, criticize those they consider to be part
of the economic elite---they fall short of being traditional populists,
at least under Fieschi's definition. For [one, neither claims to
represent an exclusive and homogenous "people," but rather the interests
of citizens as a whole. And neither has vilified his opponents as
inherently illegitimate.]{.underline}

[The way populism is often applied suggests that its use is more for
effect rather than explanation]{.underline}. Much in the same way
that [socialist](https://www.theatlantic.com/politics/archive/2019/02/trump-socialism-venezuela-bernie-sanders-ocasio-cortez/583135/) has
been bandied around to discredit politicians like Sanders in the U.S.
(where the term conjures negative images of the Soviet Union and
Chavismo in Venezuela), [populist has its own negative baggage. As a
result, neither of these terms ends up communicating an understood idea.
Instead, they simply obscure.]{.underline}

We will likely never have a foolproof definition of populism---it's
difficult enough to clearly define a political philosophy, let alone a
political style.

Still, this doesn't preclude us from applying it more responsibly. Part
of this requires more clearly defining our terms. As someone who
frequently writes about populism and nationalism, I've had my own fair
share of feedback about use of these terms. In my reporting of the
recent Irish election, [for
example](https://www.theatlantic.com/international/archive/2020/02/ireland-election-sinn-fein-brexit-nationalism/606328/),
I referred to Sinn Féin, a left-wing party that advocates for the
unification of the Republic of Ireland and Northern Ireland, as a
"nationalist party," much in the same way one might use the term to
describe the Scottish Nationalist Party or the Catalan independence
movement. Still, some readers presumed that by calling Sinn Féin
"nationalist," I was likening them to other far-right, nativist elements
in Europe---a comparison that is wholly unrepresentative of the party.

But it also means not overusing these terms to the point of confusion.
"For example, are you speaking about Trump denigrating Mexicans? Well,
that's [racism,](https://www.theatlantic.com/magazine/archive/2019/06/trump-racism-comments/588067/)"
Moffitt said. "Don't call that 'populist rhetoric' and soften the blow.
It just muddies the waters."

Worse yet, it risks making the term entirely meaningless.

["If everyone is a populist in one way or another, then nobody is not a
populist," Halikiopoulou said. "It explains absolutely everything, and
therefore it explains nothing."]{.underline}

### IL\-\--AT: Ukraine 

#### Ukraine is [winning]{.underline} the info war [now]{.underline}

Michael **Butler 22**, member of the Governing Council of the
International Studies Association-Northeast as well as a Senior Fellow
at the Canadian Centre for the Responsibility to Protect (CCR2P) at the
University of Toronto, 5/12/22, "Ukraine's information war is winning
hearts and minds in the West,"
<https://theconversation.com/ukraines-information-war-is-winning-hearts-and-minds-in-the-west-181892>
//mh

[Russia's invasion of Ukraine has dominated headlines since late
February 2022. The war struck a nerve among Western audiences, evoking a
**high degree of support for Ukraine**.]{.underline}

The reasons for the prominence of the war in the West are many and
varied.

A ground war in Europe launched by a major military power evokes the
ghosts of World War II. This is especially true when the attacking
country has designs on territory it considers integral to its nation,
and is led by a personalist authoritarian regime where all power is
concentrated in a single leader. The deep involvement of the U.S. and
European countries, both individually and collectively through NATO and
the European Union, also inspires Cold War comparisons.

The resulting humanitarian crisis, including the mass exodus of over 5
million refugees, underscores the ethical and moral implications of the
war.

These historical analogies and simplifying ideas help explain why the
West's imagination has been captured by this war.

[But there's more to the West's captivation with the war than is
immediately apparent. As a scholar of armed conflict and security, I
also find a compelling explanation for why the West is so focused on
Ukraine in the Ukrainian government's ability to provide information
about the war in a way that appeals to Western
sensibilities.]{.underline}

The wreckage of buildings destroyed by shelling.

'A ground war in Europe launched by a major military power evokes the
ghosts of World War II,' writes the author. Here, buildings destroyed by
intensive shelling by Russian troops in Kharkiv, Ukraine. Eugene
Zinchenko/Global Images Ukraine via Getty Images

Weaponizing information

[Russia's use of propaganda and symbols during the conflict, most
recently in the "Victory Day" celebrations attempting to draw its own
distorted parallels to World War II, has gotten a lot of attention. In
the process, Ukraine's skillful use of information warfare should not be
overlooked.]{.underline}

Information warfare entails one party denying, exploiting or corrupting
the delivery and function of an enemy's information. It is used both to
protect oneself against the enemy's information and to create a
favorable environment for one's own information.

[With the charismatic President Volodymyr Zelenskyy leading the way,
Ukraine's savvy use of traditional and social media as well as direct
appeals to the U.S. Congress, European Parliament and the court of world
opinion have provided a clear and compelling framing of the
war.]{.underline}

That frame is structured around five affecting themes: the inherently
just cause of Ukrainian self-defense; the tenacity of Ukrainian
resistance; the barbarity of Russian conduct; Russia's flawed military
strategy and general ineptitude; and Ukraine's desperate need for more,
and more sophisticated, military hardware.

[Ukraine's successful strategy in the battle over information
demonstrates the connection between armed conflict and information
warfare. Ukraine has forged a stalemate with Russia by stressing these
themes of a just war for national liberation using not only traditional
tools of warfare -- bullets, missiles, tanks -- but also by shaping the
Western public's perceptions of the war.]{.underline}

Learning from the enemy

The information front in the Russia-Ukraine war is nothing new. It was
opened by Russia in 2014 during its annexation of Crimea and incursion
in the Donbas region. Russia took the offensive to cover up its
territorial aims, saying instead that it was there to protect civilians
and resist the further spread of Western imperialism.

[At the time, Ukrainians and Russians alike were buffeted with this
disinformation through Russia's state-controlled international
English-language service RT and viral videos on YouTube and various
social media outlets.]{.underline}

[Since then, Ukraine's security and defense establishment has focused on
improving its ability to counter such disinformation tactics.
Zelenskyy's surprise landslide victory in the 2019 presidential election
gave Ukraine what has proved to be its biggest asset. A skilled
communicator and performer, Zelenskyy regularly and effectively uses
available information to present Ukraine's version of the war and debunk
Russia's. His initial selfie videos from the streets of Kyiv underscored
Ukrainian bravery and unity in a war of self-defense -- "the citizens
are here, and we are here."]{.underline}

## Solvency

### No Solvency\-\--Baltics/Eastern Europe 

#### Aff can't solve---personal connections means disinformation doesn't sway 

Joanna **Szostek, 2017**, PhD in Politics from the University of Oxford
and lecturer in Political Communication at the University of Glasgow,
November 20, 2017, "Nothing Is True? The Credibility of News and
Conflicting Narratives during "Information War" in Ukraine"// SK

The Ukrainian case similarly disrupts the assumption that audiences
support a foreign state's strategic narrative because they are
"vulnerable" to its influence activities. To describe an audience as
vulnerable implies that it is excessively credulous, lacks critical
thinking skills, or perhaps lacks access to good quality journalism. [In
the present study, the participants who sympathized with Russia's
strategic narrative were no more credulous nor deprived of good
journalism than their West-leaning and non-aligned counterparts. One
cannot, therefore, attribute their attitudes solely to interaction
between misleading Russian media content and their naivety.]{.underline}
In fact, the Russia-leaning participants did not particularly trust
Russian sources, and their views were shaped through exposure not only
to the Russian narrative, but also to the fiercely anti-Russian
Ukrainian narrative, which infuriated them. [Their infuriation at the
Ukrainian narrative can be traced to their personal, social connections
to Russia, which they valued and perceived as threatened by Ukrainian
politicians who had given them nothing in return. The present study,
thus, supports the idea that social and communication "linkage" to a
foreign state (Levitsky and Way 2010) at the individual level can play a
role in strategic narrative reception.]{.underline} Linkage generates
practical and emotional reasons for some Ukrainians to value friendly
relations with Russia (Szostek 2017b), setting them at loggerheads with
their government, which presents ties to Russia as thoroughly
undesirable.

The present study has exposed complexities in what credibility means
when it is applied to narratives in the news. Within International
Relations, credibility has previously been described as "an important
source of soft power" (Nye 2004: 106), but it has usually been presented
as the straightforward product of honesty and good reputation. Studying
how the Odesa diarists responded to news has shown that [credibility
also depends on whether sources and narratives address the issues of
most concern to the audience]{.underline}, with skepticism elicited by
what gets ignored, as well as what gets said[. It should not be
surprising that people negotiate the meanings of news with reference to
their values and experiences. Decades of work on "interpretive
communities" have shown personal experience playing a central part in
how people negotiate the meanings of other genres, including soap operas
and literature]{.underline} (Schrøder 1994).

At present, Russia, the United States, and other western countries are
all keen for Ukrainians to use their media and support their narrative
of political events. Politicians and some journalists tend to fight the
opponent's narrative by vociferously criticizing the opponent's
misconduct. The resulting repetitive and one-sided attributions of blame
risk alienating the unconverted among the general population, who may
perceive elites as dodging responsibility and avoiding more important
issues. A lot of effort is currently directed into exposing and
debunking "fake news" in the Russian media. Yet[, the credibility of the
Russian narrative among the Russia-leaning section of Ukrainian society
is not based solely on their confidence in particular facts, but also on
their priorities, which cannot be debunked. The "persuasive power" of
the Russian narrative among a minority of Ukrainians comes not from
propagandistic news alone, but also from people's memories of their
grandparents, and this is what makes it difficult for competing
messengers to overcome.]{.underline}

# ADV\-\--Information Ecosystem

## AT: Info Ecosystem ILs

### 1NC\-\--Squo Solves 

#### Squo solves

Ondrej **Filipec 2019**, Ph.D. is Assistant Professor at the Department
of Politics and Social Sciences, Faculty of Law, Palacký University in
Olomouc, "Towards a Disinformation Resilient Society? The Experience of
the Czech Republic" vol. 11 no. 11 pg 16//SK

On the other hand[, the gap is slowly being filled by NGOs and
individuals who provide textbooks (often on a commercial basis), and
materials and information on how to teach media education.]{.underline}
Lecturers and universities provide assistance or volunteers (initiative
Zvolsi.info) and the NGO People in Need organizes the Week of Media
Education. [Some webs contribute to the field with the fact checking of
political speeches (Demagog.cz), and are aimed at debunking political
disinformation (Manipulatori.cz) or hoaxes (]{.underline}Hoax.cz). In
recent years, [there have also been valuable books written by experts on
disinformation and propaganda, which are not fully academic but have a
popular style in order to reach a larger audience. In this way, the role
of civil society and active individuals play an important role in the
fight against disinformation and propaganda as they help to reveal and
debunk the disinformation and contribute to media literacy at least
within the selected segments.]{.underline} Moreover, approximat crely
[since 2018 there are 'Czech Elves' present on the social networks who
fight 'Russian Trolls'.]{.underline} As pointed out by Elven anonymous
speakers: 'we know that they are dividing our society and that support
of extremes is intentional, backed by foreign interests. Activities are
made by variously motivated enemies of our values \... we are not
indifferent to the division of our society, that is why we want to
defend our state and fight against Russian propaganda' (Aktulne.cz
2018). However, the Czech environment is different from that of the
Baltic States where people are more aware of Russian influence. For
example while Elves in Latvia have approximately a five year long
tradition and Elves are counted in hundreds, in the Czech Republic
society is divided and there are just dozens of Elves (Aktualne.cz
2018). It is too early to evaluate the presence of Czech Elves on the
internet as the real effects remain hidden. The presence has been
notified also by its critics who consider Elves as the agents on the
side of the censors as they help to fight disinformation.

### 1NC\-\--AT: Info Ecosystem IL 

#### Threats are [exaggerated]{.underline}. Misinformation is a [drop in the bucket.]{.underline} 

Gabrielle **Lim 20**, researcher at Harvard Kennedy School's Shorenstein
Center and a fellow with Citizen Lab. "The Risks of Exaggerating Foreign
Influence Operations and Disinformation," Centre for International
Governance Innovation (CGI),
<https://www.cigionline.org/articles/risks-exaggerating-foreign-influence-operations-and-disinformation/>
//chico

In recent years, concerns over foreign interference from "bad actors"
have increased, and in the wake of the 2016 US presidential election,
governments around the world, social media companies and civil society
alike have been on the lookout for such attempts to degrade the
integrity of our elections or, more vaguely, to "sow discord." From
pseudonymous trolls and botnets to outrage-inducing, hyper-partisan
content, [it seems that week after week]{.underline}, [there
is]{.underline} [news]{.underline} that online [accounts are pushing
narratives in the interest of Russia, Iran or China]{.underline}. The
Global Engagement Center ([GEC]{.underline}), a division of the US State
Department, for example, has [alleged that Russia]{.underline} is
[operating an "ecosystem"]{.underline} of humans and bots
[to]{.underline} amplify conspiracy theories related to COVID-19 in a
bid to "[sow discord]{.underline} and undermine U.S. institutions and
alliances." Senator Elizabeth Warren even released a detailed plan to
fight disinformation as part of her presidential campaign, citing
"foreign actors" as the main threat. Scholars and journalists are also
on the hunt. Indeed, plenty of ink has been spilled on the ills of
"weaponized social media" and the next generation of "active measures."

However, [despite all the fears of mass-targeted influence operations
from foreign adversaries]{.underline}, it remains [unclear whether they
have much impact at all.]{.underline}

Evidence and analysis of activity from the Russian-based Internet
Research Agency (IRA) continue to be debated. Although some suggest that
it was plausible the IRA influenced public opinion, [there is very
little evidence of direct impact on]{.underline} the US
[2016]{.underline} presidential [election.]{.underline} The [bulk
of]{.underline} their [activity was engaged in audience
building]{.underline}, and [when compared to]{.underline} the [massive
volumes of media consumed by]{.underline} the average
[American]{.underline} across mainstream, independent and social media,
[Russian-sponsored activities would have been]{.underline} but [a
drop]{.underline} in an otherwise [chaotic and constantly churning sea
of information]{.underline}. [Attempts by China to
influence]{.underline} the [Taiwanese election]{.underline} were
[likewise ineffective]{.underline}, as incumbent and pro-democracy
leader Tsai Ing-wen won a second term by a wide margin.
[Reporting]{.underline} on such influence operations,
[however,]{.underline} is [often couched in wording that implies
attribution and effect without actual verification or convincing
evidence.]{.underline}

And, [in an ironic twist,]{.underline} our [fears and
concerns]{.underline} that [foreign actors]{.underline} are [somehow
interfering]{.underline} [with democracy and]{.underline} deliberative
[discourse are]{.underline}, [counterintuitively]{.underline}, [allowing
for]{.underline} the [further erosion of democracy]{.underline} and
deliberative discourse.

Of course, the threat of influence operations should not be taken
lightly and warrants investigation and thoughtful study. Yet, the
[knee-jerk reactions to foreign influence campaigns]{.underline}
[from]{.underline} some [policy makers]{.underline} and parts of civil
society [have exaggerated the impact]{.underline}, [and]{.underline}
therefore the [threat,]{.underline} [of foreign-targeted influence
op]{.underline}eration[s]{.underline}. And, in an ironic twist, our
fears and concerns that foreign actors are somehow interfering with
democracy and deliberative discourse are, counterintuitively, allowing
for the further erosion of democracy and deliberative discourse.

### 2NC\-\--AT: Info Ecosystem IL 

#### Data [flows neg]{.underline}\-\--it's [hype]{.underline}. AND [fake news]{.underline} is [declining]{.underline} now.

Mathew **Ingram 19**, CJR's chief digital writer. "Researchers say fears
about 'fake news' are exaggerated," Columbia Journalism Review (CJR),
<https://www.cjr.org/the_media_today/researchers-fake-news-exaggerated.php>
//chico

IT'S [SO WIDELY ACCEPTED]{.underline} that it's [verging on conventional
wisdom]{.underline}: [misinfo]{.underline}rmation, or "fake news,"
[spread primarily by Facebook to hundreds of millions of
people]{.underline} (and [created by Russian agents]{.underline}),
[helped distort the political landscape before and during]{.underline}
the [2016]{.underline} US presidential election, [and this resulted
in]{.underline} Donald [Trump]{.underline} becoming president. But is it
really that cut and dried? Not according to Brendan Nyhan, a political
scientist and professor of public policy at the University of Michigan.
He and several colleagues have been researching this question since the
election, and have come to a very different conclusion. [Fears about the
spread and influence of fake news have been over-hyped,]{.underline}
Nyhan says, and [many of the initial conclusions about the scope of the
problem and its effect on US politics were exaggerated or just plain
wrong.]{.underline}

Nyhan says his [data shows]{.underline} so-called ["fake news" reached
only a tiny proportion of the population before and during the 2016
election]{.underline}. [In most cases,]{.underline}
[misinfor]{.underline}mation from a range of fake news sites [made up
just 2 percent or less of the average person's online news
consumption]{.underline}, [and even among the group of older
conservatives who were most likely to consume fake news,]{.underline}
[it only made up about 8 percent]{.underline}. Not only that, but the
University of Michigan researcher says a new paper he and his colleagues
recently published shows the reach of [fake news actually fell
significantly between the 2016 election and the midterm elections last
year]{.underline}, which [suggests Facebook has cracked down on the
problem]{.underline}. Nyhan also says "[no credible evidence exists that
exposure to fake news changed the outcome of the 2016
election]{.underline}."

#### Disinformation is a confirmation bias---research proves the amount of fake news is incredible tiny

Matthew **Ingram 2019**, He is CJR's chief digital writer. Previously,
he was a senior writer with Fortune magazine. He has written about the
intersection between media and technology since the earliest days of the
commercial internet. His writing has been published in the Washington
Post and the Financial Times as well as by Reuters and Bloomberg.,
Febuary 2019, "Researchers say fears about 'fake news' are exaggerated",
[https://www.cjr.org/the_media_today/researchers-fake-news-exaggerated.php
//](https://www.cjr.org/the_media_today/researchers-fake-news-exaggerated.php%20//)
SK

IT'S SO WIDELY ACCEPTED that it's verging on conventional wisdom:
misinformation, or "fake news," spread primarily by Facebook to hundreds
of millions of people (and created by Russian agents), helped distort
the political landscape before and during the 2016 US presidential
election, and this resulted in Donald Trump becoming president. [But is
it really that cut and dried? Not according to Brendan Nyhan, a
political scientist and professor of public policy at the University of
Michigan.]{.underline} He and several colleagues have been researching
this question since the election, and have come to a very different
conclusion. [Fears about the spread and influence of fake news have been
over-hyped]{.underline}, Nyhan says, and [many of the initial
conclusions about the scope of the problem and its effect on US politics
were exaggerated or just plain wrong.]{.underline}

Nyhan says his data shows so-called ["fake news" reached only a tiny
proportion of the population before and during the 2016
election]{.underline}. In most cases, [misinformation from a range of
fake news sites made up just 2 percent or less of the average person's
online news consumption, and even among the group of older conservatives
who were most likely to consume fake news, it only made up about 8
percent.]{.underline} Not only that, but the University of Michigan
researcher says a new paper he and his colleagues recently published
shows the reach of fake news actually fell significantly between the
2016 election and the midterm elections last year, which suggests
Facebook has cracked down on the problem. Nyhan also says ["no credible
evidence exists that exposure to fake news changed the outcome of the
2016 election."]{.underline}

This might come as a surprise to Kathleen Hall Jamieson. She's a veteran
public policy researcher who published a book last year entitled
Cyberwar: How Russian Hackers and Trolls Helped Elect a President.
Jamieson, whose colleagues call her "the Drill Sergeant" for her
no-nonsense attitude, has more 40 years of studying human behavior under
her belt. In the book, she says the evidence suggests misinformation
propagated by Russian trolls likely influenced the outcome of the
election, in part because of the number of "swing" or undecided voters
who were susceptible to those kinds of tactics. Jamieson also notes that
the traditional news media played a key role in spreading this fake news
and propaganda, by writing innumerable articles about Hillary Clinton's
emails. And she argues fake news wouldn't have had to make much of an
impact to influence the election, since a fairly small number of votes
gave Trump the electoral college wins he needed.

[Nyhan and his fellow researchers, however, including Princeton
political scientist Andrew Guess,]{.underline} say their study looked at
the actual behavior of a large sample of users who consented to have
their online activity tracked and recorded in real time, and then
followed up with interviews about their perceptions of the content. [Not
only was the amount of actual fake news they encountered incredibly
tiny, Guess told CJR this past fall, but the idea that this would
influence their behavior is also a bit of a stretch (something Nyhan
wrote about for The New York Times last year). "It's predominantly
people who are inclined to believe the conclusions that are being made
in this content, not so much swaying them to believe something," Guess
said. "In other words, it's more or less just confirmation
bias."]{.underline}

So why has this myth of fake news swinging the election persisted
despite a lack of evidence to support it? Nyhan's theory is that it's a
little [like the myth that Orson Welles's radio play "War of the Worlds"
caused widespread panic among the US population when it was aired in
1938.]{.underline} The play was likely only heard by a tiny number of
people, and there's no actual evidence that it caused any kind of panic,
and yet the myth persists---in part because newspapers at the time
played up the idea, as a way of discrediting radio (a relatively new
competitor) as a source of news. In the same way, Nyhan argues,
[concerns about fake news being spread by Russian agents on Facebook are
fueled by broader concerns about the influence of social networks on
society.]{.underline}

#### Combatting is not key---[new studies]{.underline} reveal misinformation leads to [better recollection]{.underline} of correct information

Bryan **Robinson 2020**, He is a Professor Emeritus at the University of
North Carolina at Charlotte, authored 40 nonfiction books, and was
featured on 20/20, Good Morning America, ABC's World News Tonight, NBC
Nightly News, NBC Universal, The CBS Early Show, CNBC's The Big Idea and
NPR\'s Marketplace, October 2020, "A New Study Shows Fake News May
Benefit Your Memory", Forbes,
https://www.forbes.com/sites/bryanrobinson/2020/10/17/a-new-study-shows-fake-news-may\--benefit-your-memory/?sh=27d81e9c2687//SK

During the workday, we are flooded with emails, texts, and other social
media. And with the advent of photo shopping and political leaders who
don't divulge the truth, it's often difficult to know what to believe
anymore. Hence, the term fake news has caused many people to become
skeptical about what they read or see on television news feeds---even
the authentic news. But a new study says we shouldn't throw out the baby
with the bathwater. Not all news is fake, and even if a story turns out
to be fake news, there's value in it, according to a study in the
journal Psychological Science. [Thinking back on a time you encountered
false information or "fake news" may prime your brain to better recall
truthful memories. People who receive reminders of past misinformation
may form new factual memories with greater fidelity.]{.underline} Past
research highlights one insidious side of fake news: The more you
encounter the same misinformation---for instance, that world governments
are covering up the existence of Bigfoot and flying saucers---the more
familiar and potentially believable that false information becomes. [New
research, however, has found that reminders of past misinformation can
help protect against remembering misinformation as true while improving
recollection of real-world events and information.]{.underline}
Researcher Christopher Wahlheim at the University of North Carolina at
Greensboro and his research team conducted two experiments with 96
participants, who read factual statements and misinformation statements
taken from news websites and then read statements that corrected the
misinformation. Reminders of past misinformation appeared before some
corrections but not others. Study participants then tried to recall
facts, indicated their belief in those recalls and indicated whether
they remembered corrections and misinformation. The researchers examined
whether reminders of misinformation could improve memory for and beliefs
in corrections. [Study results showed that misinformation reminders
increased the participants\' recall of facts and belief accuracy. The
researchers interpreted the results to indicate that misinformation
reminders raise awareness of discrepancies and promote memory updating.
These results may be pertinent to individuals who confront
misinformation frequently.]{.underline} \"Reminding people of previous
encounters with [fake news can improve memory and beliefs for facts that
correct misinformation]{.underline},\" said Wahlheim. \"This suggests
that pointing out conflicting information could improve the
comprehension of truth in some situations.\" These findings demonstrate
that misinformation reminders can diminish the negative effects of
fake-news exposure in the short term. According to Walheim, \"It
suggests that there may be benefits to learning how someone was being
misleading. [This knowledge may inform strategies that people use to
counteract high exposure to misinformation spread for political
gain."]{.underline}

#### Sample size [data proves]{.underline}. Per-capita consumption is [tiny]{.underline} AND [confirmation bias]{.underline} means minds aren't being [changed.]{.underline} 

Mathew **Ingram 19**, CJR's chief digital writer. "Researchers say fears
about 'fake news' are exaggerated," Columbia Journalism Review (CJR),
<https://www.cjr.org/the_media_today/researchers-fake-news-exaggerated.php>
//chico

Nyhan and his fellow researchers, however, including Princeton political
scientist Andrew Guess, say their [study looked at the actual behavior
of a large sample of users who consented to have their online activity
tracked and recorded in]{.underline} real time, and [then followed up
with interviews about their perceptions of the content]{.underline}.
[Not only was the amount of actual fake news they encountered incredibly
tiny]{.underline}, Guess told CJR this past fall, [but the idea that
this would influence their behavior is also a bit of a
stretch]{.underline} (something Nyhan wrote about for The New York Times
last year). "It's [predominantly people who are inclined to believe the
conclusions that are being made in this content]{.underline}, not so
much swaying them to believe something," Guess said. "In other words,
it's [more or less just confirmation bias]{.underline}."

#### [Media hype]{.underline} has [overshadowed]{.underline} empirical evidence\-\--research is [lacking]{.underline} and the most [comprehensive data]{.underline} still concludes [NEG.]{.underline}

Joseph **Bernstein 21** is a senior reporter at BuzzFeed News and a 2021
Nieman Fellow. "Bad News: Selling the story of disinformation," Harper's
Magazine,
<https://harpers.org/archive/2021/09/bad-news-selling-the-story-of-disinformation/>
//chico

The [media narrative of sinister digital mind control]{.underline} has
[obscured a body of research that is skeptical about the effects of
political advertising and disinformation]{.underline}. A [2019
examination]{.underline} of thousands of Facebook users by political
scientists at Princeton and NYU [found that "sharing articles from fake
news domains was a rare activity"]{.underline}---more than 90 percent of
users had never shared any. A 2017 Stanford and NYU study concluded that
[if one fake news article were about as persuasive as one TV campaign
ad]{.underline}, [the fake news in our database would have changed vote
shares by an amount on the order of hundredths of a percentage
point]{.underline}. [This is much smaller than Trump's margin of victory
in]{.underline} the [pivotal states]{.underline} on which the outcome
depended.

Not that these studies should be taken as definitive proof of anything.
[Despite its prominence in the media]{.underline}, [the study of
disinformation is still in the process of answering definitional
questions and hasn't begun to reckon with some basic epistemological
issues.]{.underline}

[The most comprehensive survey of the field]{.underline} to date, a 2018
scientific literature review titled "Social Media, Political
Polarization, and Political Disinformation," reveals some [gobsmacking
deficits.]{.underline} The [authors fault disinfo]{.underline}rmation
[research for failing to explain why opinions change]{.underline};
[lacking solid data on the prevalence and reach of
disinformation]{.underline}; [and declining to establish common
definitions for the most important terms in the field]{.underline},
including disinformation, misinformation, online propaganda,
hyperpartisan news, fake news, clickbait, rumors, and conspiracy
theories. The sense prevails that no two people who research
disinformation are talking about quite the same thing.

This will ring true to anyone who follows the current media discussion
around online propaganda. ["Misinformation" and "disinformation" are
used casually and interchangeably t]{.underline}o refer to an enormous
range of content, ranging from well-worn scams to viral news
aggregation; from foreign-intelligence operations to trolling; from
opposition research to harassment. In their crudest use, the [terms are
simply jargon for]{.underline} ["things I disagree with."]{.underline}
Attempts to define "disinformation" broadly enough as to rinse it of
political perspective or ideology leave us in territory so abstract as
to be absurd. As the literature review put it:

"Disinformation" is intended to be a broad category describing the types
of information that one could encounter online that could possibly lead
to misperceptions about the actual state of the world.

That narrows it down!

The term has always been political and belligerent. When dezinformatsiya
appeared as an entry in the 1952 Great Soviet Encyclopedia, its meaning
was ruthlessly ideological: "Dissemination (in the press, on the radio,
etc.) of false reports intended to mislead public opinion. The
capitalist press and radio make wide use of dezinformatsiya." Today,
journalists, academics, and politicians still frame the disinformation
issue in martial language, as a "war on truth" or "weaponized lies." In
the new context, however, bad information is a weapon wielded in an
occasionally violent domestic political conflict rather than a cold war
between superpowers.

Because the [standards of the new field of study are so
murky]{.underline}, the [popular understanding of the persuasive effects
of bad information]{.underline} has [become overly dependent on anecdata
about "rabbit holes"]{.underline} that privilege the role of novel
technology over social, cultural, economic, and political context.
(There are [echoes of]{.underline} [Cold War brainwashing]{.underline}
fears here.) These [stories of persuasion]{.underline} are, like the
story of online advertising, [plagued by]{.underline} the [difficulty of
disentangling correlation from causation.]{.underline} Is social media
creating new types of people, or simply revealing long-obscured types of
people to a segment of the public unaccustomed to seeing them? The
latter possibility has embarrassing implications for the media and
academia alike.

#### Disinformation concerns have not been thoroughly studied---empirical research states that disinformation is overstated

William H. **Dutton 2017**, Professor of Media and Information Policy,
Michigan State University, May 2017, "Fake news, echo chambers and
filter bubbles: Underresearched and overhyped",
<https://theconversation.com/fake-news-echo-chambers-and-filter-bubbles-underresearched-and-overhyped-76688//>
SK

In the early years of the internet, it was revolutionary to have a world
of information just a click away from anyone, anywhere, anytime. Many
hoped this inherently democratic technology could lead to
better-informed citizens more easily participating in debate, elections
and public discourse.

Today, though, many observers are concerned that search algorithms and
social media are undermining the quality of online information people
see. They worry that bad information may be weakening democracy in the
digital age.

The problems include online services conveying fake news, splitting
users into "filter bubbles" of like-minded people and enabling users to
unwittingly lock themselves up in virtual echo chambers that reinforce
their own biases.

[These concerns are much discussed, but have not yet been thoroughly
studied]{.underline}. What research does exist has typically been
limited to a single platform, such Twitter or Facebook. [Our study of
search and politics in seven nations -- which surveyed the United
States, Britain, France, Germany, Italy, Poland and Spain in January
2017 -- found these concerns to be overstated, if not
wrong.]{.underline} In fact, many internet users trust search to help
them find the best information, check other sources and discover new
information in ways that can burst filter bubbles and open echo
chambers.

Surveying internet users

We sought to learn directly from people about how they used search
engines, social media and other sources of information about politics.
Through funding from Google, we conducted an online survey of more than
14,000 internet users in seven nations.

[We found that the fears surrounding search algorithms and social media
are not irrelevant -- there are problems for some users some of the
time. However, they are exaggerated, creating unwarranted fears that
could lead to inappropriate responses by users, regulators and
policymakers.]{.underline}

The importance of searching

The survey findings demonstrate the importance of search results over
other ways to get information. When people are looking for information,
they very often search the internet. Nearly two-thirds of users across
our seven nations said they use a search engine to look for news online
at least once a day. They view search results as equally accurate and
reliable as other key sources, like television news.

In line with that general finding, [a search engine is the first place
internet users go online for information about politics.]{.underline}
Moreover, those internet users who are very interested in politics, and
who participate in political activities online, are the most likely to
use a search engine like Bing or Google to find information online about
politics.

[But crucially, those same users engaged in search are also very likely
to get information about politics on other media, exposing themselves to
diverse sources of information, which makes them more likely to
encounter diverse viewpoints. Further, we found that people who are
interested and involved in politics online are more likely to
double-check questionable information they find on the internet and
social media, including by searching online for additional sources in
ways that will pop filter bubbles and break out of echo
chambers.]{.underline}

Internet-savvy or not?

It's not just politically interested people who have these helpful
search habits: People who use the internet more often and have more
practice searching online do so as well.

[That leaves the least politically interested people and the least
skilled internet users as most susceptible to fake news, filter bubbles
and echo chambers online. These individuals could benefit from support
and training in digital literacy.]{.underline}

[However, for most people, internet searches are critical for checking
the reliability and validity of information they come across, whether
online, on social media, on traditional media or in everyday
conversation. Our research shows that these internet users find search
engines useful for checking facts, discovering new information,
understanding others' views on issues, exploring their own views and
deciding how to vote.]{.underline}

International variations

We found that people in different countries do vary in how much they
trust and rely on the internet and searches for information. For
example, internet users in Germany, and to a lesser extent those in
France and the United Kingdom, are more trusting in TV and radio news,
and more skeptical of searches and online information. Internet users in
Germany rate the reliability of search engines lower than those in all
the other nations, with 44 percent saying search engines are reliable,
compared with 50 to 57 percent across the other six countries.

In Poland, Italy and Spain, people trust traditional broadcast media
less and are more reliant on, and trusting of, internet and searching.
Americans are in the middle; there were greater differences within
European countries than between Europe as a whole and the U.S. American
internet users were so much more likely to consult multiple sources of
information that we called them "media omnivores."

Internet users generally rely on a diverse array of sources for
political information. And they display a healthy skepticism, leading
them to question information and check facts. [Regulating the internet,
as some have proposed, could undermine existing trust and introduce new
questions about accuracy and bias in search results.]{.underline}

[But panic over fake news, echo chambers and filter bubbles is
exaggerated, and not supported by the evidence from users across seven
countries.]{.underline}

### AT: Climate IL

#### The [Heartland Institute]{.underline} and other [conservative think tanks]{.underline} are the [engines]{.underline} of climate denialism\-\--foreign ops not key 

Heather W. **Cann et. al 22**, H.C. has a PhD in political science from
Purdue University, Leigh Raymond is a Professor of Political Science at
Purdue University, "Does climate denialism still matter? The prevalence
of alternative frames in opposition to climate policy," Environmental
Politics, 27:3, pg. 433-454, DOI: 10.1080/09644016.2018.1439353 //chico

Think tanks and climate change policy opposition

We focus our analysis on the framing efforts of a leading think tank
with global reach opposed to climate change action, the Heartland
Institute, for several reasons. [Conservative think tanks]{.underline}
[play]{.underline} a [central role in opposition to climate
policy]{.underline}, [as well as other environmental policy]{.underline}
issues (McCright and Dunlap 2003). [Traditionally understood as
producing and disseminating]{.underline} policy [research
with]{.underline} the [aim of informing]{.underline} public policy
[debates]{.underline} (Medvetz 2012), [think tanks opposing climate
change policies sow doubt]{.underline} as [to the seriousness and
reality]{.underline} of anthropogenic [climate change]{.underline} in
order [to stall and oppose policy action]{.underline} (Jacques et al.
2008, Oreskes and Conway 2010, Dunlap and Jacques 2013). Prior work has
documented the [financial ties between conservative think tanks and
fossil fuel industries]{.underline} (Brulle 2013), [and]{.underline}
conservative [think tanks like Heartland]{.underline} have been
described as the ['engines' of the climate change 'denial
machine']{.underline} (Elsasser and Dunlap 2012, Dunlap and Jacques
2013, Boussalis and Coan 2016). [Such organizations]{.underline}, [by
way of]{.underline} the [scientific legitimacy of their 'in-house'
experts]{.underline} (McCright and Dunlap 2003), [achieve considerable
global influence in both the public and political sphere]{.underline}:
t[hrough books, op-eds, articles, policy documents, online posts, other
forms of written media, interviews, and government
hearings.]{.underline} This is especially true given the ease with which
skeptic materials are circulated online (Holliman 2011, Lewandowsky et
al. 2013, Sharman 2014).

[Think tanks]{.underline} also [experience privileged status as
'alternate academia']{.underline} -- a [perception that
such]{.underline} [organizations produce legitimate scientific
work]{.underline} (Medvetz 2012, Dunlap and Jacques 2013). Indeed, [in
the US]{.underline}, [conservative think tank
rep]{.underline}resentative[s]{.underline} [often achieve direct access
to policy elites]{.underline} when [invited to testify at congressional
hearings or provide briefings]{.underline} to decision makers, [as well
as access to classrooms]{.underline} via the distribution of learning
materials.

The [Heartland Institute is especially influential at shaping climate
change discourse on a global scale. Internationally]{.underline},
Heartland is recognized as a think tank with some of the [strongest
networking capabilities]{.underline} (McGann 2017), and one of the
[highest-impact public policy think tanks in the US]{.underline} (McGann
2015). As noted by The Economist (and reported on Heartland's own
website), [the organization is renowned as 'the world's most prominent
think-tank supporting skepticism about man-made climate
change']{.underline} (2012), a finding consistent with prior work in
this area (McCright and Dunlap 2003, Pooley 2010).

### AT: CDC/Public Health IL 

#### C.D.C is functionally [broken]{.underline}\-\--lack of [funding]{.underline}, [authority]{.underline}, and internal [conflicts]{.underline} all [swamp credibility.]{.underline}

Jeneen **Interlandi 21**, staff writer at the New York Times, "Covid
Proved the C.D.C. Is Broken. Can It Be Fixed?," The New York Times
Magazine,
<https://www.nytimes.com/2021/06/16/magazine/cdc-covid-response.html>
//chico

[For most of the last seven decades,]{.underline} the [C.D.C. has stood
as the world's premier public-health institution]{.underline} --- so
much so that counterpart agencies in other countries are often called
C.D.C.s, even when the abbreviation means nothing in their native
languages. [The agency invented disease surveillance as we
know]{.underline} it, helped lead the (successful) quest to eradicate
smallpox, initiated the (ongoing) fight against H.I.V. and beat back
Ebola --- more than once. [Its heroics have been the stuff of novels and
movies and harrowing nonfiction best]{.underline} sellers. [Americans
took for granted that the C.D.C. would be engaged and quick in a
crisis]{.underline}; [that it was well funded and equipped with modern
technology]{.underline}; [that it had, or could quickly get,
comprehensive data on diseases of concern]{.underline}; [and that it
knew how to translate that data into sound guidance in a
crisis.]{.underline} Wasn't that, at least partly, how bird flu, swine
flu and a thousand other nameless plagues were prevented from decimating
the American masses?

The agency may be just one cog in the nation's public-health apparatus,
but it is a crucial one. In an ideal world, its edicts would hold sway
not only over schools but also nursing homes, prisons and meatpacking
plants. It would guide elected officials and private institutions alike
through not just global pandemics but all manner of public-health
threats: food-borne pathogen outbreaks, the opioid crisis, gun violence.
In an ideal world, its efforts would succeed, more often than not, at
keeping people safe and helping them stay healthy. This is the C.D.C. we
need. But as the last year has made clear, it is not the C.D.C. we have.

[The C.D.C.]{.underline} we have is hardly a monolith: Some of its many
[pockets]{.underline} are bursting with innovation[;]{.underline} others
are [plagued by inertia. But scientists and administrators who have
spent decades working]{.underline} with and [for]{.underline} the
[agency]{.underline} say that [three problems]{.underline} in particular
[affect]{.underline} the whole [institution: a lack of funding, a lack
of authority and a culture that has been warped by both.]{.underline}
Some of these problems come down to politics, but [most are a result of
flaws in the agency's very foundation.]{.underline}

[From its inception in 1946, the]{.underline} [agency's existence hinged
on its officers' ability to sell its services to state leaders who were
leery of federal interference]{.underline}, and to lawmakers who often
struggled to appreciate the point of epidemiology. They did this by
taking on the jobs that no other agency wanted, quickly developing a
reputation for being the first to arrive at any given emergency, the
last to leave and the one with the most cutting-edge technology. But
w[ith each success, a pattern emerged. The agency received an infusion
of funding in times of crises, and]{.underline} [praise and more
responsibility when it saved the day. But it was often starved of
resources the rest of the time and rived by internal conflicts over how
to apportion the money it did receive.]{.underline} "Everybody was
trying to establish his own thing," the historian Elizabeth Etheridge
writes in "Sentinel for Health," her biography of the agency. Each
branch had strong leadership, but none of those strong leaders were
great at working together.

Today the [C.D.C. is both sprawling in its reach and extremely
constrained in what it can]{.underline} do. It consists of more than a
dozen centers, institutes and offices and [employs more than 11,000
people in all, in a gargantuan roster of public-health
initiatives]{.underline} --- not just infectious-disease control but
also chronic-disease prevention, workplace safety, health equity and
more. A majority of that work is concentrated in the agency's Atlanta
headquarters, but there are also C.D.C. labs and programs across the
United States and C.D.C. operations around the world. [Despite that
scope]{.underline}, the [agency has little authority.]{.underline} Its
[officers can't compel individual states to participate in its
initiatives]{.underline}, for example, nor to include C.D.C. scientists
in local outbreak investigations, nor to share much data with the agency
--- even in the middle of a pandemic. It can't force people to wear
masks, or local leaders to close (or open) schools or other
establishments. The agency did try to halt evictions during the height
of the pandemic, but that edict faced such a barrage of court challenges
that its fate remains uncertain even now. [Aside from a few quarantine
powers, the most the C.D.C. can do is issue guidance, which is
unenforceable]{.underline} and --- as the past year has repeatedly shown
[--- just as likely to be weaponized as meaningfully
employed.]{.underline}

Insiders say three problems affect the institution: a lack of funding, a
lack of authority and a culture that has been warped by both.

The C.D[.C.'s multibillion-dollar annual budget is both too
small]{.underline} --- it [has barely kept pace with
inflation]{.underline} in the last two decades --- and [subject to too
many restrictions]{.underline}. Around [half of the agency's domestic
budget is funneled to the states]{.underline}, but only after [passing
through a bureaucratic thicket.]{.underline} There are nearly 200
separate line items in the C.D.C.'s budget. [Neither the agency's
director nor any state official has the power to consolidate those line
items or shift funds among them]{.underline}. "It ends up being
[extremely fragmented and beholden to different centers and advocacy
groups,]{.underline}" says Tom Frieden, who led the C.D.C. during the
Obama administration. That [lack of flexibility makes it extremely
difficult to adapt]{.underline} to the needs of individual states.

This [funding system]{.underline} also [hobbles emergency-response
efforts]{.underline}, because there is [no real budget for the
unexpected.]{.underline} When something like swine flu or Zika or
Covid-19 emerges, the [agency must rely on Congress for additional
resources --- almost always a large, one-time infusion that can't be
used for longer-term planning]{.underline} --- and then deploy those
resources, quickly, in the middle of the crisis. Public-health experts
like to call this ["building the plane while flying the
plane."]{.underline} In the past, they say, it made the C.D.C. scrappy
and fostered an esprit de corps among its officers that helped the
broader operation thrive. But in recent decades, these privations appear
to have done the opposite. "I'd go into a meeting and say, 'What needs
to be done?'" William Darrow, a former chief of the agency's Behavioral
and Prevention Research branch, told me. "And they'd give me a
five-point chart. And then I'd ask, 'Well why aren't we doing those
things?' And it was all hemming and hawing about whether we could
convince the states, or get top leadership to support it, or if it would
be controversial."

The [C.D.C. is resistant to change]{.underline}, [slow to act and
reluctant to innovat]{.underline}e, according to critics. The agency's
officers are overly reliant on published studies, which take time to
produce; and are incapable of making necessary judgment calls. Agency
departments are also deeply siloed. "We are really good at drilling
down," Darrow says. "But terrible at looking up and reaching across."
[Ongoing tensions between the C.D.C. and its parent agency]{.underline},
the Department of Health and Human Services, [have exacerbated these
tendencies]{.underline}, insiders say, and the [agency is constantly
fending off H.H.S.'s efforts to usurp some of its
portfolio.]{.underline} "There are a lot of very good people there,"
Bill Hanage, a scientist who studies the evolution of infectious
diseases at the Harvard T.H. Chan School of Public Health, says. "But
[when your resources are constantly constrained]{.underline} like that
--- [when you're constantly told no --- that forces you into a defensive
crouch."]{.underline}

#### Moderna [decked]{.underline} vaccine [diplomacy.]{.underline}

Mario H. **Lopez 21**, Opinion Contributor for THE HILL, "[Moderna's
missteps undermine US vaccine diplomacy]{.underline}," THE HILL,
<https://thehill.com/opinion/healthcare/583662-modernas-missteps-undermine-us-vaccine-diplomacy/>
//chico

This [isn't just problematic for the company]{.underline}. It [hurts
America's standing on the world's stage at a time when we need to
project strength and stability.]{.underline} [Instead of riding high on
the historic wave of innovation unleashed by the U.S. pharmaceutical
industry]{.underline}, the [Biden]{.underline} administration [is
publicly admonishing Moderna for failing to increase its global vaccine
supply]{.underline}.

Consider the events that have unfolded since December 2020 when Moderna
became the second company to obtain FDA authorization for its vaccine.
[Despite receiving \$2.5 billion from American taxpayers, Moderna has
opted not to follow the lead of other COVID vaccine manufacturers who
have offered their product at a reduced rate]{.underline}. The company's
president flatly stated, "We will not sell it at cost."

### AT: Polarization IL 

#### [No impact]{.underline} to disinformation\-\--[empirics.]{.underline}

Che-Yuan **Liang 12** and Mattias Nordin, C.L has a Ph.D. Economics,
Uppsala University, M.N is a researcher and senior lecturer at the
Department of statistics at Uppsala University. "The Internet, News
Consumption, and Political Attitudes," Uppsala Center for Fiscal Studies
Working Paper Series,
<https://econpapers.repec.org/paper/hhsuufswp/2012_5f010.htm> //chico

6\. Concluding Discussion

We investigate the [effects of the rise of the Internet]{.underline} as
an additional mass medium on news consumption patterns [and political
attitudes]{.underline}. We use [Swedish survey data]{.underline} from
2002 to 2007, a period during which online news media emerged.
Specifically, we estimate the effect of the introduction of high-speed
Internet (broadband) and find that broadband access is highly associated
with online media consumption that crowds out a portion of offline media
consumption. Overall, broadband access at home increases the share of
individuals who read newspapers (especially tabloids) while decreasing
the time people spends watching television or listening to radio.
Furthermore, more people consume newspapers, online or offline, on any
given day. The average time spent per reader is, however, lower. This
may indicate a new way of reading news that focuses on shorter articles.
The changes in media consumption patterns do, however,
[result]{.underline} in little to [no change in citizens' political
attitudes]{.underline}. We [find no effects on political interest,
ideological polarization, and opinion formation]{.underline}, and we
find a small right-wing ideological shift. This result might not be
surprising for several reasons. The main effect that we find is a shift
from offline to online media. However, the main online actors are
basically the main offline actors that have simply created online
editions with similar content. Media penetration was also high in Sweden
prior to the emergence of the Internet. The political effects of one
additional source in a sea of sources of information might be marginal.
We have focused on the largest mainstream, online mass media. Today, the
Internet increasingly offers new non-traditional types of interactive
communication, such as blogs and social networks, which are often
tailored toward specific groups. In many aspects, these media differ
more from traditional media than the media we discuss in this paper. A
study of the political effects of these media would be a fruitful area
of research. Furthermore, we have investigated the effects on the
general population; however, it is possible that the effects are more
pronounced among some groups, such as young people, who may be more
inclined to make use of new technologies.

#### Even if polarization is [increasing]{.underline} there's no [causal]{.underline} link 

Levi **Boxell 17**, L.B Stanford Institute for Economic Policy Research,
Matthew Gentzkow Department of Economics Stanford University, Jesse M.
Shapiro Economics Department @ Brown University, "IS THE INTERNET
CAUSING POLITICAL POLARIZATION? EVIDENCE FROM DEMOGRAPHICS," NBER
WORKING PAPER SERIES,
<https://www-nber-org.proxy.lib.umich.edu/system/files/working_papers/w23258/w23258.pdf>
//chico

Our [findings are difficult to square with a straightforward account
linking]{.underline} the [recent rise of polarization to the
internet]{.underline}. This is [especially true for accounts in which
social media plays a central role.]{.underline} Unless cross-group
spillovers are very large or the effects of digital media vary greatly
across groups, [some other forces must explain the large increase in
polarization]{.underline} among the groups least likely to use the
internet. None of this is to say that the rise of digital technologies
is not important. They may well account for some recent polarization,
and whatever role they may have played in the past is likely to grow in
coming years.

### AT: Truth Decay/Public Trust IL 

#### Info is [not]{.underline} the root cause. Foreign adversaries are [scapegoats]{.underline} for declining public trust 

Gabrielle **Lim 20**, researcher at Harvard Kennedy School's Shorenstein
Center and a fellow with Citizen Lab. "The Risks of Exaggerating Foreign
Influence Operations and Disinformation," Centre for International
Governance Innovation (CGI),
<https://www.cigionline.org/articles/risks-exaggerating-foreign-influence-operations-and-disinformation/>
//chico

As a first step, the US Foreign Agents Registration Act, which risks
being abused for political reasons, should be reformed, as Nick Robinson
argues in Foreign Policy. Second, increasing transparency around
campaign funding and online ad spending would also be helpful,
specifically around "dark money" --- where the identities of the donors
are concealed. And lastly, states need to do the hard work of
governance. In many ways the prevalence of false and misleading content
is symptomatic of deeper issues. As Johan Farkas and Jannick Schou
demonstrate in their book, Post-Truth, Fake News and Democracy, the
decline in democracy has been ongoing for decades and is not because of
social media: "There is a [series of deep-seated problems facing liberal
democracies]{.underline}, but the [rise of fake news and alternative
facts is not the biggest of our problems]{.underline}." [Instead of
looking overseas for scapegoats]{.underline}, [we should be looking at
why trust in our own institutions and authorities has
fallen]{.underline}, [why civil discourse has devolved and how to better
address the many social divisions that drive our receptivity for dubious
content.]{.underline}

#### [Education]{.underline} system is a [massive alt-cause]{.underline}. Students lack [media literacy.]{.underline} dissemination becomes [inevitable.]{.underline} 

Jennifer **Kavanagh 18**, J.K senior fellow, American Statecraft
Program, M.R is a Chief Executive Officer of the RAND Corporation,
"Truth Decay: An Initial Exploration of the Diminishing Role of Facts
and Analysis in American Public Life," RAND Corporation, pg. 133
<https://www.rand.org/pubs/research_reports/RR2314.html> //chico

Competing Demands on the Educational System

As the [info]{.underline}rmation [system changes and
evolves]{.underline}, [the U.S.]{.underline} [ed]{.underline}ucational
[system faces increasing]{.underline} [demands from]{.underline} a
[number of sources]{.underline}, [including the responsibility to
prepare students to]{.underline} [confront a more complicated and
challenging info]{.underline}rmatio[n system]{.underline}, to evaluate
information and sources, and to distinguish between opinion and fact.
This [responsibility is added]{.underline} to a [growing]{.underline}
[list of]{.underline} new and preexisting [demands]{.underline}:
standardized tests, extracurricular activities, before- and after-school
care, and other services. At the same time, [schools are facing budget
constraints.]{.underline} The [fiscal constraints and
demands]{.underline} placed [on the educational system]{.underline} and
the [resulting gap between the rapidly evolving challenges]{.underline}
of the [new info]{.underline}rmation [system and]{.underline} the
[curricula offered to students in most public schools]{.underline}
constitute the third [key driver of Truth Decay]{.underline}. This [gap
drives and perpetuates Truth Decay by contributing centrally to the
development of]{.underline} a [citizenry]{.underline} that [is
susceptible to consuming]{.underline} and [disseminating
disinfo]{.underline}rmation, [misinfo]{.underline}rmation, [and
infor]{.underline}mation [that blur the line between fact and
opinion]{.underline}. Specifically, [without the training that they need
to carefully evaluate sources]{.underline}, to identify and check their
own biases, [and to separate opinion and fact,]{.underline} [students
matriculating out of schools]{.underline} that teach kindergarten
through 12th grade ([K--12]{.underline})---which is the focus in this
report---or universities may be [highly vulnerable to false and
misleading information and easy targets for intentional
disinformation]{.underline} [campaigns and propaganda.]{.underline}
Furthermore, [once consuming this info]{.underline}rmation
[themselves]{.underline}, [these users are more likely to pass the
info]{.underline}rmation [along to others,]{.underline}
[perpetuating]{.underline} the [challenges]{.underline} that [Truth
Decay poses]{.underline} [and contributing to]{.underline} a
[context]{.underline} in [which Truth Decay flourish]{.underline}es.

## AT: Democracy IL 

### 1NC\-\--AT: Democracy Internal

#### Russian disinformation [can't]{.underline} collapse democracy BUT the 1AC's divisiveness and blame shifting can.

Kevin **Riehle 21**, Associate Professor at the University of
Mississippi Center for Intelligence and Security Studies, January 2021,
"Winners and losers in Russia's information war," *Intelligence &
National Security*, Vol. 36, Issue 7, pp. 1057-1064,
https://doi.org/10.1080/02684527.2021.1877405, RMax

[It might be soothing to claim that Russia is the root of our
problems]{.underline}, and Russia certainly has no desire to help us
solve those problems. Jankowicz even seems to imply that maintaining
vigilance against Russian influence activities will help in 'repairing
the cracks that allowed them in the first place.'40 However, [such
sentiments hide the true origin of Russia's influence: our internal
divisiveness]{.underline}. The success of Russian influence activities
can only serve as an indicator of how far we have to go to heal our own
societies. Nevertheless, Russia's actions have placed it back on the
table as an adversary, just as its Soviet predecessor was, which is not
in Russia's best interests. That is evidenced by the very existence of
these two books: without Russia's actions, Kent and Jankowicz would
never have written them. However, [Russia's strategy of division and
deception is a losing one. Russia is not capable of destroying a
democratic society]{.underline}; the [society can only do that to
itself. Democratic societies survived the Soviet-era information
onslaught and will survive the current one]{.underline} if they can
reduce internal anger and divisiveness, while Russia offers nothing
constructive to the world. In her claim to be describing How to Lose the
Information War, Jankowicz is in fact showing how Russia is doing just
that.

### 1NC\-\--AT: Democracy Internal\-\--Squo Solves 

#### The United States\' current response to disinformation solves democracy - we respond by declassifying intelligence which increases trust between allies

Chris **Zappone 22**, an inaugural member of the National Security
College's Futures Hub in 2017. His focus has been on hybrid warfare,
propaganda, cyber competition. He is Digital Foreign Editor at The Age
and Sydney Morning Herald, where he was among the first in the media to
report on the Kremlin's efforts to interfere in the 2016 US election. He
has presented on related subjects at SXSW in the US and testified to
Parliament on the political risk of social media manipulation, March
2022, \"'It's a clear pattern': Why declassifying secrets is good for
democracy,\" The Sydney Morning Herald,
https://www.smh.com.au/world/europe/it-s-a-clear-pattern-why-declassifying-secrets-is-good-for-democracy-20220304-p5a1nw.html
//AShah

[The [Biden]{.mark} administration's [decision]{.mark} on Thursday [to
tell the public that]{.mark} Vladimir [Putin was likely]{.mark} [to
use]{.mark} chemical [weapons in Ukraine shows]{.mark} the extent to
which [the US strategy to battle]{.mark} Russia's [disinformation has
evolved.]{.mark}]{.underline}

Once upon a time, such intelligence would have only been shared with the
top echelons of allied countries. [But in the evolving East-West
confrontation, [declassifying secrets is proving good for
democracy.]{.mark}]{.underline}

In the new warning, White House press secretary Jen Psaki said the US
had noticed an uptick in false claims from Russia about "US biological
weapons labs and chemical weapons development in Ukraine", and those
false claims could foreshadow Russia's real use of the banned weapons
against the country.

"[Now that Russia has made these false claims, and China has seemingly
endorsed this propaganda, we should all be on the lookout for Russia to
possibly use chemical or biological weapons in Ukraine, or to create a
false flag operation using them,]{.underline}" Psaki tweeted. "It's a
clear pattern."

After years of being outwitted by Russia on the world stage of public
opinion, [[the US has found a]{.mark} surprisingly [effective]{.mark}
new [counter-tactic: strategically declassifying and sharing
intelligence.]{.mark}]{.underline}

For example, the US declassified and shared information warning of
Russia's invasion of Ukraine in the months leading up to it. The US and
the UK revealed that Russia had already positioned operatives to stage a
fake attack and to install a pro-Russian leadership in Kiev. The US also
repeatedly warned of "false-flag" operations to be staged by Russia as a
pretext for invasion.

In contrast to the Kremlin's famed use of internet trolls and bots to
sow doubts in other countries, [[the US's new strategy of
sharing]{.mark} factual [information has]{.mark} -- at least for now --
[helped built trust between the US, its allies and war-hit
Ukraine.]{.mark}]{.underline}

For more than a decade, [[democracies have struggled to convince their
own citizens that they were operating in good
faith.]{.underline}]{.mark}

In some case, the cynicism has understandable roots: the cooked
intelligence seized on by the US to justify the 2003 Iraq War or genuine
cynicism for Western power in the wake of the global financial crisis.

Putin and his partisans in the media have seized on those events and
helped shape them -- highlighting, and even exacerbating, the disorders
through the dissemination of fake news, conspiracy theories and official
statements.

But [in preempting Putin's invasion, the US has drawn attention to
Ukraine, ensuring journalists flooded the country in the weeks before
the attack.]{.underline}

This has allowed the nation of 44 million, itself apt in strategic
communication, to establish narrative control of the event through the
journalists' work or through genuine video footage by citizens.

The US also appears to have extended a similar strategy to China, with
US officials revealing Beijing shared information with Moscow about
meetings Chinese diplomats had with their US counterparts before the
Ukrainian invasion began.

On Thursday, Psaki also called out Chinese officials for echoing
Russia's conspiracy theories.

The success of this "pre-bunking" tactic relies on sharing credible
information to forewarn allies and the broader public of lies told by
the Moscow regime.

Whether Australia will embrace this tactic remains to be seen.

"It's uncharted territory," said John Blaxland who is professor of
International Security & Intelligence Studies at the Australian National
University. "But now that the US has done it, the prospect becomes more
feasible."

Forewarning the public about bad information to come has "been discussed
at the individual level for years," said Joshua Tucker, professor of
Politics and Co-Director, Centre for Social Media and Politics at New
York University. "Now we're seeing this play out at a macro scale."

"[This is what the US is doing," Tucker said. "It's worked particularly
well."]{.underline}

The US government, even before it faltered in its ability to shape
global narratives, relied on spin if not outright deception, in its
involvement in the Iraq War, or in Vietnam, El Salvador and Cambodia.

But it was perhaps the Kremlin's embrace of deception to interfere in
the US 2016 presidential election (and in others around the world) that
explains why the sizable disinformation research community in the West
was surprised by the new tactic of declassifying intel for strategic
advantage.

Many in that community have struggled to explain why Ukraine's
narratives have succeeded where Russia's have so far failed - at least,
outside Russia.

["[We've gotten so hyper-focused on disinformation]{.mark}," Tucker
said, [that we've missed the potential truth has to shape
perceptions.]{.mark}]{.underline}

### AT: LIO IL 

#### [LIO]{.underline} is terminally [unsustainable]{.underline}\-\--[poisons relations]{.underline}, causes internal [polarization]{.underline}, and economic [globalization]{.underline} causes [instability]{.underline} and [multipolarity.]{.underline}

John J. **Mearsheimer 19**, R. Wendell Harrison Distinguished Service
Professor of Political Science at the University of Chicago. "Bound to
Fail: The Rise and Fall of the Liberal International Order,"
International Security (2019) 43 (4): 7--50.
<https://doi-org.proxy.lib.umich.edu/10.1162/isec_a_00342> //chico

By 2019, it was [clear]{.underline} that the [l]{.underline}iberal
[i]{.underline}nternational [o]{.underline}rder was [in deep
trouble.]{.underline} [The tectonic plates that underpin it are
shifting]{.underline}, and [little can be done to repair and
rescue]{.underline} it. Indeed, that [order was destined to fail from
the start]{.underline}, as it contained the [seeds of its own
destruction.]{.underline}

The [fall of]{.underline} the [l]{.underline}iberal
[i]{.underline}nternational [o]{.underline}rder [horrifies]{.underline}
the [Western elites who built]{.underline} it and who have benefited
from it in many ways.1 These elites fervently believe that this order
was and remains an important force for promoting peace and prosperity
around the globe. [Many of them blame]{.underline} President Donald
[Trump]{.underline} for its demise. After all, he expressed contempt for
the liberal order when campaigning for president in 2016; and since
taking office, he has pursued policies that seem designed to tear it
down.

It would be a [mistake]{.underline}, however, [to]{.underline} think
that the liberal international order [is in trouble solely]{.underline}
[because of Trump\']{.underline}s rhetoric or policies. In fact, [more
fundamental problems are at play]{.underline}, which account for why
Trump has been able to successfully challenge an order that enjoys
almost universal support among the foreign policy elites in the West.
The aim of this article is to determine why the liberal world order is
in big trouble and to identify the kind of international order that will
replace it.

I offer three main sets of arguments. First, [because
states]{.underline} in the modern world [are deeply
interconnected]{.underline} in a variety of ways, [orders are essential
for facilitating efficient and timely interactions.]{.underline} There
are different kinds of international orders, and which type emerges
depends primarily on the global distribution of power. But [when the
system is unipolar]{.underline}, the political [ideology of the sole
pole]{.underline} also [matters]{.underline}. [L]{.underline}iberal
[i]{.underline}nternational [o]{.underline}rders can [arise only in
unipolar systems where the leading state is a liberal
democracy]{.underline}.

Second, the [U]{.underline}nited [S]{.underline}tates [has led two
different orders since World War II]{.underline}. The [Cold War
order]{.underline}, which is sometimes mistakenly referred to as a
"liberal international order," [was neither liberal]{.underline} [nor
international]{.underline}. It was a [bounded order]{.underline} that
was [limited mainly to the West and was realist]{.underline} in all its
key dimensions. [It had certain features that were also consistent with
a liberal order]{.underline}, [but]{.underline} those
[attributes]{.underline} were [based on realist logic]{.underline}. The
U[.S.-led post--Cold War order]{.underline}, on the other hand, [is
liberal and international]{.underline}, and [thus differs]{.underline}
in fundamental ways from the bounded order the United States dominated
during the Cold War.

Third, the post--Cold War [l]{.underline}iberal
[i]{.underline}nternational [o]{.underline}rder [was doomed to
collapse]{.underline}, [because the key policies on which it rested are
deeply flawed]{.underline}. [Spreading liberal democracy around the
globe]{.underline}, which is of paramount importance for building such
an order, [not only is extremely difficult]{.underline},
[but]{.underline} often [poisons relations with other countries
and]{.underline} sometimes [leads to disastrous wars.]{.underline}
[Nationalism]{.underline} within the target state [is the main obstacle
to]{.underline} the promotion of [democracy]{.underline}, [but balance
of power politics also function as an important blocking
force.]{.underline}

Furthermore, the liberal [order\'s tendency to privilege international
institutions over domestic considerations]{.underline}, as well as its
deep commitment to porous, if not [open borders]{.underline}, [has had
toxic political effects inside the leading liberal states
themselves]{.underline}, [including the U.S. unipole]{.underline}.
[Those policies clash with nationalism over key issues such as
sovereignty and national identity]{.underline}. [Because nationalism
is]{.underline} the [most powerful political ideology]{.underline} on
the planet, [it invariably trumps]{.underline} [liberalism]{.underline}
whenever the two clash, thus [undermining the order at its
core.]{.underline}

In addition, [hyperglobalization]{.underline}, which
[sought]{.underline} to [minimize barriers to global trade
and]{.underline} [investment]{.underline}, [resulted in lost jobs,
declining wages, and rising]{.underline} income [inequality throughout
the liberal world.]{.underline} It also [made the international
financial system less stable, leading to recurring financial
crises]{.underline}. Those t[roubles]{.underline} then [morphed into
political problems]{.underline}, further [eroding support for the
liberal order.]{.underline}

A [hyperglobalized economy undermines the order in yet another
way]{.underline}: [it helps countries other than the unipole grow more
powerful]{.underline}, which can [undermine unipolarity and bring the
liberal]{.underline} [order to an end]{.underline}. This is what is
happening with the [rise of China]{.underline}, which, along with the
[revival of Russian]{.underline} power, has [brought the unipolar era to
a close]{.underline}. The [emerging multipolar world will consist of a
realist-based international order]{.underline}, which [will
play]{.underline} an [important role in managing]{.underline} the [world
economy]{.underline}, [dealing with arms control]{.underline}, [and
handling problems of the global commons]{.underline} such as climate
change. In addition to this new international order, the
[U]{.underline}nited [S]{.underline}tates [and China will lead bounded
orders that will compete with each other]{.underline} in both the
economic and military realms.2

## AT: Polarization IL

### 1NC\-\--AT: Polarization IL 

#### Polarization in democracies is inevitable and good-- more polarization creates stronger democracies

Markus **Pausch 21**, political scientist and professor at the
University of Salzburg, 10/10/21, "The future of polarisation in Europe:
relative cosmopolitanism and democracy,"
<https://eujournalfuturesresearch.springeropen.com/articles/10.1186/s40309-021-00183-2/>
mh

The [political polarisation that we observe in recent years, is **linked
to various factors of political equality** \[11\], including
representation, participation, transparency, but is also a dialectical
relationship between contradictory needs for freedom and belonging, to
which cosmopolitanism and communitarianism correspond at the political
level]{.underline}. A balance between these needs requires a
non-dogmatic relative cosmopolitanism that is based on real life
experiences and competences of democracy, dialogue and citizenship
education.

Basis characteristics of polarisation

[In a complex world where there are no simple explanations, the **risk
of polarisation increases**. Unequal power relations, socio-economic
inequality, structural marginalisation, discrimination or exclusion of
certain groups can drive its pernicious forms.]{.underline} The
polarisation we encounter today thus has an existential basis, the
contradiction between the need for freedom and that for belonging.

[Four features characterise polarisation processes \[49\].]{.underline}

\* **[Discrepancy of opinions]{.underline}**: Two clearly identifiable
and profiled opinions oppose each other. These opinions are not
compatible and configure themselves in an either/or relationship. The
communitarians aim at a narrower concept of belonging, the cosmopolitans
at a broad understanding in which individual freedom and solidarity are
thought globally and universally.

**\* [Group formation]{.underline}**[: The two opinions are held by two
different groups whose members are aware of the discrepancy and feel
they belong to one of the two groups. The world is divided into "Us
versus Them"]{.underline} \[9\]. Political opponents are increasingly
becoming antagonists \[36\] or even enemies. Carl Schmitt's friend-enemy
scheme has recently received greater attention again \[40, 56\]. In
political science, the term "affective polarisation" refers to the
mutual dislike of the groups (cf. \[33\]). What is necessary is the
awareness that one's own opinion is one pole in a spectrum that can
contain many opinions and that one's position is represented by a group
that is visible in some way. Often these groups give themselves a name,
or names are attributed to them. With regard to positioning on the EU,
we know the attributions as pro- and anti-Europeans or Eurosceptics.
With regard to positioning on democracy, it is mainly a distinction
between representative and direct democratic elements.

\* [**Purism**: Relative positions are not considered by the two groups.
A conciliatory position is rejected. The groups that form the poles in a
polarisation process cannot take a middle position because their
opinions are too far apart]{.underline}. A drastic example can
illustrate this: opponents of the death penalty cannot negotiate about
the death penalty. Their position is non-negotiable. The same is true
for human rights activists. The historical fighters for democracy could
not negotiate their goal with those who wanted to preserve their
authoritarian power. Someone fighting for women's rights cannot soften
or weaken the goal of equality. Conversely, authoritarian forces that
oppose emancipation do not give an inch. [The positions at the poles are
therefore fundamentally non-negotiable for the representatives of these
poles. This is also true in the case of the polarisation around Europe.
Those who advocate a European republic will not discuss the possibility
of renationalisation. The reverse is also true.]{.underline}

\* [**Political struggle**: The fourth characteristic to be mentioned is
that a political struggle for positions must be waged in order to speak
of polarisation.]{.underline} The mere existence of major differences of
opinion is not per se politically relevant, because it would also be
conceivable that one of the groups or even both simply exist in silence
without engaging in a political struggle. Only when there is a dispute
in public can we talk about polarisation.

[However, polarisation processes are **not to be regarded as dangerous
or endangering democracy** per se. To a certain extent, they are **part
of pluralistic societies**]{.underline}. [Historically, polarisation
processes have even often been a **precondition for social change**
towards more democracy. Polarisation often starts from below and
develops bottom-up. When social movements recognise a lack of justice or
opportunities for themselves or other groups and fight against it, a
hardening of positions is to be expected at first, as the dominant or
privileged groups feel threatened and may reject the demands. Only when
the pressure of the social movement becomes so strong that it **leads to
a concession** **can polarisation develop towards democratisation**. For
this to happen, the polarisation process must be turned around
positively through dialogue and inclusion]{.underline} (cf. \[39\],
234).

## Alt Causes 

### Alt Cause\-\--Domestic Disinfo 

#### Domestic information warfare is an alt cause

Samia Benaissa **Pedriza 2021**, She has a PhD in Journalism at the
Complutense University of Madrid and Is a researcher on communication
and international law, "Sources, Channels and Strategies of
Disinformation in the 2020 US Election: Social Networks, Traditional
Media and Political Candidates", Vol. 2 Iss. 4//SK

In relation to the sources of disinformation, it is usual that the
amount of fake news grow exponentially during electoral seasons
(Waisbord 2018). As Shin et al. (2016) recall, during the 2012 US
election, false information was widely disseminated via Twitter,
especially among politically polarized voters. The 2016 US election was
also another clear example of misinformation derived from social media,
but in that case, it was also largely orchestrated by foreign powers
that managed to unwantedly influence the electoral campaign (Hall
Jamieson 2018). However, [in the 2020 election, the sources of
disinformation that most attracted the attention of fact-checkers were
those represented by users of social networks, the candidates themselves
and traditional media. Therefore, in this case, no foreign power
following a planned and sustained over time disinformation strategy was
involved, according to the concept of "organized disinformation" used in
international relations (Volkoff 1986). In the 2020 election, the only
messages analyzed by international fact-checkers that came from an
institutional source were those issued by the White House
itself.]{.underline}

#### Non-state actors and extremist groups are an alt cause---erodes trust in democratic institutions

Ritu **Gill et al. 2022**, Ritu Gill is Ritu Gill is an Intelligence
Analyst with 13 years of experience working with Canadian law
enforcement, 12 of those years were with the Royal Canadian Mounted
Police (RCMP), Dr. Rebecca Goolsby currently serves as a program officer
for the Office of Naval Research and the lead on NATO Research
Technology Group, HFM-293 "Digital and Social Media Assessment For
Effective Communication And Cyber Diplomacy", "COVID-19 Disinformation:
A Multi-National, Whole of Society Perspective", pg.48//SK

Social media is characterized as a powerful online interaction and
information exchange medium. However, it has given rise to new forms of
deviant behav- iors such as spreading fake news, rumors, misinformation,
disinformation, and conducting propaganda and influence campaigns. Due
to afforded anonymity and perceived diminished personal risk of
connecting and acting online, deviant groups are becoming increasingly
common. [Online deviant groups have grown in parallel with online social
networks, whether it is black hat hackers using Twitter to recruit and
arm attackers, announce operational details, coordinate cyber-attacks
(Calabresi, 2017), and post instructional or recruitment videos on
YouTube targeting certain demographics; or state/non-state actors' and
extremist groups' (such as ISIS) savvy use of social communication
platforms to conduct phishing operations, such as viral retweeting of
messages containing harmful URLs leading to malware (Al-khateeb et al.,
2016).]{.underline} These campaigns use a variety of tactics,
techniques, and strategies to further their agenda. Some of these
campaigns exploit deep-rooted biases along racial, ethnic and political
lines (leveraging pandemic disparity), [to erode trust in scientific and
democratic institutions]{.underline} (invoking vaccination fears), to
stoke anger, anxiety, and chaos, and ultimately polarize an already
divided society. People increasingly obtain their news from social media
rather than from mainstream media (Barthel & Mitchell, 2017), and with
the world adjusting to the current pandemic and officials struggling
with the misinfodemic, it is important now, more than ever, to closely
monitor social media platforms to identify misinformation and
disinformation campaigns and stem their impact on society.

### Alt Cause\-\--Global Disinfo 

#### Alt causes. China's information warfare o/w- global ambitions, broad range, and transform LIO 

David L. **Sloss 2022**, He is a professor at Santa Clara University
School of Law, received his JD from Stanford University, MPP from
Harvard University Kennedy School of Government, and BA from Hampshire
College. He worked as a litigation associate at Wilson, Sonsini,
Goodrich & Rosati in Palo Alto and clerked for Senior Judge Joseph T.
Sneed, U.S. Court of Appeals, Ninth Circuit, San Francisco. He also
worked for the U.S. Arms Control and Disarmament Agency for nine years
before he attended law school., "Tyrants on Twitter", pg 76// SK

We saw in the last two chapters that Russia is actively using social
media to interfere with democratic elections in the United States and
western Europe. [China's approach to information operations differs from
Russia's in several respects. First, China's ambitions are global: it
aims to reshape the global information environment to align with its
authoritarian values. Second, social media is a fairly small element of
China's global information strategy: China is utilizing a broad range of
communication tools to achieve its goals. Third, whereas Russia's agenda
is primarily negative--- to undermine Western democracies--- China has a
much more positive agenda.]{.underline} Ultimately, [China seeks to
transform the liberal international order]{.underline} created by the
United States and its allies after World War II so that [international
norms and institutions align more closely with China's authoritarian
governance model]{.underline}. The Chinese term huayuquan is translated
as "discourse power." Discourse power is the "national capability to
infl uence global values, governance, and even day- to- day discussions
on the world stage."1 One commentator notes: "[The Chinese Communist
Party's quest to dominate thought and narrative has always been central
to its pursuit of power]{.underline}. To this end, every supreme party
leader since Mao has [reaffirmed the strategic and national security
importance of the party's control of media, culture, and
narrative.]{.underline}

### Alt Cause\-\--Algorithms 

#### Big tech [algorithms]{.underline} makes polarization [inevitable.]{.underline} 

Paul **Barret et. al 21** P.B Deputy Director and Senior Research
Scholar - NYU Stern Center for Business and Human Rights, J.H Associate
Research Scientist and Adjunct Instructor - NYU Tandon School of
Engineering Founder and Editor - Tech Policy Press, G.S Grant Sims
Research Fellow - NYU Stern Center for Business and Human Rights, "How
tech platforms fuel U.S. political polarization and what government can
do about it," BROOKINGS,
<https://www.brookings.edu/blog/techtank/2021/09/27/how-tech-platforms-fuel-u-s-political-polarization-and-what-government-can-do-about-it/>
//chico

As both members of Congress and federal law enforcement agencies
investigate the origins and execution of the January 6 insurrection at
the U.S. Capitol, the [role social media]{.underline} played in the
mayhem is [emerging as a crucial issue]{.underline}.

The House Select Committee probing the mob attack has asked a wide range
of social media and telecommunications companies to preserve records
related to several hundred people, including members of Congress, who
could be relevant to the investigation. Beyond these specific requests,
the Committee has signaled a broader interest in how false claims about
the 2020 election spread on platforms like [Facebook and
Twitter]{.underline}, including how [algorithms]{.underline} might
[contribute to the promotion of disinformation and
extremism]{.underline}. Meanwhile, federal prosecutors pursuing more
than 600 criminal cases are relying on evidence gathered from social
media accounts used to organize the attempt by Trump supporters to stop
Congress from certifying President Joe Biden's victory.

A report we recently published through the Center for Business and Human
Rights at New York University's Stern School of Business sheds light on
the relationship between tech platforms and the kind of extreme
polarization that can lead to the erosion of democratic values and
partisan violence. While Facebook, the largest social media platform,
has gone out of its way to deny that it contributes to extreme
divisiveness, a growing body of social science research, as well as
[Facebook's own actions and leaked documents]{.underline}, [indicate
that an important relationship exists.]{.underline}

Our central conclusion, based on a review of more than 50 social science
studies and interviews with more than 40 academics, policy experts,
activists, and current and former industry people, is that platforms
like Facebook, YouTube, and Twitter likely are not the root causes of
political polarization, but they do exacerbate it. Clarifying this point
is important for two reasons. First, Facebook's disavowals, in
congressional testimony and other public statements, may have clouded
the issue in the minds of lawmakers and the public. Second, as the
country simultaneously tries to make sense of what happened on January 6
and turns its attention to elections in 2022, 2024, and beyond,
understanding the harmful role popular tech platforms can play in U.S.
politics should be an urgent priority.

SOCIAL MEDIA CONTRIBUTES TO PARTISAN ANIMOSITY

Facebook's Mark Zuckerberg has on multiple occasions dismissed
suggestions that his company stokes divisiveness. "Some people say that
the problem is that social networks are polarizing us, but that's not at
all clear from the evidence or research," he testified before a U.S.
House of Representatives subcommittee in March 2021, instead pointing to
"a political and media environment that drives Americans apart." A few
days later, Nick Clegg, Facebook's vice president for global affairs and
communication, argued that "what evidence there is simply does not
support the idea that social media, or the filter bubbles it supposedly
creates, are the unambiguous driver of polarization that many assert."

Contrary to Facebook's contentions, however, a range of [experts have
concluded that the use of social media contributes to partisan animosity
in the U.S.]{.underline} In an article published in October 2020 in the
journal Science, a group of 15 researchers summarized the scholarly
consensus this way: "In recent years, [social media companies like
Facebook and Twitter have played an influential role in political
discourse, intensifying political sectarianism."]{.underline} In August
2021, a separate quintet of researchers summed up their review of the
empirical evidence in an article in the journal Trends in Cognitive
Sciences: "Although [social media]{.underline} is unlikely to be the
main driver of polarization, they concluded, "we posit that it is often
a [key facilitator]{.underline}."

PARTISANSHIP IS COMPLICATED, BUT PLATFORMS DO NOT FULLY ESCAPE
RESPONSIBILITY

Polarization is a complicated phenomenon. Some divisiveness is natural
in a democracy. In the U.S., struggles for social and racial justice
have led to backlash and partisan animosity. But the extreme
polarization we are now witnessing, especially on the political right,
has consequences that threaten to undermine democracy itself. These
include declining trust in institutions; scorn for facts; legislative
dysfunction; erosion of democratic norms; and, in the worst case,
real-world violence.

All of this cannot be attributed to the rise of Silicon Valley, of
course. Polarization began growing in the U.S. decades before Facebook,
Twitter, and YouTube appeared. Other factors---including the realignment
of political party membership, the rise of hyper-partisan radio and
cable TV outlets, and increased racial animus during Donald Trump's
uniquely divisive presidency---have contributed to the problem.

But that doesn't exonerate the tech platforms, as Facebook would have us
believe. One study published in March 2020 described an experiment in
which subjects stopped using Facebook for a month and then were surveyed
on their views. [Staying off the platform "significantly reduced
polarization of views on policy issues,]{.underline}" researchers found,
although it didn't diminish divisiveness based strictly on party
identity. "[That's consistent with the view that people are seeing
political content on social media that does tend to make them more
upset, more angry at the other side \[]{.underline}and more likely\] to
[have stronger views on specific issues]{.underline}," Matthew Gentzkow,
a Stanford economist and co-author of the study, told us in an
interview.

Facebook and others have pointed to other research to raise questions
about the relationship between social media and polarization. A 2017
study found that from 1996 to 2016, polarization rose most sharply among
Americans aged 65 and older---the demographic least likely to use social
media. A 2020 paper compared rising polarization levels in the U.S. over
four decades to those in eight other developed democracies. The other
countries experienced smaller increases in divisiveness or saw
polarization decrease. These variations by country suggest that, over
the long term, factors other than social media have driven polarization
in America

But notice that both the age-group and inter-country comparisons spanned
decades, including extended stretches of time before the emergence of
social media. More recent snapshots of the U.S. are thus more relevant.
A paper published in March, based on a [study of more than]{.underline}
[17,000 Americans]{.underline}, [found that Facebook's content-ranking
algorithm may limit users' exposure to news outlets offering viewpoints
contrary to their own]{.underline}---and thereby [increase
polarization.]{.underline}

MAXIMIZING ONLINE ENGAGEMENT LEADS TO INCREASED POLARIZATION

The [fundamental design of platform algorithms helps explain why they
amplify divisive content.]{.underline} "[Social media technology employs
popularity-based algorithms that tailor content to maximize user
engagement,"]{.underline} the co-authors of the Science paper wrote.
[Maximizing engagement increases polarization, especially within
networks of like-minded users.]{.underline} This is "in [part because of
the contagious power of content that elicits sectarian fear or
indignation]{.underline}," the researchers said.

As we wrote in our report, "[social media companies]{.underline} do not
seek to [boost user engagement]{.underline} because they want to
intensify polarization. They do so [because the amount of time users
spend on a platform liking, sharing, and retweeting is also the amount
of time they spend looking at the paid advertising that makes the major
platforms so lucrative]{.underline}."

### Alt Cause\-\--Social Media 

#### Tech corporations like Facebook exacerbate partisan divisions and threaten democracy---it's an alt cause

Paul **Barrett et al 2021**, Paul M. Barrett is an assistant managing
editor and senior writer at Bloomberg Businessweek.; Justin Hendrix is
CEO and Editor of Tech Policy Press, a new nonprofit media venture
concerned with the intersection of technology and democracy. Previously,
he was Executive Director of NYC Media Lab; Grant Sims; Septemer 2021,
"How tech platforms fuel U.S. political polarization and what government
can do about it",
<https://www.brookings.edu/blog/techtank/2021/09/27/how-tech-platforms-fuel-u-s-political-polarization-and-what-government-can-do-about-it/>
//SK

As both members of Congress and federal law enforcement agencies
investigate the origins and execution of the January 6 insurrection at
the U.S. Capitol, the role social media played in the mayhem is emerging
as a crucial issue.

The House Select Committee probing the mob attack has asked a wide range
of social media and telecommunications companies to preserve records
related to several hundred people, including members of Congress, who
could be relevant to the investigation. Beyond these specific requests,
the Committee has signaled a broader interest in how false claims about
the 2020 election spread on platforms like Facebook and Twitter,
including how algorithms might contribute to the promotion of
disinformation and extremism. Meanwhile, federal prosecutors pursuing
more than 600 criminal cases are relying on evidence gathered from
social media accounts used to organize the attempt by Trump supporters
to stop Congress from certifying President Joe Biden's victory.

A report we recently published through the Center for Business and Human
Rights at New York University's Stern School of Business sheds light on
[the relationship between tech platforms and the kind of extreme
polarization that can lead to the erosion of democratic values and
partisan violence]{.underline}. While Facebook, the largest social media
platform, has gone out of its way to deny that it contributes to extreme
divisiveness[, a growing body of social science research, as well as
Facebook's own actions and leaked documents, indicate that an important
relationship exists.]{.underline}

Our central conclusion, based on a review of more than 50 social science
studies and interviews with more than 40 academics, policy experts,
activists, and current and former industry people, is that [platforms
like Facebook, YouTube, and Twitter likely are not the root causes of
political polarization, but they do exacerbate it.]{.underline}
Clarifying this point is important for two reasons. First, [Facebook's
disavowals, in congressional testimony and other public statements, may
have clouded the issue in the minds of lawmakers and the
public]{.underline}. Second, as the country simultaneously tries to make
sense of what happened on January 6 and turns its attention to elections
in 2022, 2024, and beyond, [understanding the harmful role popular tech
platforms can play in U.S. politics should be an urgent
priority]{.underline}.

SOCIAL MEDIA CONTRIBUTES TO PARTISAN ANIMOSITY

Facebook's Mark Zuckerberg has on multiple occasions dismissed
suggestions that his company stokes divisiveness. "Some people say that
the problem is that social networks are polarizing us, but that's not at
all clear from the evidence or research," he testified before a U.S.
House of Representatives subcommittee in March 2021, instead pointing to
"a political and media environment that drives Americans apart." A few
days later, Nick Clegg, Facebook's vice president for global affairs and
communication, argued that "what evidence there is simply does not
support the idea that social media, or the filter bubbles it supposedly
creates, are the unambiguous driver of polarization that many assert."

Contrary to Facebook's contentions, however, [a range of experts have
concluded that the use of social media contributes to partisan animosity
in the U.S]{.underline}. In an article published in October 2020 in the
journal Science, a group of 15 researchers summarized the scholarly
consensus this way: "[In recent years, social media companies like
Facebook and Twitter have played an influential role in political
discourse, intensifying political sectarianism]{.underline}." In August
2021, a separate quintet of researchers summed up their review of the
empirical evidence in an article in the journal Trends in Cognitive
Sciences: "[Although social media is unlikely to be the main driver of
polarization, they concluded, "we posit that it is often a key
facilitator."]{.underline}

PARTISANSHIP IS COMPLICATED, BUT PLATFORMS DO NOT FULLY ESCAPE
RESPONSIBILITY

Polarization is a complicated phenomenon. Some divisiveness is natural
in a democracy. In the U.S., struggles for social and racial justice
have led to backlash and partisan animosity. [But the extreme
polarization we are now witnessing, especially on the political right,
has consequences that threaten to undermine democracy itself. These
include declining trust in institutions; scorn for facts; legislative
dysfunction; erosion of democratic norms; and, in the worst case,
real-world violence.]{.underline}

All of this cannot be attributed to the rise of Silicon Valley, of
course. Polarization began growing in the U.S. decades before Facebook,
Twitter, and YouTube appeared. Other factors---including the realignment
of political party membership, the rise of hyper-partisan radio and
cable TV outlets, and increased racial animus during Donald Trump's
uniquely divisive presidency---have contributed to the problem.

[But that doesn't exonerate the tech platforms, as Facebook would have
us believe.]{.underline} One study published in March 2020 described an
experiment in which subjects stopped using Facebook for a month and then
were surveyed on their views. [Staying off the platform "significantly
reduced polarization of views on policy issues," researchers found,
although it didn't diminish divisiveness based strictly on party
identity]{.underline}. "That's consistent with the view that people are
seeing political content on social media that does tend to make them
more upset, more angry at the other side \[and more likely\] to have
stronger views on specific issues," Matthew Gentzkow, a Stanford
economist and co-author of the study, told us in an interview.

#### Social media inevitably collapses the info ecosystem 

Serena **Giusti 21,** Head of the Programme on Eastern Europe and Russia
at Sant'Anna School of Advanced Studies (Pisa) and Senior Associate
Research Fellow at the Institute for International Studies. (ISPI)
"Multilateralism, Global Governance and the Challenges of
Disinformation," Cyber Insights Magazine, October 1 2021,
<https://www.cyber-insights.org/multilateralism-global-governance-and-the-challenges-of-disinformation>

**[[Social media]{.underline}]{.mark}** (including messaging platforms)
are [becoming more and more relevant for contemporary
societies:]{.underline} they **[[constitute]{.mark}]{.underline}** the
**[main sources of information]{.underline}** for an increasing number
of citizens. They [have also become **[vital communication
tools]{.mark}** [for]{.mark} governments, diplomatic personnel,
international organisations (IOs) and [all actors]{.mark}, formal and
informal, taking part **[in the international
system]{.mark}**]{.underline}**[.]{.mark}**

Social media can be used by states as **[[tools to project
power]{.underline}]{.mark}**, by spreading [manipulated information or
fake news or to libel individuals or institutions working in crucial
sectors. Both **authoritarian** and democratic]{.underline} leaders tend
to [deploy them]{.underline} quite often in order [to reach a wide range
of political goals: inter alia, to delegitimise disruptive journalists
and media, [to **discredit political opponents**]{.mark} **or leaders of
foreign states**, to orient electoral choices in other states or even to
contribute to the justification of especially grave decisions, such as
**[foreign interventions]{.mark}** motivated by alleged violations of
international law by third countries' governments]{.underline}. In
particular, the use of [disinformation by state and non-state actors to
**interfere in** domestic **affairs of other countries**]{.underline}
(e.g., before and/or during political elections or referenda) is
**[[endangering]{.mark}]{.underline}** not only **[the very concept of
[sovereignty]{.mark}]{.underline}**, but also the **[independence and
[security of states]{.mark}]{.underline}** and the functioning of
democratic processes, [with **[serious implications]{.mark}**
**[for]{.mark}** relations among states and **[multilat]{.mark}eralism
a**]{.underline}s a consequence. [Whereas cases of weaponization of
disinformation regard especially autocratic regimes, **democracies are
not exempted**, as the attempts by some American Alt-Right groups to
influence the 2017 French President elections prove.]{.underline}

[The **frequent use** of disinformation **[challenges]{.mark} the
reciprocal trust among** actors who participate in the **multilateral
[governance]{.mark} of the international system** and it
**[makes]{.mark} enduring and effective [cooperation]{.mark}** on global
challenges **[much more difficult]{.mark} to achieve.**]{.underline}

**[Effective communication is key to multilateral
[governance]{.mark}]{.underline}**[,]{.mark} and it is [especially
useful to **envisage and implement actions** which [r**equire** the
**constructive coop**]{.mark}**eratio**n of governments and third
parties]{.underline}, involving not [only governments but also civil
society actors]{.underline} -- such as in the [case of actions needed to
realise the goals defined in the 2030 Sustainable Development
Agenda]{.underline}, the actions defined in the Global Compact for Safe,
Orderly and Regular Migration, and the measures [to contrast the
Covid-19 pandemic (]{.underline}in primis realising far-reaching
vaccination campaigns and guaranteeing people's safe mobility). As
underlined by Mark Zuckerberg, social media are a sort of a "town
square": if you want to be part of the conversation, you have no choice
but to be there; otherwise, you are a digital outcast[. However, the
**use of s[ocial media can cause]{.mark}** a **[polarisation]{.mark} of
opinions and [sectarianism]{.mark}** and harbour conflictual
relationships **[among]{.mark} i**ndividuals, groups, **political
[parties, and state]{.mark}**]{.underline}**[s]{.mark}**. Moreover,
since our activities happen mostly in-between the digital and the
physical worlds, as effectively expressed by Luciano Floridi's
well-known concept of "onlife", spill-over effects are more and more
frequent and conflicts can move offline from social media and have an
impact on violent conflicts. Therefore[, the **spread of malicious [fake
news]{.mark}** and disinformation **can** be a tool of hybrid war,
**[bring]{.mark}**ing about **long-[lasting]{.mark} negative
[implications for multilat]{.mark}eralism**]{.underline}**.**

The Covid-19 pandemic has shown how the spread of disinformation on
sensitive issues -- a phenomenon known as "infodemic", conceptualised by
the WHO in 2020 -- can powerfully influence people's behaviour and
affect the impact of countermeasures deployed by governments.
Disinformation can even speed up the epidemic by influencing and
fragmenting the social response to the disease; moreover, people might
find it difficult to discern which information sources are trustworthy,
especially if the scientific community does not reach a unanimous
position and scientists provide different explanations and solutions for
a given problem. Also, while the production of accurate and detailed
information can be expensive and time-consuming, fake news can cheaply
and quickly fill the gap and satisfy the public's demand for
information, at least for a broad target. The "infodemic" highlights the
need for evidence-based policymaking with a high quality scientific
advisory system. Without knowledge, research, reliable and accessible
data, and effective and well-timed coordination among the key actors
responsible for managing health emergency, leaders run the risk of
enacting very fragmented and even controversial political responses, by
relying on a rooted policy style that is overly influenced by the rules
and structures of civil service and the political systems they operate
in. In order to face this kind of threats, multilateral cooperation is
paramount, and it constitutes a precious resource to bypass and fix the
rigidity and inefficiency of national systems. As a matter of fact,
achieving multilateral cooperation requires smooth, open and continuous
communication. To obtain that, governments and international
organisations need to tackle disinformation, detecting and contrasting
the attempts at hampering multilateralism, focusing on those conducted
via social media, which are especially pervasive and produce
long-lasting effects.

The challenges mentioned above show the urgency of dealing with
regulating social media, assigning the responsibility of content control
to social media companies or to ad hoc nominated expert panels, engaging
states and regional organisations such as the EU in the creation of an
international regulation, policing with algorithms and artificial
intelligence (AI), and investing in specific digital education
programmes. Moreover, permanent roundtable discussions with social media
corporations ought to be established, in order to contribute to the
adoption of standardised rules concerning the detection and contrast to
fake news and disinformation for all social media platforms. It would
also help to construct a collaborative relationship with social media
for the diffusion of agreed and reliable information concerning critical
issues, such as transnational health emergencies, and propose viable
measures for sanctioning the creators and diffusers of harmful fake
news.

[Finally, in order to contribute to the fight against malicious
disinformation, formal and informal institutions **working on
i**nternational **multilat**eßral governance **[need to]{.mark} improve
their communication strategies**, working towards **increasing the
clarity and accurac**y of the information they produce, **improving
their reputation** as authoritative sources of information and
**[reduc]{.mark}ing the [public]{.mark}'s [exposure to rumours]{.mark}
on fundamental issu**e**s,** which tend to circulate in order to fill
information voids, **[especially amidst a crisis.]{.mark}**]{.underline}

### Alt Cause\-\--Politicians 

#### Elected officials are an alt cause---spread highly partisan claims on mainstream media--- Trump proves

Brendan **Nyhan 2019**, Professor of Public Policy, University of
Michigan, February 2019, "Why Fears of Fake News Are Overhyped",
<https://gen.medium.com/why-fears-of-fake-news-are-overhyped-2ed9ca0a52c9//>
SK

We must also recognize that fake news entrepreneurs aren't the only
people trying to meet the demand for this kind of content. [The most
worrisome misinformation in U.S. politics remains the old-fashioned
kind: false and misleading statements made by elected officials who
dominate news coverage and wield the powers of government. As 2016
illustrated, the costs of making unsupported claims are low in highly
partisan contexts, which limits the incentive for politicians to avoid
them.]{.underline} Reading a fact-check of Trump's convention speech,
for instance, reduced false beliefs that crime was increasing in the
long term but did not affect his support.

[Trump has gone on to make more than 8,000 false claims during his first
two years in office, many of which are amplified in cable news chyrons
or in credulous online news headlines.]{.underline} As a result, a
sizable minority of Americans still believes some of his most frequently
repeated false claims. [These beliefs persist despite unprecedented
fact-checking efforts, which struggle to overcome unprecedented levels
of polarization in media trust.]{.underline} Even more corrosively,
Trump's supporters are increasingly rationalizing those falsehoods.
[Belief in the importance of presidential candidates being honest has
declined from 71 percent among Republicans in 2007 to just 49 percent
today, threatening the previously uncontested norm that the president
should be expected to say things that are true, or at least not
obviously false.]{.underline}

Ultimately, fake news helped alert us to the threat, but [it is Trump
who has most effectively weaponized partisan misinformation in our
politics]{.underline}. [Understanding how to prevent our leaders from
exploiting this vulnerability further must therefore be a top democratic
priority.]{.underline}

## Offense

### IL\-\--Credibility Turn 

#### Forewarnings of disinformation reduces the credibility of true information

Melanie **Freeze et al. 2020**, PhD from Duke University, Visiting
Assistant Professor at the Department of Political Science, Carleton
College; Mary Baumgartner, Peter Bruno, Jacob R. Gunderson, Joshua Olin,
Morgan Quinn Ross, and Justine Szafran all have BAs from Carleton
College; February 2020, "Fake Claims of Fake News: Political
Misinformation, Warnings, and the Tainted Truth Effect",
<https://link.springer.com/epdf/10.1007/s11109-020-09597-3?author_access_token=jlne4X9bmNXeiro8bIL5v_e4RwlQNchNByi7wbcMAY5VsgsSHPhSfVqOPQBCG7ca18LkrBHJQMR182ZUZZWCaOC9jKU2ihU0BF4UKzY1UjdbtLCSymJYBmvsywO67tUufYcsWoBQ8Kw_LIb3ZAnEJw%3D%3D>
//SK

A subset of research on the misinformation effect explores whether the
negative effects of misinformation on memory can be reversed, or at
least minimized (e.g., Blank and Launay 2014; Chambers and Zaragoza
2001; Christiaansen and Ochalek 1983; Eakin et al. 2003; Echterhoff et
al. 2005; Ecker et al. 2010; Wright 1993). For example, one of the
earliest studies on the effects of misinformation warnings conducted by
Dodd and Bradshaw (1980) found identifying the source of the
misinformation as biased dramatically reduced the effect of misleading
information on eyewitness memory. In the field of political science, a
related body of literature also scrutinizes the causes, implications,
and difficulty of countering political misinformation for topics,
including the 2010 health care reform (Berinsky 2015; Nyhan 2010);
climate change (van der Linden et al. 2017); campaign advertisements and
political candidates (Amazeen et al. 2018; Cappella and Jamieson 1994;
Pfau and Louden 1994; Thorson 2016; Wintersieck et al. 2018); political
news (Clayton et al. 2019); and governmental policies, actions, and
politically relevant data (Pennycook et al. 2018; Weeks 2015).Footnote7
Under some conditions, warnings of misinformation can help individuals
counter the effects of misinformation on attitudes and memory, but the
corrections are often only partial, with long-lasting negative effects
on trust (Cook and Lewandowsky 2011; Huang 2015; Lewandowsky et al.
2012; Nyhan and Reifler 2012). [Warnings may even produce a boomerang or
backfire effect and lead to misinformation becoming more deeply
entrenched in memory when corrections conflict with personal worldview
or ideology]{.underline} (Nyhan and Reifler 2010). In a meta-analysis of
25 studies on retrospective warnings and post-event misinformation,
Blank and Launay (2014) found [retrospective warnings were only somewhat
effective, on average reducing the post-event misinformation effect by
half.]{.underline}

In addition to imperfectly counteracting misperceptions, misinformation
warnings can produce other, often unintended, consequences. Although few
in number, some studies outside of political science have investigated
how [misinformation warnings can extend beyond the intended target of
misinformation and negatively influence surrounding information and
memories]{.underline}. For example, Greene et al. (1982) [discovered
participants who were warned that post-event information came from an
untrustworthy source were less likely to recognize events that were
correctly described in the post-event description, compared to a no
warning condition.]{.underline} Similarly, Meade and Roediger (2002)
found [warnings of an unreliable co-witness reduced recall of correct
items reported by the co-witness.]{.underline}

Green et al. (1982) and Meade and Roediger (2002) noted the negative
effects of warnings on memory, but these findings were not the primary
focus of their research. Drawing on the research of Greene et al. (1982)
and Meade and Roediger (2002), Echterhoff et al. (2007) [deliberately
began to study misinformation warnings' potentially adverse influence on
correct memories, which they defined as the tainted truth
effect.]{.underline} [They found that when warned about misinformation,
participants were less likely to recognize events that were accurately
described in a post-event description, especially when the items were
somewhat peripheral or difficult to remember.]{.underline}

In their investigation of the tainted truth effect, Echterhoff et al.
(2007) considered various proposed mechanisms that could drive the
misinformation and tainted truth effects.Footnote8 Echterhoff et al.
argued that under certain circumstances, [misinformation warnings will
reduce the ability to remember original events because warned
individuals are more likely to monitor information from a source that
has been discredited by a warning.]{.underline} Increased skepticism
leads any information that is associated with the untrustworthy source
to be tainted and rejected in retrospect, regardless of whether it is
true or false. We also propose that retrospective warnings fundamentally
alter how people reconstruct memory. In the absence of misinformation
warnings, individuals should naturally rely more on post-event
descriptions of an event as they are more recent and accessible (Wyler
and Oswald 2016; Zaller 1992). [However, when these post-event
descriptions become tainted by misinformation warnings, individuals will
feel more uncertainty and engage in a memory reconstruction process that
discounts and rejects more recent data that comes from the post-event
description, including both misinformation and accurate
information.]{.underline}

Only a few studies on the tainted truth effect emerged after the initial
formal consideration of the phenomenon by Echterhoff et al. (2007). In a
series of related experiments, Szpitalak and Polczyk (2010, 2011, 2012)
drew on Polish high school and university student subject pools to
replicate and test the misinformation and the tainted truth effects in
the contexts of a radio debate on education reform and a historical
lecture on Christopher Columbus. Clayton et al. (2019) also recently
identified the need for further research on the tainted truth effect in
the area of political misinformation warnings. While the tainted truth
effect was not the central hypothesis motivating their research, Clayton
et al. (2019) found [general warnings shown to participants before they
read a set of headlines reduced the credibility of both truthful and
untruthful headlines.]{.underline}

### IL\-\--Cooption Turn 

#### Greenlights authoritarian [crackdowns]{.underline}\-\--even if their concerns are [true]{.underline} their rhetoric gets [coopted]{.underline}

Gabrielle **Lim 20**, researcher at Harvard Kennedy School's Shorenstein
Center and a fellow with Citizen Lab. "The Risks of Exaggerating Foreign
Influence Operations and Disinformation," Centre for International
Governance Innovation (CGI),
<https://www.cigionline.org/articles/risks-exaggerating-foreign-influence-operations-and-disinformation/>
//chico

First, the widespread use of the [term "fake news" combined with
concerns over national security]{.underline} (although often sincere and
well-meaning) have [given illiberal and authoritarian-leaning
governments]{.underline} around the world [top cover to enact
a]{.underline} range of [censorship-enabling measures]{.underline} that
are then [used to crack down on dissent]{.underline}, [target political
opponents and instill]{.underline} a [culture of
self-censorship]{.underline}. In the Philippines --- where President
Rodrigo [Duterte continues to]{.underline} [prosecute a "war on
drugs"]{.underline} that has led to the [deaths of
thousands]{.underline} --- [penalties for spreading]{.underline} [false
and alarming info]{.underline}rmation [were included in]{.underline} a
special [measures bill to combat COVID-19]{.underline}. Critics of the
bill warn that it will be [selectively used to punish political
opponents and deter dissent.]{.underline} Last year,
[Singapore]{.underline} --- which has continually [ranked poorly for
press freedom]{.underline} --- also [passed a law targeting "fake news"
and false information]{.underline}. Citing examples of foreign
interference in the United States and the United Kingdom, Singapore
[justified the bill on the grounds of national security.]{.underline}
Borrowing a [common refrain from the West]{.underline}, the
[gov]{.underline}ernment [stated that falsehoods]{.underline}
"[weaponised, to attack the infrastructure of fact, destroy trust and
attack societie]{.underline}s." [Now Nigeria]{.underline}, again [in the
name of national security]{.underline}, [is mulling its own bill
targeting false info]{.underline}rmation, which has [widely been mocked
as a copy-paste]{.underline} of Singapore's law

### IL\-\--free press turn 

#### Its New Age [McCarthyism]{.underline}\-\--enforcement is [inconsistent]{.underline}. Cracks down on [free press]{.underline} AND increases [xenophobia]{.underline}\-\--turns case. 

Gabrielle **Lim 20**, researcher at Harvard Kennedy School's Shorenstein
Center and a fellow with Citizen Lab. "The Risks of Exaggerating Foreign
Influence Operations and Disinformation," Centre for International
Governance Innovation (CGI),
<https://www.cigionline.org/articles/risks-exaggerating-foreign-influence-operations-and-disinformation/>
//chico

Second, the [fear of foreign speech]{.underline} could [exacerbate
ongoing tensions between states]{.underline} in a way that will likely
hurt civil society and press freedom. [Although influence
op]{.underline}eration[s]{.underline} [have little]{.underline} (if any)
actual [impact]{.underline} on a state's national security,
[governments]{.underline} may [use the fear of foreign speech to
expel]{.underline}, [control and surveil foreign journalists and civil
society]{.underline}. Take [China and]{.underline} the
[U]{.underline}nited [S]{.underline}tates, for example. [Both accuse one
another of interfering in each other's]{.underline} [domestic
affairs]{.underline}, [citing influence
op]{.underline}eration[s]{.underline} [and collusion that may be
detrimental]{.underline} ([although rarely articulated]{.underline} in
specifics or evidence). As such, [retaliatory measures]{.underline} have
been [carried out by both]{.underline} states [through the expulsion of
journalists]{.underline} and by [forcing media workers to register
personal information with government officials]{.underline}. Hua
Chunying, a spokeswoman for the Chinese foreign ministry, defended the
expulsion of journalists from The New York Times, The Wall Street
Journal and The Washington Post, tweeting: "We reject ideological bias
against China, reject fake news made in the name of press freedom,
reject breaches of ethics in journalism." And as Harvard Law School's
Evelyn Douek shows in her chapter for the forthcoming book, "Combating
Election Interference: When Foreign Powers Target Democracies," [the way
social media companies and governments are moderating foreign content
amounts to a "free speech blind spot,"]{.underline} due to their
seemingly [ad hoc and inconsistent]{.underline}
[enforcement]{.underline}. The [ongoing rhetoric of fear surrounding
foreign influence]{.underline} operations [and espionage]{.underline} is
[now expanding to include foreign students and businesses]{.underline}.
In addition to [curtailing the flow of info]{.underline}rmation and
[intellectual collab]{.underline}oration, [such actions]{.underline} may
also [contribute to increasing xenophobia.]{.underline}

### IL\-\--trade off turn

#### Emphasis on "bad actors" [trades off]{.underline} with addressing the material [conditions]{.underline} that cause people to be susceptible to disinfo in the [first place]{.underline}. The AFF turns into never-ending ["whack-a-mole."]{.underline} 

Gabrielle **Lim 20**, researcher at Harvard Kennedy School's Shorenstein
Center and a fellow with Citizen Lab. "The Risks of Exaggerating Foreign
Influence Operations and Disinformation," Centre for International
Governance Innovation (CGI),
<https://www.cigionline.org/articles/risks-exaggerating-foreign-influence-operations-and-disinformation/>
//chico

Third, an [overemphasis on "bad actors" and]{.underline} their [supply
of disinfo]{.underline}rmation [diverts our attention from the material
problems that drive our demand for and receptivity to dubious content of
suspicious origin.]{.underline} In a commentary for the Harvard Kennedy
School's Misinformation Review, Alexei Abrahams and I argue that thus
far [the focus of the West's countermeasures]{.underline} in the fight
against misinformation and disinformation [has relied on repressive
strategies]{.underline} --- [root out the networks, shut down the
accounts and remove the content.]{.underline} [However,]{.underline}
this [strategy is]{.underline}, as many have pointed out already, a
[never-ending "game of whack-a-mole"]{.underline} that ([at
best]{.underline}) [provides short-term]{.underline} tactical
[gains.]{.underline} These palliative measures must be coupled with
long-term solutions that take aim at the reasons why people flock to
fringe websites and dubious accounts for their news. It is not that we
want to be lied to, but rather that our trust in the institutions and
authorities to which we delegate our well-being and future has eroded.
As such, redressive strategies should also be explored to regain and
restore trust and legitimacy in our institutions, politicians and
governing bodies. And, where possible, domestic policy should be
directed at making democratic participation easier. "[Bad actors" will
always be around and]{.underline} try to [mess with information
systems]{.underline}, [but we can choose]{.underline} [to make voting
easier]{.underline}, [prevent gerrymandering]{.underline}, [and amend or
repeal laws]{.underline} that [lead to voter suppression.]{.underline}

"Bad actors" will always be around and try to mess with information
systems, but we can choose to make voting easier, prevent
gerrymandering, and amend or repeal laws that lead to voter suppression.

[Mass-targeted covert influence op]{.underline}eration[s and
disinformation campaigns are real]{.underline}. Analysis from studies
show that they promote narratives that aim to provoke outrage,
capitalize on social cleavages and, in some cases, push narratives in
the interest of certain countries. However, [evidence of activity is not
evidence of impact]{.underline}. To be sure, we should be aware of such
operations, bringing them to light and, when appropriate, removing them.
However[, if the free flow of ideas]{.underline}, [freedom of expression
and a better quality of democratic participation]{.underline} [are the
ultimate goals]{.underline}, [relying on detection and deletion is not
enough]{.underline}, and, as outlined above, [the exaggeration of the
threat of foreign influence op]{.underline}eration[s]{.underline} [may
do more harm than good.]{.underline} Instead, we should invest in
solutions that shore up trust and increase political participation,
civil discourse and pluralism.

# Add-Ons

## DOD Innovation

### AT: DoD Innovation Add-On\-\--2NC

#### [Structural]{.underline} issues prevent DoD innovation

Brad **Williams 21**, reporter for Breaking Defense covering cyber,
networks, and emerging tech, 7/29/2021, \"To Transform Tech, DoD Must
Stop Being An 'Innovation Tourist:' Report,\" Breaking Defense,
https://breakingdefense.com/2021/07/to-transform-tech-dod-should-stop-being-an-innovation-tourist-report/

WASHINGTON: A new report urges the Pentagon to stop acting like an
"innovation tourist... visiting new shops, spending some money, and
moving on to the next destination" if it wants to truly achieve "a bona
fide strategy for bringing emerging technologies into the department."

The report, Ending Innovation Tourism: Rethinking the U.S. Military's
Approach to Emerging Technology Adoption, is authored by Melissa Flagg
and Jack Corrigan of Georgetown University's Center for Security and
Emerging Technology.

Noting [it's "unlikely]{.underline} that [any significant progress
toward overhauling the DoD acquisition process will be made in the near
future]{.underline}," the report lays out several recommendations DoD
could take today to accelerate the types of innovations needed to remain
competitive against near-peer adversaries.

The authors note that [the challenges around DoD innovation --- or lack
thereof --- are many and multifaceted, but the crux]{.underline} of the
matter [is "under the DoD's current organizational structure, defense
innovation is disconnected from defense procurement]{.underline}."

The report then provides a brief history, spanning from the end of World
War II to present, of how [DoD's acquisition bureaucracy]{.underline}
came into being, and how an acquisition structure that consistently
produced innovations such as the internet and global position systems
[has, for decades, become more of a hindrance than a help]{.underline}.

The report notes that DoD has made some positive strides to adapt to an
environment in which the private tech sector has displaced it as the
driver of innovation. For instance, DoD has created innovation offices,
such as those run by the Defense Innovation Unit --- the Pentagon's
office originally established for outreach to Silicon Valley companies
--- as well as AFWERX, NavalX, and the Army Applications Lab. While
these [offices]{.underline} have produced some "one-off tools" and
"bolt-ons" to existing military tech, they [have "impacted only small
slivers" of "the major platforms and systems that account for the vast
majority of military warfighting capabilities,"]{.underline} the report
observes.

[Why?]{.underline} Well, just like everything defense acquisition
related, [the answer is complex, with factors ranging from Pentagon
procurement requirements to business models]{.underline}. But [a primary
reason]{.underline} among many, the authors note, [is that DoD's
innovation efforts are tied to the research & development part of the
budget and not to specific procurement programs]{.underline} ---
especially so-called "programs of record" for the largest DoD projects.

#### No tech innovation impact\-\--China's too far behind

**Gilli & Gilli 19** Andrea Gilli, Senior Researcher in Military Affairs
at the NATO Defense College in Rome, works at the Center for
International Security and Cooperation, PhD in Political Science from
the European University Institute, MSc in International Relations from
the London School of Economics, & Mauro Gilli, a Senior Researcher in
Military Technology and International Security, PhD in Political Science
from Northwestern University, MA in International Studies from Johns
Hopkins University. \[Why China Has Not Caught Up Yet:
Military-Technological Superiority and the Limits of Imitation, Reverse
Engineering, and Cyber Espionage, 43(3), 141--189\]

[Can adversaries of the U]{.underline}nited [S]{.underline}tates [easily
imitate its most advanced weapon systems and]{.underline} thus [erode
its military-technological superiority? Do reverse
engineering]{.underline}, industrial espionage, [and]{.underline}, in
particular, cyber [espionage]{.underline} facilitate and [accelerate
this process?]{.underline} China\'s decades-long economic boom, military
modernization program, massive reliance on cyber espionage, and
assertive foreign policy have made these questions increasingly salient.
Yet, almost everything known about this topic draws from the past. As we
explain in this article, the conclusions that [the existing
[lit]{.mark}erature]{.underline} has reached by studying prior eras
[[have no applicability to]{.mark} the current [day]{.mark}. Scholarship
in [i]{.mark}]{.underline}nternational [[r]{.underline}]{.mark}elations
theory generally [[assumes]{.underline}]{.mark} that rising [[states
benefit from]{.mark} the \"advantage of
[backwardness]{.mark},\"]{.underline} as described by \[End Page 141\]
Alexander Gerschenkron.1 [By free riding on the research and technology
of the most advanced countries]{.underline}, less developed states can
allegedly close the military-technological gap with their rivals
relatively easily and quickly.2 More recent works maintain that
globalization, the emergence of dual-use components, and advances in
communications (including the opportunity for cyber espionage) have
facilitated this process.3 [[This]{.mark} literature [is built on
shaky]{.mark} theoretical [foundations]{.mark}, [and]{.mark} its claims
[lack]{.mark} empirical [support]{.mark}]{.underline}. The
[international relations [lit]{.mark}erature largely [ignores]{.mark}
one of [the most important change]{.mark}s]{.underline} to have occurred
in the realm of weapons development since the second industrial
revolution (1870--1914): [the exponential [increase in]{.mark} the
[complexity]{.mark} of military technology]{.underline}. We argue that
[[this]{.underline}]{.mark} increase in complexity has promoted a change
in the system of production that has [[made]{.underline}]{.mark} the
[[imitation]{.underline}]{.mark} and replication of the performance [of
state-of-the-art weapon systems [harder]{.mark}---so much so as [to
offset]{.mark}]{.underline} the diffusing effects of
[[globalization]{.underline}]{.mark} and advances in communications. On
the one hand, the increase in [[complexity]{.mark} has significantly
[raised the]{.mark} entry [barriers for]{.mark}]{.underline} the
production of [advanced weapon [systems: countries
must]{.mark}]{.underline} now [[possess an extremely advanced]{.mark}
industrial, scientific, and technological [base]{.mark}]{.underline} in
weapons production [[before they can copy]{.mark} foreign military
[tech]{.mark}nology]{.underline}. On the other hand, [the
[knowledge]{.mark}]{.underline} to design, develop, and produce advanced
weapon systems [[is less likely to diffuse, given its]{.mark}
increasingly [tacit]{.mark} and [organizational
nature]{.mark}]{.underline}. As a result, the [advantage of backwardness
has shrunk significantly]{.underline}, and know-how and experience in
the production of advanced weapon systems have become an important
source of power for those who master them. We employ two case studies to
test this argument: Imperial Germany\'s rapid success in closing the
technological gap with the British Dreadnought battleship, despite
significant inhibiting factors; and China\'s struggle to imitate the
U.S. F-22/A Raptor jet fighter, despite several facilitating conditions.
Our research contributes to key theoretical and policy debates. First,
the \[End Page 142\] ability to imitate state-of-the-art military
hardware plays a central role in theories that seek to explain patterns
of internal balancing and the rise and fall of great powers. Yet, the
mainstream international relations literature has not investigated this
process.4 Because imitating military technology was relatively easy in
the past, scholars and policymakers assume that it also is today, as
frequent analogies between Wilhelmine Germany and contemporary China
epitomize.5 In this article, we investigate the conditions under which
the imitation of state-of-the-art weapon systems such as attack
submarines and combat aircraft is more or less likely to succeed.
Second, [[we develop the]{.mark} first systematic theoretical
[explanation of why U.S. superiority]{.mark} in military technology
[remains]{.mark} largely [unrivaled]{.mark}]{.underline} almost thirty
years after the end of the Cold War, despite globalization and the
information and communication technology revolution. Some scholars have
argued that developing modern weapon systems has become dramatically
more demanding, which in turn has made internal balancing against the
United States more difficult.6 This literature, however, cannot explain
why in the age of globalization and instant communications---with cyber
espionage permitting the theft of massive amount of digital data---U.S.
know-how in advanced weapon systems has not already diffused to other
states. Other contributors to the debate on unipolarity have either
pointed to the relative inferiority of Chinese military technology
without providing a theoretical explanation, or they have argued that
developing the military capabilities to challenge the status quo is, in
the long run, a function of political will---an argument that cannot
account for the failure of the Soviet Union to cope with U.S. military
technology from the late 1970s onward.7 We argue that in the transition
from the second industrial \[End Page 143\] revolution to the
information age, the imitation of state-of-the-art military technology
has become more difficult, so much so that today [rising powers or even
peer [competitors cannot]{.mark} easily [copy]{.mark} foreign weapon
[systems]{.mark}]{.underline}.8 [Our findings address]{.underline}
existing [concerns that China\'s]{.underline} use of cyber
[espionage]{.underline} and the increasing globalization of arms
production [will allow Beijing to]{.underline} rapidly [close
the]{.underline} military-technological [gap]{.underline} with the
United States.9

# Solvency 

## Broad

### 1NC\-\--Solvency

#### The AFF [fails]{.underline} and cohesion is [impossible]{.underline}\-\--NATO is [uncoordinated]{.underline} and [says no]{.underline}, the research center [empirically isn't enough]{.underline}, and any military strategies are [pipe dreams]{.underline}.

Rod **Thornton 15**, Senior Lecturer in the Defence Studies Department
of King\'s College London. He previously taught at the University of
Kurdistan Hewler in Erbil, Iraq and in the University of Nottingham\'s
department of Politics and International Relations. "The Changing Nature
of Modern Warfare",
<https://www.tandfonline.com/doi/abs/10.1080/03071847.2015.1079047>
//lenox

[[Russia]{.mark} has shown it can [occupy whole slices of another
state's territory using]{.mark} no more than [info]{.mark}rmation
[war]{.mark}fare]{.underline}, deniability and a few highly disciplined
special forces. The Russian military, supported by a substantial
information warfare infrastructure, has employed the tenets of hybrid
warfare remarkably skillfully. Such activities have, of course, to be
countered by NATO and the EU to ensure Moscow cannot use these tactics
so easily in future. As NATO STRATCOM COE puts it, 'analysis of the
Ukraine conflict suggests that NATO and the EU must adapt to the new
reality where information superiority, as opposed to military power, is
becoming increasingly important'. 70 If today 'the main battlespace is
in the mind', [[it must be considered how Western powers]{.mark} and
institutions [engage]{.mark} in [this arena]{.mark}]{.underline}. The
first option, [[censorship]{.mark} of the Russian media message,
[is]{.mark} widely [dismissed]{.mark}]{.underline} across the EU and in
the US. As John Whittingdale, the UK's current secretary of state for
culture, media and sport, stressed in 2014: 'There is nothing Russia
would like more than to be able to say the West is censoring \[it\]'. 71
The [second [alternative would be for]{.mark} Western powers, through
[NATO, to employ their own counter-information warfare]{.mark}
campaigns]{.underline} to match those of Russia. However, [[this would
be futile]{.underline}]{.mark}, not least [because [NATO's members
are]{.mark}, for the most part, [liberal democracies]{.mark} whose
governments are expected to remain wedded to the truth in the
information they provide]{.underline} to both domestic and international
audiences. Moreover, [they have a free media acting as the fourth estate
to ensure that the truth is told]{.underline}. When it comes to
conducting information-warfare campaigns, [this predilection for the
truth can be something of a handicap]{.underline}, allowing for the
projection of only one narrative amid the welter of counter-narratives
produced by Russian outlets. Furthermore, [[Western efforts to
promote]{.mark} this singular [message have been
underwhelming]{.mark}]{.underline}. As the UK parliamentary Defence
Committee was recently told, 'although the BBC Russian Service was
available, it was only online and was in no way a counterweight to the
propaganda channelled through Russian Television'. 72 [[One outlet
tucked away on a website is no answer to]{.mark} a [Russian]{.mark}
[information-warfare]{.mark} 'blitzkrieg']{.underline}. There is similar
reluctance, for instance, in Washington, to use the Voice of America
radio station in an 'overtly propagandistic role'. Meanwhile, in the
[Baltic States the [attempts to counter]{.mark} Moscow's 'information
war' [are]{.mark} seen as ['uncoordinated and
weak']{.mark}]{.underline}. 73 The basic problem across the board is
that [[liberal democracies have an inherent distaste for producing
anything at the strategic level]{.mark} that resembles propaganda or
could be classed as psychological warfare]{.underline}.74 In fact, [one
of the reasons that the Russians concentrate so much on their
information-warfare output is that they know it cannot be countered
effectively]{.underline}; indeed, they have shown a '[readiness to stoop
to methods the West cannot emulate without sullying
itself']{.underline}.75 As Peter Pomerantsev and Michael Weiss point
out, the Russians are thinking asymmetrically: 'Feeling itself
relatively weak, the Kremlin has systematically learnt to use the
principles of liberal democracies against them'.76 This asymmetry in
willingness and abilities does not, however, mean that no action has
been taken by Western powers. In January 2014, [[NATO set up a Strategic
Communications Centre]{.mark} of Excellence in Riga as a direct
consequence of the Russian information-warfare]{.underline} campaign in
an attempt to counter Russia's significant advantage in this realm. Yet
[[even this body recognises that it is difficult for the West]{.mark}
with its free media '[to compete with the forceful]{.mark}, synchronised
[messaging of the Russian government']{.mark}]{.underline}. 77 For its
part, the EU is discussing sponsoring its own Russian-language channel
as 'The truth is the best weapon the EU has'. 78 However, doubts remain
as to how much impact a single channel can have; indeed, this channel
'needs to find a way to counter Moscow's grip on the Russian-language
airwaves or its target audience will never hear \[the truth\]'. 79
Furthermore, [[it will always be difficult for]{.mark}]{.underline} any
collective of states -- whether [[NATO]{.underline}]{.mark} or the EU --
[[to agree on]{.mark} the [nature]{.mark} and content [of information
campaigns]{.mark}]{.underline}, not least [[due to disagreement over
what]{.mark} exactly [the 'truth' is]{.mark} and how best to present
it]{.underline}. As one Estonian military officer concerned with NATO's
information operations put it, 'if we want to counter Russian
propaganda...we have to unite our lines and speak with the same
voice'.80 However, [[there is no such unity]{.mark} in these
international organisations and thus the idea of [NATO producing its own
'synchronised messaging' remains a pipe-dream]{.mark}]{.underline}.
Therefore [what collectives such as [NATO will always lack]{.mark} is
what makes Moscow's information assault so effective: [a truly
integrated approach]{.mark}]{.underline}. The major threat to Western
interests anywhere in the world is not terrorism, it is the threat posed
by information warfare such as that recently conducted by Russia. It has
achieved clear results and this success can be repeated. As [[NATO finds
it almost impossible to react effectively in a symmetrical
fashion]{.mark} to this threat,]{.underline} it has felt the need to
resort to more traditional means. Yet the responses seen so far are
redolent of 'Maginot Line thinking'--in other words, these are responses
that are better suited to the 'last war'. Unlike the Russian military,
[[NATO is still putting the]{.mark} use of [military force ahead]{.mark}
of information warfare [because]{.mark} -- as an institution--[it knows
no other way]{.mark} of reacting]{.underline}. The US and the UK have,
for instance, decided to send a small number of (non-combat) troops to
Ukraine.81 This, though, is a naive move that does no more than play
into the Kremlin's hands. The message that Moscow can now send out to
those who would support its actions is that while Russia is not sending
any of its own troops over the border into Ukraine (officially, at
least), the US and UK are doing so -- and from thousands of miles away.
Under such circumstances, [it raises questions as to who the aggressor
really is]{.underline}. It is an easy sell for the
information-warfare-savvy Russians. There is talk, too, of NATO
responding both by beefing up the rapid reaction forces currently on
standby to be sent to the Baltic States and by holding more exercises
there.82 This, though, raisesthe question of to what exactly they are
supposed to 'react'. Russian troops, while they might one day mass near
the Baltics to apply psychological pressure, are unlikely to cross any
borders, at least not overtly. Indeed, [Russia's 'new generation of
warfare' is specifically designed to achieve results without the need
for any such crass action]{.underline} that might, in turn, provide an
excuse for NATO (or others) to interfere--thereby paralysing both the
target country and those that might come to its defence. Moreover, [one
aim of the Russian information warfare campaign has always been to 'sow
discord' within NATO]{.underline}. 83 'Russia', as the former head of
Polish special forces, Roman Polko, says, 'is mercilessly using NATO's
weaknesses in order to play its own game'. 84 Of prime importance to
Russia is to prevent the invocation of Article V by avoiding the trigger
for 'an armed attack' on any one NATO state.85 This weakness of Article
V has been recognised -- with the UK parliamentary Defence Committee one
voice among many calling for the word 'armed' to be removed:86 NATO must
resolve the contradiction between the specification in Article 5 that a
response should be to an 'armed attack' and the likelihood on the other
hand of an 'unarmed attack' (such as a cyber attack or another form of
ambiguous warfare). NATO must consider whether the adjective 'armed'
should be removed from the definition of an Article 5 attack. [Most
[NATO states are]{.mark}, however, [unlikely to agree]{.mark} to
this]{.underline} -- again [[showing the weakness of a multinational
body]{.underline}]{.mark}. They will not want to engage militarily with
Russia just because one of their number might be subject to a (plausibly
deniable) 'form of ambiguous warfare', however disruptive. Thus, such
debate over rapid reaction forces and Article V merely facilitates
Moscow's information-warfare campaign. It should be remembered that
NATO's offer of military assistance to the Baltic States is also an
offer to fight a war--a very destructive one -- on their territory. Such
an offer may well have the effect of stoking fear among both Balts and
compatriot Russians, once again providing potential grist to Moscow's
information-warfare mill.

### 2NC\-\--Solvency

#### [Say no]{.underline} and [coordinated responses fail]{.underline}\-\--liberal democracies are [incapable]{.underline} of countering disinformation.

Dr. Rod **Thornton 15**, Senior Lecturer in the Defence Studies
Department of King's College London, Ph.D. from the University of
Birmingham, September 2015, "The Changing Nature of Modern Warfare:
Responding to Russian Information Warfare," *The RUSI Journal*, Vol.
160, No. 4, pp. 40-48, https://doi.org/10.1080/03071847.2015.1079047,
RMax

The first option, censorship of the Russian media message, is widely
dismissed across the EU and in the US. As John Whittingdale, the UK's
current secretary of state for culture, media and sport, stressed in
2014: 'There is nothing Russia would like more than to be able to say
the West is censoring \[it\]'. 71 The second alternative would be for
[Western powers, through NATO, to employ their own counter-information
warfare campaigns to match those of Russia]{.underline}. However, [this
would be futile]{.underline}, not least [because NATO's members
are]{.underline}, for the most part, [liberal democracies
who]{.underline}se governments [are expected to remain wedded to the
truth in the information]{.underline} they provide [to]{.underline} both
domestic and [international audiences]{.underline}. Moreover, [they have
a free media acting as the fourth estate to ensure]{.underline} that
[the truth is told]{.underline}. When it comes to conducting
information-warfare campaigns, this [predilection for the truth can
be]{.underline} something of [a]{.underline} handicap \[[barrier\],
allowing for]{.underline} the projection of [only one
narrative]{.underline} amid the welter of counter-narratives produced by
Russian outlets. Furthermore, [Western efforts]{.underline} to promote
this singular message [have been underwhelming]{.underline}. As the UK
parliamentary Defence Committee was recently told, 'although the BBC
Russian Service was available, it was only online and was in no way a
counterweight to the propaganda channelled through Russian Television'.
72 One outlet tucked away on a website is no answer to a Russian
information-warfare 'blitzkrieg'. There is similar reluctance, for
instance, in Washington, to use the Voice of America radio station in an
'overtly propagandistic role'. Meanwhile, in the Baltic States the
attempts to counter Moscow's 'information war' are seen as
'uncoordinated and weak'. 73 The [basic problem across the board is that
liberal democracies have an]{.underline} [inherent distaste]{.underline}
[for]{.underline} producing [anything at the strategic level that
resembles propaganda or could be]{.underline} classed as [psychological
warfare]{.underline}.74 In fact, [one]{.underline} of the
[reason]{.underline}s that the [Russians concentrate so much
on]{.underline} their [information-warfare]{.underline} output [is that
they know it cannot be countered effectively]{.underline}; indeed, they
have shown a 'readiness to stoop to methods the West cannot emulate
without sullying itself'.

75 As Peter Pomerantsev and Michael Weiss point out, the Russians are
thinking asymmetrically: 'Feeling itself relatively weak, the [Kremlin
has]{.underline} systematically [learnt to use]{.underline} the
[principles of liberal democracies against them']{.underline}.76

This asymmetry in willingness and abilities does not, however, mean that
no action has been taken by Western powers. In January 2014, NATO set
upaStrategic Communications Centre of Excellence in Riga asadirect
consequence of the Russian information-warfare campaign in an attempt to
counter Russia's significant advantage in this realm. Yet even this body
recognises that it is difficult for the West with itsfree media 'to
compete with the forceful, synchronised messaging of the Russian
government'. 77

For its part, the EU is discussing sponsoring its own Russian-language
channel as 'The truth is the best weapon the EU has'. 78 However, doubts
remain as to how much impact a single channel can have; indeed, this
channel 'needs to find a way to counter Moscow's grip on the
Russian-language airwaves or its target audience will never hear \[the
truth\]'. 79

Furthermore, [it will always be difficult for any collective of
states]{.underline} -- whether NATO or the EU -- [to agree on the nature
and content of information campaigns]{.underline}, not least due to
disagreement over what exactly the 'truth' is and how best to present
it. As one Estonian military officer concerned with NATO's information
operations put it, 'if we want to counter Russian propaganda...we have
to unite our lines and speak with the same voice'.80 However, [there is
no such unity in]{.underline} these [international organisations
and]{.underline} thus [the idea of NATO producing its own 'synchronised
messaging' remains a pipe-dream]{.underline}. Therefore what collectives
such as [NATO will always lack is what makes Moscow's information
assault so effective]{.underline}: a truly integrated approach.

#### A silver bullet is [impossible]{.underline}.

Terry **Thompson 20**, lecturer in cyber policy at Johns Hopkins
University and University of Maryland, 2020, "No Silver Bullet: Fighting
Russian Disinformation Requires Multiple Actions," *Georgetown Journal
of International Affairs*, Vol. 21, No. 1, pp. 182-194, https://doi.org/
10.1353/gia.2020.0033, RMax

[[There is no single solution]{.mark}---no [silver bullet---that will
effectively address]{.mark} the [organized, well-funded, and efficient
Russian]{.mark}]{.underline} deception and [[disinfo]{.mark}rmation
operations]{.underline} or their broader campaign of active measures
[directed against US and Europe]{.underline}an elections. Expanding
efforts by governments, think tanks, social media companies, and the
growing social media analysis industry will help to detect, publicize,
and respond to disinformation. The authorities granted by the 2020 NDAA
will go a long way toward addressing the problem of information warfare
directed against the United States. But a much harder challenge will be
overcoming political and cultural polarization and Americans' love of
social media. Absent a comprehensive national effort involving all
elements of government and society, [the [U]{.mark}nited [S]{.mark}tates
[will continue to struggle with foreign
interference]{.mark}]{.underline}. The 2020 election will demonstrate
whether US actions to date are enough to thwart Russian disinformation
in the election process.

### 1NC\-\--Countering Fails 

#### Identifying disinformation [fails.]{.underline} People [don't care]{.underline}, it [induces]{.underline} them to hit share. [BUT]{.underline} it enables [big tech]{.underline} to [obscure]{.underline} its role in polarization 

Joseph **Bernstein 21** is a senior reporter at BuzzFeed News and a 2021
Nieman Fellow. "Bad News: Selling the story of disinformation," Harper's
Magazine,
<https://harpers.org/archive/2021/09/bad-news-selling-the-story-of-disinformation/>
//chico

And to what effect? Last year, Facebook started putting [warning
labels]{.underline} on Trump's [misinformative and disinformative
posts]{.underline}. BuzzFeed News reported in November that the labels
[reduced sharing by only 8 percent]{.underline}. It was almost as if the
[vast majority of people who spread]{.underline} what Trump posted
[didn't care whether a third party had rated]{.underline} his [speech
unreliable.]{.underline} (In fact, one wonders if, to a certain type of
person, [such a warning might even be an inducement]{.underline} to
share.) [Facebook could say that it had listened to
critics]{.underline}, [and]{.underline} what's more, [it could point to
numbers indicating that it had cleaned up the information ecosystem by 8
percent.]{.underline} [Its critics]{.underline}, having been listened
to, [could stand there with their hands in their pockets.]{.underline}

### 2NC\-\--Countering Fails 

#### Information Operations are insulated because of uncertainty and lack of kinetic proof

Tonya **Riley 21** (Tonya, Technology and cybersecurity policy
researcher, 4-30-2021, \"Analysis,\" Washington Post,
https://www.washingtonpost.com/politics/2021/04/30/cybersecurity-202-defense-department-isnt-armed-combat-growing-threat-information-warfare-experts-warn/,
DOA: 6-22-2022//Smarx Ahsan)

Experts will say [the United States can learn from how cyberthreats have
evolved in addressing]{.underline} growing online [information
operations]{.underline}.

[Gerstell]{.underline}, a [senior adviser at]{.underline} the [Center
for Strategic and International Studies]{.underline}, will [warn that
foreign intelligence agencies are taking a page from cyber criminals\'
playbook by operating just far enough under the radar to avoid
repercussions]{.underline}.

"[The same factors that shield those foes in]{.underline} [hacks and
attacks]{.underline} --- [the uncertainty of provable
attribution]{.underline}, [the absence of directly caused actual injury
or physical damage]{.underline} and other factors --- also [will
insulate them]{.underline} [as they inevitably step up their
disinformation campaigns]{.underline}," he says in his written
testimony.

The hearing comes just weeks after the [Biden]{.underline}
administration [sanctioned Russian companies]{.underline} and actors
[for interfering in the U.S. elections as well as a massive cyberattack
that infiltrated nine federal agencies]{.underline}.

The [Biden]{.underline} administration has [responded to the SolarWinds
breach by committing to enhancing the federal cybersecurity
workforce]{.underline}. Jankowicz will suggest a similar approach of
creating a workforce "[of skilled people with a nuanced understanding of
the threat who are capable of applying the full range of tools and
techniques for monitoring, detecting and responding to information
operations]{.underline}."

#### Democracy [fails]{.underline}. [Autocratic regimes]{.underline} are [more effective]{.underline} in information ops.

Jakub **Kalenský 22**, Senior Fellow at the Atlantic Council\'s Digital
Forensic Research Lab, "COVID-19 Disinformation: A Multi-National, Whole
of Society Perspective," *Advanced Science and Technology for Security
Applications*, ISBN 978-3-030-94824-5, Springer Cham, DOI:
<https://doi.org/10.1007/978-3-030-94825-2>, p. 169 (under ch. titled,
"Chapter 7: How to Defend Against Covid Related Disinformation,")
//chico

7.2 What to Avoid When Countering Disinformation

There are several potential [weaknesses when it comes to countering
disinformation]{.underline}. Most of these weaknesses,
[ironically,]{.underline} are related to some of the
[inherent]{.underline} strengths [characteristic of democratic
societies]{.underline}---like the [division of power,]{.underline} or
the [tendency not to abuse state]{.underline} [power]{.underline}---and
might sometimes [lead towards a reluctance to act.]{.underline} It might
be useful to take note of these weakness as lessons learned to
strengthen subsequent efforts.

First, we are dealing with a problem that spans across multiple
traditional domains. This problem is hybrid not only in that
disinformation campaigns lie somewhere in the grey area between war and
peace, but also in that it pertains equally to foreign policy as it does
to internal security, external security, and digital space. However, our
institutions frequently do not reflect this new reality. As such, we
need to avoid the mindset that puts new threats, like disinformation and
other hybrid threats, into just one box, and makes such threats the
responsibility of just one ministry or institution.2

Second, the [tendency to look for silver bullet,]{.underline} or
[catch-all]{.underline}, [solutions]{.underline} might [detract from
more targeted]{.underline}, [effective measures that solve smaller parts
of the problem. There are no magic solutions.]{.underline} Information
aggressors use many different weapons, channels, rhetoric, and
approaches for different audiences (EUvsDisinfo, 2018a). Aggressors have
adopted this strategy because they know that each given channel and
approach will reach and resonate with only a segment of the population,
and that other parts will need something different. We need to copy this
approach when countering disinformation. We need to adopt a mindset that
accepts that many coun- termeasures can solve no more than, for example,
one to five per cent of a given problem, and that we need many different
countermeasures applied simultaneously, ideally in a coordinated manner,
in order to succeed.

Third, [democratic states]{.underline} may often be [significantly more
hesitant to act and defend their interests than]{.underline} their
[autocratic]{.underline} opponents,3 which is also [demonstrated in
their response to disinformation.]{.underline} The [Kremlin's
disinfo]{.underline}rmation [campaigns constantly evolve and adapt to
new conditions]{.underline} and also, therefore, [to]{.underline} some
of our [uncoordi- nated countermeasures]{.underline} (Newman, 2020;
Snegovaya & Watanabe, 2021). [Informa- tion aggressors]{.underline} will
[even experiment]{.underline} with rudimentary measures [that show them
the potential "dead ends]{.underline}", [which provides
them]{.underline} with the [knowledge of how not to conduct their
op]{.underline}eration[s]{.underline}.4 [They collect data
about]{.underline} the [reactions of]{.underline} our
[populations]{.underline} to given information and material, [up to the
point where they]{.underline} [may even know our audiences better than
we know them ourselves]{.underline} (Kalenský, 2019a). [By
contrast]{.underline}, the [countermeasures employed by Western
societies]{.underline} are [significantly more conservative and
risk-averse]{.underline}. [Far too often]{.underline}, [we go
for]{.underline} the [easiest, least controversial measures that have
the highest chance of being accepted without issue]{.underline}, [but
also tend to have the lowest chance of actually solving]{.underline} the
[problem]{.underline} at hand. Countermeasures like "media literacy
programs" or "positive narratives" have been frequently utilized in
policy debates, even dating back to 2014--2015. [Despite all this time
spent]{.underline}, solutions either have yet to show very persuasive
results or, at best, they [have shown that these measures are not
enough.]{.underline}

#### [Private sector]{.underline} won't comply [Facebook proves]{.underline}. 

Terry L. **Thompson 20**, lecturer in cyber policy at the Johns Hopkins
University and University of Maryland, Baltimore County, "No Silver
Bullet: Fighting Russian Disinformation Requires Multiple Actions,"
Georgetown Journal of International Affairs, vol 21, no 1, pp. 182,
<https://muse.jhu.edu/article/766401> //chico

A third reason that US and EU countermeasures against disinformation
have been only partly successful is the [reluctance of social media
companies to identify and block or delete deceptive posts.]{.underline}
Concerned employees at [Facebook]{.underline} were \"[prevented from
making any changes for fear of violating Facebook\'s
\'objectivity,\']{.underline} as well as [alienating conservative
users]{.underline} and legislators.\" (35) In an apparent about-face,
Facebook announced in October 2019 measures designed to prevent foreign
interference in the 2020 elections. (36) These [measures]{.underline}
will [take time]{.underline}, [and]{.underline} their [effectiveness is
uncertain]{.underline}. Other [social media companies are]{.underline}
also [taking action]{.underline}, [but not quickly enough]{.underline},
and experts point out that dealing with disinformation requires a
political response as well. (37) Meanwhile, [Russian disinformation in
social media continues to be a concern]{.underline}. As recently as
February 2020, FBI Director Christopher Wray warned the House Judiciary
Committee about Russia\'s ongoing \"information warfare\" against the
United States. (38)

### 1NC\-\--Circumvention 

#### Cyber troops [circumvent]{.underline} the plan.

David **Sloss 22**, Professor of Law at the Santa Clara University,
internationally renowned scholar who has published three books, 2022, "A
Proposal for Transnational Regulation," *Tyrants on Twitter: Protecting
Democracies from Information Warfare*, Chapter Six,
https://doi.org/10.1515/9781503631151, RMax, shoutout to sk for the book

[LIKELY CIRCUMVENTION STRATEGIES]{.underline}

[Russian and Chinese cyber troops have exploited U.S. social media
platforms]{.underline} to pursue various foreign policy objectives. [If
Alliance member states enact statutes and regulations to
prohibit]{.underline} Chinese and Russian [agents from]{.underline}
creating or [operating accounts on regulated]{.underline} social media
[platforms, those foreign agents will undoubtedly attempt to evade that
prohibition]{.underline}. This section describes seven distinct
circumvention strategies that Chinese and Russian agents might pursue in
an effort to evade the ban.

First, [Chinese and Russian cyber troops might]{.underline} attempt to
[create fictitious user accounts]{.underline}. A fictitious user account
is a social media account created in the name of a nonexistent person
who pretends to be a citizen or national of an Alliance member state.
Russian agents made extensive use of fictitious user accounts during the
2016 presidential election campaign in the United States.1 Indeed,
[fictitious user accounts were one of the most potent
weapons]{.underline} that [Russia deployed in]{.underline} that
[information warfare operation]{.underline}. The registration system
described later in this chapter is designed to prevent Chinese and
Russian cyber troops from creating or operating fictitious user
accounts. If that system is implemented effectively by Alliance member
states, it would become practically impossible for foreign agents to
operate fictitious user accounts.

Second, [Chinese and Russian cyber troops might]{.underline} attempt to
[create impostor accounts]{.underline}. An impostor account is a social
media account operated by a Chinese or Russian agent who misappropriates
the identity of a real person without that person's knowledge or
consent. There are three main ways to establish an impostor account.
First, [Chinese agents have hacked into existing accounts]{.underline}
created by real people [and taken control]{.underline} of those accounts
("hacked accounts").2 Second, Chinese agents have purchased "stolen
accounts" that are available for sale on the black market.3 A stolen
account is a hacked account that has been sold to a third party. Third,
[cyber troops could create an impostor account from scratch]{.underline}
by obtaining the identifying information of a real person and using that
information to create a new account. The registration system described
later in this chapter, if implemented effectively, would make it much
more difficult and costly (but not impossible) for Chinese and Russian
cyber troops to create new impostor accounts from scratch. However, the
proposed registration system would not address the problem of hacked or
stolen accounts. The best way to prevent cyber troops from obtaining
hacked or stolen accounts is to educate ordinary social media users and
induce them to adopt better cyber security practices.

Third, [Chinese and Russian cyber troops might]{.underline} attempt to
[create rental accounts]{.underline}. A rental account is a specific
type of impostor account in which a foreign agent pays a bribe to a
national of an Alliance member state, so that the foreign agent can
appropriate the identity of the payee for the purpose of operating a
social media account. In fact, [U.S. citizens have accepted bribes from
Russian agents to enable]{.underline} those agents to operate [rental
accounts]{.underline}.4 Rental accounts differ from stolen and hacked
accounts in that the owner of a stolen or hacked account is an unwitting
victim, whereas the initial owner of a rental account is a willing
participant in the fraud. The proposed regulatory system would impose
criminal penalties on citizens or nationals of Alliance member states
who accept money or any other thing of value from foreign agents to
facilitate creation of rental accounts.

Fourth, [Chinese and Russian cyber troops might register as Chinese or
Russian nationals, while attempting to conceal the fact]{.underline}
that [they are state agents]{.underline}. The proposed regulatory system
creates a rebuttable presumption to address this particular
circumvention strategy. Specifically, the law would establish a
rebuttable presumption that any person who registers as a Chinese or
Russian national is presumed to be acting as a state agent, unless that
person is a legal resident of an Alliance member state. Any person who
registers as a Chinese or Russian national would have an opportunity to
rebut that presumption by presenting evidence to show that he or she is
not in fact a state agent. Chinese and Russian nationals who are not
state agents would be subject to the disclaimer requirement, but they
would not be banned from U.S. social media platforms.

Fifth, [Chinese and Russian cyber troops might]{.underline} attempt to
[create fake foreign national accounts. A fake foreign national account
is]{.underline} an account [created by a Chinese or Russian agent who
claims to be a citizen or national of some state other than China or
Russia that is not an Alliance member state]{.underline}. Under the
registration system, if a person claims to be a citizen of Venezuela,
for example, his/her declaration of citizenship would not be subject to
verification by the Venezuelan government, assuming that Venezuela is
not an Alliance member state. Accounts registered to persons who claim
to be nationals of nonmember states would be subject to disclaimer
requirements, but would not be banned. Therefore, once the registration
system is established, [Russian and Chinese cyber troops
would]{.underline} likely try to [evade the ban by creating fake foreign
national accounts that are not subject to the verification
system]{.underline} operated by governments of Alliance member states.
Social media companies and Alliance member states could develop
technical measures (discussed later in this chapter) to detect fake
foreign national accounts. However, [Chinese and Russian cyber troops
would]{.underline} likely [be able to create and operate]{.underline}
some [fake foreign national accounts because they have]{.underline} the
[technical skills to evade even very sophisticated technical
measures]{.underline}. Therefore, under the proposed regulatory system,
this strategy would likely become a viable strategy for Chinese and
Russian agents to circumvent the ban. To reiterate, though, fake foreign
national accounts would still be subject to disclaimer requirements.

Sixth, [Chinese and Russian agents might]{.underline} attempt to [create
bots or cyborg accounts]{.underline}. A "bot" is "a software tool that
performs specific actions on computers connected in a network without
the intervention of human users."5 A "cyborg account" is an account that
is either operated by a human being with assistance from a bot, or
operated by a bot with assistance from a human being. Companies use a
variety of "good bots" for legitimate business purposes. However, [cyber
troops]{.underline} can [use bots or cyborg accounts to]{.underline}
help [spread disinformation on social media to large
numbers]{.underline} of recipients. [Russian cyber troops have made
extensive use of bots to conduct information warfare]{.underline}.6 The
transnational regulatory system described later in this chapter includes
specific provisions designed to prevent Chinese and Russian cyber troops
from creating bots or cyborg accounts. It also includes special
disclaimers to warn users when they receive messages generated by bots
or cyborg accounts.

Finally, [if the]{.underline} transnational [regulatory regime applied
only to U.S.]{.underline} social media [platforms, Chinese and Russian
cyber troops could exploit]{.underline} TikTok or some [other non-U.S.
platform to engage in foreign influence operations]{.underline}. TikTok
is an app that reportedly has about 800 million monthly active users,
including about 344 million outside of China.7 TikTok's large global
user base and the Chinese government's control over the platform makes
it a potentially attractive tool for Chinese agents engaged in
information warfare. The proposed regulatory system addresses this issue
by specifying that the rules apply to all social media platforms with
more than 50 million monthly active users outside of Russia and China
(see the appendix). Under this approach, TikTok would qualify as a
regulated social media platform.

There is one other [circumvention strategy that]{.underline} the
proposed transnational [regulatory system does not address: useful
idiots]{.underline}. As discussed in the preface, the category of
["useful idiots" includes people like]{.underline} Donald
[Trump]{.underline} who--- in pursuing their own, individual political
agendas--- also happen to [advance Russian (or Chinese) foreign policy
goals]{.underline}, such as Russia's goal of undermining faith in
American democracy. Technically, exploitation of useful idiots is not
really a circumvention "strategy" because it does not require any
strategic planning by Russia or China. From the perspective of Russia,
it is simply a lucky accident that some U.S. citizens happen to advance
Russia's foreign policy goals by pursuing their own political agendas.
Thus, useful idiots who spread disinformation on social media are
properly viewed as a species of domestic OSM rather than a tactic of
information warfare. Of course, Donald Trump--- who is the most
notorious useful idiot--- arguably poses a greater threat to American
democracy than either Chinese or Russian information warfare. Even so,
the regulatory proposal presented in this chapter does not address the
threat posed by useful idiots because the proposal is designed to
counter the threat posed by information warfare, not domestic OSM. The
remainder of this chapter describes and explains the key elements of a
transnational regulatory system designed to mitigate the threat posed by
Chinese and Russian cyber troops who exploit social media to conduct a
proposal for transnational regulation 151 information warfare. Some
elements of that transnational regulatory system could be incorporated
into domestic laws and/or regulations in virtually identical terms in
all Alliance member states. Other elements would require differential
treatment in different states to accomplish the same broad objectives.

## Say No 

### 1NC\-\--Say No

#### Diverging opinions on countering Russia disinformation means NATO says no.

Jean-Baptiste **Vilmer 18**, director of the Institute for Strategic
Research of the Ministry for the Armed Forces, August 2018, "Information
Manipulation: A Challenge for Our Democracies,"
https://www.diplomatie.gouv.fr/IMG/pdf/information_manipulation_rvb_cle838736.pdf,
RMax

The [French]{.underline} position, which [holds that NATO's role in this
field should remain confined to the detection and analysis]{.underline}
of [and response to hostile operations]{.underline} targeting its
activities [(rather than all disinformation and malicious interference
operations) is widely shared within the Alliance. Fault
lines]{.underline} nevertheless [arise between allies on the question of
what sort of response is most appropriate. They]{.underline} also
[disagree over whether or not to try to "beat Russia at its own game,"
including within Russian-speaking communities, by spreading doubt about
Moscow's activities and goals or by offering a revised version of some
chapters of history. Such an approach is highly contentious within NATO,
where there are diverging views on the severity of the threat that
partly reflect different perspectives on Russia's role and the adequate
NATO response to Moscow]{.underline}.

### 2NC\-\--Say No 

#### NATO can't solve---wide disagreements, contradictions, and slow regulations

Lisa **Schirch 21**, Lisa Schirch is Senior Research Fellow for the Toda
Peace Institute and Sr. Professor of the Practice of Peace Studies at
University of Notre Dame, "Social Media Impacts on Conflict and
Democracy : The Techtonic Shift" pg. 216, April 2021 // SK

There are no quick fixes to threats stemming from social media use.
[There are wide disagreements and conceptual contradictions on how to
define disinformation, dangerous speech, privacy and
addiction]{.underline}. Most conversations about fixing social media
focus on government regulation, or changes to tech companies' platforms
and moderation. The research documented in this book suggests the
[challenges related to social media are too big and too complex for any
one actor]{.underline}. At present, tech companies do not have
sufficient incentives to change. [Government regulations are complex and
slow to develop]{.underline}. There is an urgent need for civil society
to form digital social movements to address digital threats to democracy
and social cohesion.
