## **[Aff -- Digital Cyclops 2 -- BFHR 7wk]{.underline}**

### **[2AC\-\--C/I\-\--HW v. SW]{.underline}**

#### **Only a [software]{.underline} based analysis can provide a better understanding of technology in the world**

**Frabetti 14** (Federica Frabetti PhD - MRes and PhD in Media and
Communications at Goldsmiths, University of London, "Software Theory",
Rowman and Littlefield International Ltd, Pages xv-xix, 2014, MG)

[This]{.underline} ambivalence---one could even say, this [circular
movement---between the technical and the social seems to me to
characterize the whole field of software and code studies. Individual
**academic** contributions can choose to privilege one term over the
other, but ultimately they turn to the technical in order to explain the
social, and then revert to the social in order to explain the technical.
Representative of a stronger emphasis on the technical aspects of new
technologies are studies]{.underline} such as Nick Montfort and Ian Bo-
gost's 2009 book on the Atari video computer system, entitled Racing the
Beam, which has been positioned as the inaugural text of platform
studies. Overlapping with software studies, platform studies pays
particular attention to the specific hardware and software systems on
which 'expressive computing' (another name for Manovich's 'cultural
software'---that is, software applications for video games, digital art,
and electronic literature) is based. Montfort and Bogost recommend
['delving into the code' and giving 'serious and in-depth consideration
\[to\] circuits, chips, peripherals and **how they are integrated and
used'** in order to make sense of new media.22 Also intent on the
functional unpacking of technology is the classical work of Alexander
Galloway, Protocol (2004), which offers a welcome counterargument to the
widespread discursive use of digital networks as metaphors of horizontal
connectivity and intrinsic political empowerment. By unpacking the
hierarchical workings of 'real' networks]{.underline}, which are
functionally based on layers of software that 'wrap up' the contents of
communication, Galloway also unpacks and [critiques the rhetoric of
freedom that surrounds digital networks]{.underline}. For instance, he
demonstrates how [protocols incorporate ('embed') censorship and other
mechanisms of distributed control, and how these technical
characteristics **embody a logic of governmentality** which he
ultimately associates with the **military origins of the**]{.underline}
**[Internet]{.underline}**. 'Distributed networks', Galloway states,
'are native to Deleuze's control society.' 23 In sum, for Galloway,
discovering [the control mechanisms which found the technical
functioning of networks is a way to complicate the political discourse
on networks inside and outside the academy.]{.underline} Although
Galloway's approach remains very important and politically meaningful
for the cultural study of software, it also runs the risk of positioning
the technical as the ultimate truth, as showing [what 'truly' **lies
behind any discourse** on technology (**celebratory or
otherwise**]{.underline}). In the end, this approach rests on a strategy
that draws on technical explanation as a way to reach a 'deeper'
understanding of technology---an understanding supposedly located
'behind' or 'beyond' the social.

[This 'quest for depth' in the analysis of software, which positions
software as the truth of new technologies while also intertwining
software with issues of 'power' (or 'biopower'), 'control' and
'governmentality', is also present in more socially orientated studies
of software]{.underline}, such as David Berry's 2011 book, The
Philosophy of Software. For Berry, in order to understand the way in
which one experiences software today and to develop a 'phenomenology of
software', [software studies need to '**unpack'** software, to
understand what it '**really does'**, to reach a technical grasp of
it.24 Yet, again, this process of unpacking leads to the analysis of the
practices of production, usage, and consumption that shape and are
shaped by software]{.underline}. Importantly, according to Berry, such a
deeper understanding of software---which, for instance, unmasks the
decisions made by big corporations such as Google with regard to their
software---is ultimately an emancipatory practice, because it leads
individuals to better-informed political decisions. An analogous
emancipatory aim characterizes Robert Kitchin and Martin Dodge's book,
Code/Space (2011), which investigates the way in which [**software
shapes social space** by enabling 'forms of automation, the monitoring
and controlling of systems from a distance, the reconfiguring and
rejuvenation of established industries, the development of new forms of
labor practices and paid work, the reorganization and recombination of
social and economic formations at different scales' and many other
innovations]{.underline}.25 Kitchin and Dodge develop the idea of
'automated management' in order to explore how [software enables a whole
new range of movements]{.underline} and transactions across space while
also automatically and systematically capturing and storing data on
these transactions, thus bringing about new opportunities for personal
and collective empowerment which are also new possibilities for
regulation and control.

The intertwining between digital technologies and power is also at the
core of the articulated analysis of software offered by Wendy Chun in
her recent book, Programmed Visions (2011). Chun argues that computers,
and particularly software, 'embody a certain logic of governing or
steering through the increasingly complex world around us', which she
calls 'the logic of programmability'. 26 [Programmability gives users a
sense of empowerment by ultimately incorporating them into the **logic
of a machine** that they **do not fully understand but feel somewhat in
control of.** In other words, we feel empowered by software because we
**feel in control of something** we do not have a grasp of. In fact,
Chun argues that our fascination with software resides precisely in the
fact that we do not understand it. Instead, we view it as something
hidden, obscure, difficult to pin down, and generally invisible, which
nevertheless generates visible effects in the world (for instance,
lights flickering on a screen or the functioning of telecommunication
networks]{.underline}). Rather than aiming at dispelling the
mysteriousness of software, she analyzes how [software functions as a
'**metaphor of metaphors'** in a number of discourses and fields of
knowledge precisely because of its relative]{.underline}
[obscurity]{.underline}. She writes: '\[[Software's\] combination of
what can be seen and not seen, can be known and not known---its
separation of interface from algorithm; software from hardware---makes
it a powerful metaphor for everything we believe is invisible yet
generates visible effects, from genetics to the invisible hand of the
market; from ideology to culture.' 27]{.underline} Although critical of
those approaches of software studies that view knowing software as 'a
form of enlightenment', in her own analysis Chun still combines
historical-cultural narratives (for instance, the history of programming
languages) with technical explanations (for instance, the exposition of
how digital circuits work) in order to complicate her cultural account
of technology and particularly of software.

This political commitment with the analysis of software has been taken
further by a number of studies on software which draw on neomaterialism,
media archaeology, and object-oriented philosophy.28 In their quest for
thinking software as a material entity or process which spreads into
economics, politics, and---again---the whole logic of control society as
an 'immanent' force understood in a Simondonian and Deleuzian sense,
these [studies tend to 'ontologize' software as the condition of
possibility of contemporary life, and to privilege software studies as a
master discourse capable of making visible the foundational but
otherwise invisible, hidden, embedded, off-shored, or forgotten nature
of software and code]{.underline}. And yet, one could ask: To what
extent can software and code be privileged in this respect? On what
basis can they be said to constitute the conditions for revealing the
truth of human life or society?29

So, to recap, not only is the number of existing studies of software
still relatively limited, but these studies also give an account of
software that is based on the analysis of the processes of software
production, reception, and consumption combined with the technical
exposition of how software 'really' works (either as a technical
artefact or as the all-pervasive logic of control societies). Although I
recognize that the above perspective remains absolutely relevant to the
political and cultural study of technology, I suggest that this approach
should be supplemented by an alternative, or I would even hesitantly say
more 'theoretical', and yet more 'direct', investigation of
software---although I will raise questions for both these notions of
'theory' and 'directness' later on. As I have suggested above, [in order
to understand the role that **new technologies** play in our lives and
the world as a whole we do need to shift the focus of analysis from the
practices and discourses concerning them to a thorough investigation of
**how new technologies work**, and, in particular, of how software works
and of what it does]{.underline}. And yet, in Software Theory I propose
[an investigation of software that takes historical-cultural and
technical narratives as a starting point, rather than as a final
one]{.underline}, and I suggest that these narratives [should be
problematized rather than treated as explanatory]{.underline}. Such an
investigation of software will help me to problematize the intertwining
of the technical and the social aspects of software which currently
preoccupies Software Studies. At the same time, I will refrain from
making any sweeping ontological claims about what software is and will
instead engage in a critical examination of the alleged relations
between 'software'/'code' on the one hand and 'ontology' and
'materiality' on the other hand, as conceptualized by cultural theorists
of computation such as Katherine Hayles. This is why earlier on I
suggested that the title of this book, Software Theory, hints at a
different engagement with theory from what Lev Manovich had in mind.30
Let me now explain how such an investigation of software can be
undertaken.

#### **Counter-interpretation -- reject debating the [Hardware]{.underline} called by the resolution and instead teams must debate over [Software]{.underline}**

**Hui 19** (Yuk Hui PhD - juror of the [Berggruen Prize for Philosophy
and Culture](https://www.berggruen.org/prize/) since 2020, and initiator
of the [Research Network for Philosophy and
Technology](http://philosophyandtechnology.network/?page_id=625) since
2014, teaching in various institutes including Goldsmiths College,
Leuphana University, Bauhaus University, Strelka Institute Moscow,
Chinese Academy of Art, and City University of Hong Kong, "Recursivity
and Contingency", Rowman and Littlefield International, Pages 238-241,
January 2019, MG s/o PFox)

[The destruction of all organic life points to the **only possibility
for the survival of the human**, which is the separation between body
and mind, between **hardware and software**. This metaphor of software
and hardware is technological, but it is also **not a metaphor** because
it is a **research agenda** that covers everything from dietetics,
neurophysiology, genetics]{.underline}, and tissue synthesis to particle
physics, astrophysics, [electronics, information science, and nuclear
physics. 57]{.underline} The search for the separation between thinking
and organic life is a response to the prospect of solar catastrophe,
since the central question is, [how is it possible to survive without an
organic form of life? Or]{.underline}, as Lyotard puts it: "\[[H\]ow to
provide this **software with a hardware that is independent of the
conditions of life on earth**?" 58 This is a negative organology, or an
extreme humanism. It is negative since it is based on a total negation
of the organic and on the belief that **there is a possibility**, no
matter how small it might be, of replacing the organic body with an
inorganic artifice for the survival of thinking]{.underline}. Lyotard,
through the incarnation of a female interrogator called Him, implicitly
goes back to the recursive structure of organization and [the
possibility that such a recursive algorithm could be independent from
the organic body:]{.underline}

[Most of all: \[human\]'s equipped with a symbolic system that's both
arbitrary (in semantics and syntax), letting it be less dependent on an
immediate environment, and also "**recursive**" (Hofstadter), allowing
it to take into account (above and beyond raw data) the way it has of
**processing such data**. . . . Isn't that exactly what constitutes the
basis of your transcendence in immanence? 59]{.underline}

The notion of recursivity is raised here, but Lyotard does not explore
the relation between recursivity and reflective judgment further. He did
not understand the concept of recursion, just as he had already
dismissed information theory in cybernetics for its "triviality" earlier
in his The Postmodern Condition. Here he is prepared to reject this
thesis by invoking Hubert Dreyfus, whose What Computers Cannot Do? A
Critique of Artificial Reason (1972) [challenged the **research in
artificial intelligence** (AI) of that time as being too Cartesian in
the sense that AI reduces intelligence to a very limited way
of]{.underline} [knowing]{.underline}. This could be briefly explained
with what in classical AI or "Good Old-Fashioned AI" (GOFAI) is called
the frame problem, which is about the AI's description of the world. [In
order to know an event or an environment, the AI will have to produce a
huge amount of descriptions. However, it remains very difficult to
contextualize these descriptions]{.underline}. It is Cartesian because[,
in this form of knowing, everything is merely **present-at-hand** in the
sense of Heidegger, while it ignores the fact that in the preoccupations
of everyday life Dasein encounters situations that are ready-to-hand and
have to do with embodiment and intuition. The rejection of reducing
thinking to a binary form is also a **rejection of the separation
between body and mind**]{.underline}. The philosopher, who is challenged
in this dialogue, is also a phenomenologist. He has to defend the
importance of the body and of sexuality, since without the body and
without sexuality, [**can thinking exist at all**?]{.underline} Brassier
has nicely summarized the perspectives of the two interrogators:

one for which the inseparability between thought and its material
substrate necessitates separating thought from its rootedness in organic
life in general, and the human organism in particular; another according
to which it is the irreducible separation of the sexes that renders
thought inseparable from organic embodiment, and human embodiment
specifically. 60

[If becoming system presents a negativity for Lyotard, this is because
it is based on a negative organology, which ignores the question of life
and existence. And if Lyotard here invokes this negativity, it is
because he wants to think through the question of
resistance]{.underline}, as he asks in his introduction: ["\[W\]hat else
remains as 'politics' except **resistance to this inhuman**?" This
resistance is also inhuman since the negative inhuman doesn't occupy the
totality of this concept. Like the sublime, the inhuman also has
its]{.underline} [double]{.underline}, as Lyotard emphasizes: "[The
inhumanity of the system which is currently being consolidated under the
name of development (among others) must not be confused with the
infinitely secret one of which the soul is hostage." 61]{.underline}

[The inhuman is truly posthuman in the sense that it considers the
dissolution of the human as messages, waves, particles, and
cells]{.underline}. However, the inhuman is not transhuman. [Although
the inhuman shares the negativity of the transhuman--- that is to say,
it is imprisoned by the fanaticism of development or technological
singularity---at the same time it **resists such negativity not by
rejecting a humanmachine hybridity** but by rejecting the tendency
imposed by a transhumanist ideology that is **motivated by the
anticipation of the solar catastrophe and desire of inorganic
immortality**]{.underline}. What is meant by "the infinitely secret one
of which the soul is hostage"? Ashley Woodward [identifies the double of
the inhuman by suggesting that the negative inhuman can be identified
with nihilism]{.underline}, and further that art is the second sense of
the inhuman. 62 However, I have strong reservations about this second
observation since this is too narrow and it does not seem to be what
Lyotard was referring to, though it is interesting here to consider in
art the potential of overcoming the determination of the system. [If the
soul is the hostage of the inhuman, it is because the inhuman is like
its preindividual reality as well as its call. It is like water to fish:
Even though the latter live in the former, it remains transparent to it.
This inhuman cannot be reduced to calculation and to representation. The
possible explanation of seeing an intimacy between art and the inhuman
is that art sends the system back to a primordial creativity in order to
undo the totalization of the system]{.underline}. It is clearer when we
refer to Lyotard's reading of Augustine. However, instead of discussing
his The Confession of Augustine, I will instead make a short-cut by
referring to an episode of a TV program called Apostrophes that was
broadcast on the January 9, 1981. I transcribe part of the lengthy
conversation below.

JFL: You remember that in the eleventh book that you cited, and that you
remember, those confessions, there is this formula, it is a god more
interior in myself than me, that is what I make allusion to, what Wilson
searches, it is that, isn't it? There is something in me which is more
interior in myself than me, well, [this what I call the inhuman, I have
the right, it is perfectly clear, in fact, because it is just something
with which I will never arrive at having . . .]{.underline}

[Interrogator: Vulgarly, when we employ the word inhuman, we think about
the horrible, appalling, cruel, and detestable, we don't think about
**interior being which unfolds** . . .]{.underline}

JFL: You do it on purpose!

[Interrogator: But I am not philosopher, I am journalist, **I am a bit
flat.** 63]{.underline}

Lyotard sometimes refers [to this inhuman "which is more interior in
myself than me," as la chose or the child, which carries within it the
antidote to the negative inhuman. However, these two inhumans are **not
completely separate**, since the latter is also partially a condition
for the former, without which the positive inhuman remains merely an
element of theology]{.underline}, meaning that there is only one mode of
rationalization of the Unknown through God. The logical sense of the
inhuman is exemplified in Ludwig Wittgenstein and Gödel, since both
logicians refused the subordination to positivism. Like Gödel, who shows
the incompleteness of any logical system in terms of proof, for his part
Wittgenstein "did not opt for the positivism that was being developed by
the Vienna Circle, but outlined in [his investigation of **language
games a kind of legitimation not based on performativity**." 64 The
positive inhuman is that which resists systematization and reduction to
calculation. The question is, how can we articulate the question of the
inhuman, which is not hermeneutic, and not reflexive, without returning
to theology or mysticism?]{.underline}

#### **Focusing on playing the [game]{.underline} of debate with [ZERO]{.underline} specific end point enables [psychic violence]{.underline}, eliminates [Otherness]{.underline}, and creates [disaffective]{.underline} [behaviors]{.underline}**

**Halpern 14** (Orit Halpern - associate professor in Sociology at
Concordia University in Montréal, "Cybernetic Rationality", Distinktion:
Journal of Social Theory, 4 July 2014,
<https://www.tandfonline.com/doi/abs/10.1080/1600910X.2014.923320>, MG
s/o PFox and Townes)

Affective logics

[What the cybernetic reformulation of logic as]{.underline}
'~~psychotic'~~ [permitted was an abandonment of **ontological concern**
with the past and the present in the interest of focusing on **future
interactions**. These models measured not what is happening, but prepare
us for **what will happen** as a result of finding patterns of past
data, that ironically are devoid of historical
temporalities.]{.underline} The transformation in truth claims and
epistemology opened a new frontier for study -- subjective interactions
in environments with incomplete information.

These nervous networks and logical rationalities proliferated in the
social and human sciences. Cybernetic and communicative concepts of mind
were part of a broader shift at the time in concepts of reason,
psychology, and consciousness; informing everything from finance and
options trading equations, to environmental psychology and urban
planning programs of individuals such as Kevin Lynch, and later MIT's
Architecture Machine Group and the Media Lab headed by Nicholas
Negroponte, to the political science models of Karl Deutsch at Harvard,
and the 'bounded rationality' introduced by Herbert Simon and widely
considered the foundation of contemporary finance. The post-war social
sciences were repositories of these techniques that transformed what had
once been a question of political economy, value production, and the
organization of human desire and social relations to problems of
circulation and communication by way of a new approach to modeling
intelligence and agency (Halpern 2014; Simon 1955; Crowther-Heyck 2005;
Simon 1992).

[This rationality is also sensible, perhaps **affective**; a situation
that puts in considerable revision-dominant understandings of digital
and computational mediums as distancing, disembodied, or
abstract]{.underline}. And if it is one of the dominant assumptions in
the study of modern history and governance that liberal subjectivity and
economic agency is defined as a logic guided by a reason separate from
sense, then these discourses mark a clear contrast. The historian of
science Lorraine Daston reminds us that we would do well to recall that
those things today considered virtuous and intelligent, such as speed,
logic, and definitiveness in action, were not always so. She is
explicit: [rationality in its cold war formulation, despite the
insistence of technocrats, policy-makers, and free-market advocating
economists, is not reason as understood by Enlightenment thinkers,
liberals, or even modern logicians]{.underline} (Daston 2011; see also
MacKenzie 2006; Mirowski 2002).

[If this is true, then our financial instruments, markets, governments,
organizations, and machines are **rational, affective, sensible, and
pre-emptive**, but not reasonable]{.underline}. To recognize the
significance of this thinking in our present, it might help to
contemplate Brian Massumi's definition of 'pre-emption'. [Pre-emption,
he argues, is not prevention; it is a **different way of knowing the
world**. Prevention, he claims, 'assumes an ability to assess threats
empirically and identify their causes'. Pre-emption, on the other hand,
is affective; it lacks representation, it is a constant nervous
anticipation, at a literally neural if not molecular level, for a never
fully articulated threat or future]{.underline} (Massumi 2007, 4).

[Cyberneticians, within 10 years from the war, moved from working on
anti-aircraft prediction to building systems **without clear end-points
or goals**, and embracing an epistemology without final objectives, or
perhaps]{.underline} objectivity (even if many practitioners denied
this). Nets, taken as systems, are probabilistic scenarios, with
multiple states and indefinite run times even if each separate neuron
can act definitively. In cognitive and early neuroscience the [forms of
knowledge being espoused were always framed in terms of **experiment**,
never definitive conclusions. 'Experimental
epistemologies']{.underline}, as McCulloch put it[, came to mean that
there are never final facts, only ongoing experiments.]{.underline}

These human and social scientists made operative [the unknowable space
between legibility and emergence, and turned it into a **technological
impulse** to proliferate new tools of measurement, diagrams, and
interfaces]{.underline}. At the limits of this analysis is the
possibility that [emergence itself has been automated]{.underline}. As
the theorist Luciana Parisi puts it, [cybernetics takes hold of the
space between infinity and logic, and makes it the very site of
technical intervention, the very site to proliferate algorithms
into]{.underline} life (Parisi 2013). If cybernetics initially sought to
control the future, now control itself became the unclear site of
emergence, an indefinable state that was part of networks operating in
the future without full definition or information either about
end-points or pasts. The problem of how to act under conditions of
uncertainty, or how to define a man or a machine, became instead a
pragmatic mandate and a focus on process. Instead of asking what is a
circuit, a neuron, or a market, human scientists turned to asking what
do circuits do? How do agents act? Creating an ongoing opportunity to
entangle calculation and life at the level of nervous networks, by
correlating the nervous system with the financial and political system.

Memory as a cyclical machine

[Having supposedly exorcised the ghosts of historicity, cyberneticians,
however, continued to struggle with memory and
signification]{.underline}. In a 1952 letter to the cybernetician
Norbert Wiener, Gregory Bateson spelled out the problem of memory, time,
repetition, and rationality:

[What applications of the theory of **games** do is to reinforce the
players' acceptance of the rules and competitive premises, and therefore
make it more and more difficult for the players to conceive that there
might be **other ways of meeting and dealing with each
other**]{.underline} \[ ... \] I question the wisdom of the static
theory as a basis for action in a human world. The theory may be
'static' within itself, but its use propagates changes, and I suspect
that the long-term changes so propagated are in a ~~paranoidal~~
direction and odious.5

[Discussing the]{.underline} premier private consulting group to the
[**United States** **government and military** on national security and
public policy]{.underline} -- the RAND Corporation -- Bateson [makes
explicit a new dilemma: violence. In this formulation, players no longer
create violence because of a misdirected desire resulting in a loathing
for an imagined Other, but instead are led to produce violence through a
**self-referential performance within the game**. Bateson correlates
'static' games]{.underline} with ~~paranoid~~ ~~schizophrenics~~[, as a
perceptual problem resulting in repetitive cycles culminating in
**potentially genocidal violence** (nuclear war in this case) -- in his
language a]{.underline} '~~paranoidal~~ [direction'. Authority emerging
from the pure self-reference of the data field is]{.underline}
~~psychotic~~ [and comes at the expense of futurity]{.underline}.
Bateson fears that [the performance of past data paraded as prophecy
will produce only **repetition without difference**]{.underline}. In a
stunning inversion of psychoanalytic concerns, Bateson recognizes that
[the ubiquity of computational logics makes distance impossible to
achieve, and induces violence, not as a result of any misdirected object
choices or imagined enemy Others -- game theories have no such
formulations within them -- but as the result of performing and
repeating commands without interpretation. In fact, it is precisely the
lack of imagination that defines this condition]{.underline}. Bateson
foresees [a total war without desire.]{.underline}

[Having displaced older terms of consciousness, reason, and desire from
the algorithmic rationality of the network, these terms would return in
cybernetics under the **guise of visualization, time, and memory**.
At]{.underline} the famous Sixth Macy Conference on Circular and Causal
Feedback Mechanisms in Biological and Social Systems in 1949 in New York
City, memory was increasingly problematized in terms of the relations
between its dynamic and stable elements and storage. In this instance
the immediacy and temporality of the televisual came to replace the
older conceptions of tapes, photographs, and films. McCulloch opened the
conference with a beacon and a warning. He offered the example of a new
type of tube, in development at Princeton, similar to a cathode ray
tube, that beams onto a screen on which items are stored. The
persistence of the 'memory' of the beam is temporary, and must be
refreshed. This idea of a cycling, or scanning, memory McCulloch viewed
as offering the possibility of miniaturizing and expanding machine
memory (Pias 2003, 31).

His second example was a warning from John von Neumann: even the entire
number of neurons in the brain, according to calculation, could not
account for the complexity of human behavior and ability. McCulloch
reported the finding that 'the performance of the army ant \[ ... \] is
far more complicated than can be computed by 300 yes or no devices'
(Pias 2003, 31). But this was not to say that these capacities need be
understood as illogical or analog. Rather, McCulloch turned to another
model that might retain the logical nature of the neurons, but still
account for the capacity to learn, and behave at scales beyond the
comprehension of computation.

The answer, coming through a range of discussions about protein
structure and memory within cells, involved refreshing information in
time. Wiener argued, 'this variability in time here postulated will do
in fact the sort of thing that von Neumann wants, that is, the
variability need not be fixed as? variability in space, but may actually
be a variability in time'. The psychologist John Stroud offered the
example of a 'very large macro-organism called a destroyer'. This
military ship has endless 'metabolic' changes of small chores throughout
the day, but still retains the function of a destroyer. This systemic
stability, but internal differentiation and cycling, became the ideal of
agency and action in memory (Pias 2003, 35).

McCulloch and Stroud went on to present [understandings of memory in
terms of an opposition between perfect retention of all information with
retroactive selection, and memory as a constantly active site of
**processing of information** for further action, based on internal
'reflectors' or 'internal eyes'. 'We may', Stroud stated, 'need only
very tiny little reflectors which somehow or other can become a stimulus
pattern which is available for this particular mode of operation of our
very ordinary **thinking, seeing, and hearing
machinery**]{.underline}**.** This particular pattern of reflectors is
what I see as it were with my internal eyes just as what I see when I
look at a store window, is a pattern on the retinal mosaic' (Pias 2003,
121). Mental processes are equated here with processing data, and
pattern-seeking, but it is internal 'eyes' from within the psychic
apparatus that allow a selfreflexive apparatus for deferring decisions
and agency. Mind emerges from multiple time systems operating between
the real-time present of reception and circulating data, and memory in
time, a cyclical 'refreshing' as in a television screen system, where
change, and differentiation -- between the organism and the environment,
between networks -- becomes possible through the delay and
reorganization of circuits from within the organism. The problems of
computational representation, the initial problems that were faced in
mathematically and logically representing intelligence, were reorganized
away from a language of conscious and unconscious, discrete and
infinite, reason and psychosis, to the new terms of vacillating
temporalities between immediacy and reflexivity.

Bateson, also an attendant at the aforementioned conferences and one of
the founders of family therapy and addiction treatment programs, offered
[one of the more compelling models and practices for rethinking mind in
his use of a model of the 'double bind' to explain **psychic suffering,
addiction, and other maladjusted and compulsive
behaviors**]{.underline}. In a conference in 1969, at the National
Institute of Health, he offered an example to demonstrate his ideas of
both psychology and treatment. He discussed [a research project
conducted with porpoises trained at Navy research facilities to perform
tricks and other trained acts in return for fish. One day, he recounted,
one of the porpoises was introduced to a new regimen. Her trainers
deprived her of food if she repeated the same trick. Starved if she
repeated the same act, but also if she did not perform, the porpoise was
caught in a double bind. This experiment was repeated with numerous
porpoises, usually culminating in **extreme aggression**, and a descent
into what from an anthropomorphic perspective might be labeled
**disaffection, confusion, anti-social and violent
behavior**]{.underline}. Bateson with his usual lack of reservation was
ready to label these dolphins as suffering a ~~paranoid~~ form of
~~schizophrenia~~. The anthropologist was at pains, however, to remind
his audience that these ~~psychotic~~ animals were acting rationally. In
fact, they were doing exactly what their training as animals in a navy
laboratory would lead them to do. Their problem was that they had two
conflicting signals. The poor animals, having no perspective on their
situation as laboratory experiments, were naturally breaking apart,
fissuring their personalities (and Bateson thought they had them) in
efforts to be both rebellious and compliant, but above all to act as
they had been taught. [Bateson argued this was the standard condition
for humans in contemporary societies.]{.underline}

Having established the mechanisms that led to a decentered and multiple
subject, Bateson commenced to articulate the dangers and possibilities
of this condition. He recalled how, between the fourteenth and fifteenth
time of demonstration, one of the porpoises 'appeared much excited', and
for her final performance gave an 'elaborate' display, including
multiple pieces of behavior of which four were 'entirely new -- never
before observed in this species of animal' (Bateson 2000, 278). These
were not solely genetically endowed abilities, then, but were learned,
the result of an experiment in time. [This process in which the subject,
whether a patient or a dolphin, uses the memories of other interactions
and other situations to **transform their actions** within the immediate
scenario was represented as the site of innovation. The dolphin's ego
(insofar as we decide she has one) was sufficiently weakened to develop
**new attachments to objects** in its environment through the memories
of its past and of other types of encounters]{.underline}. This re-wired
network of relations was what was held to lead to emergence through the
re-contextualization of the situation within which the confused and
conflicted animal found itself.

Bateson ended in triumph, having now successfully made the psyche
inter-subjective and simultaneously amenable to technical appropriation
via family therapy (Bateson 2000, 278). The productivity of a
~~schizoid~~ situation rested for Bateson on the discovery made by both
communication theory and physics that different times could not
communicate directly to one another. [Only temporal differences **resist
circulation from within the definition of communication** that was being
put forward here. Bateson applied this understanding liberally to
animals. In cybernetic models the ability of an entity to differentiate
itself from its environment and make autonomous choices is contingent on
its ability to engage simultaneously in dangerous spatial proximities
with other entities and its ability to achieve distance from them in
time.]{.underline}

[At stake in the negotiation over the nature of networks and the
time-scale of analysis was nothing less than **how to encounter
difference** -- whether between individuals, value in markets, or
between vast states during the cold war. A question that perhaps started
in psychoanalytic concerns over]{.underline} ~~psychosis~~ [found
technical realization in cybernetics. For cyberneticians the problem
of]{.underline} analogue or digital, otherwise understood as [the
**limits** between discrete logic and infinity, the separation between
the calculable and the incalculable, the representable and the
non-representable, and the differences between **subjects and objects**,
was transformed into a reconfiguration of memory and storage; a
transformation that continues to inform our multiplying fantasies of
real-time analytics, while massive data storage infrastructures are
erected to insure the permanence, and recyclability, of
data.]{.underline}

While the time of neural nets and communication theories is always
pre-emptive, the shadow archive haunting the speculative network is one
of an endless data repository whose [arrangement and visualization might
return imagination and agency to subjects. These wavering interactions
-- between the networked individual and the fetish of data -- preoccupy
us in the present, speaking through our contemporary concerns with data
mining, search engines, and connectivity]{.underline}. The relationship
between rationality and control drives the ongoing penetration and
application of media technologies as the result of an imperative to seek
consciousness through better visualization and collective intelligence
through the collaboration of many logical, but hardly reasonable,
agents. Architecturally [these dual desires incarnate themselves in a
**proliferation of interfaces** and a fetish for visualization and
interactivity, merged with an obsession to amass and store data in huge
systems of data centers and server farms.]{.underline} What had first
been articulated as a problem of memory and time has now become a
compulsion for analytics.

### 2AC\-\--AT: Cap K

#### **Only the [aff]{.underline} can destroy capitalism**

**Hui 19** (Yuk Hui PhD - juror of the [Berggruen Prize for Philosophy
and Culture](https://www.berggruen.org/prize/) since 2020, and initiator
of the [Research Network for Philosophy and
Technology](http://philosophyandtechnology.network/?page_id=625) since
2014, teaching in various institutes including Goldsmiths College,
Leuphana University, Bauhaus University, Strelka Institute Moscow,
Chinese Academy of Art, and City University of Hong Kong, "Recursivity
and Contingency", Rowman and Littlefield International, Pages 255-258,
January 2019, MG s/o PFox)

The technophobes see the first image of cybernetics; Simondon sees [the
second image of cybernetics and imagines a universal cybernetics or
**general allagmatic** to resolve alienation and antagonism between
nature and technics]{.underline}. Heidegger [sees both mechanism and
organism as the impasse of philosophy and therefore wants to go back to
another beginning by invoking the pre-Socratic thinkers, an attempt to
discover a new cosmotechnics, as I have claimed]{.underline}
[elsewhere]{.underline}. 96 I believe that it is necessary to read
Simondon with Heidegger here, since Simondon's [concept of genesis of
technicity resonates with Heidegger's proposal to **overcome modern
technology** by reconstructing a different **thinking** hence another
beginning]{.underline}, and in this sense Simondon's more
technologyoriented approach complements Heidegger's more
culture-oriented program. Lyotard, in spite of his fierce critique of
cybernetics, allows us to see the importance of the question of
sensibility and how it constitutes the postmodern episteme, which may be
strategically appropriated to open society to new transformations. These
two images of cybernetics have completely different social, economical,
and political implications. [The organicist epistemology, presenting a
new paradigm shift of thought in the twentieth century, is naturalized
in practice and it turns out to be nothing organicist but mechanical,
like when we use a recursive machine to write a program printing out
"**Hello, World**]{.underline}." Control through tertiary retentions and
protensions such as surveillance, social credits, and big data analysis
is taking the first path, in which recursive machines are integrating
individuals as the constituents of computation. What Deleuze calls [the
society of control is fully demonstrated in our digital epoch, of which
digital control and flexibility (e.g., modulation or performativity) are
its means. We may want to say that it is a mechanist use of organicist
machines for deterministic use, which, as we wanted to show, is
something that has to be reproached, and a broader historical and
philosophical perspective opened up, as we have attempted throughout
this book]{.underline}. However, let us raise the final question: Is it
possible to take seriously the organismic philosophy and transform it
into elements of an organology that would allow us to reevaluate actual
technological development and leave its finality open?

Organicism is still a philosophy of nature. General systems theory and
secondorder cybernetics have moved a step further, but in the
twenty-first century, [can we go even further toward **elaborating an
organological thinking**, one that goes beyond the illusion of human
beings as mere observers and machines as replacements for human beings?
In order to do so we need to inscribe the cosmos organologically, and
this is what cybernetics didn't do and this is at core of the thinking
of cosmotechnics. Cybernetics in the Western tradition has already
adopted its "modern cosmology," namely, astrophysics: **the end of the
cosmos**, as some historians have claimed. 97]{.underline} It is also in
this sense that Heidegger sees the end of philosophy and the beginning
of a world civilization based exclusively on Western thought. In Chinese
cosmotechnics, the cosmos is organic insofar as it is analogical to the
body. Chinese medicine is therefore very different from Greek medicine,
even though they share certain similarities (for example, diagnosis
according to pulses). 98 The cosmos is an organ of principle, governing
both the aesthetic and the moral. The heaven-earth that is the name for
the cosmos is correlated with the human activities, while these
relations are real and maintained by "resonance." Precisely because of
this, Needham considers neo-Confucianism to be a veritable organic
philosophy. 99 It is also the reason that Mou Zhongsan, the great New
Confucian of the twentieth century, characterizes Chinese philosophy as
a moral metaphysics and moral cosmology. 100 Standing against it is
treating the cosmos as a mere resource---the eternal goal of the
deterritorialization of capital.

With the question of the moral we also come back to the question of
episteme, which I reformulate as the question of sensibility, or, if you
wish, a reterritorialization against determinism. [The destruction of
capitalism will happen **not** because it is surpassed by its
technology, but because its cosmotechnology is **fundamentally** against
the conditions of subsistence and existence. The epistemologies of
capitalist technologies can be overcome **only** by different
cosmotechnics that provide alternative epistemologies and maintain
technodiversity and noodiversity. Or, put another way, the totalization
of capitalism through more advanced means can be challenged by
inventions and usages only according to **different ontologies and
epistemologies**. 101]{.underline} Looking back at history, the
Polynesian gift economy that inspired the work of Marcel Mauss and
Georges Bataille has been haunting capitalism ever since, and continues
in the anticapitalist thought of anthropologists like David Graeber,
though modern science has since long rejected Hau and Mana. This
sensibility of the world, of the relation between humans and the cosmos,
is different from the modern view, but being at odds with modern science
is not an excuse not to develop a cosmotechnical thinking that will
organologically inscribe science in its working principle. [For a
hundred years the absolutization of science has **led to conflict**,
while the absolutization doesn't mean that one is moving toward an end
that is called the Absolute, since the Absolute is neither a thing nor a
theory of a thing, but is precisely the unthinged (Unbedingt) of an
epoch]{.underline}. If we follow Hegel's analysis in the Vorlesungen
über die Ästhetik that the absolute spirit passed through different
stages from art in the ancient Greek time to religion and, arriving at
the Enlightenment, philosophy, perhaps cybernetics is the current
expression of the Absolute, as Günther has analyzed. 102 After Hegel's
verdict on the end of art, we continue to produce more and more
artworks. Religions have survived even though they are not compatible
with modern science. There are still many Christians, as there are many
Buddhists. What sustains religion is not purely fanaticism, but rather
faith, and [it is in faith that we find the inhuman]{.underline}, as
Lyotard found in Saint Augustine's Confessions. [Maybe after the end of
the age of reason art will come back with new gestures and as new forms
of resistance, which are beyond the linear history that Hegel has
perceived]{.underline}. However, all these remain to be thought and
explored beyond the Enlightenment humanism. If the end of European
philosophy, according to Heidegger, means [the need for new forms of
thinking to surpass the challenging mode of unconcealment in modern
technology, then these new forms of thinking must first render **modern
technology contingent before elevating it to necessity**. The
fundamental question is the regrounding of technology. We have to
emphasize that this is not to add an ethics to AI or robotics, since we
won't be able to change the technological tendency by just adding more
values. Instead we have to provide new **frameworks** for future
technological developments so that a new geopolitics can emerge that is
not based on an apocalyptic singularity but technodiversity; this is
also the reason cosmotechnics is a political concept]{.underline}.

What Needham tried to think through in his multiple volumes of work is
the relation between ancient Chinese thought and modern Western science
and technology. In other words, he wanted to render Chinese thought
contemporary: contemporary not in the sense that Chinese thought has
already anticipated and is more superior than modern Western science and
technology (in the bad spirit of nationalism and ethnocentrism), but
rather in the sense that Chinese thought may be useful for showing
another way of thinking without being simply opposed to European
thought. 103 I hold the view that the contribution of a study of Chinese
thought of technology in The Question Concerning Technology in China
(and this is by no means limited to China, but has to be open to all
cultures and civilizations) is not only the demonstration of a
philosophy of the organism, which has been done by Needham, but [rather
a reopening of the concept of technics as multiple cosmotechnics and the
future of technological imaginations. This will necessitate the
rediscovery of the **nonmodern epistemologies and the reinvention of
epistemes** through the regime of **aesthetics** as responses to the
current crisis from the point of view of]{.underline}
[localities]{.underline}, or as what Augustin Berque calls recosmosizing
\[récosmiser\]. Schiller's [aesthetic education remains important for us
today, and it is all the more significant when we recognize it as a
political and cultural project, but we can no longer respond to
Schiller's question with the same humanist approach, since future
**aesthetic education will be about inhumanity**. Aesthetics is at the
base of the episteme in the sense that it is local and constituted by
its particular way of **living and sensing,** which are very often
mistakenly considered as mere customs]{.underline}. When Whitehead
claims that time and space are relational, he is proposing at the same
time a new science and a new aesthetics.
