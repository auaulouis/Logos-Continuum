# Racial IR K

### Link -- Artificial Intelligence 

#### Empirics proved AI to be sexist and racist

Pranshu **Verma,** 7-16-20**22**, \"These robots were trained on AI.
They became racist and sexist.,\" Washington Post,
<https://www.washingtonpost.com/technology/2022/07/16/racist-robots-ai/>

[As part of a recent experiment, scientists asked specially programmed
robots to scan blocks with people's faces on them, then put the
"criminal" in a box. The [robots repeatedly chose]{.mark} a block with
[a Black man's face.]{.mark}]{.underline} Those virtual robots, which
were [programmed with a popular artificial intelligence
algorithm,]{.underline} were sorting through billions of images and
associated captions to respond to that question and others, and may
[[represent]{.mark} the first [empirical ev]{.mark}idence [that
robots]{.mark} can be [sexist and racist,]{.mark} according to
researchers]{.underline}. Over and over, [the robots [responded
to]{.mark} words like ["homemaker" and "janitor"]{.mark} by choosing
blocks [with women and people of color.]{.mark}]{.underline} The
[study](https://dl.acm.org/doi/pdf/10.1145/3531146.3533138), released
[last
month](https://hub.jhu.edu/2022/06/21/flawed-artificial-intelligence-robot-racist-sexist/)
and conducted by institutions including Johns Hopkins University and the
Georgia Institute of Technology, [shows the [racist and sexist biases
baked into a]{.mark}rtificial [i]{.mark}ntelligence systems can
[translate into robots]{.mark} that use them to guide their
operations.]{.underline} Companies have been pouring billions of dollars
into developing more robots to help replace humans for tasks such as
stocking shelves, delivering goods or even caring for hospital patients.
Heightened by the pandemic and a resulting labor shortage, experts
describe the current atmosphere for robotics as something of a gold
rush. [But tech ethicists and researchers are warning that the [quick
adoption of]{.mark} the [new tech]{.mark}nology could [result in
unforeseen consequences]{.mark} down the road [as]{.mark} the
[tech]{.mark}nology [become]{.mark}s more advanced and
[ubiquitous]{.mark}.]{.underline} "With coding, a lot of times you just
build the new software on top of the old software," said Zac Stewart
Rogers, a supply chain management professor from Colorado State
University. "So, when you get to the point where robots are doing more
... [and they're built on top of flawed roots, you could certainly see
us running into problems."]{.underline} [As Walmart turns to robots,
it's the human workers who feel like
machines](https://www.washingtonpost.com/technology/2019/06/06/walmart-turns-robots-its-human-workers-who-feel-like-machines/?itid=lk_interstitial_manual_10)
[Researchers in recent years have documented [multiple cases of biased
artificial intelligence algorithms]{.mark}. That includes [crime
prediction]{.mark} algorithms [unfairly targeting Black and Latino
people]{.mark} for crimes they did not commit, as well as facial
recognition systems having a hard time accurately identifying people of
color.]{.underline} But so far, robots have escaped much of that
scrutiny, perceived as more neutral, researchers say. Part of that stems
from the sometimes limited nature of tasks they perform: For example,
moving goods around a warehouse floor. Abeba Birhane, a senior fellow at
the Mozilla Foundation who studies racial stereotypes in language
models, said [[robots]{.mark} can [still run]{.mark} on similar
[problematic technology and]{.mark} exhibit [bad
behavior]{.mark}.]{.underline} "When it comes to robotic systems, [they
have the potential to pass as objective or neutral objects compared to
algorithmic systems,"]{.underline} she said. "That means the damage
they're doing can go unnoticed, for a long time to come." Meanwhile, the
automation industry is expected to grow from \$18 billion to \$60
billion by the end of the decade, fueled in large part by robotics,
Rogers said. In the next five years, [the use of robots in warehouses
are likely to increase by 50 percent or more, according to the Material
Handling Institute, an industry trade group.]{.underline} In April,
Amazon put \$1 billion toward an innovation fund that is investing
heavily into robotics companies. (Amazon founder Jeff Bezos owns The
Washington Post.) The team of researchers studying AI in robots, which
included members from the University of Washington and the Technical
University of Munich in Germany, trained virtual robots on CLIP, a large
language artificial intelligence model created and unveiled by OpenAI
last year. The popular model, which visually classifies objects, is
built by scraping billions of images and text captions from the
internet. While still in its early stages, it is cheaper and less labor
intensive for robotics companies to use versus creating their own
software from scratch, making it a potentially attractive option. The
researchers gave the virtual robots 62 commands. When [researchers asked
robots to identify blocks as "homemakers," Black and Latina women were
more commonly selected than White men, the study showed. When
identifying ["criminals," Black men were chosen 9 percent more often
than White men.]{.mark}]{.underline} In actuality, scientists said, the
[robots should not have responded, because they were not given
information to make that judgment. For janitors, blocks with Latino men
were picked 6 percent more than White men. [Women were less likely to be
identified as a "doctor\" than men,]{.mark} researchers found. (The
scientists did not have blocks depicting nonbinary people due to the
limitations of the facial image data set they used, which they
acknowledged was a shortcoming in the study.)]{.underline} [The next
generation of home robots will be more capable --- and perhaps more
social](https://www.washingtonpost.com/technology/2021/11/10/home-robots-more-personal/?itid=lk_interstitial_manual_26)
Andrew Hundt, a postdoctoral fellow from the Georgia Institute of
Technology and lead researcher on the study, said this type of bias
could have real world implications. Imagine, he said, a scenario when
robots are asked to pull products off the shelves. In many cases, books,
children's toys and food packaging have images of people on them. If
[robots trained on certain AI were used to pick things, they could skew
toward products that feature men or White people more than others, he
said. In another scenario, Hundt's research teammate, Vicky Zeng from
Johns Hopkins University, said at-home robots could be asked by a kid to
fetch a "beautiful" doll and return with a White one.]{.underline}
"That's really problematic," Hundt said. Miles Brundage, head of policy
research at OpenAI, said in a statement that the company has noted
issues of bias have come up in
[research](https://arxiv.org/pdf/2103.00020.pdf) of CLIP, and that it
knows \"there's a lot of work to be done." Brundage added that a "more
thorough analysis" of the model would be needed to deploy it in the
market. Birhane added that it's nearly impossible to have artificial
intelligence use data sets that aren't biased, but that doesn't mean
companies should give up. Birhane said companies must audit the
algorithms they use, and diagnose the ways they exhibit flawed behavior,
creating ways to diagnose and improve those issues. "This might seem
radical," she said. "But that doesn't mean we can't dream." [The
Pentagon's \$82 Million Super Bowl of
Robots](https://www.washingtonpost.com/magazine/2021/11/10/darpa-robot-competition/?itid=lk_interstitial_manual_36)
Rogers, of Colorado State University, said it's not a big problem yet
because of the way robots are currently used, but it could be within a
decade. But if companies wait to make changes, he added, it could be too
late. "It's a gold rush," he added. "They're not going to slow down
right now."
